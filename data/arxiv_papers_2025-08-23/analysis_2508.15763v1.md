# Intern-S1: A Scientific Multimodal Foundation Model

## 基本情報
- arXiv ID: 2508.15763v1 (https://arxiv.org/abs/2508.15763)
- 著者: Intern-S1 Team, Shanghai AI Laboratory（175名の著者による大規模な共同研究プロジェクト）
- 所属: Shanghai AI Laboratory
- 投稿日: 2025年8月28日
- カテゴリ: cs.AI, cs.LG

## 簡単に説明すると

Intern-S1は、科学分野に特化した大規模マルチモーダル基盤モデルです。28億の活性パラメータと241億の総パラメータを持つMixture-of-Experts（MoE）アーキテクチャを採用し、5兆トークン（うち2.5兆トークンは科学分野）で継続事前学習しました。テキスト、画像、分子構造、時系列データなどの多様な科学データを処理でき、分子合成計画、反応条件予測、結晶の熱力学安定性予測などの専門的な科学タスクで業界最高水準の性能を達成しています。モデルはHugging Face（https://huggingface.co/internlm/Intern-S1）で公開されており、軽量版のIntern-S1-miniも提供されています。

## 1. 研究概要

### 1.1 背景と動機

科学研究は人工汎用知能（AGI）の究極的な目標の1つとされているが、現在のオープンソース基盤モデルは一般的なタスク（数学、コード生成など）では優秀な性能を示す一方で、科学分野では大きく遅れを取っています。この問題の根本的な原因は、科学分野のデータが相対的に少なく、またそのデータの質が低いことにあります。研究者らは、人気のあるタスクでは急速に性能が向上するモデルでも、科学分野のタスクでは性能が向上しないという現象を観察しました。

このギャップを解決するためには、スケーラブルな方法でモデルの低リソースタスクに対する能力を向上させることが必要です。科学分野は多様で専門性が高いため、各分野に特化したヒューリスティクスやドメイン知識に頼ることは現実的ではありません。そこで、事前学習段階でのデータキュレーションと、後訓練段階でのより効率的な強化学習アプローチの両方から、この問題に取り組む必要があります。

### 1.2 主要な貢献

本研究の主要な貢献は以下の通りです。

- **大規模科学データの効率的キュレーション**: 2つのパイプラインを通じて2.5兆トークンの高品質科学データを収集。Webデータからの科学データの純度を2%から50%以上に向上させ、PDFドキュメントからの効率的な知識抽出を実現
- **革新的なDynamic Tokenizerの提案**: 科学的表現（分子式、タンパク質配列など）に適応的な分割戦略を適用し、自然言語と科学データで異なる埋め込み空間を使用することで、各モダリティの表現能力を最大化
- **Mixture-of-Rewards（MoR）フレームワークの開発**: 1000以上の多様なタスクからの異なる形式のフィードバックを統一的な報酬スカラーに調和させる革新的な強化学習アルゴリズム
- **マルチモーダル科学理解の実現**: 視覚的データ（気象画像、科学図表）、線形化可能な離散データ（分子構造）、ドメイン固有データ（時系列信号）を統合的に処理
- **最先端の科学性能**: 分子合成計画、反応条件予測、結晶安定性予測など、専門的な科学タスクでクローズドソースモデルを上回る性能を実現
- **効率的な学習**: 既存ベースラインと比較して10倍高速な強化学習を実現し、少ないサンプルで専門的スキルを習得

## 2. 提案手法

### 2.1 手法の概要

Intern-S1の全体的なアプローチは、科学分野に特化した大規模基盤モデルの構築において、データ、アーキテクチャ、学習アルゴリズムの3つの側面から包括的に取り組むものです。

アーキテクチャの面では、Qwen3-235B MoEモデルをベースとし、科学的モダリティを3つのカテゴリに分類して異なる戦略で処理します。視覚化可能な表現（気象画像など）にはVision Transformer（ViT）を使用し、線形化可能な離散表現（分子構造など）には新しいDynamic Tokenizerを提案し、ドメイン固有表現（時系列信号など）には専用設計のエンコーダーを使用します。

データの面では、Web データからのリコール・フィルタリングパイプラインとPDFドキュメントのページレベル解析パイプラインという2つの主要なデータキュレーション戦略を採用しています。これにより、従来のWebクロールデータでは約2%しかなかった科学データの純度を50%以上まで向上させることに成功しました。

学習の面では、4段階の訓練プロセスを採用しています。まず単一モダリティでの継続事前学習、次に画像テキストでの継続事前学習、その後オフライン強化学習、最後にオンライン強化学習を行います。特に後訓練段階では、Mixture-of-Rewards（MoR）フレームワークを提案し、多様なタスクからの異なる形式のフィードバックを効率的に統合します。

### 2.2 技術的詳細

#### Dynamic Tokenizerの革新性

従来のトークナイザーは全てのシーケンスに同じ分割戦略を適用し、異なるモダリティ間で同じトークンが同じ埋め込みを共有していました。これは科学分野において2つの重要な問題を引き起こしていました。

第一に、圧縮率の問題があります。SMILES形式の分子構造のような科学的表現は一般的なテキストコーパスには稀にしか出現しないため、汎用LLMでは効率的にエンコードできませんでした。静的トークナイザーは全ての状況で同じ分割戦略を使用するため、科学的モダリティを優先すると自然言語テキストの圧縮率が低下するトレードオフが発生していました。

第二に、共有埋め込みの問題があります。例えば文字「C」がDNA配列、分子式、選択肢問題に現れた場合、同じ埋め込みを共有することで、最も頻繁な用法に偏った表現になってしまい、科学的モダリティでの性能が制限されていました。

Dynamic Tokenizerは、入力シーケンスのタグ（例：`<SMILES>C1CCCCC1</SMILES>`）を解析し、コンテンツタイプに基づいて異なるトークン分割戦略と埋め込み空間を動的に選択します。これにより、各モダリティで最適化された表現を実現し、科学データの効率的な処理を可能にしています。

#### Mixture-of-Rewards（MoR）フレームワーク

InternBootCampという1000以上のタスクを含む大規模対話環境において、多様なフィードバック形式を統一的に処理するためのフレームワークです。

検証が困難なタスク（創作、チャット）については、PLOARアルゴリズムを採用して、現在の応答と期待される分布との距離を表す統一的な報酬スカラーを提供します。一方、検証が容易なタスクについては、検証モデル、ルール、環境フィードバックの様々な組み合わせを使用して、正確性を正確に示す報酬スカラーを生成します。

このフレキシブルで目標指向の報酬メカニズムの設計により、MoRは多様なタスクの処理において高い効率性、スケーラビリティ、適応性を実現しています。さらに、複数の強化学習アルゴリズム技術とインフラストラクチャ最適化を統合することで、大規模MoE訓練を安定化・高速化しています。

### 2.3 新規性

既存の科学特化モデルとの主要な差別化ポイントは以下の通りです。

**マルチモーダル統合の革新性**: 従来の科学モデルは単一モダリティまたは限定的なマルチモーダル対応でしたが、Intern-S1は視覚的データ、分子構造、時系列信号を統一的なアーキテクチャで処理する最初の大規模モデルです。

**Dynamic Tokenizerの技術的革新**: コンテンツタイプに応じた適応的なトークナイゼーション戦略は、科学データの効率的な表現において画期的なアプローチです。これまでのモデルは静的なトークナイゼーション戦略に依存していましたが、Intern-S1は各科学分野の特性に応じた最適な分割と埋め込み戦略を動的に選択します。

**大規模科学データキュレーションの手法**: Web データからの科学データ純度を2%から50%以上に向上させる体系的なパイプラインの開発は、科学分野における事前学習データの質向上において重要な貢献です。

**Mixture-of-Rewardsによる効率的学習**: 1000以上の多様なタスクを同時に学習する強化学習フレームワークは、従来のアプローチと比較して10倍の効率化を実現し、科学分野の専門的スキル習得における新しい標準を確立しました。

## 3. 実験結果

### 3.1 実験設定

評価にはVLMEvalKitとOpenCompassを使用し、思考モード（`enable_thinking=True`）を有効にして実験を行いました。貪欲デコーディングに伴う反復を緩和するため、サンプリングデコーディング戦略を採用し、Intern-S1では温度0.7、Intern-S1-miniでは温度0.8を設定しました。

評価ベンチマークは一般推論と科学推理の2つの領域に大別されます。一般推論では、MMLU-Pro（記憶より推論を重視し、12,000問以上の問題）、GPQA（専門家が作成した大学院レベルの生物学、物理学、化学の448問）、AIME-2025（アメリカ数学招待試験の30問）、IFEval（検証可能な制約による指示追従評価）などを使用しました。

科学推理では、数学、物理学、化学、生命科学、材料科学、地球科学の主要分野をカバーする最近のベンチマークを選定し、テキストのみとマルチモーダル設定の両方で評価を行いました。これにより、トップティアモデル間での専門的推論の公平な比較を可能にしています。

### 3.2 主要な結果

Intern-S1は、オープンソースモデル間でトップティアの一般推論能力を示すとともに、科学分野においてクローズドソースモデルをも上回る性能を達成しました。

一般推論ベンチマークでは、MMLU-Pro、GPQA、AIME2025、MMMU、MMStarにおいて、既存のオープンソースモデルと競合する性能を示しています。特にGPQAのような専門知識を要求するベンチマークでも優秀な結果を記録しており、基盤的な推論能力の高さを証明しています。

科学分野では特に顕著な成果を上げており、SmolInstruct（テキストのみ）、ChemBench（テキストのみ）、MatBench（テキストのみ）、SFE、Physicsなどのベンチマークで、オープンソースモデルを大幅に上回る性能を示しています。特に、分子合成計画、反応条件予測、結晶の熱力学的安定性予測などの専門的なタスクでは、OpenAI o3、Gemini-2.5-Pro、Grok-4などの最先端クローズドソースモデルを上回る性能を実現しました。

軽量版のIntern-S1-miniも、リソース効率を考慮しながら競合する性能を示しており、計算コストと性能のバランスを重視する用途において有用な選択肢となっています。

### 3.3 既存手法との比較

既存のオープンソース科学モデルとの比較において、Intern-S1の優位性は多方面にわたって確認されています。

マルチモーダル能力の比較では、従来のモデルが単一モダリティまたは限定的なマルチモーダル対応に留まる中、Intern-S1は多様な科学データタイプを統一的に処理する能力を示しています。分子構造の理解、科学図表の解析、時系列データの処理において、既存モデルを大幅に上回る性能を記録しています。

効率性の面では、MoRフレームワークによる強化学習が従来手法と比較して10倍の効率化を実現しており、同等の性能を少ない計算リソースで達成できることが実証されています。

専門分野での性能比較では、化学分野のChemBenchで従来のオープンソースモデルを20ポイント以上上回る性能を示し、材料科学のMatBenchでも同様に大幅な性能向上を達成しています。これらの結果は、単なるスケールアップではなく、科学分野に特化した技術革新の効果を明確に示しています。

## 4. 実用性評価

### 4.1 実装の容易性

Intern-S1の実装容易性は非常に高く評価できます。モデルはHugging Face Hub（https://huggingface.co/internlm/Intern-S1）で公開されており、標準的なTransformersライブラリを通じて容易にアクセス可能です。軽量版のIntern-S1-miniも提供されているため、計算リソースが限られた環境でも利用できます。

Dynamic Tokenizerの実装は複雑に見えるかもしれませんが、タグベースの入力形式（例：`<SMILES>C1CCCCC1</SMILES>`）により、ユーザーは既存のワークフローを大幅に変更することなくモデルを統合できます。APIインターフェースは直感的で、科学研究者が既存のデータパイプラインに組み込みやすい設計になっています。

ただし、MoEアーキテクチャによる241億パラメータという大規模性により、フル機能での運用には相当の計算資源（GPU メモリ等）が必要となることは考慮すべき点です。しかし、研究チームはこの問題に対してIntern-S1-miniという軽量版を提供することで対応しており、実用的な解決策を示しています。

### 4.2 計算効率

計算効率の面では、Intern-S1は革新的な設計により優れた性能を実現しています。MoEアーキテクチャにより28億の活性パラメータで241億パラメータの総容量を実現しており、推論時の計算コストを大幅に削減しています。これは、全パラメータを常に使用する従来の密なモデルと比較して、大幅な効率向上を意味します。

Dynamic Tokenizerによる適応的トークナイゼーションも計算効率に貢献しており、科学データの圧縮率向上により必要なトークン数を削減しています。これは特に長い分子配列や複雑な化学構造を扱う際に顕著な効果を発揮します。

MoRフレームワークによる学習効率化も特筆すべき点です。従来のベースラインと比較して10倍高速な強化学習を実現しており、モデルの継続的な改善や新しいドメインへの適応において大幅なコスト削減を可能にしています。

ただし、マルチモーダル処理における計算オーバーヘッドは無視できず、特に高解像度画像や大量の時系列データを同時処理する際には注意が必要です。しかし、InternViT-300Mの採用など効率性を考慮した設計により、実用的な範囲での運用が可能となっています。

### 4.3 応用可能性

Intern-S1の応用可能性は極めて広範囲にわたっています。化学分野では、分子合成計画、反応条件予測、新薬開発スクリーニングなどの実用的タスクで即座に活用可能です。実際に、これらの分野で最先端の性能を示していることから、既存の創薬パイプラインや化学研究ワークフローへの統合が期待されます。

材料科学においても、結晶の熱力学的安定性予測は新材料開発において中核的な技術であり、Intern-S1の高い性能は材料設計の効率化に直接貢献できます。時系列データ処理能力と組み合わせることで、材料特性の動的予測や最適化も可能になります。

生命科学分野では、タンパク質配列の理解、生物学的画像の解析、遺伝子発現データの解釈など、多様な生物学的モダリティを統合的に処理できる点が強みです。これは個別化医療や新しい治療法の開発において重要な価値を提供します。

教育分野での応用も有望です。科学概念の視覚的説明、複雑な数式の直感的理解、実験データの解釈支援など、科学教育の質向上に大きく貢献できる可能性があります。マルチモーダル能力により、テキスト、図表、データを組み合わせた包括的な学習支援が実現できます。

産業応用では、製造業での品質管理、エネルギー分野での効率最適化、環境モニタリングでのデータ解析など、科学的知識と実践的問題解決を組み合わせた用途で威力を発揮することが期待されます。

## 5. まとめと所感

### 5.1 論文の意義

本研究は、科学分野における AI の応用において画期的な進展を示す極めて重要な貢献です。従来のオープンソースモデルが一般的なタスクでは優秀な性能を示す一方で、科学分野では大きく遅れを取っていたという根本的な問題に対して、データ、アーキテクチャ、学習アルゴリズムの3つの側面から包括的なソリューションを提供しています。

特に、175名という大規模な研究チームによる共同研究としての側面も重要です。これは単一機関や小規模チームでは実現困難な規模のプロジェクトであり、科学分野AI研究におけるコラボレーションの新しいモデルを示しています。Shanghai AI Laboratoryのような大規模研究機関のリソースと組織力が、このような野心的なプロジェクトの実現を可能にしたと言えます。

技術的な観点では、Dynamic Tokenizerの提案は科学データ処理における根本的な改善を実現しており、今後の科学特化モデル開発における標準的なアプローチとなる可能性があります。また、Mixture-of-Rewards フレームワークは、多様なタスクを同時学習する効率的な方法論として、科学分野を超えた広い応用が期待されます。

オープンソースとしてのリリースも大きな意義があります。これまでクローズドソースモデルが優勢だった科学分野において、競合する性能を持つオープンソースモデルの登場は、研究の民主化と透明性の向上に大きく貢献します。特に、リソースが限られた研究機関や新興国の研究者にとって、高品質な科学AI ツールへのアクセスが可能になることは社会的にも重要です。

### 5.2 今後の展望

Intern-S1 の登場により、科学分野における AI 応用の可能性が大幅に拡張されましたが、同時にいくつかの今後の課題と展望も明確になりました。

技術的な発展の方向性としては、さらなるモダリティの統合が期待されます。現在のテキスト、画像、分子構造、時系列データに加えて、音響データ（実験装置からの音響信号）、3D構造データ（より複雑な分子や材料構造）、動的データ（化学反応の時間発展）などの統合により、より包括的な科学理解が可能になるでしょう。

データの質と量の継続的改善も重要な課題です。2.5兆トークンの科学データは大量ですが、科学分野の多様性を考慮すると、特定の専門分野ではまだ不足している可能性があります。特に新興研究分野や学際的分野でのデータ充実が求められます。

計算効率のさらなる向上も必要です。MoEアーキテクチャにより大幅な効率化を実現していますが、モバイルデバイスやエッジコンピューティング環境での動作を可能にする、より軽量なバリエーションの開発が期待されます。これにより、フィールドワークや実験現場での直接利用が可能になります。

応用分野の拡大も重要な展望です。現在実証されている化学、材料科学、生命科学に加えて、地球科学、天体物理学、社会科学などの分野への適用可能性の探求が期待されます。また、基礎研究だけでなく、産業応用での実績蓄積も重要です。

倫理的・社会的側面も考慮すべき重要な要素です。科学研究における AI の役割が拡大するにつれて、研究の透明性、結果の検証可能性、AI による発見の帰属問題などについて、科学コミュニティ全体での議論と合意形成が必要になるでしょう。

最終的には、Intern-S1のような科学特化AIモデルが、人間の科学者と協働して新しい発見や革新を生み出すパートナーとしての役割を確立することが期待されます。これは単なるツールとしての使用を超えて、科学的思考プロセス自体を支援し、拡張する新しい研究パラダイムの創出につながる可能性があります。