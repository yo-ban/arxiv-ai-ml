# Empowering Dynamic Urban Navigation with Stereo and Mid-Level Vision

## 基本情報
- **arXiv ID**: 2512.10956v1 (https://arxiv.org/abs/2512.10956)
- **著者**: Wentao Zhou, Xuweiyi Chen, Vignesh Rajagopal, Jeffrey Chen, Rohan Chandra, Zezhou Cheng
- **所属**: University of Virginia
- **投稿日**: 2025年12月14日
- **カテゴリ**: cs.CV, cs.AI

## 簡単に説明すると
この論文は、都市環境での動的ナビゲーションを改善するStereoWalkerという新しい視覚ナビゲーション基盤モデルを提案している。従来のナビゲーション基盤モデル（NFM）は単眼視覚に依存し、中レベル視覚機能（深度推定、トラッキング等）が暗黙的に出現することを仮定していたが、これは非効率的である。StereoWalkerは、ステレオ入力と明示的な中レベル視覚モジュールを統合することで、わずか1.5%の訓練データで最先端手法と同等の性能を達成し、全データを使用した場合は最先端を上回る。プロジェクトページ（https://www.cs.virginia.edu/~tsx4zn/stereowalk/）では詳細情報と実装が公開されている。

## 1. 研究概要
### 1.1 背景と動機
都市環境での具現化視覚ナビゲーション（画素から速度・加速度へのマッピング）は、ラストマイル配送などの実世界応用において直接的なend-to-endデプロイを可能にするため、人気の高い研究領域である。しかし、視覚ナビゲーションは動的かつ非構造化環境において性能が低下する問題がある。

このような環境では、密で多様な歩行者の動き、不規則な道路脇の構成、オープンワールドの様々な物体カテゴリが存在する。効果的なナビゲーションには、3Dシーン意味論、幾何学、動力学の包括的で正確な理解に加え、歩道の使用、交通信号の遵守、適切な対人距離の維持といった常識的ルールや社会的慣習への準拠が必要である。

初期の視覚ナビゲーションアプローチは検出、トラッキング、プランニングのモジュラー視覚システムに基づいていたが、ハードコーディングされたルールベースの意思決定と単純または近静的環境での評価により性能が制約されていた。強化学習とフォトリアリスティックシミュレータの組み合わせは進歩を達成したが、sim-to-realギャップの問題があった。

最近のNFMは専門家デモンストレーションから学習して視覚入力を行動に直接マッピングするが、画素対行動の教師データの不足によりスケーラビリティが制限されている。CityWalkerのような手法はインターネットから人間のナビゲーション動画を自動的にマイニングして注釈付けすることでこの制限に対処したが、動的・非構造化環境での堅牢性は依然として不十分である。

### 1.2 主要な貢献
本研究は、NFMをステレオ入力と中レベル視覚で強化するという2つの主要な洞察に基づいている。第一に、ステレオ入力は単眼知覚に固有の深度スケール曖昧性を解決する。第二に、中レベル視覚は汎化、安定性、データ効率を改善する。

- ステレオ入力と明示的中レベル視覚モジュールで構築された視覚NFM「StereoWalker」の提案：全体的なナビゲーションで最先端性能を達成
- グローバル都市圏での歩行者の新しいステレオデータセットの公開：目標指向歩行を含まないコンテンツを除去するVLMベースフィルターの開発
- 確立されたベンチマーク（CityWalker）、新しいベンチマーク（StereoWalker）、実世界環境での手法の実証

提案手法は、DINOv2（高レベルパッチ表現）、DepthAnythingV2（画素単位深度推定）、CoTracker-v3（時間的点軌跡）という3つの既製基盤視覚モデルを活用し、これらをトラッキング誘導注意、グローバル注意、ターゲットトークン注意の3段階アーキテクチャで統合する。

## 2. 提案手法
### 2.1 手法の概要
StereoWalkerは、従来のNFMが各フレームを単一のDINOv2 [CLS]トークンに圧縮するのとは対照的に、細かい空間構造を保持するために全てのパッチトークンを維持する。正確なナビゲーションには、グローバルな要約が提供できるよりも豊富な視覚知覚が必要であるという直感に基づいている。

与えられた矯正されたステレオ（または単眼）フレームの短時間ウィンドウと対応する位置に対して、モデルは外観、幾何学、短期運動手がかりを共同でエンコードする密な中レベルトークンを形成する。全フレームからのトークンは、(i) 時間対応の維持とドリフト削減のためのトラッキング誘導注意、(ii) 視点間でのシーン文脈統合のためのグローバル注意、(iii) 目標関連領域への予測集中のためのターゲットトークン注意の3段階で処理される。

### 2.2 技術的詳細
**画像トークン化：** 各フレームから相補的情報を得るため、3つの既製基盤視覚モデルを使用する。DINOv2は高レベルパッチ表現を提供し、DepthAnythingV2は画素単位深度を推定し、CoTracker-v3は時間的点軌跡を生成する。すべての事前訓練モデルはアーキテクチャ内で凍結される。

**深度集約：** 深度モジュールは単眼・ステレオ入力の両方に対応可能である。ステレオ画像ペアの場合、DepthAnythingV2を左画像に適用して深度マップを得、事前訓練されたMonSter++ステレオマッチングネットワークで左右視点間の精密視差マップを取得する。幾何学的関係 Z = f·B/d（Zは深度、fは焦点距離、Bはステレオベースライン、dは視差）を用いて視差マップを深度マップに変換し、深度エンコーダでパッチ化して深度埋め込みを生成する。

**トラッキング誘導注意：** TrackTentionにインスパイアされたこのモジュールは、フレーム間の時間対応を捉える。CoTracker-v3から得られた点トラックを用いて、(1) トラック認識サンプリング：各2D点を埋め込み、クロス注意により画像トークンから局所視覚証拠を集約、(2) 時間的伝播：連続フレームからのトラック特徴を時間軸に沿って自己注意処理、(3) 特徴更新：空間座標埋め込みをクエリとし、更新されたトラックトークンをキー・バリューとして第二のクロス注意を実行し、運動認識補正を残差接続で追加する。

**グローバル注意とターゲットトークン注意：** サブゴール航路点と最近の軌跡を軽量MLPで投射して軌跡トークンとターゲットトークンを取得。トラッキング誘導注意後、全画像トークンと軌跡トークンを統一シーケンスとして多頭自己注意層で処理（グローバル注意段階）。その後、ターゲットトークンを導入して別の自己注意層で処理（ターゲットトークン注意）。最終的に更新されたターゲットトークンをMLPと2つのヘッド（到達確率予測の到達ヘッドと次のN個航路点予測の行動ヘッド）に通す。

### 2.3 新規性
本研究の最大の新規性は、NFMにおける明示的な中レベル視覚とステレオ入力の統合にある。従来のGNM、ViNT、NoMaD、CityWalkerなどが単眼入力と暗黙的な中レベル視覚能力の出現に依存していたのに対し、StereoWalkerは構造化された幾何学的・時間的手がかりを明示的に活用する。

技術的革新として：
1. **マルチモーダル基盤モデル統合：** DINOv2、DepthAnythingV2、CoTracker-v3の凍結された組み合わせによる相補的情報抽出
2. **3段階注意機構：** トラッキング誘導→グローバル→ターゲットトークン注意による階層的情報処理
3. **ステレオ対応アーキテクチャ：** 単眼・ステレオ入力を同一アーキテクチャで処理、トークン化のみで差別化
4. **インターネットVR180動画からのデータキュレーション：** VLMベースフィルタリングによる大規模ステレオナビゲーションデータセットの構築

また、全パッチトークンの保持による細かい空間情報の維持は、従来の単一[CLS]トークン圧縮と比較して根本的に異なるアプローチである。

## 3. 実験結果
### 3.1 実験設定
実験は3つの主要な質問に答えることを目的としている：(i) 明示的中レベル視覚特徴の組み込みが強力なNFMベースラインよりロボットナビゲーションを改善するか、(ii) 高品質ステレオデータでの訓練が単眼設定と比較してナビゲーションの堅牢性と精度を向上させるか、(iii) StereoWalkerが様々な重要ナビゲーションシナリオで実世界ロボット展開に確実に転移するか。

ベースラインには、GNM、ViNT、NoMaD、CityWalkerを含む屋外ナビゲーションモデルを使用。評価指標として、最大平均方向誤差（MAOE）、到達精度、ユークリッド距離を使用。MAOEは予測運動方向と真値方向の最悪ステップ方向誤差のサンプル平均として定義され、軌跡スケールに依存しないサブゴール向けの正しい方向維持能力を捉える。

実世界評価では、Ouster LiDARとZED 2iステレオカメラを装備したClearpath Jackalロボットを使用。LiDARベースSLAMシステムでロボットポーズを推定し、真値行動ラベルとして使用。車輪オドメトリが連続相対運動推定を提供し、現在ポーズ推論と将来軌跡予測を可能にした。

### 3.2 主要な結果
**単眼ベンチマーク：** CityWalkerベンチマークでの結果では、微調整されたStereoWalkerが大多数のカテゴリで性能を改善し、MAOEを平均4-13%改善、到達率を1-19%改善した。「ターン」ケース以外の全シナリオで最高スコアを達成。深度とトラッキングを含む明示的中レベル視覚特徴の追加が大多数のカテゴリで性能を改善し、単眼ナビゲーションにおける構造化幾何学・時間手がかりの価値を強調した。

**ステレオベンチマーク：** StereoWalkerベンチマークでは、単眼バリアントでさえ実質的な改善を示し、平均L2誤差を17-73%削減、MAOEを11-48%削減、到達率を3-24%改善。ステレオ訓練により、「交差点」、「迂回」、「群衆」、「その他」で一貫した改善を達成し、全体的にL2誤差を18-73%削減、MAOEを22-54%削減、到達率を3-25%改善した。

**実世界展開：** Clearpath Jackal J100ロボットを用いた実世界設定では、前進、左折、右折の3つの運動パターンで各14試行を実施。全運動タイプでの一貫した改善により、動的条件下でより安定した航路点推定を提供し、ステレオ訓練データがさらに性能を向上させることが示された。

### 3.3 既存手法との比較
アブレーション分析では、全パッチトークンの使用が単一[CLS]トークンと比較してMAOEを3.7%改善することを確認。深度の組み込みにより4.0%の追加削減、トラッキングの組み込みにより2.8%の追加削減を達成し、各中レベル手がかりが相補的な誘導信号を提供することが実証された。

実世界評価では、微調整されたStereoWalkerが前進、左折、右折シナリオで平均23.8%の性能改善を達成。これは、明示的な深度と運動のモデリングが実世界条件での堅牢性と効果を大幅に改善することを示している。

わずか1.5%の訓練データでCityWalker（最先端手法）と同等の性能を達成し、全データ使用時は最先端を上回る性能を実現した。これは、構造化された中レベル視覚表現の驚くべきデータ効率を実証している。

## 4. 実用性評価
### 4.1 実装の容易性
実装は既製の基盤モデル（DINOv2、DepthAnythingV2、CoTracker-v3）を凍結して使用するため、比較的実装が容易である。これらのモデルはすでに広く利用可能で十分に文書化されており、統合が簡単である。アーキテクチャの3段階設計は直感的で理解しやすく、他のナビゲーションタスクへの適用も可能である。

ただし、ステレオカメラのキャリブレーションと矯正が必要であり、これには専門的知識が要求される。また、複数の基盤モデルの協調的使用により、メモリ使用量と初期セットアップの複雑さが増加する可能性がある。実世界展開では、FastAPIを通じたGPUサーバとの通信、ROS2での低レベル制御への変換など、システム統合の側面も考慮する必要がある。

### 4.2 計算効率
3つの大規模基盤モデル（DINOv2、DepthAnythingV2、CoTracker-v3）を同時に使用するため、単一モデルアプローチと比較して計算コストが高い。しかし、これらのモデルは凍結されているため、追加の訓練コストは主に注意機構とMLPレイヤーに限定される。

興味深いことに、この計算オーバーヘッドは驚くべきデータ効率で相殺される。わずか1.5%の訓練データで最先端と同等の性能を達成できるため、全体的な訓練時間とデータ収集コストは大幅に削減される。推論時は3段階注意処理が必要だが、実世界ロボット展開では許容可能な速度で動作することが実証されている。

### 4.3 応用可能性
提案手法の応用可能性は非常に高い。都市環境でのロボットナビゲーションにとどまらず、自律走行車、配送ロボット、監視システム、拡張現実アプリケーションなど、幅広い領域での活用が期待される。特に、精密な深度情報と動的追跡が重要な安全クリティカルなアプリケーションにおいて高い価値を持つ。

新しいステレオデータセットの公開により、研究コミュニティでのさらなる発展が期待される。VR180動画からの自動データキュレーションパイプラインは、他の研究者が独自のデータセットを構築する際のテンプレートとしても機能する。

また、中レベル視覚の明示的統合というアプローチは、他のロボティクスタスク（操作、空中ロボット、水中ロボットなど）への転用も可能であり、汎用的なロボット学習の新しいパラダイムを示している。

## 5. まとめと所感
### 5.1 論文の意義
この研究は、end-to-end学習の流れの中で中レベル視覚表現の重要性を再確認した点で極めて意義深い。NFMの分野では、暗黙的な能力出現への過度な依存が見られたが、本研究は明示的な構造化表現の継続的な関連性を実証している。

特に注目すべきは、わずか1.5%の訓練データで最先端と同等の性能を達成したことである。これは、適切な帰納バイアス（ステレオ視覚と中レベル特徴）を組み込むことで、大規模データへの依存を大幅に削減できることを示しており、持続可能なAI研究の観点からも重要な示唆を提供している。

実世界ロボットでの検証も評価できる点である。多くの視覚ナビゲーション研究がシミュレーション評価に留まる中、実際のClearpath Jackalでの成功実証は提案手法の実用性を強く裏付けている。また、University of Virginiaという単一機関からの研究としては非常に包括的で高品質な研究成果である。

### 5.2 今後の展望
論文の制限事項として著者らが指摘しているように、ステレオと中レベル視覚のアイデアは、より広範なロボティクスタスクにおいてまだ完全には探求されていない。移動操作ロボットや空中ロボットなど、他の具現化システムでの構造化幾何学手がかりと運動認識視覚表現の活用が今後の重要な研究方向となる。

技術的には、より大規模で多様なマルチロボットデータセットでの訓練により、さらに広い汎化性能と柔軟な能力の獲得が期待される。また、現在の3つの基盤モデルを統合する代わりに、ステレオ視覚と中レベル特徴を統一的に学習する新しい基盤モデルの開発も興味深い方向性である。

動的環境での長期ナビゲーション、予測不可能な障害物への対処、社会的に適切な行動の学習など、より複雑なシナリオへの拡張も重要な課題である。特に、人間との相互作用が頻繁な都市環境では、社会的規範を考慮したナビゲーション能力の向上が求められる。

また、計算効率の更なる改善、エッジデバイスでの実行可能性、リアルタイム処理の最適化なども実用化に向けて重要な発展方向となるだろう。この研究は、視覚ナビゲーションにおける基盤モデル設計の新しい方向性を示す重要な一歩として位置づけられる。
