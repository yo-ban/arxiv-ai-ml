# CAViAR: Critic-Augmented Video Agentic Reasoning

## 基本情報
- **arXiv ID**: 2509.07680v1 (https://arxiv.org/abs/2509.07680)
- **著者**: Sachit Menon, Ahmet Iscen, Arsha Nagrani, Tobias Weyand, Carl Vondrick, Cordelia Schmid 
- **所属**: Google DeepMind, Columbia University
- **投稿日**: 2025年09月12日
- **カテゴリ**: cs.CV, cs.AI

## 簡単に説明すると
従来の映像理解モデルは短い映像の基本的な認識は得意だが、長い映像での複雑な推論が苦手という課題がある。
本研究では、映像処理モジュールを道具として使用できるAIエージェントと、そのエージェントの推論過程を評価する
「批評者（critic）」を組み合わせた新しい映像理解フレームワーク「CAViAR」を提案している。
エージェントは固定的なプログラムを生成するのではなく、各ステップの結果を見ながら次の行動を決定する適応的な推論を行う。
批評者は複数の推論戦略を比較し、最も有望なアプローチを選択することで、システム全体の性能を大幅に改善する。
この手法により、LVBench、Neptune、ActivityNet-RTLといった難しい映像理解ベンチマークで
従来手法を大きく上回る性能を達成している。

## 1. 研究概要
### 1.1 背景と動機
近年の映像理解分野では、マルチモーダル大規模言語モデル（MLLM）の発展により短い映像クリップでの基本的な認識能力は大幅に向上している。
しかし、LVBench、Neptune、ActivityNet-RTLなどの最新ベンチマークが示すように、長い映像での複合的な推論や複雑なクエリを扱う際には性能が大きく低下するという課題がある。

従来のツール拡張推論手法（Visual Programming、ViperGPT、MoReVQAなど）は、事前に固定された手順に従って推論を実行するため、実行開始後に計画を変更することができない。
この固定性により、モジュールの出力を実際に確認することなく次のステップを決定する必要があり、
1つの誤った判断が回復不能なエラーに発展し、幻覚の伝播を招くという問題が生じています。
映像処理では潜在的な失敗ポイントが増加するため、この問題がより深刻になる。

研究者らは、システムが中間結果に応じて計画を適応させ、異なる戦略を探索できれば、
状況に応じてより適切に動作する計画を見つけることができると考えた。
これが本研究の主要な動機となっている。

### 1.2 主要な貢献
本研究の主要な貢献は以下の3点に集約される。
第一に、映像モジュールに対するエージェント推論を用いた映像理解フレームワークの提案である。
従来の固定的なプログラム生成とは異なり、エージェントが各ステップの結果を確認しながら次の行動を決定する適応的な推論システムを構築した。

第二に、小規模なフィードバックを活用して大幅な性能向上を実現する批評者（critic）の導入である。
批評者は複数の推論戦略を比較評価し、データセット固有のモジュール調整を避けながら最適な戦略を選択する機能を提供する。

第三に、時間的局在化推論（temporal localization with reasoning）や長編映像質問応答など、
複数の困難なタスクにおけるCAViARの強力な性能実証である。
最新の困難なデータセットにおいて従来手法を大幅に上回る結果を達成し、提案手法の有効性を実証した。

- プログラム生成エージェントと自然言語批評者を組み合わせた新しい映像推論フレームワークの開発
- 適応的推論による固定的なツール選択問題の解決
- 複数データセットでの最先端性能の達成と包括的なアブレーション研究による有効性の実証

## 2. 提案手法
### 2.1 手法の概要
CAViARは、プログラム生成エージェントと推論批評者の2つの主要コンポーネントから構成される。
推論エージェントは映像とクエリが与えられると、提供された映像処理モジュールとPythonインタープリターを使用して、
反復的にプログラムを生成・実行し、最終的な答えに収束する。
各ステップでエージェントはプログラムの実行結果を観察し、その情報を基に次のプログラムを決定する適応的な推論を行う。

推論批評者は、エージェントが生成した複数の推論トレース（異なる戦略による解答過程）を受け取り、
過去の成功・失敗例に基づいてそれらの成功可能性を自然言語で評価する。
批評者は最も有望な推論戦略を特定し、その戦略に対応する最終回答を選択する。
このアプローチにより、一部の戦略が失敗しても他の戦略が成功する場合に正解を得ることができる。

### 2.2 技術的詳細
推論エージェントは映像入力x、テキストクエリqに対して最初のプログラムz₁ = π(q)を生成する。
実行エンジンφがこのプログラムを実行してr₁ = φ(x,z₁)を得る。
その後エージェントは生成したプログラムとその結果の両方を参照して次のプログラムz₂ = π(q,z₁,r₁)を生成する。
この過程は解答が得られるまで継続され、推論トレースS=(z₁,r₁,z₂,r₂,...,zₙ,rₙ)を生成する。

映像モジュールAPI includes以下の要素から構成される：
- **Visual Retrieval + QA**：クエリに視覚的に関連するフレームを取得し、それらを用いて回答を生成
- **Temporal Grounding**：開始・終了タイムスタンプに基づいて映像セグメントを切り出し
- **Temporal Localization**：イベントやアクションに対応する時間範囲を特定
- **ASR Understanding**：音声の自動転写から関連情報を抽出
- **Think**：次のツール使用前の明示的な推論ステップを実行
- **Completion**：最終回答を示して推論を終了

推論批評者cは複数の推論トレースS_iを受け取り、成功・失敗例に基づいて各戦略の成功可能性を評価する。
数値スコアではなく自然言語フィードバックを生成し、最も有望な戦略を推奨する。
異なる戦略を得るため、エージェントには異なるモジュールサブセットを提供し、
各サブセットで直接回答可能なモジュールには直接適用の指針も与える。

### 2.3 新規性
既存の単一プログラム手法（Visual Programming、ViperGPT）との最大の違いは適応性にある。
従来手法は実行前に完全なプログラムを生成し、実行中の修正ができないため、
モジュールの実際の出力を見ることなく仮定に基づいて処理を進める必要があった。
CAViARはエージェントが各ステップでモジュール出力を確認し、その情報に基づいて次の行動を決定するため、
予期しない結果に対して適応的に対応できる。

既存のマルチステージ手法（MoReVQA）は固定的な3段階手順（イベント解析、グラウンディング、推論）を使用するが、
CAViARはより柔軟な推論過程を可能にする。

批評者の導入も大きな新規性である。従来研究では単一の推論パスに依存していたが、
複数戦略の比較評価により、モジュール選択やプロンプト設計の手作業調整なしに性能向上を実現している。
批評者はRLHFの研究知見を活用し、独立スコア付けよりも選択肢間の比較が容易であることを利用している。

## 3. 実験結果
### 3.1 実験設定
評価は3つの困難なデータセットで実施された。
LVBench（CC-BY-NC-SA-4.0ライセンス）は数時間に及ぶ非常に長い映像での視覚理解を評価し、
音響・音声情報は使用禁止という制約がある視覚専用の困難な評価指標である。
Neptune（CC-BY/Apache 2.0ライセンス）は音声情報を含む長編映像で、
カウンティングやイベントの時間的順序付けなど多様で複雑な質問タイプを扱う。
ActivityNet-RTL（映像はMITライセンス）は推論時間的局在化タスクで、
直接的な認識だけでなく論理的推論が必要な時間範囲特定を評価する。

ベースモデルとしてGemini Flash 1.5（32kトークン、約120フレーム対応）を使用した。
選択理由は映像処理能力、エージェント機能、コスト・速度・計算リソースの入手可能性を総合的に考慮したためである。
批評者も同一のベースモデルで実装し、単一モデルの性能向上を目指した。
各データセットに対して批評者用の文脈内例を4つ使用し、異なる戦略を得るための3つの戦略設定を採用した。

### 3.2 主要な結果
LVBenchにおいてCAViARは62.0%の精度を達成し、従来の最高性能（GLM-4V-Plus-0111の48.7%）を13%以上上回る大幅な改善を実現した。
直接推論（46.0%）と比較して16%の向上である。

Neptuneデータセットでは77.2%の精度を達成し、LLaVA-OneVisionの66.2%を11%上回った。
注目すべきは、ASR情報を手動提供した直接推論（74.9%）をも上回っており、
CAViARがASR理解モジュールを効果的に統合し、さらにそれを超える推論を実現していることを示している。

ActivityNet-RTLの推論時間的局在化タスクでは、mIOU（平均intersection-over-union）32.3を達成し、
完全教師ありの最先端手法LITA（28.6）を3.7ポイント、直接推論（23.0）を9.3ポイント上回った。

### 3.3 既存手法との比較
アブレーション研究により、批評者の重要性が明確に示された。
批評者なしでは性能が直接推論レベル近くまで低下し、特にLVBenchのような長編映像では
find_whenモジュールの信頼性低下が問題となることが判明した。
批評者は複数のモジュールサブセットで生成された戦略を比較し、より精度の高い戦略を選択する。

単一プログラム手法との比較では、CAViARの推論エージェントアプローチがほぼランダム性能（LVBench 27.1%、Neptune 28.7%）
の単一プログラム手法を大幅に上回った。
単一プログラム手法は実際のモジュール出力を確認できないため、不正確な仮定に基づく処理が多発し、
例外やガードによる破綻が頻繁に発生することが原因である。

VideoAgentで採用されている信頼度自己評価との比較では、自己評価がむしろ性能低下（39.9%）を招くことが判明した。
自己評価スコアの校正不良により、無関係な情報を繰り返し収集する問題が生じるためである。
これは大規模言語モデルが独立した状況での自己推論判断を苦手とするという既存研究の知見と一致している。

## 4. 実用性評価
### 4.1 実装の容易性
実装の容易性は高く評価できる。
CAViARは既存の大規模言語モデル（Gemini Flash 1.5）をそのまま使用し、追加の学習や微調整を必要としない。
映像処理モジュールは明確なAPIとして定義され、新しいドメインに応じて追加モジュールを容易に組み込める拡張性を持つ。
Python環境での実装であり、既存のコンピュータビジョンライブラリとの統合も直接的である。

手作業によるプログラム例や推論トレースの注釈を意図的に提供していないため、
実用的な設定での運用が可能である。従来手法で必要とされていた専門家による詳細な例示や
API記述の手作業調整を最小限に抑えている。
批評者用の文脈内例を4つと少数で済み、新しいデータセットへの適用コストが低い。

### 4.2 計算効率
計算効率の面では、同一ベースモデルでの性能向上を実現している一方、
追加の計算コストが発生することは制限事項として認識される必要がある。
複数の推論戦略（通常3戦略）を生成し、批評者による評価を行うため、
単一推論アプローチと比較して約3-4倍の推論コストが想定される。

ただし、推論時計算の増加による性能向上というトレードオフは、
多くの実用アプリケーションで許容可能と考えられる。
特に高精度が要求される映像解析タスクにおいて、計算コストの増加に見合う大幅な性能改善を提供している。
商用APIを使用しているため、計算リソースの確保や管理の複雑さは軽減されている。

### 4.3 応用可能性
応用可能性は非常に高い。
映像理解が重要な多くのドメインでの活用が期待される。
長編映像での質問応答、時間的イベントの局在化、映像内容の詳細分析など、
従来手法では困難だった複合的推論を要するタスクに効果的である。

アクセシビリティ向上（映像コンテンツの自動説明生成）、教育分野（講義映像の自動解析）、
エンターテインメント（映像コンテンツの自動要約・検索）、セキュリティ（監視映像の自動解析）
など幅広い分野での実用化が考えられる。

一方で、潜在的な負の応用として、望まない監視システムでの使用可能性も論文で言及されており、
倫理的配慮が必要である。
モジュラー設計により、特定のドメイン要件に応じたカスタマイズも容易で、
研究コミュニティでの発展的活用も期待される。

## 5. まとめと所感
### 5.1 論文の意義
本論文は映像理解における重要な技術的ブレークスルーを提示している。
従来の固定的なプログラム生成手法の根本的制約を適応的推論により解決し、
複数戦略の比較評価という革新的なアプローチを提示した点で高い学術的価値を有する。

特に注目すべきは、追加の学習なしに単一モデルの性能を大幅に向上させる手法を確立した点である。
これは計算リソースやデータが限られた環境での実用的価値が高い。
LVBenchで13%、ActivityNet-RTLで9%以上という大幅な性能向上は、
映像理解分野における実質的な進歩として評価できる。

方法論的にも、テキスト推論分野の知見（批評者の概念）を映像理解に効果的に転移した点が優れている。
RLHFの選択比較アプローチの活用や、自己評価の限界を実証的に示した点も学術的貢献となっている。

包括的なアブレーション研究により、各コンポーネントの寄与を明確に分析し、
手法の理解促進と今後の研究方向性の示唆を提供している。
実装詳細の十分な開示により再現可能性も確保されている。

### 5.2 今後の展望
いくつかの発展方向が期待される。
第一に、計算効率の更なる改善である。現在の3-4倍の推論コスト増加を、
戦略選択の効率化や早期終了機能により削減できる可能性がある。

第二に、より多様な映像モジュールの統合である。
物体追跡、シーン理解、感情認識など、専門的なモジュールを追加することで、
より複雑な推論タスクへの対応が可能になると考えられる。

第三に、他のマルチモーダルドメインへの拡張である。
音声・テキスト・画像の複合理解や、ロボティクスでの活用など、
CAViARの基本概念は広範な応用可能性を持つ。

一方で、大規模な映像データでのスケーラビリティ、リアルタイム処理の実現、
より強力な基盤モデルとの統合などの技術的課題も存在する。

倫理的観点からは、映像監視技術としての悪用防止策の検討や、
プライバシー保護機能の統合なども重要な今後の検討課題である。
全体として、映像理解の実用化に向けた重要な一歩を示す意義深い研究と評価できる。