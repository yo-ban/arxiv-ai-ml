# Parallel-R1: Towards Parallel Thinking via Reinforcement Learning

## 基本情報
- arXiv ID: 2509.07980v1 (https://arxiv.org/abs/2509.07980)
- 著者: Tong Zheng, Hongming Zhang, Wenhao Yu, Dong Yu
- 所属: Tencent AI Lab Seattle, University of Maryland, Carnegie Mellon University
- 投稿日: 2025年09月12日
- カテゴリ: cs.LG, cs.AI

## 簡単に説明すると
従来の大規模言語モデルは逐次的な推論に依存していますが、人間のように複数の推論パスを並列に探索する「並列思考」能力は限定的です。
本研究では、強化学習を用いて大規模言語モデルに並列思考能力を習得させる初のフレームワーク「Parallel-R1」を提案しています。
従来の教師あり学習アプローチとは異なり、段階的カリキュラムを採用します。
このカリキュラムは簡単な問題での教師あり学習から始まり、GSM8K、困難な数学問題へと段階的に進みます。
モデルが自然に並列思考パターンを探索・学習できます。
実験では、MATH、AMC23、AIME等の数学ベンチマークで従来手法を8.4%上回る性能を達成し、
特にAIME25では42.9%の大幅改善を実現しています。
興味深い発見として、訓練過程でモデルの戦略が探索目的の並列思考から検証目的の並列思考へと進化することも明らかにしています。
GitHubでコードとデータが公開予定です。

## 1. 研究概要
### 1.1 背景と動機
近年、大規模言語モデルの推論能力向上が注目されています。
人間の問題解決では、迷いや不確実性に直面したとき、複数の解決パスを同時に探索する「並列思考」を行います。
このアプローチは発散思考を促進し、早期の解に固執することを防ぎ、構造化された理由づけを可能にします。

しかし、現在の大規模言語モデルは主に逐次的な推論パラダイムに依存しています。
推論時のストラテジーは存在しますが、訓練を通じてこの能力を永続的に体化することは困難です。
既存の教師あり学習アプローチは、事前に生成された推論軌跡の行動クローニングであり、本質的な推論スキルよりも表面的なパターンマッチングを学習する傾向があります。

### 1.2 主要な貢献
本研究の主要な貢献は以下の3点です。

第一に、一般的な数学推論タスクで並列思考をゼロから学習する初の強化学習フレームワークを提案しました。
段階的カリキュラムと専用の報酬設計により、このフレームワークを実現しています。

第二に、学習ダイナミクスの深い分析を行い、モデルの戦略が探索から検証へと進化することを明らかにしました。
さらに、並列思考を中間訓練探索スキャフォールドとして活用する概念を実証しました。

第三に、因果モデルと構造化モデルの両方で包括的な実証を行いました。
複数のベンチマークで一貫した改善を示し、アブレーション研究から実用的な知見を提供しています。

- 一般的な数学推論タスクで並列思考を学習する初の強化学習フレームワークの開発
- モデルの戦略が探索から検証へ進化するメカニズムの解明
- 並列思考を中間訓練探索スキャフォールドとして活用する新手法の提案

## 2. 提案手法
### 2.1 手法の概要
Parallel-R1は、大規模言語モデルに並列思考能力を付与するための3段階訓練フレームワークです。

コールドスタート段階では、Parallel-GSM8Kデータセットを用いた教師あり学習で基本フォーマットを学習します。
簡単な数学段階では、GSM8Kデータを用いた強化学習で並列思考の基本パターンを安定化させます。
一般数学段階では、DAPOデータセットでの強化学習でこの能力をより困難なタスクに一般化します。

### 2.2 技術的詳細
並列思考の実装には、3つの制御タグを使用します。
`<Parallel>...</Parallel>`は探索フェーズ、`<Path>...</Path>`は推論スレッドの分離、
`<Summary>...</Summary>`は並列思考の結果統合を表します。

強化学習アルゴリズムとしてはGRPO（Group Relative Policy Optimization）を採用しています。
報酬設計では、正解率と並列思考の使用をバランスさせるための工夫がされています。

構造化モデル変種では、注意メカニズムにパスウィンドウマスキングとマルチバース位置エンコーディングを導入し、
並列パス間の情報漏洩を防いでいます。

### 2.3 新規性
既存の教師あり学習アプローチとの主要な違いは以下の通りです。

第一に、強化学習を用いた探索と一般化です。
既存手法は事前生成されたデータの模倣に依存しますが、本手法はモデルが自分で並列思考パターンを探索できます。

第二に、段階的カリキュラムでのコールドスタート問題の解決です。
簡単なタスクで高品質な並列思考データを生成し、これを基盤として強化学習で能力を拡張します。

第三に、適応的報酬スケジュールの導入です。
正解率と並列思考使用のバランスをとるため、交互的な報酬スケジュールを提案しています。

## 3. 実験結果
### 3.1 実験設定
ベースモデルとしてQwen-3-4B-Baseを使用し、最新のオープンソースモデルとして性能と効率のバランスを提供しています。

評価には4つの標準数学推論ベンチマークを使用しました。
AIME'24、AIME'25、AMC'23、MATHデータセットです。
MATHでは温度T=1.0で問題ごとに1回の応答を生成し、他の3つでは16回の独立サンプルの平均精度を報告しています。

### 3.2 主要な結果
Parallel-R1フレームワークが最も効果的であることが示され、全てのベースラインを一貫して上回りました。

最高性能の因果変種であるParallel-R1-Seenは、平均スコア48.9を達成しました。
この成功は、より簡単な手法の制約を克服するために設計されたカリキュラムに由来します。

教師あり学習は実質的な基礎的改善を提供しますが（Parallel-SFT-Unseenで31.7、ベースモデルで6.6）、
高度な推論には不十分で、標準GRPOベースラインの45.1を大幅に下回ります。

### 3.3 既存手法との比較
アブレーション研究では、2段階強化学習の役割を詳細に調査しました。
因果変種では、第1段階のGSM8Kでの強化学習を除去すると一貫した性能低下（平均-2.3%）が観察されました。

一方、構造化変種では逆の倾向が示され、第1段階強化学習を追加すると性能が大幅に悪化（平均-8.6%）しました。

報酬モデリングのアブレーション研究では、単純な精度報酬は並列思考を刺激するのに不十分であり、
直接的な並列思考報酬は全体的な性能に有害であることが明らかになりました。
本研究の交互アプローチが最適なバランスを提供することが実証されています。

## 4. 実用性評価
### 4.1 実装の容易性
実装面での実用性は高く評価できます。
VERLコードベースを採用し、公式の訓練レシピをハイパーパラメーター調整なしで使用しています。
モデル、データ、コードがオープンソースで公開予定であり、再現性と拡張性が確保されています。

### 4.2 計算効率
計算効率はトレードオフが存在します。
並列思考は複数のパスを同時に探索するため、単一パス推論と比較して計算コストが高くなります。
しかし、最終的な性能向上はこのコストを十分に上回り、特に困難なタスクでは顕著な改善を示しています。

### 4.3 応用可能性
応用可能性は非常に幅広いです。
数学推論を超えて、論理的推論、プログラミング、科学的問題解決など、複雑な推論が必要な様々な領域での活用が期待されます。

特に、並列思考を中間訓練探索スキャフォールドとして活用するアイデアは、
強化学習の探索効率を向上させる汎用的な手法として期待されます。

## 5. まとめと所感
### 5.1 論文の意義
本論文は、大規模言語モデルの推論能力向上において画期的な貢献をした重要な研究です。

第一に、並列思考を強化学習で学習させる初の成功事例であることが高く評価されます。
段階的カリキュラムと適応的報酬設計により、コールドスタート問題を解決したことは特に優れています。

第二に、モデルの学習ダイナミクスの深い分析が科学的価値を持ちます。
探索から検証への戦略進化の発見は、人工知能の推論メカニズム理解に新しい知見を提供しています。

第三に、中間訓練探索スキャフォールドの概念は、強化学習の新しいパラダイムを提示しています。
一時的な探索フェーズが最終性能の天井を押し上げるという発見は実用上重要です。

### 5.2 今後の展望
今後の研究方向として、以下の領域が期待されます。

第一に、より幅広いタスクドメインへの拡張です。
数学以外の推論タスク、特に自然言語処理、科学的推論、プログラミングなどでの有効性検証が重要です。

第二に、より大規模なモデルでの有効性検証です。
4Bパラメーターでの成功を、より大きなモデルでどのようにスケールできるかが課題です。

第三に、並列思考の動的制御メカニズムの高度化です。
現在の手法では固定的なタグを使用していますが、より適応的で汎用的な制御メカニズムの開発が期待されます。

第四に、計算効率の最適化です。
並列思考に伴う計算オーバーヘッドを削減しつつ、性能を維持する手法の開発が必要です。

全体として、人間のような柔軟で適応的な推論能力を機械学習モデルに付与するための重要な一歩を示した研究であり、
今後の人工知能研究に大きな影響を与えると考えられます。