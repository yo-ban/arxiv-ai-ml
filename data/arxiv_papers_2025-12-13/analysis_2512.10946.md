# ImplicitRDP: An End-to-End Visual-Force Diffusion Policy with Structural Slow-Fast Learning

## 基本情報
- arXiv ID: 2512.10946v1 (https://arxiv.org/abs/2512.10946)
- 著者: Wendi Chen・Han Xue・Yi Wang・Fangyuan Zhou・Jun Lv・Yang Jin・Shirun Tang・Chuan Wen・Cewu Lu
- 所属: Shanghai Jiao Tong University, Shanghai Innovation Institute, Noematrix Ltd.
- 投稿日: 2025年12月13日
- カテゴリ: cs.RO (Robotics)

## 簡単に説明すると
この論文は、ロボットの接触豊富な操作タスクにおいて視覚と力センシングを統合するImplicitRDPという新しいフレームワークを提案しています。従来の階層的手法と異なり、低周波の視覚情報と高周波の力情報をエンドツーエンドで処理し、拡散政策内で閉ループ制御を実現します。プロジェクトページ（https://implicit-rdp.github.io）でコードと動画が公開予定です。

## 1. 研究概要
### 1.1 背景と動機
人間レベルの接触豊富な操作は、視覚と力センシングという2つの重要なモダリティの異なる役割に依存しています。視覚は空間的に豊富だが時間的に低速な大域的コンテキストを提供し、力センシングは急速で高周波な局所接触ダイナミクスを捉えます。

これらの信号を統合する際の根本的な課題は、周波数と情報の本質的な格差です。視覚は環境の「大域的文脈」を1-2Hzで提供する一方、力は接触の「局所的現実」を10Hz以上の高周波で反映します。

従来のReactive Diffusion Policy（RDP）のような階層的アプローチには問題があります。スロー政策が視覚を処理して潜在アクションを生成し、ファスト政策が力を処理して実際のアクションを予測します。しかし、これには情報ボトルネック、モーダル競合、固定的ハンドオーバーという課題が存在します。

### 1.2 主要な貢献
この研究の主要な貢献は以下の通りです：
- ImplicitRDPという、構造的スローファスト学習によりスローとファスト観測を同時処理し閉ループ力制御を実現するエンドツーエンド視覚力政策の提案
- 政策が異なるモダリティの重みを適応的に調整することを促す仮想ターゲット予測に基づく補助タスクの導入。これは力を直交アクション空間にマッピングし、力の大きさに応じて適切に損失重み付けを行い、従来の力予測より効果的な指導を提供
- 2つの代表的な接触豊富タスクでの広範囲な実験により、ImplicitRDPがベースライン手法より高い性能を達成し、より合理化された統一訓練フレームワークも提供することを実証

## 2. 提案手法
### 2.1 手法の概要
ImplicitRDPは視覚計画と反応的力制御を統一したエンドツーエンドフレームワークです。階層的な分離を強制するのではなく、マルチモーダル制御をシーケンスモデリング問題として扱います。

主要な構成要素は以下の2つです：
1. Structural Slow-Fast Learning（SSL）：時間的因果構造を活用してアクションチャンク内でエンドツーエンド閉ループ制御を実現
2. Virtual-target-based Representation Regularization（VRR）：モダリティ崩壊を防ぎ、適応的重み付けを促進

### 2.2 技術的詳細

#### Structural Slow-Fast Learning
従来のRDPの2段階スローファストアーキテクチャと異なり、時間的因果構造と一貫推論メカニズムにより変動周波数観測でのエンドツーエンドアクションモデリングを実現します。

**時間的因果構造**：
- 観測を「スロー」部分（視覚観測と固有受容）と「ファスト」部分（力信号）に分離
- GRUによる力エンコーディングで因果制約を保持
- 力トークンに因果注意マスクを適用し、未来情報の漏洩を防止

**一貫推論メカニズム**：
- DDIMサンプラー（η=0）を使用して決定論的な除ノイズ軌道を実現
- スロー観測エンコーディングとノイズサンプリングを各チャンクの開始時に1回実行
- 結果をキャッシュし、チャンク全体で再利用

#### Virtual-target-based Representation Regularization
compliance制御理論に基づく「仮想ターゲット」概念を導入：

```
x_vt = x_real + K^(-1) * f_ext
```

適応剛性割り当てにより、力の方向に垂直な方向には高い剛性k_highを、力方向には力の大きさに応じて変化する適応剛性k_adpを割り当てます。

### 2.3 新規性
1. **統一表現空間**：視覚と力を同一座標系で処理
2. **エンドツーエンド最適化**：階層的分離による情報ボトルネックの排除
3. **適応重み付け**：力の大きさに基づく動的重要度調整
4. **velocity-prediction parameterization**：学習安定性の向上

## 3. 実験結果
### 3.1 実験設定
**ハードウェア構成**：
- Flexiv Rizon 4s ロボットアーム
- 関節トルクセンサーと6軸F/Tセンサー
- 手首カメラとして使用のウェブカメラ
- カスタム準拠フィンガーチップ

**実験タスク**：
1. **Box Flipping**：薄い電話ボックスを固定具に押し付けて立てる（力制限14N未満）
2. **Switch Toggling**：回路ブレーカースイッチの切り替え

各タスクで40回のデモンストレーションを10Hzで収集。

### 3.2 主要な結果
成功率の比較（20回実行中の成功数）：

| 手法 | Box Flipping | Switch Toggling |
|------|-------------|-----------------|
| DP (視覚のみ) | 0/20 | 8/20 |
| RDP (階層的) | 16/20 | 10/20 |
| **ImplicitRDP** | **18/20** | **18/20** |

**アブレーション研究の結果**：
- SSL除去により性能が大幅低下（特にBox Flippingで顕著）
- VRRが他の補助タスクより効果的
- velocity-predictionとオイラー角が最高の安定性を達成

### 3.3 既存手法との比較
**失敗ケース分析**：
- **DP**：適切な力判定ができず、過度な力適用により破損発生
- **RDP**：潜在圧縮エラーにより精密な接触位置を見逃し
- **ImplicitRDP**：力フィードバックに基づく適応制御で両タスクを安全に完了

注意重み可視化により、補助タスクなしではモダリティ間の重要関係学習に失敗することが確認されました。

## 4. 実用性評価
### 4.1 実装の容易性
プロジェクトページでコードが公開予定であり、標準的なTransformerベースのアーキテクチャを使用しているため実装は比較的容易です。ただし、カスタムハードウェア（準拠フィンガーチップ）と低レベル制御器の調整が必要です。

### 4.2 計算効率
高周波制御（10Hz）を実現しながら、キャッシュメカニズムにより効率的な推論を実現しています。DDIMサンプラーの決定論的性質を活用し、計算コストを削減しています。

### 4.3 応用可能性
接触豊富な操作タスク全般に適用可能です：
- 製造業における組み立て・検査作業
- サービスロボティクスでの安全な物品取り扱い
- 医療ロボティクスでの触覚フィードバック統合

## 5. まとめと所感
### 5.1 論文の意義
この研究は、ロボット操作におけるマルチモーダル学習の新しいパラダイムを提案しています。階層的分離を排除したエンドツーエンド学習により、情報ボトルネックの問題を解決し、90%の高い成功率を達成しました。特に、仮想ターゲットという新しい概念により、力と視覚の統合に革新的なアプローチを提供している点が評価できます。

### 5.2 今後の展望
論文では、Vision-Language-Action（VLA）モデルへの拡張と触覚センシングなど他の高周波モダリティの統合が今後の研究方向として示されています。より多様なタスクでの検証と、産業環境での大規模展開が期待されます。この統一フレームワークは、実用的なロボットシステムへの重要な貢献となると考えられます。