# Mitigating Object Hallucinations via Sentence-Level Early Intervention

## 基本情報
- arXiv ID: 2507.12455v1 (https://arxiv.org/abs/2507.12455)
- 著者: Shangpin Peng, Senqiao Yang, Li Jiang, Zhuotao Tian
- 所属: Harbin Institute of Technology (Shenzhen), The Chinese University of Hong Kong, The Chinese University of Hong Kong (Shenzhen)
- 投稿日: 2025年07月17日
- カテゴリ: cs.CL, cs.AI

## 簡単に説明すると
この論文は、マルチモーダル大規模言語モデル（MLLMs）における「幻覚」問題を解決する新しい手法「SENTINEL」を提案しています。幻覚とは、視覚的入力と矛盾する誤った内容を生成する問題です。従来の手法は、計算コストの高さや訓練データとモデル出力の分布不一致という問題を抱えています。SENTINELは文レベルでの早期介入により、幻覚の発生を初期段階で抑制します。

特に重要な発見として、幻覚は主にテキスト生成の初期段階で発生し、その後の出力に伝播することが明らかになりました。SENTINELは人間のアノテーションに依存せず、2つのオープンボキャブラリー検出器を使用してオブジェクトの存在を検証します。これらの検出器はGroundingDINOとYolo Worldです。文脈を考慮した preference learning（C-DPO）により訓練します。実験結果では、元のモデルと比較して90%以上の幻覚削減を達成しました。GitHubリポジトリ（https://github.com/pspdada/SENTINEL）も公開されています。

## 1. 研究概要
### 1.1 背景と動機
マルチモーダル大規模言語モデル（MLLMs）は、視覚と言語の表現を統合することで大きな進歩を遂げ、汎用AIシステムの開発に向けた重要な一歩となっています。しかし、マルチモーダル設定において重要な課題が残っています。それは「幻覚」現象です。モデルがユーザーの画像内容と矛盾する情報や架空の情報を生成してしまう問題を指します。

この問題は、ユーザーの信頼性と体験を損なうだけでなく、MLLMsの実世界での応用において重大なリスクをもたらし、信頼できる汎用AIシステムの実現を妨げています。医療画像分析、自動運転、身体化タスク計画などの分野での応用を考えると、この問題の解決は急務です。

論文では、幻覚の強度が生成されたテキストの長さとともに増大することを発見しました。特定の文で幻覚を軽減することで、後続の出力での幻覚の発生を92%減少させることができました。これらの発見は、幻覚が最初に発生した時点での早期介入が、後の生成での伝播を防ぐために重要であることを示唆しています。

### 1.2 主要な貢献
この論文の主要な貢献は以下の3点にまとめられます。

第一に、MLLMsのモデル出力において、幻覚の最初の発生時点での早期介入が、その後の伝播を防ぐために重要であることを実証しました。これは、幻覚対策における新しい視点を提供しています。

第二に、広範な外部リソースや手動作業を必要とせずに、効果的かつ効率的に幻覚を軽減するSENTINELを提案しました。これにより、実用的で拡張可能な解決策を提供しています。

第三に、モデルに依存しないSENTINELが、MLLMsの一般的な能力を損なうことなく、幻覚ベンチマークでベースラインを上回る性能を達成したことを示しました。

- 幻覚の早期介入の重要性の実証
- 効率的で実用的な幻覚軽減フレームワークの提案
- 汎用性を保ちながら幻覚を90%以上削減する手法の実現

## 2. 提案手法
### 2.1 手法の概要
SENTINELは、手動作業や大規模LLMsへの依存なしに、ドメイン内データでのpreference learningを通じて、文レベルでの早期介入でオブジェクト幻覚を軽減します。既存のpreference learning手法は、外部モデルを使用して文を書き換えたり、モデル生成の応答を訓練データとして使用することがあります。これらの手法は訓練データとモデルの元の出力との間で分布や表現パターンの不一致を引き起こす可能性があります。

SENTINELは6つの重要なステップから構成されています。
1. ドメイン内候補の生成：事実的なオブジェクトと幻覚的なオブジェクトを含む候補を生成
2. Preference データペアの構築：ドメイン内候補からデータペアを作成
3. Preference learningの実施：厳選されたデータを活用して学習

### 2.2 技術的詳細
SENTINELの技術的な詳細は、3つの主要なコンポーネントから構成されています。

**In-domain Candidate Bootstrapping**では、現在のモデルから複数回サンプリングを行い、出力からオブジェクトを抽出します。その後、一貫性のあるクロスチェック手法を適用して、モデルの出力オブジェクトを「幻覚的」「不確実」「事実的」の3つのカテゴリに分類します。サンプリングベースのデコーディングを使用してn個の候補サンプルを取得し、文の完了時点（ピリオドの検出など）で生成を停止します。

オブジェクト抽出にはSceneGraphParserモデルを使用し、テキスト記述を一連のトリプレットベースのシーングラフに変換します。オブジェクトの存在検証には、GroundingDINOとYolo Worldという2つのオープンボキャブラリーオブジェクト検出器を使用してクロス検証を行います。

**Context-aware Preference Data Generation**では、文脈に関連するデータを抽出し、訓練データがモデルの出力分布をより良く表現することを保証します。正のサンプルは「文脈一貫性のある正のサンプル」と「文脈に依存しない正のサンプル」の2つのカテゴリに分割されます。また、Iterative Contextual Bootstrapping (ICB) 戦略を導入し、多様な文脈での堅牢性を向上させます。

**Context-aware Preference Learning**では、修正されたcontext-aware DPO (C-DPO) 損失を使用します。この損失関数は、入力と文脈に条件付けられたモデルが次の2つを達成するよう設計されています。
- 文脈的に一貫性のある正のサンプルを生成する可能性を最大化
- 負のサンプルを生成する可能性を最小化

### 2.3 新規性
SENTINELの新規性は、以下の点にあります。

第一に、幻覚が主にテキスト生成の初期段階で発生し、その後の出力に伝播するという重要な洞察に基づいて、文レベルでの早期介入アプローチを採用している点です。これは従来の手法とは異なる新しい視点です。

第二に、外部の大規模言語モデルによる書き換えに依存せず、モデルの元の出力の範囲内に学習ターゲットを厳密に保つことで、モデルの固有の分布と表現パターンを保持しながら、効果的に幻覚の伝播を抑制している点です。

第三に、人間のアノテーションや高価な外部リソースに依存せず、オープンボキャブラリー検出器を使用した自動的な幻覚検出と、文脈を考慮したpreference learningを組み合わせることで、実用的で拡張可能なソリューションを提供している点です。

## 3. 実験結果
### 3.1 実験設定
実験では、先行研究との公正な比較を確保するため、LLaVA-v1.5を参照モデルとして使用しました。データ収集では、詳細な画像記述でモデルにプロンプトを与えて訓練データを生成し、画像はVisual Genomeデータセットから取得しました。

モデルの訓練は、C-DPO損失関数とLoRAを組み合わせて行い、AdamWで最適化しました。7Bモデルは8.6Kサンプル、13Bモデルは7.0Kサンプルで1エポック訓練し、学習率はそれぞれ2×10^-7と3×10^-7を使用しました。

評価には、幻覚評価用のObject HalBench、AMBER、HallusionBenchを使用しました。一般能力の評価にはVQAv2、TextVQA、ScienceQA、MM-Vetを使用しました。

### 3.2 主要な結果
SENTINELは複数のベンチマークでベースライン手法を上回る性能を示しました。

Object HalBenchにおいて、7BモデルでSENTINELは応答レベルで4.3、言及レベルで2.6の幻覚率を達成しました。
従来の先端手法TPO（応答レベル5.6、言及レベル3.2）と比較して、合計24%の幻覚削減を実現しています。13BモデルでもCHAIRスコア2.7、幻覚スコア11.7、認知スコア0.9を達成しました。
ベースライン（CHAIR 6.9、幻覚スコア31.9、認知スコア4.0）から61〜78%の改善を示しました。

AMBERベンチマークの判別部分では、SENTINELは6つすべての幻覚タイプでベースラインを上回りました。特に「存在」幻覚タイプでは、7Bモデルで6.3、13Bモデルで7.6の改善を達成しました。

### 3.3 既存手法との比較
SENTINELは、デコーディング戦略に焦点を当てたVCD、OPERA、DoLaや、preference trainingを活用するHA-DPO、POVID、CLIP-DPO、RLAIF-V、TPOなどの先端手法と比較されました。

一般的な能力の面でも、SENTINELはモデルの性能を向上させました。VQAv2とTextVQAで安定した性能を示しました。幻覚軽減のために設計された以前の手法が10〜20%の性能低下を示したのとは対照的でした。さらに、ScienceQAでは2.3%、MM-Vetでは3.5%の性能向上を達成しました。

データスタイルの一貫性の効果を分析するため、GPT-4を使用して書き換えたデータでモデルを訓練して比較しました。結果は、書き換えが幻覚削減と一般能力の両方で性能低下を示し、ドメイン内データを保持するアプローチの利点を強調しています。

## 4. 実用性評価
### 4.1 実装の容易性
SENTINELの実装は比較的シンプルで、既存のMLLMsアーキテクチャに容易に統合できます。主要なコンポーネントは、オープンソースのオブジェクト検出器（GroundingDINOとYolo World）とSceneGraphParserのみで構成されており、特別なハードウェアや高価な外部APIへのアクセスは必要ありません。

訓練プロセスもLoRAを使用した効率的なファインチューニングにより、限られた計算リソースでも実行可能です。また、推論時の追加計算コストがないため、実運用環境での展開が容易です。

### 4.2 計算効率
SENTINELの最大の利点の1つは、推論時の追加計算オーバーヘッドがないことです。従来のデコーディング戦略ベースの手法とは異なり、SENTINELは訓練段階でのみ追加の処理を行い、推論時は通常のMLLMsと同じ速度で動作します。

訓練データの生成プロセスは、オブジェクト検出器の効率性により、比較的高速に実行できます。7Bモデルで8.6K、13Bモデルで7.0Kのサンプルで効果的な改善が得られることから、データ効率も高いことが示されています。

### 4.3 応用可能性
SENTINELはモデルに依存しない手法であるため、様々なMLLMsアーキテクチャに適用可能です。医療画像分析、自動運転、ロボティクスなど、高い信頼性が要求される分野での応用が期待されます。

また、人間のアノテーションや外部の大規模モデルに依存しないため、リソースが限られた環境でも適用可能です。さらに、ドメイン内データを使用することで、特定のドメインや言語に特化したモデルの改善にも効果的に適用できる可能性があります。

## 5. まとめと所感
### 5.1 論文の意義
この論文は、MLLMsにおける幻覚問題に対する新しいアプローチを提示しています。幻覚が生成の初期段階で発生し、後続の出力に伝播するという重要な洞察に基づいて、文レベルでの早期介入という革新的な解決策を提案しました。

SENTINELは、計算効率性と性能の両立を実現し、90%以上の幻覚削減を達成しながら、モデルの一般的な能力を維持または向上させることに成功しました。これは、実用的なMLLMsの開発において重要な進歩であり、信頼できるAIシステムの構築に向けた大きな一歩となります。

### 5.2 今後の展望
論文では、現在のSENTINELが時空間情報を取り込む能力を欠いているため、ビデオMLLMsにおける長期的な推論を必要とする幻覚問題に効果的に対処できない可能性があるという制限が述べられています。

今後の研究方向として、ビデオや他のマルチモーダルデータへの拡張、より高度な文脈理解メカニズムの導入、リアルタイムアプリケーションへの最適化などが考えられます。また、他の種類の幻覚（属性幻覚、関係幻覚など）への適用や、多言語環境での有効性の検証も重要な課題です。