# Language Models Improve When Pretraining Data Matches Target Tasks

## 基本情報
- arXiv ID: 2507.12466v1 (https://arxiv.org/abs/2507.12466)
- 著者: David Mizrahi, Anders Boesen Lindbo Larsen, Jesse Allardice, Suzie Petryk, Yuri Gorokhov, Jeffrey Li, Alex Fang, Josh Gardner, Tom Gunter, Afshin Dehghan
- 所属: Apple, University of Washington, Stanford, Anthropic
- 投稿日: 2025年07月17日
- カテゴリ: cs.LG, cs.CL

## 簡単に説明すると
この論文は、大規模言語モデル（LLM）の事前学習データを評価タスクに明示的に合わせる新手法を提案しています。この手法は「BETR（Benchmark-Targeted Ranking）」と呼ばれます。従来の「高品質」データという曖昧な基準に頼るのではなく、評価したいベンチマークのデータと類似した文書を選択します。この手法により、モデルの性能を1.8〜2.8倍の計算効率で向上させることができます。

BETRは3つのステップで動作します。
1. ベンチマークの例と事前学習データの一部を共通の埋め込み空間に射影
2. 類似度に基づいてスコアリング
3. 軽量な分類器を訓練して全コーパスのスコアを予測

この手法により、特定のタスクに特化したモデルや汎用的なモデルを作成できます。

## 1. 研究概要
### 1.1 背景と動機
大規模言語モデルの性能はその事前学習データに大きく依存しており、近年のLLMの進歩においてデータの改善は重要な役割を果たしてきました。しかし、現在のデータ選択手法は「品質」という曖昧な概念に依存しており、研究者の直感や反復的な実験に頼っているのが現状です。

論文では、「品質」は本質的にタスク依存的であると指摘しています。数学の証明、詩、ニュース記事といった異なる種類の文書を、特定の目的なしに比較することは意味がありません。実際のところ、データ選択手法の開発では暗黙的に標準ベンチマークでの性能を最適化しているため、この暗黙的な最適化を明示的に行うことで何が起こるかを探求することが本研究の動機となっています。

### 1.2 主要な貢献
この論文の主要な貢献は、以下の点にまとめられます。

まず、ベンチマークとの類似性に基づいて事前学習データを直接ランク付けする新しい手法BETRを提案しました。500以上のモデルを訓練して10^19から10^22 FLOPsにわたるスケーリング則を分析した結果、BETRは既存のベースラインと比較して1.8〜2.8倍の計算効率向上を達成しました。さらに、10のタスクのうち9つで性能向上を示しました。

- 明示的なベンチマークターゲティングによる一貫した性能向上の実証
- 個別ベンチマークターゲティングによる精密な能力制御の実現
- 多様なベンチマークをターゲットにすることで汎用的な能力を獲得できることの発見
- モデルスケールに応じて最適なフィルタリング戦略が変化することの発見（小規模モデルではアグレッシブなフィルタリング、大規模モデルではより多様なデータが有効）

## 2. 提案手法
### 2.1 手法の概要
BETRは文書ランキング問題としてデータ選択を定式化します。大規模な事前学習文書プール D = {d1, ..., dN} が与えられます。また、ターゲットを表すベンチマーク訓練例の小さなセット B = {b1, ..., bM} も与えられます。目標は、各文書のベンチマーク性能への寄与を測定するスコアリング関数 s: D → [0,1] を学習することです。

手法は以下の3つのステップで構成されています。
1. ベンチマーク例と事前学習文書のサンプルを共通空間に埋め込む
2. ベンチマーク例への近接性に基づいてサンプルされた文書をスコアリングする
3. これらのスコア付き文書で分類器を訓練し、全データプールのスコアを効率的に予測する

### 2.2 技術的詳細
埋め込みフェーズでは、計算効率のために事前学習文書から1000万文書（全体の0.1%未満）をサンプリングします。ベンチマークターゲットの粒度については、各ベンチマーク例を個別に埋め込むアプローチが最も良い性能を示しました。埋め込みモデルとしては、Arctic-Embed L 2.0などのBERTライクなトランスフォーマーエンコーダを使用しています。

スコアリング関数は類似度ランクに基づいて定義されます。各ベンチマーク例が全文書を類似度でランク付けし、各文書djはベンチマーク例iに対する相対的なランクrijを持ちます。これらのランクに値関数v(r)を適用し、平均または最大値で集約します。実験では、最大値集約（各文書を全ベンチマーク例中での最良ランクでスコアリング）が最も効果的でした。

全データプールへのスケーリングでは、FastText分類器を使用して文書がランク上位10%に入るかどうかを予測します。この軽量なアプローチにより、数十億の文書に対しても効率的にスコアリングが可能になります。

### 2.3 新規性
BETRの新規性は、データ選択における「品質」の概念を具体的なベンチマークターゲットで置き換えた点にあります。従来手法が研究者の直感や暗黙的な基準で依存していたのに対し、BETRは評価したいタスクと事前学習データを直接結びつけます。

また、ターゲティング戦略として「評価認識型（Evaluation-aware）」と「評価盲検型（Evaluation-blind）」の2つのアプローチを提案している点も特徴的です。前者は特定のタスクを最適化したい場合に対応するベンチマークを直接ターゲットとし、後者は汎用的な能力を求める場合に評価スイートとは異なる多様なベンチマークをターゲットとします。

## 3. 実験結果
### 3.1 実験設定
実験では2つの大規模データプールを使用しました。DCLM-RefinedWebは24兆トークンを含むCommonCrawlの処理済みコーパスです。Nemotron-CCは6.3兆トークンを含む別のCommonCrawl処理版で、そのうち1.9兆トークンは合成的に生成されたものです。

評価には10個のCoreベンチマークと39個のNoncoreベンチマークを使用しました。Coreベンチマークには9つのタスクが含まれます。
MMLU、ARC-Easy/Challenge、HellaSwag、Lambada、PIQA、SciQ、TriviaQA、WebQuestions、WinoGrandeです。
モデルは7Bパラメータで140Bトークン（7B-1x）および1.4Tトークン（7B-10x）で訓練しました。スケーリング則の分析では500以上のモデルを訓練しました。

### 3.2 主要な結果
BETRは両データプールにおいて、全てのベースラインを上回る性能を示しました。DCLM-RefinedWebでは、DCLM-Baselineに対して1.8倍、フィルタリングなしに対して4.7倍の計算効率向上を達成しました。Nemotron-CCでは、さらに高い改善率を示しています。DCLM-Baselineに対して2.5倍、Nemotron-CC HQに対して2.8倍、フィルタリングなしに対して4.7倍の向上を達成しました。

個別のベンチマークレベルでも、BETRは10個のCoreタスクのうち9個で全ベースラインを上回りました。DCLM-RefinedWebではMMLU以外の全タスクで、Nemotron-CCではWinogrande以外の全タスクで優位性を示しました。オーバートレーニング領域（7B-10x）でも優位性は維持されました。DCLM-RefinedWebではDCLM-Baselineに対して+1.7ポイント、Nemotron-CCでは+1.8ポイントの改善を達成しました。

### 3.3 既存手法との比較
個別ベンチマークターゲティングの実験では、各ベンチマークを個別にターゲットとしたモデルが、そのターゲットベンチマークで最も高い性能を示す「対角優位性」が観察されました。これにより、BETRが精密な能力制御を可能にすることが実証されました。

一方で、個別ターゲティングは特化したモデルを生成し、他のタスクでの性能低下をもたらすことも明らかになりました。例えば、Winograndeをターゲットとすると言語理解タスクのLambadaは改善されますが、MMLUのような知識ベンチマークでは性能が低下します。全Coreベンチマークを共同でターゲットとすることで、これらのトレードオフを回避できることが示されました。

## 4. 実用性評価
### 4.1 実装の容易性
BETRの実装は比較的シンプルで、既存の埋め込みモデルとFastText分類器という広く利用可能なコンポーネントのみを必要とします。計算コストの大部分は初期の埋め込みとスコアリングフェーズにありますが、1000万文書のサンプリングにより管理可能な範囲に収まっています。

スコア予測のためのFastText分類器は非常に高速で、数十億の文書に対しても現実的な時間内で処理可能です。また、より高精度な言語モデルベースの分類器を使用しても、性能向上は限定的であることが示されており、シンプルなアプローチの有効性が確認されています。

### 4.2 計算効率
BETRの最大の利点の1つは計算効率の大幅な向上です。1.8〜2.8倍の計算効率向上は、同じ性能を達成するのに必要な計算リソースを35〜55%に削減できることを意味します。これは大規模モデルの訓練において、数百万ドル規模のコスト削減につながる可能性があります。

スケーリング分析により、最適なフィルタリング率がモデルスケールに依存することも明らかになりました。小規模モデル（10^20 FLOPs）では上位3%のアグレッシブなフィルタリングが最適ですが、大規模モデル（10^23 FLOPs）では上位30%のより多様なデータが必要となります。この知見は、固定フィルタリング率を使用する現在の実践が最適でない可能性を示唆しています。

### 4.3 応用可能性
BETRの応用範囲は広く、特定のドメインや能力に特化したモデルの開発から、汎用的な基盤モデルの構築まで対応可能です。評価盲検型アプローチを使用することで、特定の評価ベンチマークに過度に最適化されることなく、広範な能力を持つモデルを作成できます。

この手法は埋め込みモデルに限定されず、リランカーや他の類似度を測る手法とも組み合わせ可能です。将来的には、より洗練されたスコアリング関数の開発も期待されます。さらに、動的にターゲットを調整する適応的アプローチへの拡張も考えられます。

## 5. まとめと所感
### 5.1 論文の意義
この論文は、LLMの事前学習におけるデータ選択の根本的な問題に取り組んでいます。「品質」という曖昧な概念を、具体的なベンチマークターゲットに置き換えることで、データ選択を体系的かつ制御可能なプロセスに変換しました。

特に重要なのは、ベンチマークが単に進歩を測定するだけでなく、暗黙的にその方向性を導いているという洞察です。BETRはこの暗黙的なプロセスを明示化し、研究者がモデルの能力を意図的に形成できるようにします。同時に、標準的な評価ベンチマークへの過度の最適化がより広範な能力を損なう可能性があることを実証し、評価方法論についても重要な示唆を与えています。

### 5.2 今後の展望
今後の研究方向として、いくつかの興味深い可能性があります。まず、より高度なスコアリング関数の開発により、文書の多様性と関連性のバランスをより精密に制御できる可能性があります。また、訓練中でターゲットを動的に調整する適応的アプローチも考えられます。複数のターゲット間の相互作用をより深く理解することも重要な課題です。

さらに、この手法を他のモダリティ（画像、音声など）を含むマルチモーダルモデルに拡張することや、継続学習やファインチューニングのシナリオでの応用も検討に値します。最終的には、BETRのようなアプローチが、特定の用途に最適化されたAIシステムや、計算リソースを効率的に活用する大規模モデルの開発につながることが期待されます。