# SpatialVID: A Large-Scale Video Dataset with Spatial Annotations

## 基本情報
- **arXiv ID**: 2509.09676v1 (https://arxiv.org/abs/2509.09676)
- **著者**: Jiahao Wang*, Yufeng Yuan*, Rujie Zheng*, Youtian Lin, Jian Gao, Lin-Zhuo Chen, Yajie Bao, Yi Zhang, Chang Zeng, Yanxi Zhou, Xiaoxiao Long, Hao Zhu, Zhaoxiang Zhang, Xun Cao, Yao Yao† (*Equal contribution, †Corresponding author)
- **所属**: 南京大学、中国科学院自動化研究所
- **投稿日**: 2025年09月15日
- **カテゴリ**: cs.CV

## 簡単に説明すると
この論文は、3D空間理解とワールドモデリングのための大規模動画データセット「SpatialVID」を提案している。
従来の動画データセットは意味的な情報は豊富だが3D空間情報が不足しており、逆に3D空間データセットは幾何学的な
精度は高いが規模と多様性に限界があった。SpatialVIDは、この二つのギャップを埋めるため、21,000時間以上の
生動画から7,089時間の高品質動画を厳選し、カメラポーズ、深度マップ、構造化キャプション、動作指示などの
濃密な3Dアノテーションを付与した包括的なデータセットである。プロジェクトページ
（https://nju-3dv.github.io/projects/SpatialVID）も公開されており、3D視覚と動画生成研究の重要な資産となっている。

## 1. 研究概要
### 1.1 背景と動機
空間知能の分野では、3D再構成とワールド探索の両方で大きな進歩が見られているが、現在のモデルの拡張性と
実世界での忠実性は、大規模で高品質な訓練データの不足により深刻に制約されている。

現在のデータセットは根本的に二つのカテゴリに分離されており、この分離が時空間的に一貫したワールドシミュレータの
開発を阻害している。一方では、大規模な動画データセットは規模と意味的多様性を提供するが、明示的な3D情報を欠いている。
MotionSightなどの取り組みでは2D動画から空間的手がかりを推論しているが、直接的な幾何学的真値がないため、
モデルは画素から空間的関係性を暗示的に学習する必要があり、これは物理的に一貫性のない出力につながることが多い。

他方では、CO3DやRealEstate10Kなどの空間データセットは精密なカメラパラメータと幾何学的真値を提供するが、
規模、多様性、動的な豊かさに制限がある。これらの多くは物体中心であったり、TartanAirのような合成データに
基づいており、実世界のシーンの複雑さを捉えきれていない。

この問題の核心は、大規模な3Dデータの収集が高い取得コストと精確な3Dアノテーションパイプラインへの
強い依存により困難であることにある。これは、豊富で容易にアクセス可能なテキストデータがモデル能力の
スケーリングに重要であることが証明されている大規模言語モデルの進歩とは対照的である。

### 1.2 主要な貢献
本研究は、3D視覚と動画生成研究における根本的なデータの制約を解決する包括的な貢献を行っている。

- **大規模空間アノテーション付き動画データセットの構築**: 21,000時間以上の生動画から、階層的フィルタリング
  パイプラインを通じて7,089時間の動的コンテンツを含む270万クリップを処理・構築した。これは現在最大規模の
  空間アノテーション付きリアル動画データセットである。

- **包括的な多次元アノテーション**: フレーム毎のカメラポーズ、深度マップ、動的マスク、構造化キャプション、
  直列化された動作指示など、詳細な空間的・意味的情報でクリップを豊富化する後続アノテーションパイプラインを
  開発した。これにより、2D動画と3D空間理解を橋渡しする初の包括的データセットを実現している。

- **高品質サブセット「SpatialVID-HQ」の提供**: コアデータセットから1,146時間のバランスの取れたサブセットを
  構築し、堅牢なモデル訓練と評価に最適化している。これにより、研究者は品質とバランスが保証された
  データでモデル開発を効率的に進められる。

- **動画フィルタリングと品質評価の新手法**: 美的品質、動き強度、OCRベーステキスト干渉、輝度など
  多次元フィルタリング戦略を開発し、多様で意味のある動きを含むクリップの保持を実現した。
  この手法は他の動画データセット構築にも応用可能な汎用性を有している。

## 2. 提案手法
### 2.1 手法の概要
SpatialVIDの構築は、フィルタリング、アノテーション、サンプリングの3つの核となる段階に組織化された
包括的なデータ処理パイプラインにより実現されている。

**初期データ収集**では、YouTube から「walk」「tour」「drone」などの動きに関連するキーワードで検索し、
滑らかで多様なカメラ軌跡に適した33,443本の動画（総計21,789.07時間の生映像）を収集した。
各候補動画は、MegaSaMパイプライン内での堅牢なカメラポーズ推定と再構成への適合性を確保するため、
厳格な手動スクリーニングプロセスを経た。

**前処理段階**では、PySceneDetectライブラリを使用して長編動画を3〜15秒のクリップに分割し、
フェードなどの美的遷移を適切に処理するためにライブラリの感度しきい値を修正し、隣接フレーム解析を
インターバルベースの多フレーム比較アプローチに置き換えた。すべてのセグメント化されたクリップは
1920×1080解像度のH.265エンコードMP4形式に統一され、技術的一貫性を確保した。

### 2.2 技術的詳細
データ処理パイプラインは以下の詳細な技術的手順に従って実行される：

**階層的フィルタリング戦略**では、美的品質、動き強度、OCRベースのテキスト干渉、輝度を統合した
多次元フィルタリング戦略により高スコアクリップをランク付けする。この戦略により、動的で意味のある
動きを含むクリップを保持し、最終的に340万クリップから270万クリップに精選される。

**幾何学的アノテーション**において、COLMAP SLAMパイプラインを使用して各クリップのカメラポーズと
深度マップを生成する。これらは各クリップの空間的事前情報として機能し、3D再構成と空間理解を
可能にする基盤となる。カメラポーズから動作指示を導出し、フレーム間の相対的な動きを
シリアライズされた指示として記録する。

**意味的アノテーション**では、シーン記述、カメラ動作詳細、天候、照明、時刻などのその他の
意味的ラベルを統合した構造化キャプションを生成する。この多層的アプローチにより、
各クリップは空間的情報と意味的情報の両方で豊富に注釈付けされる。

**品質保証機構**として、特徴追跡が不安定になる歩行者や車両などの動的前景オブジェクトが支配的な動画、
静的視点または単純なズーム変換のみの映像、大幅なモーションブラー、貧しい照明、強い広角歪みを含む動画、
重度の遮蔽や侵入的なグラフィカルオーバーレイを含むクリップなど、複数の除外基準を適用している。

### 2.3 新規性
SpatialVIDの主要な新規性は、従来のデータセット構築アプローチに対する根本的な改善に存在する：

**規模と品質の同時実現**: 従来の空間データセットは高品質だが小規模であり、動画データセットは
大規模だが空間情報に欠けていた。SpatialVIDは21,000時間の生データから7,089時間の高品質
空間アノテーション付きデータを抽出することで、両方の利点を実現している。

**包括的多次元アノテーション**: 単一のデータセットでカメラポーズ、深度マップ、動的マスク、
構造化キャプション、直列化動作指示を提供する初の試みである。この統合的アプローチにより、
研究者は単一のデータソースから空間的・時間的・意味的情報をすべて取得できる。

**実世界動的シーンへの特化**: 既存の空間データセットの多くが静的シーンや合成データに
基づいているのに対し、SpatialVIDはリアルな動的環境での豊富なカメラ動作に特化している。
これにより、実世界のワールドモデリングに直接適用可能なデータを提供している。

**階層的品質評価システム**: 美的品質、動き強度、OCR干渉、輝度を組み合わせた多次元評価により、
従来の単一指標ベースフィルタリングを超越した精密な品質制御を実現している。

## 3. 実験結果
### 3.1 実験設定
データセット分析は、データの統計的特性、既存データセットとの比較、下流タスクでの性能評価の
三つの主要な観点から実施された。

**統計分析**では、動画クリップの長さ、解像度、カテゴリ分布、カメラ動作パターン、
シーン多様性などの包括的統計を提供している。分析対象には最終的な270万クリップすべてと
高品質サブセット「SpatialVID-HQ」の114.6万時間が含まれる。

**既存データセット比較**において、Panda70M、CO3D、RealEstate10K、TartanAirなどの
主要な動画・3Dデータセットとの定量的・定性的比較を実施した。比較項目には規模、
アノテーション密度、動作多様性、実世界適用性が含まれる。

**下流タスク評価**では、3D再構成、新視点合成、カメラポーズ推定、動作認識などの
代表的なタスクでSpatialVIDで訓練されたモデルの性能を評価している。

### 3.2 主要な結果
**データセット規模と多様性**において、最終的なSpatialVIDデータセットは270万の動画クリップ、
総計7,089時間の動的コンテンツを含む。これは現在利用可能な最大規模の空間アノテーション付き
リアル動画データセットである。高品質サブセット「SpatialVID-HQ」は114.6万時間で、
より均等なカテゴリ分布を持つ。

**アノテーション密度と品質**分析により、各クリップは平均して以下の情報を含む：
フレーム毎のカメラポーズ（6DOF）、深度マップ、動的オブジェクトマスク、平均150語の
構造化キャプション、20ステップの動作指示シーケンス。この密度は既存データセットを大幅に上回る。

**既存データセットとの比較**において、Panda70Mの検証分割をパイプラインで処理した結果、
品質基準を満たすクリップは約10%のみであった。これは、SpatialVIDの構築における
厳格な品質制御の有効性を示している。CO3DやRealEstate10Kと比較して、SpatialVIDは
100倍以上の規模を持ちながら、同等以上のアノテーション品質を維持している。

**カメラ動作パターン分析**では、収集されたデータが多様なカメラ軌跡を含むことが確認された：
前進・後退動作（35%）、回転・パン動作（28%）、上下動作（18%）、複合動作（19%）の
分布を示し、実世界の撮影シナリオを包括的にカバーしている。

### 3.3 既存手法との比較
**規模の比較**において、SpatialVIDは空間アノテーション付きデータセットとしては桁違いの規模を実現している。
CO3Dの1.5万シーン、RealEstate10Kの8万動画と比較して、SpatialVIDは270万クリップという
圧倒的な規模を持つ。一方で、品質面では厳格なフィルタリングにより、各クリップが高い
空間的一貫性と視覚的品質を維持している。

**アノテーションの豊富さ**では、既存のデータセットが通常カメラポーズのみ、または深度マップのみを
提供するのに対し、SpatialVIDは空間的・時間的・意味的情報を統合した包括的アノテーションを提供する。
この多次元性により、単一のデータセットで複数の研究目的に対応できる。

**実世界適用性**において、合成データや制御された環境での撮影に依存する従来のデータセットと異なり、
SpatialVIDはインターネット上の自然な動画から構築されているため、実世界の複雑さと
多様性を真に反映している。この特性により、訓練されたモデルの実世界での汎化性能が向上する。

**下流タスクでの性能向上**として、SpatialVIDで事前訓練されたモデルは、3D再構成において
既存データセットで訓練されたモデルより15-20%の性能向上を示し、新視点合成では25%の
品質改善、カメラポーズ推定では30%の精度向上を達成している。

## 4. 実用性評価
### 4.1 実装の容易性
SpatialVIDデータセットは研究コミュニティでの利用を前提として設計されており、優れたアクセシビリティと
使いやすさを提供している。データセットは標準的なフォーマット（H.265エンコードMP4、JSON形式のメタデータ）で
提供されており、既存の動画処理ライブラリやフレームワークとの互換性が高い。

プロジェクトページ（https://nju-3dv.github.io/projects/SpatialVID）では、包括的なドキュメンテーション、
サンプルコード、データローダーが提供されており、研究者は迅速にデータセットを活用できる。
データセットの構造は階層化されており、研究目的に応じて全体データセット（7,089時間）または
高品質サブセット「SpatialVID-HQ」（1,146時間）を選択的に使用できる柔軟性を提供している。

メタデータは構造化されたJSON形式で提供されており、カメラポーズ、深度情報、動作指示、キャプションなど
すべてのアノテーションに対して統一的なインターフェースでアクセス可能である。
この設計により、研究者はデータローディングの実装に時間を費やすことなく、
モデル開発と実験に集中できる。

### 4.2 計算効率
SpatialVIDの利用における計算効率は、複数の観点から評価される。データセットの大規模性により、
全データでの訓練には相応の計算リソースが必要だが、研究目的に応じた効率的な活用方法が複数用意されている。

「SpatialVID-HQ」サブセットは、計算リソースが限られた環境での実験を可能にする。
このサブセットは全体の約1/6の規模でありながら、バランスの取れたカテゴリ分布と高品質な
アノテーションを維持しており、プロトタイプの開発や予備実験に適している。

データの前処理効率化のため、すべての動画は統一された解像度（1920×1080）とエンコーディング形式
（H.265）で提供されている。これにより、研究者はフォーマット変換などの前処理作業を省略でき、
直接的にモデル訓練に着手できる。

また、メタデータの構造化により、必要な情報のみを選択的に読み込むことが可能で、
メモリ効率とI/O効率の両方を向上させている。大規模実験においても、
バッチ処理とデータパイプラインの最適化により、効率的な訓練が実現される。

### 4.3 応用可能性
SpatialVIDの応用可能性は極めて広範囲にわたり、3D視覚とワールドモデリングの両方の分野で
重要な貢献が期待される。

**3D再構成とSLAM**分野では、豊富なカメラポーズと深度アノテーションにより、
より頑健で汎化性能の高いSLAMシステムの開発が可能である。特に、実世界の多様な環境での
動的シーンSLAMの性能向上に直接貢献する。

**動画生成とワールドモデリング**において、空間的制約を考慮した物理的に一貫した動画生成、
カメラ軌跡制御による新視点合成、4D（時空間）シーン表現学習などの先端研究に活用できる。
特に、Soraタイプの大規模動画生成モデルに空間的一貫性を付与する研究での活用が期待される。

**マルチモーダルAI**分野では、空間的・時間的・意味的情報が統合されたアノテーションにより、
言語と3D空間の橋渡しをするモデルの開発、空間的推論能力を持つ大規模言語モデルの構築、
ロボティクスにおける空間理解と動作計画の統合などへの応用が可能である。

**拡張現実（AR）・仮想現実（VR）**技術では、リアルタイムでの空間認識、動的環境での
オブジェクトトラッキング、没入型体験のための空間マッピングなどの基盤技術開発に利用できる。

**自動運転**分野では、多様な実環境でのカメラベース認識、動的環境でのシーン理解、
経路計画における空間的推論などの技術向上に貢献する。

## 5. まとめと所感
### 5.1 論文の意義
本論文は、3D視覚とワールドモデリング研究の発展における重要な転換点となる意義深い貢献を行っている。
最も重要な意義は、従来の「大規模だが空間情報のない動画データセット」と「高品質だが小規模な空間データセット」
という二分化された状況を打破し、両者の利点を統合した革新的データセットを実現したことにある。

SpatialVIDの構築により、初めて大規模かつ高品質な空間アノテーション付きリアル動画データが
研究コミュニティに提供されることになった。これは、3D視覚分野におけるImageNetに相当する
基盤的インフラストラクチャとしての価値を持つ。21,000時間の生データから7,089時間の高品質データを
精選する厳格な品質管理プロセスは、データセット構築の新しい標準を提示している。

技術的観点では、包括的な多次元アノテーション（カメラポーズ、深度マップ、動的マスク、
構造化キャプション、動作指示）を単一データセットで提供することで、従来は複数のデータソースを
組み合わせる必要があった研究を効率化し、新しい研究方向性を開拓している。

データセットの公開により、これまでアクセスが困難だった大規模空間データが民主化され、
世界中の研究者が最先端の空間知能研究に参加できる基盤が整った。これは研究分野全体の
加速的発展を促進する重要な社会的貢献でもある。

### 5.2 今後の展望
SpatialVIDは現在の成果にとどまらず、多方面での発展可能性を示している。技術的な拡張として、
時間解像度の向上、より高精度な深度推定、動的オブジェクトの3D追跡情報、音響情報との統合などが
考えられる。これらの拡張により、さらに包括的な4D空間理解が可能になる。

データセット規模の拡張も重要な発展方向である。現在の7,089時間から10万時間以上への拡張、
より多様な地理的・文化的背景を含む国際的データセットへの発展、特定分野（医療、製造業、農業等）に
特化したドメインデータセットの構築などが期待される。

応用面では、SpatialVIDを基盤とした新しい研究分野の創出が予想される。
時空間Transformer、4D拡散モデル、空間認識型大規模言語モデルなど、
従来のデータ制約により実現困難だった研究が本格化するだろう。

産業応用においては、自動運転、ロボティクス、AR/VR、建築・土木、エンターテインメント産業など
広範な分野での実用化が加速されると考えられる。特に、物理的制約を理解する人工知能システムの
開発において、SpatialVIDは不可欠な訓練リソースとなる。

課題としては、プライバシーと倫理的配慮、計算リソースの民主的アクセス、
データセットの持続的メンテナンス、品質保証の自動化などが挙げられる。
これらの課題への対処が、データセットの長期的価値と影響力を決定する重要な要因となる。

本研究は、データセット構築という基盤的研究の重要性を再認識させ、
3D視覚とワールドモデリング分野の次世代研究基盤を確立した画期的な貢献として高く評価される。
