# Slot Attention with Re-Initialization and Self-Distillation

## 基本情報
- arXiv ID: 2507.23755v1 (https://arxiv.org/abs/2507.23755)
- 著者: Rongzhen Zhao, Yi Zhao, Juho Kannala, Joni Pajarinen
- 所属: Aalto University, University of Oulu
- 投稿日: 2025年8月1日
- カテゴリ: cs.CV, cs.LG

## 簡単に説明すると
この論文は、画像や動画の中からオブジェクトを自動的に分離・認識するObject-Centric Learning（OCL）という分野の研究です。従来の手法では、シーン内のオブジェクトを「スロット」と呼ばれる特徴ベクトルに変換しますが、余分なスロットが有効なスロットと競合してオブジェクトが誤って分割される問題がありました。本研究では、余分なスロットを削減した後に追加の集約する「再初期化」と、最後の反復の注意マップを使って最初の反復を改善する「自己蒸留」という2つの新しい技術を提案しています。コードはGitHubで公開されています（https://github.com/Genera1Z/DIAS）。

## 1. 研究概要
### 1.1 背景と動機
人間の視覚システムは、シーンをオブジェクトに分解し、オブジェクトレベルで注意を配分することで効率的にシーン情報を捉えます。これにより、予測、推論、計画、意思決定などの複雑な機能をサポートします。人工知能においても、OCLは画像や動画の密なスーパーピクセルを、オブジェクトを表すスパースな特徴ベクトル（スロット）に集約します。

既存のOCLは通常、エンコーディング・集約・デコーディングのパラダイムに従います。処理の流れは以下の通りです。

1. 入力画像や動画のピクセルを特徴マップにエンコード
2. オブジェクトのスーパーピクセルを競争的クロスアテンション（Slot Attention）を使って反復的にスロットに集約
3. これらのスロットをデコードして入力を再構築し、自己教師信号を提供

しかし、従来手法には2つの主要な問題がありました。第一に、一度初期化されたスロットは集約において単純に反復されます。オブジェクト数が事前定義されたスロット数より少ない場合、余分なスロットが有効なスロットと競合してオブジェクト表現を妨害します。その結果、オブジェクトが誤って部分に分割されてしまいます。第二に、主流の手法は集約されたスロットを使った入力の再構築からのみ教師信号を導出します。後の反復の集約注意マップがより良いオブジェクトセグメンテーションを持つという内部情報を活用していませんでした。

### 1.2 主要な貢献
本研究では、Object-Centric Learningの性能を向上させる3つの革新的な技術を提案しています。
- 再初期化された集約：余分なスロットを削減した後、残りのスロットを更新するために追加の集約を再初期化する
- 自己蒸留された集約：最初の集約反復の注意マップを最後の反復の注意マップに近似させることで、追加の内部教師信号を得る
- ランダム自己回帰デコーディング：2次元特徴マップを1次元シーケンスへランダムに平坦化することで、空間相関のモデリングを強制する
- 新しい最先端性能の達成：画像と動画の両方でOCLタスクにおいて最高性能を実現

## 2. 提案手法
### 2.1 手法の概要
提案手法DIASは、Object-Centric Learningの集約とデコーディングモジュールにおける3つの技術革新を組み合わせています。

まず、再初期化された集約では、初期集約の後に冗長性を削減し、残りのスロットのみで追加の集約します。これにより、余分なスロットからの妨害なしに高品質なオブジェクト表現を得ることができます。

次に、自己蒸留では、最後の集約反復の注意マップが最初の反復よりもほぼ常に優れているという観察に基づき、最初の反復を最後の反復に近似させる追加の教師信号を導入します。

最後に、ランダム自己回帰デコーディングでは、任意のスーパーピクセル順序を収容する一般化された自己回帰デコーディングスキームを実装します。

### 2.2 技術的詳細
再初期化された集約の実装では、まず初期集約を$i_a-1$回の反復で実行し、次にコサイン距離による凝集クラスタリングを使用して冗長性を削減します。その後、冗長性マスクを適用して余分なスロットの効果を破棄しながら追加の集約します。

自己蒸留の実装では、最初の集約反復の注意マップ$\mathbf{A}_a^1$と最後の反復の注意マップ$\mathbf{A}_a$の間でハンガリアンマッチングを行います。クロスエントロピー損失を使用して近似を強制します。これにより、SPOTのような事前学習された教師モデルを必要とせず、真の自己蒸留を実現します。

ランダム自己回帰デコーディングでは、ランダムなシーケンス長とシャッフルされたインデックスを使用します。デコーダーは任意の位置の既知のスーパーピクセルのサブセットを使用してターゲットを再構築します。

### 2.3 新規性
既存手法との主な違いは以下の通りです。
- 冗長スロット削減後に残りのスロットを更新する初めての手法
- 集約反復内での真の自己蒸留を実現（追加モデルや事前学習不要）
- 空間相関を保持する任意順序の自己回帰デコーディング

## 3. 実験結果
### 3.1 実験設定
実験は3つのランダムシードを使用して実施されました。オブジェクト表現品質は、オブジェクト発見と認識、および動画予測と推論などの下流タスクを通じて評価されました。

評価データセットには、合成画像のClevrTex、実世界画像のCOCOとVOC、合成動画のMOVi-D、実世界動画のYTVISが使用されました。評価指標にはARI、ARIfg、mBO、mIoUなどが使用されました。

### 3.2 主要な結果
画像でのオブジェクト発見において、DIASは無条件クエリで全てのベースラインを上回り、新しい最高性能を達成しました。例えば、COCOデータセットでmIoU 21.1を達成し、次善のSPOT（13.2）を59.8%上回りました。

動画でのオブジェクト発見では、条件付きクエリでDIAS temporalがSTEVEを上回り、無条件クエリでも既存の動画OCLモデルを凌駕しました。一般的な改善技術VVOと組み合わせることで、DIASはさらに高い性能を実現しました。

オブジェクト認識タスクでは、DIASはCOCOデータセットで分類精度（top1）51.2と境界ボックス回帰精度（R2）36.2を達成し、全てのベースラインを上回りました。

### 3.3 既存手法との比較
訓練コストの観点から、DIASはSPOTと比較してわずか半分以下の訓練コストで済みます。SPOTは教師モデルの事前学習と、教師と生徒の両方のモデルを同時に実行する必要があるのに対し、DIASは単一のモデルのみを実行し、事前学習も不要です。

視覚的予測と推論の下流タスクでも、DIAS+SlotFormerの組み合わせはより高い性能を示しました。VideoSAUR+SlotFormerベースラインと比較して、予測誤差の蓄積が遅く、より高い推論精度を達成しました。

## 4. 実用性評価
### 4.1 実装の容易性
DIASは標準的な深層学習フレームワークで実装可能であり、コードはGitHubで公開されています。実装は比較的シンプルで、既存のOCLアーキテクチャに容易に組み込むことができます。

### 4.2 計算効率
RTX 3080 GPU 1枚での訓練時間は、50エポックで24.2時間であり、SPOTの48.8時間と比較して約半分の訓練コストで済みます。これは自己蒸留に追加の教師モデルが不要なためです。

### 4.3 応用可能性
DIASは、マルチモーダルAIシステム、ロボティクス、動画理解、異常検出など、オブジェクトレベルの表現が重要な様々な応用分野で活用できます。特に、改善されたオブジェクト表現品質により、視覚的予測や推論などの下流タスクでの性能向上が期待できます。

## 5. まとめと所感
### 5.1 論文の意義
本研究は、Object-Centric Learningの根本的な問題に対してシンプルかつ効果的な解決策を提供しています。再初期化と自己蒸留という2つの主要な技術革新により、追加の計算コストをほとんどかけずに性能向上を実現しました。

特に、真の自己蒸留を実現したことで、訓練効率を約50%改善しながら性能を向上させた点は高く評価できます。また、ランダム自己回帰デコーディングによる空間相関の保持も、実用的な観点から重要な貢献です。

### 5.2 今後の展望
論文でも言及されているように、再初期化と自己蒸留の基礎は依然として手動の閾値に依存しています。これらを自動的に調整する方法の開発が今後の課題となるでしょう。

また、より大規模なモデルや異なるアーキテクチャへの適用、3D物体認識への拡張、リアルタイムアプリケーションへの最適化なども興味深い研究方向です。さらに、提案手法を他の自己教師あり学習手法と組み合わせることで、さらなる性能向上が期待できます。