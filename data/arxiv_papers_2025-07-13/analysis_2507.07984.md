# OST-Bench: Evaluating the Capabilities of MLLMs in Online Spatio-temporal Scene Understanding

## 基本情報
- arXiv ID: 2507.07984v1 (https://arxiv.org/abs/2507.07984)
- 著者: JingLi Lin, Chenming Zhu 他（Shanghai AI Laboratory 他）
- 所属: Shanghai AI Laboratory、Shanghai Jiao Tong University 他2校
- 投稿日: 2025年07月10日
- カテゴリ: cs.CV

## 簡単に説明すると

OST-Benchは、マルチモーダル大規模言語モデル（MLLM）のオンライン時空間シーン理解能力を評価する新しいベンチマークです。
従来のベンチマークが固定された事前録画入力でモデルを評価するのに対し、OST-Benchは実世界の探索エージェントのように、連続的な観測を通じて環境を理解する能力を評価します。
1.4kの実世界シーンから生成された10kの質問応答ペアを含み、エージェントの状態理解、可視情報の解釈、物体との空間関係の推論という3つの主要タスクをカバーしています。
評価結果は、現在の最先端モデルでも人間のパフォーマンスより30%以上低く、特に空間推論タスクでは深刻な課題があることを明らかにしました。
コードとデータは https://github.com/rbler1234/OST-Bench で公開されています。

## 1. 研究概要
### 1.1 背景と動機

実世界で動作するエンボディッドAIエージェントは、環境を探索しながら連続的に知覚し、理解を更新します。
しかし、現在のMLLMの評価は主にオフライン設定で行われ、固定された事前録画入力を使用しています。
この評価方法では、エージェントが実際に直面する動的な知覚と推論の課題を捉えることができません。

既存のベンチマークには以下の問題があります。
第一に、ScanQA、SQA3D、SceneVerseなどは静的なシーン理解に焦点を当てており、時間的な側面を考慮していません。
第二に、空間関係を意味的属性として扱い、エージェントの視点からの動的な空間推論を必要としません。
第三に、オフライン評価では、増加する文脈を効率的に処理し、長期記憶から関連情報を取得する能力を測定できません。

これらの課題に対処するため、本研究では、オンライン設定でMLLMの時空間の理解能力を包括的に評価する新しいベンチマークの開発を目指しました。

### 1.2 主要な貢献

本研究の主要な貢献は以下の通りです。

- OST-Benchの提案：オンライン時空間シーン理解のための初の包括的ベンチマークで、実世界の探索シナリオを反映
- エージェント中心の評価フレームワーク：エージェントの視点から3つの主要タスクカテゴリと4つの質問形式で能力を評価
- 大規模データセット：1.4kの実世界シーンから生成された10kの高品質な質問応答ペアと15の細分化された質問サブタイプ
- 包括的な評価と分析：15の最先端MLLMの評価により、現在のモデルの根本的な限界と改善の方向性を明確化

## 2. 提案手法
### 2.1 手法の概要

OST-Benchは、エンボディッドエージェントの視点からMLLMの時空間の理解能力を評価する新しいベンチマークです。

ベンチマークの設計原則は以下の通りです。
第一に、オンライン設定により、モデルは段階的に獲得される観測をストリーミング形式で処理します。
第二に、時空間的焦点により、現在の視覚入力と過去の記憶を統合して動的な空間推論をします。
第三に、エージェント中心の視点により、すべての質問は能動的に探索するエージェントの観点から構成されます。

評価は3つの主要タスクカテゴリで構成されています。
エージェント状態タスクは、エージェント自身の位置と向きの理解を評価します。
エージェント可視情報タスクは、可視シーン情報の動的な解釈（存在、数量、多様性、順序）を評価します。
エージェント・物体空間関係タスクは、方向と距離を含む3D空間関係の推論を評価します。

### 2.2 技術的詳細

データ収集パイプラインは以下の要素で構成されています。

高品質なアノテーションの活用では、EmbodiedScanの9自由度バウンディングボックスとMMScanの意味的アノテーションを利用しました。
Matterport3Dデータセットに対しては、最小全域木アルゴリズムを使用して合成探索軌跡を生成しました。

可視性の定義として、2つのタイプを設定しました。
属性可視性は、単一フレームから物体の存在や属性を判断できることを意味します。
空間可視性は、中心位置、サイズ、形状を推論できることを意味し、より高い要求レベルです。

質問生成プロセスでは、各サブタイプに合わせたテンプレートによるルールベース生成を採用しました。
手動検証により、エラー率は5%未満であることを確認しました。
曖昧さやコーナーケースを避けるための慎重な設計をしました。

### 2.3 新規性

既存手法との主な違いは以下の通りです。

- オンライン評価パラダイム：固定入力ではなく、段階的に増加する観測を処理する実世界シナリオを反映
- エージェント中心の設計：静的な第三者視点ではなく、探索エージェントの一人称視点からの評価
- 時空間統合の重視：単一時点の理解ではなく、時間経過に伴う空間理解の変化を評価
- 包括的なタスク設計：知覚から高次推論まで、実世界で必要な能力を網羅的にカバー

## 3. 実験結果
### 3.1 実験設定

評価対象として15のモデルを選定しました。
プロプライエタリモデル5種（GPT、Claude、Geminiシリーズ）とオープンソースモデル10種を含みます。
すべてのモデルはゼロショット設定で、マルチターン対話形式で評価しました。

評価指標として、ほとんどの質問では完全一致を使用しました。
推定タスクでは平均相対精度を使用しました。
人間のベースラインとチャンスレベルのベースラインも含めて比較しました。

### 3.2 主要な結果

全体的なパフォーマンスについて、最良のモデルでも人間のパフォーマンスより30%以上低い結果となりました。
モデルはエージェント可視情報タスクで約70%を達成しましたが、空間推論タスクではチャンスレベルに近い性能でした。
探索の時間が長くなるにつれて、パフォーマンスは20-30%低下することを観察しました。

モデル間の比較では、プロプライエタリモデルがオープンソースモデルを10-15%上回りました。
モデルサイズの拡大は、特に可視情報タスクで有効でした。
Geminiの「思考モード」は空間的・時間的認識を改善しました。
最高性能のプロプライエタリモデルはGemini-2.0-Flash(Thinking)で平均54.2%、最高性能のオープンソースモデルはInternVL-2.5-78Bで平均51.1%でした。

### 3.3 既存手法との比較

エラー分析により、3つの主要なエラータイプが特定されました。

プロンプト分析エラーは稀でした。
知覚エラーは可視情報タスクで支配的でした。
推論エラーは全エラーの60%以上を占め、主要なボトルネックとなっています。

時空間推論のショートカット問題も明らかになりました。
モデルは長期記憶から重要な情報を取得することを避け、最小限の情報に基づいて浅い、根拠のない推論をする傾向があります。

クロスビュー分析では、以下の条件でパフォーマンスが劇的に低下することが判明しました。
単一ステップから複数ステップの空間推論への移行時、提供されたキーフレームではなくシーケンスベースのコンテキストが必要な場合、最も困難なタスクでは精度が約10%まで低下しました。

## 4. 実用性評価
### 4.1 実装の容易性

OST-Benchは実装が容易で、以下の特徴があります。

標準的な評価プロトコルにより、既存のMLLM評価パイプラインに容易に統合可能です。
質問応答ペアは構造化されたJSONフォーマットで提供されます。
評価スクリプトとメトリクス計算コードが公開されています。
複数のデータセット（ScanNet、Matterport3D、ARKitScenes）をサポートしています。

### 4.2 計算効率

評価プロセスの計算効率について以下の特徴があります。

増加するコンテキストの処理が主な計算ボトルネックとなります。
現在のモデルは線形に増加する遅延を示し、長い探索シーケンスでは実用的でない場合があります。
メモリ使用量を削減するため、キーフレーム抽出や要約メカニズムの開発が重要です。

### 4.3 応用可能性

本ベンチマークは以下の分野で応用可能です。

ナビゲーションと探索タスクを行うエンボディッドAIの評価と改善に直接適用できます。
ロボティクスにおける動的環境理解の能力評価に活用できます。
拡張現実（AR）システムの空間認識能力の測定に使用できます。
自動運転車の周囲環境理解の評価にも拡張可能です。

## 5. まとめと所感
### 5.1 論文の意義

本論文は、MLLMの評価における重要なギャップに対処しています。
オンライン、エージェント中心の評価パラダイムを導入することで、実世界のエンボディッドAIアプリケーションに必要な能力をより正確に測定できるようになりました。

特に重要なのは、現在の最先端モデルの根本的な弱点を明らかにした点です。
静的なシーン理解では優れた性能を示すMLLMも、動的な空間推論と長期記憶の統合では深刻な課題を抱えています。
この発見は、今後の研究開発の方向性を示す重要な指針となります。

ベンチマークの公開により、コミュニティ全体でオンライン時空間理解の研究を推進する基盤が整いました。

### 5.2 今後の展望

今後の研究方向として以下が考えられます。

短期的な課題として、より良い長期記憶メカニズムを持つモデルアーキテクチャの開発が必要です。
履歴情報を要約・抽象化することで計算量を削減する手法の研究も重要です。
複数ビューにわたる空間関係を連鎖させる能力の向上も求められます。

長期的な拡張として、物体が移動・変化する動的環境への対応が挙げられます。
操作や能動的探索を含むインタラクティブタスクへの拡張も可能です。
音声や触覚など他の感覚入力との統合により、より豊かな環境理解を実現できます。
探索経験を通じて改善する継続学習モデルの開発も期待されます。

本研究は、オンラインエンボディッド推論の研究を前進させる重要な一歩であり、実世界で動作する知的エージェントの実現に向けた基盤となることが期待されます。