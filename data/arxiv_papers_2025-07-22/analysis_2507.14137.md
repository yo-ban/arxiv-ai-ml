# Franca: Nested Matryoshka Clustering for Scalable Visual Representation Learning

## 基本情報
- **arXiv ID**: 2507.14137v1 (https://arxiv.org/abs/2507.14137)
- **著者**: Shashanka Venkataramanan, Valentinos Pariza, Mohammadreza Salehi, Lukas Knobel, Spyros Gidaris, Elias Ramzi, Andrei Bursuc, Yuki M. Asano
- **所属**: valeo.ai, Paris; Fundamental AI Lab, UTN; VIS Lab, UvA
- **投稿日**: 2025年07月19日
- **カテゴリ**: cs.CV, cs.LG

## 簡単に説明すると
Francaは、コンピュータビジョンのための新しい基盤モデルで、画像から意味のある特徴を自動的に学習します。特徴的なのは、ロシアのマトリョーシカ人形のように、大きな特徴の中に段階的に小さな特徴を入れ子にする「Nested Matryoshka Clustering」という手法を採用している点です。これにより、同じモデルで粗い特徴（例：動物かどうか）から細かい特徴（例：犬の品種）まで、様々な粒度で画像を理解できます。また、画像の位置情報に頼らずに物体を認識できるようにする工夫（RASA）も組み込まれています。コード、モデル、データセットはすべて公開されており、GitHubリポジトリ（https://github.com/valeoai/Franca）で利用可能です。

## 1. 研究概要
### 1.1 背景と動機
近年、大規模なビジョン基盤モデルは人工知能研究において重要な要素となっており、複雑な3Dシステムやマルチモーダル大規模言語モデル（LLM）の基本的な構成要素として機能しています。自己教師あり学習（SSL）アプローチは、ペアになった画像キャプションデータよりもはるかに多い画像のみのデータを活用できるため、スケーラビリティの面で優位性を示しています。

しかし、現在の最先端モデル（DINOv2、SEER、billion-scale MAE、SigLIPv2など）は、すべて独自のプライベートデータセットに依存しており、再現性、アクセシビリティ、科学的進歩の大きな障壁となっています。また、既存のクラスタリングベースのSSLビジョンモデルには根本的な制限があります。これらのモデルは画像やパッチを意味のある疑似ラベルに割り当てますが、クラスタリングが本質的に曖昧であるという重要な問題を見過ごしています。例えば、車両は製造元、色、モデル年、その他多数の属性によって意味のある方法で整理できます。

### 1.2 主要な貢献
本研究では、これらの課題に対処するため、以下の4つの主要な貢献を行いました。
- 公開データで訓練された初のオープンソース・オープンデータビジョン基盤モデル「Franca」を提示し、DINOv2を含む既存の最先端モデルに匹敵またはそれを上回る性能を実現
- パラメータ効率的なネストされたマルチヘッドクラスタリングアプローチを導入し、表現品質を効率的に向上
- 空間的意味論的分離のためのポストプレトレーニング手法を開発し、より強力なバックボーンを実現
- 密な予測タスクで優れた結果を達成し、DINOv2-Gを最大3%上回る性能を実現

## 2. 提案手法
### 2.1 手法の概要
Francaは、iBoTをベースとした拡張可能なオープンソース自己教師あり学習フレームワークです。主要な構成要素として、CyclicMask（マスクされたパッチを円形にシフトして空間的連続性を破る戦略）、Matryoshka埋め込み（圧縮された多解像度表現を生成するネストされたマルチヘッドクラスタリングアプローチ）、そして絶対的なパッチ位置と相関する特徴成分を特定・除去する軽量なポストプレトレーニングステップを含みます。

モデルは、DINOのマルチクロップトレーニング戦略に従い、入力画像を複数の拡張ビュー（グローバルおよびローカルクロップ）に変換します。Vision Transformer（ViT）バックボーンがこれらのシーケンスを処理し、学生と教師ネットワークの両方で共有されます。教師のパラメータは学生のパラメータの指数移動平均（EMA）により更新されます。

### 2.2 技術的詳細
Matryoshka表現により、モデルは複数の特徴粒度にわたって柔軟で意味的に意味のある表現を生成できます。標準的なMatryoshkaアプローチとは異なり、各サブスペースに専用の投影ヘッドとクラスタリング目的を付加し、各スライスが異なるプロトタイプとプロトタイプ割り当てを生成できるようにしています。

CyclicMaskは、逆ブロックマスキングのマスクを訓練中に垂直軸と水平軸の両方に沿ってランダムに循環シフトすることで、空間的な不均衡を緩和します。これにより、連続した可視領域の利点を保持しながら、時間の経過とともにすべてのパッチ位置で均一な露出を確保します。

RASA（Removal of Absolute Spatial Attributes）は、パッチ埋め込みから位置情報を分離するポストトレーニング戦略です。交互最適化手順に従い、各反復で単純な2D回帰ヘッドを学習してパッチの正規化された2D グリッド座標を予測し、Gram-Schmidt直交化を使用して位置情報をエンコードする2D部分空間を形成します。

### 2.3 新規性
既存手法との主な違いは、クラスタリングの本質的な曖昧性に対処する点にあります。従来のアプローチが極端に大きな細粒度クラスタセット（例：DINOv2の131Kコードブック）を使用するのに対し、Francaはネストされた「マトリョーシカ」表現を実装し、ニューロンの段階的なサブセットがデータセットをますます細かいグループにクラスタリングします。これにより、従来のアプローチと比較してパラメータを削減しながら、性能を向上させ、下流タスクのメモリ要件を削減します。

## 3. 実験結果
### 3.1 実験設定
FrancaはImageNet-21K（約1,310万の高品質画像）とLAION-600M（ReLAION-2Bのサブセット）で事前訓練されました。ViT-B（86Mパラメータ）、ViT-L（300M）、ViT-G（1.1B）の3つのモデル容量で訓練され、すべてのモデルは大規模モデルからの蒸留なしでスクラッチから500エポック（625K反復）訓練されました。

### 3.2 主要な結果
画像分類タスクでは、ImageNet-1Kでの線形プロービングにおいて、Franca-GモデルがWeb-SSL-7B（85.9% vs. 86.0%）に匹敵する精度を達成しながら、150倍少ないデータと約7倍少ないパラメータを使用しました。また、DINOv2が蒸留に大きく依存していることが確認され、蒸留なしで再訓練されたDINOv2モデルは大幅に性能が低下しました。

密な予測タスクでは、Francaは一貫して強力な性能を示しました。Hummingbird Benchmarkでのインコンテキスト学習において、ViT-G/14スケールでDINOv2-GとWebSSLを最大2% mIoU上回りました。線形セグメンテーションでは、ViT-G/14バックボーンですべてのベンチマークで最高性能を達成しました。

### 3.3 既存手法との比較
ロバスト性評価では、FrancaはImageNet-A、ImageNet-R、Sketchなどの自然な分布シフト下で強力な汎化能力を示しました。Out-of-Distribution（OOD）検出では、5つのベンチマーク全体でDINOv2を一貫して上回り、大規模モデルバリアントで4%の平均改善を達成しました。

3D理解のプロービングでは、SPair-71kでのキーポイント対応タスクにおいて、224×224の入力解像度でViT-LでDINOv2を3%、ViT-Gで1.5%上回りました。Gaussian Splattingを使用したプロービングでは、Francaが幾何学的認識において最高の性能を示し、強力な3D理解能力を示しました。

## 4. 実用性評価
### 4.1 実装の容易性
Francaは完全にオープンソースであり、訓練コード、データ、モデルの重み、中間チェックポイントがすべて公開されています。これにより、研究コミュニティが収束動作の分析、表現分析、時間経過に伴う創発的特性の研究を行うことが可能です。RASAは既存の事前訓練済みモデルに容易に適応でき、アーキテクチャの変更を必要としません。

### 4.2 計算効率
Matryoshka表現により、様々な計算予算や下流の制約に対して柔軟に対応できます。k最近傍分類などの下流タスクで、同等のメモリでより高い性能を実現し、重い圧縮下でも高い性能を維持します。例えば、埋め込み次元を1/64に圧縮してもDINOv2より優れた性能を示しました。

### 4.3 応用可能性
Francaは幅広い下流タスクで優れた転移性を示しています。11の分類ベンチマークでの評価では、シーン認識、細粒度オブジェクト分類（食品、車、航空機など）、テクスチャ認識など、多様なタスクで競争力のある性能を達成しました。また、3D理解タスクでも強力な性能を示し、オブジェクト中心の事前訓練から下流の幾何学的タスクへの良好な汎化を示しました。

## 5. まとめと所感
### 5.1 論文の意義
Francaは、ビジョン基盤モデルの分野において重要なマイルストーンとなる研究です。すべての側面（訓練コード、データ、モデルの重み、中間チェックポイント）を公開した初のモデルとして、この分野の開放性の新しいベンチマークを設定しました。技術的には、クラスタリングの本質的な曖昧性に対処し、空間バイアスを除去することで、より汎用的で解釈可能な視覚表現を実現しています。

プライベートデータセットに依存せずに最先端の性能を達成したことは、オープンサイエンスの観点から非常に価値があります。また、Matryoshka表現による効率的な多粒度学習は、計算資源が限られた環境でも高性能なビジョンモデルを利用可能にする重要な技術革新です。

### 5.2 今後の展望
今後の研究方向として、より大規模なオープンデータセットでの訓練による性能向上が期待されます。また、RASAのような空間バイアス除去技術を他のビジョンモデルに適用することで、より広範な改善が可能かもしれません。Matryoshka表現の概念は、ビジョン以外のモダリティ（音声、自然言語など）にも拡張できる可能性があり、マルチモーダル学習への応用も興味深い研究方向です。

一方で、訓練に必要な計算資源（最大128個のH100 GPU）は依然として大きく、より効率的な訓練手法の開発が求められます。また、プライバシーやバイアスの観点から、大規模オープンデータセットの使用に関する倫理的考慮も今後重要になるでしょう。