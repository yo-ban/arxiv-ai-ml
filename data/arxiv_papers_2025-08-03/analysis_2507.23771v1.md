# Consensus-Driven Active Model Selection

## 基本情報
- arXiv ID: 2507.23771v1 (https://arxiv.org/abs/2507.23771)
- 著者: Justin Kay、Grant Van Horn、Subhransu Maji、Daniel Sheldon、Sara Beery
- 所属: MIT、UMass Amherst
- 投稿日: 2025年07月31日
- カテゴリ: cs.LG, cs.AI

## 簡単に説明すると
この論文は、多数の学習済みモデルの中から最適なモデルを効率的に選択するための能動的モデル選択手法「CODA」を提案しています。従来は、検証用データセットを作成してすべてのモデルを評価する必要がありましたが、これは時間とコストがかかる作業でした。

CODAは、複数のモデルの予測の合意と不一致を利用して、最も情報量の多いデータポイントを選択的にラベル付けすることで、少ないラベル数で最適なモデルを発見できます。実験では、26のベンチマークタスクにおいて、従来手法と比較して最大70%のラベル削減を達成し、多くの場合25個未満のラベルで最適モデルを特定できることを示しました。

## 1. 研究概要
### 1.1 背景と動機
事前学習済みの機械学習モデルの利用可能性が急速に拡大しています。HuggingFace Modelsリポジトリには190万以上のモデルが公開されており、野生動物モニタリングから医療まで、様々な分野向けのモデルzooも増加しています。これらは、カスタムML開発なしで正確なデータ分析を可能にする一方で、新たな課題をもたらしています。

最大の課題は、利用可能な多数のモデルの中から、特定のデータセットに最適なモデルをどう選ぶかという問題です。従来のモデル選択では、対象データの一部にラベルを付けて各モデルの性能を評価しますが、堅牢な結果を得るには大規模なデータセットが必要で、新しいデータセットごとに多大な人的労力を要します。

特に、教師なしドメイン適応（UDA）の分野では、この問題が顕著です。UDA手法は人間のラベルなしで新しいデータに適応することを目指しますが、実際にはモデル選択のために人間がラベル付けした検証セットに大きく依存しています。この矛盾が、ラベル数を削減できるモデル選択手法の必要性を浮き彫りにしています。

### 1.2 主要な貢献
本研究では、コンセンサス駆動型の能動的モデル選択手法CODAを提案し、以下の重要な貢献をしました。

- モデル間のコンセンサスとベイズ推論を活用し、テスト時のモデル選択に最も有益なラベルを特定する新しい能動的モデル選択手法CODAを導入しました。
- 26の能動的モデル選択タスクからなるベンチマークスイートを作成し、アプローチの検証と既存手法との比較をした。データは公開され、将来の研究を支援する。
- CODAがベンチマークの26タスク中18タスクで最先端性能を達成し、多くの場合わずか25個のラベルで最適または準最適モデルを特定できることを実証しました。
- 副次的な成果として、CODAの初期化ルーチンが26タスク中20タスクで従来の教師なしモデル選択結果に匹敵または上回ることを示した。
- 従来手法の限界（モデル間の関係性の無視、カテゴリ間の相関の無視）を克服する確率的フレームワークを構築しました。

## 2. 提案手法
### 2.1 手法の概要
CODAは、分類器、カテゴリ、データポイント間の関係をモデル化し、より情報に基づいたラベルクエリを行います。古典的な確率モデルであるDawid-Skeneモデルに着想を得て、各分類器をカテゴリごとの性能特性を捉える混同行列で表現します。

システムは3つの主要なステップで動作します。

1. 現在の信念に基づいて各モデルが最良である確率（P_Best）を推定する。
2. 各データポイントにラベルを付けることで得られるP_Best分布の期待情報利得を計算し、最も情報量の多いポイントを選択する。
3. 選択されたデータポイントの真のラベルをクエリし、各モデルの予測を評価して信念を更新する。

重要な設計として、複数のモデルの予測を集約して初期的なコンセンサスラベルを形成し、これを使って各モデルの事前分布を構築します。これにより、ラベル収集プロセスの初期段階から有益な情報を活用できます。

### 2.2 技術的詳細
Dawid-Skeneモデルの拡張として、各分類器h_kの予測プロセスをサイズ(C,C)の混同行列M_kでモデル化します。各行は真のクラス、各列は予測クラスに対応し、条件付き確率P(ĉ_{k,i}=c'|y_i=c)を表します。

コンセンサス事前分布の構築では、まず全モデルの予測確率を合計してコンセンサスラベルを形成します。次に、各モデルの予測とコンセンサスラベルを比較して経験的な混同行列を初期化し、これを基にディリクレ事前分布を構築します。

P_Bestの計算では、各分類器の性能をベータ分布の混合として表現し、あるモデルの性能が他のすべてのモデルを上回る確率を積分により計算します。これにより、単なる点推定ではなく、不確実性を考慮した確率的な評価が可能になります。

データポイント選択では、シャノンエントロピーを用いてP_Bestの不確実性を定量化し、各候補ポイントのラベル付けによる期待情報利得を計算します。仮想的に更新して各仮説的ラベルに対する事後エントロピーを計算し、期待情報利得が最大のポイントを選択します。

### 2.3 新規性
既存手法との主な違いには、次のような点があります。

- モデルを独立に扱うのではなく、モデル間の合意と不一致の情報を活用する確率的フレームワークを構築しました。
- カテゴリごとのモデル誤差の相関を考慮し、データポイント間の関係性を推論に組み込みました。
- 教師なし事前分布を構築することで、ラベル収集の初期段階から有益な情報を活用できるようにしました。
- 重要度サンプリングに依存せず、ベイズ推論により不確実性を適切に扱う手法を実現しました。
- 単純な単一パラメータ分布ではなく、カテゴリごとの性能を考慮した豊かな表現を採用しました。

## 3. 実験結果
### 3.1 実験設定
26の多様なモデル選択ベンチマークタスクを3つの既存ベンチマークから作成し、3500以上の事前学習済みモデルを使用しました。ModelSelectorベンチマークからは、画像とテキストベースの10の分類タスクを選択しました。WILDSベンチマークからは、分布シフトが存在する4つの分類タスクを使用しました。DomainNet126からは、4つのドメインにわたる12の適応タスクを構築しました。

比較手法として、ランダムサンプリング、不確実性サンプリング、Active Testing、VMA、ModelSelectorの5つの能動的モデル選択手法を使用しました。すべての結果は5つのランダムシードの平均として報告し、ハイパーパラメータは固定値を使用しました。

評価指標として、各時刻でのリグレット（選択したモデルと真の最良モデルの損失差）と累積リグレットを使用しました。特に、能動的選択が最も影響力を持つ少数ラベル領域での性能を評価するため、ステップ100での累積リグレットを主要な比較指標としました。

### 3.2 主要な結果
CODAは26データセット中18データセットで既存手法を上回り、多くの場合で大幅な改善を達成しました。

- 5つのデータセットで次善手法と比較して80%以上のリグレット削減を達成
- 11データセットで50%以上の削減
- 15データセットで25%以上の削減

特筆すべきは、CODAの高いラベル効率です。50%以上のタスクで25個未満のラベルで最適または準最適モデルを特定し、80%以上のタスクで100個未満のラベルで同様の結果を達成しました。

ベンチマーク別の結果では、ModelSelectorビジョンタスクとGLUEタスクで一貫して最良の性能を示しました。WILDSタスクでは、バイナリ分類タスクを除いて優れた性能を示しました。DomainNet126では、すべてのドメイン適応タスクで最良または次善の結果を達成しました。

### 3.3 既存手法との比較
ModelSelectorと比較して、CODAは多くのタスクで大幅な改善を示しました。特に初期段階（25ラベル未満）での性能差が顕著で、情報量の多い事前分布の効果が表れています。

Active TestingやVMAなどの重要度サンプリングベースの手法は、初期段階で高い分散を示し、信頼できるモデル選択には多数のアノテーションが必要でした。CODAはこの問題を回避し、少数のラベルでも安定した性能を示しました。

アブレーション研究により、コンセンサス情報に基づく事前分布がCODAの優れた性能の鍵であることが示されました。事前分布を除去すると、ラベル収集プロセスの初期段階でリグレットが最大200%増加しました。また、期待情報利得に基づく獲得関数も、ランダムサンプリングや不確実性ベースのサンプリングと比較して優れた性能を示しました。

## 4. 実用性評価
### 4.1 実装の容易性
CODAは、既存の機械学習パイプラインに容易に統合できる設計となっています。必要なのは候補モデルの予測確率のみで、モデルの内部構造や訓練プロセスに関する情報は不要です。

アルゴリズムは概念的にシンプルで、混同行列の推定、ベイズ更新、情報利得の計算という標準的な確率的操作で構成されています。コードとデータは公開されており、研究者や実務者が容易に利用できます。

ハイパーパラメータは固定値で良好な性能を示し、データセットごとのチューニングは不要です。これは実用的な観点から重要な利点です。

### 4.2 計算効率
CODAの計算コストは、候補モデル数|H|、クラス数C、データポイント数|D|に依存しますが、実用的な範囲では効率的に動作します。

最も計算量の多い操作は、各時刻での期待情報利得の計算です。これはO(|D||H|C²)の計算量を要しますが、並列化が容易で、現代的なハードウェアでは問題になりません。実験では、数千のデータポイントと数百のモデルでも、各ステップの計算は数秒で完了しました。

メモリ使用量は主に混同行列の保存に必要で、O(|H|C²)です。これは大規模な問題でも管理可能な範囲です。

### 4.3 応用可能性
CODAは様々な実用的シナリオで活用できます。モデルzooからの最適モデル選択では、ドメイン固有の知識なしに、少数のラベルで最適なモデルを特定できます。これは特に、新しいドメインやタスクでの迅速な展開に有用です。

ドメイン適応の文脈では、異なるドメインで訓練されたモデルの中から、ターゲットドメインに最適なモデルを効率的に選択できます。これは、完全な再訓練なしに既存モデルを新しい環境に適応させる実用的な方法を提供します。

継続的学習やモデル更新のシナリオでも、新しいデータに対して既存モデルと更新モデルのどちらが優れているかを少数のラベルで判断できます。これにより、モデルの品質を維持しながら、アノテーションコストを削減できます。

## 5. まとめと所感
### 5.1 論文の意義
本研究は、実用的な機械学習システムにおける重要な課題に対する効果的な解決策を提供しています。事前学習済みモデルの爆発的な増加に伴い、ラベル数を削減できるモデル選択はますます重要になっています。CODAは、この課題に対して理論的に健全で実用的な解決策を提示しました。

特に印象的なのは、わずか25個のラベルで多くのタスクで最適モデルを特定できることです。これは、従来手法と比較して桁違いの効率性であり、実用的な影響は計り知れません。アノテーションコストの大幅な削減は、機械学習の民主化に貢献します。

また、確率的フレームワークの採用により、単なるヒューリスティックではなく、原理的な方法でモデル選択を行えることも重要です。これにより、手法の振る舞いが予測可能で、信頼性の高いシステムを構築できます。

### 5.2 今後の展望
著者らは、いくつかの興味深い将来の研究方向を示唆しています。より洗練された事前分布の構築方法、精度以外のメトリクスへの拡張、モデルの信頼度などの予測量を考慮した確率モデルの開発などです。

また、能動的モデル選択を能動学習や能動的テストと並行して実行し、人的労力を最適に配分する方法も興味深い研究課題です。収集したラベルを複数の目的で活用することで、さらなる効率化が期待できます。

実用面では、大規模言語モデルや基盤モデルの選択への応用が期待されます。これらのモデルは評価コストが高いため、CODAのような少数ラベルで動作する選択手法の価値はさらに高まるでしょう。また、マルチモーダルモデルや生成モデルへの拡張も重要な研究方向です。