# MIRAGE-Bench: LLM Agent is Hallucinating and Where to Find Them

## 基本情報
- arXiv ID: 2507.21017 (https://arxiv.org/abs/2507.21017)
- 著者: Weichen Zhang, Yiyou Sun, Pohao Huang, Jiayue Pu, Heyue Lin, Dawn Song
- 所属: University of California, Berkeley
- 投稿日: 2025年07月30日
- カテゴリ: cs.CL, cs.AI

## 簡単に説明すると
この論文は、LLMベースのエージェントにおける幻覚（ハルシネーション）を評価するための初の統一ベンチマーク「MIRAGE-Bench」を提案しています。従来の自然言語生成における幻覚とは異なり、エージェントの幻覚は実際の行動に直結し、潜在的に有害な影響を与える可能性があります。論文では、幻覚を3つのタイプに分類し、6つのリスク設定での評価を通じて、最新のLLMでも30%以上の頻度で幻覚が発生することを示しています。コードとデータは公開されています：https://github.com/sunblaze-ucb/mirage-bench.git

## 1. 研究概要
### 1.1 背景と動機
LLMベースのエージェントは、Webオートメーション、ソフトウェアエンジニアリング、ロボティクスなどの分野で自律システムとして広く展開されています。しかし、従来の自然言語生成における幻覚研究とは異なり、エージェントの幻覚は実際の行動として現れ、システムの安全性に直接的な影響を与えます。

既存のエージェントベンチマークでは幻覚の観察例が散見されますが、統一的な理解や体系的な評価方法が確立されていません。また、確率的な環境のため、幻覚行動の再現が困難であり、従来のテキスト出力の検証に比べてエージェントの行動を検証することは技術的に困難です。

本研究の動機は、エージェントにおける幻覚を体系的に理解し、信頼性の高い評価フレームワークを構築することにあります。

### 1.2 主要な貢献
本論文の主要な貢献は以下の通りです。

- エージェントの幻覚を3つのタイプに分類する統一的な分類体系の提案
- 信頼性の高い再現を可能にするスナップショットベースの誘発戦略の開発
- LLM-as-a-Judge フレームワークを使用した評価ツールキットを含むベンチマークの構築
- 最先端モデルでも幻覚が持続的に発生することを示す実証的洞察の提供

## 2. 提案手法
### 2.1 手法の概要
MIRAGE-Benchは、エージェントの幻覚を文脈的要素（指示、履歴、観察）への不忠実性として定義し、6つのリスク設定で幻覚を誘発します。重要な意思決定ポイントでエージェントの状態を凍結する文脈的スナップショットを使用し、リスク認識型のLLM-as-a-Judgeによる評価します。

6つのリスク設定は以下の通りです。対象範囲外のクエリ、予期しない環境遷移、達成不可能な目標状態、不明確な指示、欠陥のある相互作用履歴、ポップアップによる注意散漫です。

### 2.2 技術的詳細
各リスク設定は、エージェントが遭遇する可能性のある実世界のシナリオを反映しています。対象範囲外のクエリでは、文脈的に適切だが答えられない質問を受け取ります。予期しない環境遷移では、環境が予想される変化を反映しません。

評価には、WebArena、TheAgentCompany、SWE-Bench、OSWorld、WorkArena、τ-benchの6つの多様な環境を使用します。文脈的スナップショット戦略により、決定論的な評価が可能になり、構造を保持しながら文脈的編集による自動スケーリングが実現されます。

### 2.3 新規性
MIRAGE-Benchの主要な新規性は、エージェント特有の幻覚に焦点を当てた初の統一ベンチマークである点です。従来のエージェントベンチマークがタスク完了に焦点を当てているのに対し、本研究は忠実性に着目しています。

スナップショットベースのアプローチにより、確率的環境での再現性の問題を解決し、リスク固有の評価プロンプトを使用したLLM審査員により、スケーラブルで一貫性のある評価を実現しています。

## 3. 実験結果
### 3.1 実験設定
12個のLLM（オープンソース7個、プロプライエタリ5個）を評価しました。決定論的デコーディング（温度=0）を使用し、評価指標として効用スコア（US）と幻覚率（HR）を使用しました。

LLM審査員の妥当性検証では、人間のアノテーションとの一致率、温度変動下での自己一貫性、プロンプト構造の摂動に対する堅牢性を評価しました。

### 3.2 主要な結果
全てのモデルでUS < 0.6およびHR > 0.3が観察され、持続的な幻覚が確認されました。最良のプロプライエタリモデル（Claude-3.7-Sonnet）のUSは0.585、HRは0.290でした。最良のオープンソースモデル（Qwen2.5-32B）のUSは0.581、HRは0.324でした。

エージェントは文脈的サポートがない情報を頻繁に作り出す傾向があり、「推定的幻覚」のパターンはチャットボット訓練からの不整合を示唆しています。一方で、ほとんどのモデルはテキストベースの注意散漫に対して良好な耐性を示しました。

### 3.3 既存手法との比較
LLM審査員は人間のアノテーションとの75-77%の一致率を達成し、温度変動下での自己一貫性は81%以上でした。プロンプト構造の摂動に対しても堅牢性を示しました。

合成データの構造的類似性は99%以上でしたが、実際の軌跡の全ての行動的ニュアンスを捉えられない可能性があります。

## 4. 実用性評価
### 4.1 実装の容易性
MIRAGE-BenchはGitHubで公開されており、研究者が容易に利用できます。スナップショットベースのアプローチにより、新しい環境やタスクへの拡張が比較的簡単です。

ただし、LLM審査員のプロンプト設計には主観性があり、評価の一貫性を保つには注意が必要です。

### 4.2 計算効率
静的スナップショット評価により、完全なロールアウトベースの評価に比べて計算コストが約80%削減されます。LLM-as-a-Judgeアプローチにより、人間のアノテーションなしでスケーラブルな評価が可能です。

ただし、高品質のLLM審査員（例：GPT-4）の使用にはコストがかかります。

### 4.3 応用可能性
MIRAGE-Benchは以下のような応用分野で特に有用と考えられます。

エージェントシステムの安全性評価と改善。

幻覚に強いエージェントアーキテクチャの開発。

実世界展開前のエージェントの信頼性テスト。

ただし、現在はテキストベースの観察を持つデジタルエージェントに限定されており、マルチモーダルエージェントや身体化されたエージェントへの拡張が必要です。また、ReActスタイルのエージェントに焦点を当てているため、より洗練されたアーキテクチャへの一般化には限界があります。

## 5. まとめと所感
### 5.1 論文の意義
この論文は、LLMエージェントの安全性における重要な問題に取り組む先駆的な研究です。MIRAGE-Benchは、エージェントの幻覚に関する体系的な洞察を提供し、実用的な評価フレームワークを確立しました。最先端モデルでも30%以上の頻度で幻覚が発生するという発見は、この研究方向の緊急性を強調しています。

静的評価アプローチには限界がありますが、エージェントの忠実性を評価するための重要な第一歩となっています。

### 5.2 今後の展望
将来の研究方向として、以下が考えられます。

動的ロールアウトベースの評価：複数ステップにわたる連鎖的な幻覚の捕捉。

マルチモーダルエージェントへの拡張：視覚的観察を含むより豊かな文脈での評価。

より洗練されたエージェントアーキテクチャ：異なる認知コンポーネントを持つエージェントの評価。

幻覚緩和技術の開発：エージェント固有のアライメント手法の研究。

実世界のエージェント展開への応用：産業応用における安全性保証のフレームワーク。

この研究は、エージェントシステムの信頼性向上に向けた重要な基盤を提供し、今後の発展が期待される分野です。