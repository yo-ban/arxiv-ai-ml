# Epona: Autoregressive Diffusion World Model for Autonomous Driving

## 基本情報
- arXiv ID: 2506.24113v1 (https://arxiv.org/abs/2506.24113v1)
- 著者: Kaiwen Zhang, Zhenyu Tang, Xiaotao Hu, Xingang Pan
- 共著者: Xiaoyang Guo, Yuan Liu, Jingwei Huang
- 共著者: Li Yuan, Qian Zhang, Xiao-Xiao Long
- 共著者: Xun Cao, Wei Yin
- 所属: Horizon Robotics, Tsinghua University, Peking University
- 追加所属: Nanjing University, HKUST, Nanyang Technological University, Tencent Hunyuan
- 投稿日: 2025年6月20日
- カテゴリ: cs.CV, cs.RO, cs.AI

## 簡単に説明すると
この論文は、自動運転のための新しい世界モデル「Epona」を提案している。Eponaは、自己回帰モデルと拡散モデルの長所を組み合わせた革新的なアプローチを採用している。従来の手法では、長時間の高品質な運転映像生成と正確な軌道計画の両立が困難であったが、Eponaは時空間を分離した処理により、2分以上の高解像度の映像生成と20Hzのリアルタイム軌道計画を実現する。特に、「Chain-of-Forward」という新しい学習戦略により、自己回帰生成における誤差の蓄積問題を解決し、長時間にわたって安定した品質を維持できる。

## 1. 研究概要
### 1.1 背景と動機
近年、ビデオ生成モデルの急速な発展により、世界モデルは物理世界のシミュレーションと自律的な意思決定のための強力なパラダイムとして注目を集めている。特に自動運転において、従来の知覚-計画パイプラインとは異なり、生成的な運転世界モデルは視覚的なシーン理解と将来予測を自己教師あり学習で統合し、人間のような端到端の自動運転への新しい解決策を提供する。

既存の生成的世界モデルは主に2つのカテゴリに分類される。拡散ベースのアプローチ（例：Vista）は、固定長ビデオの結合分布モデリングにより印象的な視覚的忠実度を達成するが、タイムステップごとの局所分布をモデル化できないという根本的な制限がある。この制限により、動的な世界シミュレーションに不可欠な可変長の長距離予測のサポートが困難になり、マルチモーダル予測メカニズムの欠如により軌道計画が実現不可能になる。

一方、GPTスタイルのアプローチ（例：GAIA-1）は、自己回帰的な次トークン予測により時間的な柔軟性に対処するが、量子化とトークン化のプロセスにより視覚的品質と計画精度が著しく劣化する。さらに、自己回帰トランスフォーマーの因果的性質により、長期的な軌道計画ではなく次のアクションの予測に制限され、端到端の運転プランナーとしての可能性が制限される。

### 1.2 主要な貢献
Eponaは以下の3つの主要な革新により、高解像度の長期ビデオ生成と正確な軌道計画を実現する。

1. **時空間の分離ファクタリゼーション**: 既存のビデオ拡散手法が過去と未来のフレームの結合した時空間分布をモデル化するのに対し、Eponaは時空間を分離した処理を行う。GPTスタイルのトランスフォーマーが圧縮された潜在空間で因果的注意により時間的ダイナミクスを処理し、2つの拡散トランスフォーマーが空間的レンダリングと軌道生成を別々に処理する。

2. **非同期マルチモーダル生成**: 並列デノイジングプロセスを通じて、軌道計画と視覚生成を分離する。2つの特化したDiTが3秒間の車両軌道と次フレーム画像を非同期に生成し、両ストリームは同じ時間的な潜在表現に条件付けられたフローマッチング目的を共有する。

3. **Chain-of-Forward学習戦略**: 自己回帰ループにおける誤差蓄積とコンテンツドリフトに対処する新しい学習戦略を導入する。これにより、モデルは自身の予測によるドリフトに対して堅牢になるよう訓練される。

## 2. 提案手法
### 2.1 手法の概要
Eponaは、自動運転のための自己回帰的な拡散世界モデルとして、3つの主要なコンポーネントから構成される。まず、マルチモーダル時空間トランスフォーマー（MST）が、過去のシーンと軌道の履歴コンテキストをコンパクトな潜在表現にエンコードする。次に、この履歴潜在表現に基づいて、2つの特化した拡散トランスフォーマーが細かい未来の詳細を予測する。軌道計画トランスフォーマー（TrajDiT）は軌道計画のためのポリシーをモデル化し、次フレーム予測トランスフォーマー（VisDiT）は未来の画像生成のための視覚分布をモデル化する。

このモジュラー設計により、様々な自動運転アプリケーションが可能になる。例えば、MSTとVisDiTは制御可能な運転シミュレーションのために独立して使用でき、MSTとTrajDiTはリアルタイム動作計画を実現する。

### 2.2 技術的詳細
**世界モデルの再定式化**:
既存のビデオ拡散ベースの世界モデルは、過去と固定長の未来の両方のグローバルな時空間分布を共同でキャプチャします。これは履歴観測と未来予測の間の因果的な時間構造を破壊し、実世界の進行的ダイナミクスをモデル化し、柔軟な長さの長期ビデオを生成する能力を制限します。

Eponaは、世界モデリングを時間領域での逐次的な未来予測プロセスとして定式化します。具体的には、過去の運転観測と運転軌道が与えられたとき、モデルは未来の軌道計画のためのポリシーと、次フレームのカメラ観測全体に対する条件付き分布の両方を予測します。

**マルチモーダル時空間トランスフォーマー（MST）**:
MSTは、インターリーブされたマルチモーダル空間注意層と因果的な時間注意層を採用する。この設計により、履歴情報をコンパクトな潜在表現に段階的に組み込みながら、フルシーケンス注意と比較してメモリ消費を大きく削減する。

**軌道計画拡散トランスフォーマー（TrajDiT）**:
TrajDiTは、MSTからの潜在埋め込みに条件付けられて、3秒間の未来軌道を生成します。わずか50Mパラメータの軽量設計により、0.05秒で長期軌道計画を生成でき、リアルタイムモーションプランナーとして機能します。

**次フレーム予測拡散トランスフォーマー（VisDiT）**:
VisDiTは、過去のコンテキストと（予測または提供された）次の動作に条件付けられて、高解像度の次フレーム画像を生成します。効率を向上させるため、事前学習済みの深層圧縮エンコーダを使用して画像をコンパクトな潜在表現にエンコードし、潜在拡散モデルを採用します。

**Chain-of-Forward学習戦略**:
自己回帰モデルの主要な課題は、誤差蓄積とコンテンツドリフトへの脆弱性です。これに対処するため、Eponaは新しいChain-of-Forward学習戦略を導入します。訓練中、モデルは定期的に自身の予測を使用して複数ステップ先を生成し、これらの生成されたフレームで訓練を続けます。これにより、モデルは自身の不完全な予測に対して堅牢になり、長期生成時のドリフトを軽減します。

### 2.3 新規性
Eponaの新規性は以下の点にある。

1. **時空間分離アーキテクチャ**: 時間的因果モデリングと空間的な詳細生成を分離することで、従来の手法の制限を克服し、柔軟な長さの高品質ビデオ生成を可能にする。

2. **マルチモーダル統合**: 視覚生成と軌道計画を統一された潜在空間で共同学習することで、両タスクの性能を相互に向上させる。

3. **Chain-of-Forward戦略**: 自己回帰生成における長年の課題である誤差蓄積問題に対する実用的な解決策を提供する。

4. **実用的な効率性**: 軌道計画と視覚生成を分離することで、20Hzのリアルタイム軌道計画を実現し、実用的な自動運転システムへの適用を可能にする。

## 3. 実験結果
### 3.1 実験設定
Eponaは2.5Bパラメータから構成され、1.3BパラメータのMST、1.2BパラメータのVisDiT、50MパラメータのTrajDiTを含みます。モデルはNuPlanデータセットの公開ビデオとNuScenesデータセットの700シーンでゼロから訓練されました。すべての画像は512×1024にリサイズされ、ビデオ生成と軌道計画の両タスクに整流フロー目的を使用して、エンドツーエンドで訓練されました。

評価は以下のベンチマークで実施されました。
- ビデオ生成：NuPlanテストセットの1628クリップとNuScenes検証データセットの1646クリップを使用しました。評価指標としてFVD（Fréchet Video Distance）とFID（Fréchet Inception Distance）を用いました。
- 軌道計画：NuScenesベンチマークとNAVSIMベンチマークで評価しました。

### 3.2 主要な結果
**ビデオ生成**:
NuScenesデータセットでの定量的比較において、Eponaは高性能なFVDスコアを達成しました。特筆すべきは、既存手法（Vista等）が大規模データセットで事前学習されたビデオ拡散モデルをファインチューニングしているのに対し、Eponaは次フレームDiTを含めてゼロから訓練されていることです。さらに、Eponaは既存のアプローチと比較して8倍長いビデオフレーム（600フレーム、2分以上）を生成できます。

**軌道計画**:
NAVSIMベンチマークにおいて、Eponaは強力な端到端プランナーを上回る性能を示した。全体的なPDMSスコアで86.2を達成し、知覚入力（3Dボックスやレーン）を使用しない条件下で優れた結果を示した。NuScenesベンチマークでも、追加の監督なしに競争力のある性能を達成し、特に1秒ホライズンで最低の衝突率（0.01%）を記録した。

**定性的結果**として、以下の点が確認された。
1. 軌道制御されたビデオ生成：事前定義された軌道に基づいて、対応する動作パスに従う未来フレームを生成できることを実証した。
2. 長時間ビデオ生成：分単位の運転ビデオを高い忠実度と一貫性で生成し、顕著なドリフトがないことを確認した。
3. 交通ルールの理解：赤信号で停止するなど、基本的な交通ルールを理解していることを実証した。

### 3.3 既存手法との比較
Eponaは以下の点で既存手法を上回った。

**Vistaとの比較**において、以下の改善が見られた。
- FVDで7.4%の改善を達成した。
- 生成長を15秒から2分以上に拡張した（8倍）。
- より高い視覚的品質と時間的一貫性を実現した。

**GPTスタイル手法との比較**では、以下の利点があった。
- 量子化による品質劣化がない。
- 連続空間での動作により、豊富なシーン詳細を保持できる。
- 長期軌道計画が可能である（次アクションのみではない）。

**計画性能**に関しては、以下の成果を達成した。
- NAVSIMで多くの端到端手法を上回った。
- カメラのみ使用で高い性能を達成した。
- リアルタイム推論（20Hz）が可能である。

## 4. 実用性評価
### 4.1 実装の容易性
Eponaの実装は、モジュラー設計により比較的容易です。各コンポーネント（MST、TrajDiT、VisDiT）は独立して使用可能で、特定のアプリケーションニーズに応じて組み合わせることができます。コードは公開予定で、研究コミュニティでの再現と拡張を可能にします。

ただし、2.5Bパラメータのモデルサイズについて考慮が必要です。48台のNVIDIA A100 GPUで2週間の訓練が必要な点は、計算リソースの制約がある研究グループにとって課題となる可能性があります。

### 4.2 計算効率
推論速度の面では、Eponaは実用的な性能を示す。
- MST：約0.02秒/フレーム
- TrajDiT：約0.03秒（10ステップ）、0.3秒（100ステップ）
- VisDiT：約0.3秒（10ステップ）、2秒（100ステップ）

特に、MSTとTrajDiTの組み合わせにより、20Hzでのリアルタイム軌道計画が可能です。これは実際の自動運転システムの要件を満たしています。

### 4.3 応用可能性
Eponaの応用可能性は広範囲に及ぶ。

1. **自動運転シミュレーション**: 長時間の高品質な運転シーンを生成し、エッジケースのテストやトレーニングデータの拡張に使用可能である。
2. **リアルタイムモーションプランニング**: 軽量なTrajDiTにより、実車での展開が可能である。
3. **人間-機械インタラクション**: 軌道制御可能な生成により、運転意図の可視化やWhat-ifシナリオの探索が可能である。
4. **安全性検証**: 交通ルールの理解を活用した、自動運転システムの安全性評価に活用できる。

特に興味深いのは、Eponaが自己教師あり学習のみで交通ルールを学習する能力です。これは、明示的な規則プログラミングなしに、より人間らしい運転行動を実現する可能性を示唆しています。

## 5. まとめと所感
### 5.1 論文の意義
この論文は、自動運転のための世界モデルにおいて重要な技術的進歩を示しています。自己回帰モデルと拡散モデルの長所を巧みに組み合わせることで、従来の手法の限界を克服し、実用的な性能を達成しました。特に、時空間の分離処理という設計選択は、長期生成と計算効率の両立という困難な課題に対する洗練された解決策です。

Chain-of-Forward学習戦略は、自己回帰生成における長年の課題に対する実用的なアプローチとして評価できます。この手法は、他の自己回帰生成タスクにも適用可能な一般性を持つ可能性があります。

また、世界モデルが自己教師あり学習のみで交通ルールを理解できることの実証は、今後の自動運転システムの方向性を示す重要な知見です。これは、大規模な注釈付きデータセットへの依存を減らし、より柔軟で適応的なシステムの開発につながる可能性があります。

### 5.2 今後の展望
今後の研究方向として以下が考えられる。

1. **より長期の生成**: 現在の2分を超えて、より長時間の一貫した生成を実現する手法の開発が必要である。
2. **マルチビュー拡張**: 現在の単一カメラから、サラウンドビューへの拡張が期待される。
3. **不確実性の扱い**: 確率的な未来予測と不確実性の定量化の実現が求められる。
4. **計算効率の改善**: より軽量なアーキテクチャの探索と、エッジデバイスでの展開が課題である。
5. **実世界での検証**: 実車両における性能評価と安全性の検証が重要である。

制限事項として、現在のモデルは前方カメラのみを使用しており、3Dシーン理解や他のセンサーモダリティの統合が今後の課題です。また、生成された軌道の安全性保証や、予期しない状況への対応能力の評価も重要な研究課題です。

総合的に見て、Eponaは自動運転のための世界モデルにおいて重要なマイルストーンを示しており、視覚的理解と行動計画を統合した新しい自動運転システムへの道を開いています。