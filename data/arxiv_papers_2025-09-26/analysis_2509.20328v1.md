# Video models are zero-shot learners and reasoners

## 基本情報
- arXiv ID: 2509.20328v1 (https://arxiv.org/abs/2509.20328)
- 著者: Thaddäus Wiedemer*, Yuxuan Li, Paul Vicol, Shixiang Shane Gu
- 共著者: Nick Matarese, Kevin Swersky, Been Kim
- 共同責任者: Priyank Jaini*, Robert Geirhos*
- 貢献: *Equal contribution
- 所属: Google DeepMind
- 投稿日: 2024年9月26日
- カテゴリ: cs.CV, cs.AI

## 簡単に説明すると

この論文は、Veo 3という動画生成モデルが、言語モデルと同様にゼロショット学習能力を持つことを実証した研究です。
研究者らは、Veo 3が明示的に訓練されていない幅広いタスクを解決できることを示しました。
具体的には、物体のセグメンテーション、エッジ検出、画像編集、物理特性の理解、物体の機能認識、道具の使用シミュレーションなど多岐にわたります。
18,384個の生成動画にわたる62の定性的タスクと7の定量的タスクで実験しました。
Veo 3は視覚世界を知覚、モデリング、操作する能力により、迷路解決や対称性問題などの初歩的な視覚的推論も実現しました。
この研究は、動画モデルがNLPにおけるLLMと同様に、コンピュータビジョンの汎用基盤モデルへと発展する可能性を示唆しています。
プロジェクトページはhttps://video-zero-shot.github.io/で公開されています。

## 1. 研究概要

### 1.1 背景と動機

近年、自然言語処理の分野は大規模言語モデル（LLM）による大きな変化を遂げました。
以前はタスク固有のモデル（翻訳用、質問応答用、要約用など）が主流でしたが、現在はLLMが統合基盤モデルとして機能しています。
この変化は単純な原理から生まれました。
大規模な生成モデルをウェブスケールのデータセットで訓練することです。
その結果、LLMはプロンプトのみで新しいタスクを解決するゼロショット学習能力を獲得しました。

一方、現在のコンピュータビジョンは数年前のNLP分野と類似した状況にあります。
セグメンテーション用の「Segment Anything」、物体検出用のYOLO変種など、優れたタスク固有モデルが存在します。
しかし、プロンプトのみで任意の視覚問題を解決できる統一モデルは存在しませんでした。

研究者らは重要な洞察を得ました。
NLPでゼロショット学習を可能にした同じ原理が、現在の生成動画モデルにも適用されることです。
大規模訓練と生成的目標（テキスト/動画の続き）をウェブスケールデータで行うことです。
この並行性により、研究者らは重要な問題を提起しました。
動画モデルも、LLMが汎用言語理解を発達させたように、汎用視覚理解を発達させるのでしょうか。

### 1.2 主要な貢献

この研究は、動画モデルがゼロショット学習者かつ推論者として機能することを実証した画期的な成果です。
論文の主要な貢献は以下の通りです。

包括的な評価として、18,384個の生成動画にわたって62の定性的タスクと7の定量的タスクで評価を実施しました。
Veo 3が訓練や適応を受けていない幅広いタスクを解決できることを実証しました。

能力の段階的構造として、Veo 3が視覚世界を知覚、モデリング、操作する能力を持つことを明らかにしました。
これらの能力により「Chain-of-Frames（CoF）」と呼ばれる初歩的な視覚推論が可能になります。
迷路解決や対称性問題などが含まれます。

急速な進歩の実証として、タスク固有の特化モデルがまだゼロショット動画モデルを上回る性能を示すものの、Veo 2からVeo 3への大幅で一貫した性能向上を観察しました。
これは動画モデルの能力が急速に進歩していることを示します。

## 2. 提案手法

### 2.1 手法の概要

この研究の核心は、既存の動画生成モデルVeo 3の能力を体系的に評価することにあります。
研究者らは特別な訓練や微調整をせず、純粋にゼロショット設定でVeo 3の能力を検証しました。
手法の特徴は、LLMのプロンプトエンジニアリングと類似したアプローチを視覚タスクに適用することです。

評価フレームワークは4つの階層構造で組織されています。
知覚レベルでは、セグメンテーション、エッジ検出、深度推定などの基本的な視覚タスクを評価します。
モデリングレベルでは、3D回転、衝突シミュレーション、物理特性理解などの世界モデル能力を評価します。
操作レベルでは、画像編集、インペインティング、物体変形などの視覚コンテンツ操作能力を評価します。
推論レベルでは、迷路解決、対称性問題、空間推論などの高次認知能力を評価します。

各タスクに対して、研究者らは慎重にプロンプトを設計しました。
テキストプロンプトと視覚プロンプト（開始フレーム）の両方を含みます。
例えば、迷路解決タスクでは、迷路の画像を提供し「この迷路を解いてください」とテキストで指示します。
モデルは解決パスを示す動画を生成することが期待されます。

### 2.2 技術的詳細

実験設計では、定性的評価と定量的評価の両方を実施しました。
定性的評価では62のタスクカテゴリにわたって幅広い能力を検証しました。
各タスクについて複数の試行をして、成功率を算出します。
定量的評価では7つの具体的なタスクについて厳密な指標を用いて性能を測定しました。

プロンプト設計は研究の重要な側面です。
視覚タスクにおけるプロンプトは、テキスト指示だけでなく視覚的な開始フレームも含みます。
研究者らは異なるプロンプト表現がタスク性能に与える影響を検討しました。
同じタスクでも異なる視覚表現（例：迷路を白黒格子、ゲーム画面、写実的シーンで表現）が可能です。

評価指標として、pass@1とpass@10を使用しました。
pass@1は最初の試行での成功率、pass@10は10回の試行での最大成功率を示します。
これにより、モデルの一貫性と潜在能力の両方を測定できます。
スケーリング結果では、pass@10がpass@1を一貫して上回り、プラトーの兆候は見られませんでした。

### 2.3 新規性

この研究の新規性は、動画生成モデルをゼロショット学習の観点から体系的に評価した初めての包括的研究である点にあります。
従来の動画モデル研究は主に生成品質やリアリズムに焦点を当てていました。
この研究は、動画モデルが視覚理解と推論の汎用ツールとして機能する可能性を初めて実証しました。

階層的能力フレームワーク（知覚→モデリング→操作→推論）は、視覚AIの能力を体系的に分析する新しいアプローチです。
これにより、動画モデルの能力を単なる生成から認知的な視覚理解まで拡張して捉えることができます。

Chain-of-Frames（CoF）という概念の提案も重要な新規性です。
これは、NLPにおけるChain-of-Thoughtの視覚版として、フレーム間の連続的な変化を通じて複雑な推論をする能力を表します。
この概念により、動画モデルの推論能力を理論的に位置づけることができます。

## 3. 実験結果

### 3.1 実験設定

実験は大規模かつ体系的に設計されました。
合計18,384個の動画を生成し、62の定性的タスクと7の定量的タスクで評価を実施しました。
タスクは4つのカテゴリに分類されます。
知覚タスク（セグメンテーション、エッジ検出、深度推定など）に加えて、モデリングタスク（3D変換、物理シミュレーション、材質理解など）があります。
さらに、操作タスク（編集、インペインティング、スタイル変換など）、推論タスク（迷路解決、対称性問題、空間推論など）に分類されます。

各タスクについて、研究者らは慎重に設計されたプロンプトを使用しました。
プロンプトには、タスクを明確に指定するテキスト指示と、対応する視覚的開始フレームが含まれます。
評価には人間の判定者による定性評価と、可能な場合は定量的指標を使用しました。

比較として、Veo 2との性能比較を実施しました。
これにより、動画モデルの急速な進歩を定量化できます。
また、可能な場合は既存のタスク固有モデルとの比較も行いました。

### 3.2 主要な結果

実験結果は、Veo 3の驚くべきゼロショット能力を明らかにしました。
知覚タスクでは、物体セグメンテーション、エッジ検出、深度推定など多くの基本的視覚タスクで良好な性能を示しました。
モデリングタスクでは、3D物体の回転、衝突のシミュレーション、重力や空気抵抗などの物理法則の理解を実演しました。

操作タスクでは、画像のインペインティング、背景除去、色付け、スタイル変換など多様な編集操作を成功裏に実行しました。
最も印象的なのは推論タスクでの成果です。
迷路解決では、複雑な経路探索問題を視覚的に解決しました。
対称性パズルでは、パターンの完成や変換を論理的に推論しました。

Veo 2からVeo 3への進歩は顕著でした。
ほぼすべてのタスクカテゴリで大幅な性能向上が観察されました。
特に推論タスクでは、Veo 2ではほとんど成功しなかった課題でVeo 3が高い成功率を示しました。

pass@10とpass@1の比較では、pass@10が一貫して高い値を示しました。
これは、モデルが潜在的にタスクを解決する能力を持ちながら、一貫性において改善の余地があることを示唆します。

### 3.3 既存手法との比較

タスク固有の特化モデルとの比較では、予想通りVeo 3は多くのタスクで特化モデルを下回る性能を示しました。
例えば、セグメンテーションタスクではSegment Anythingモデルが、物体検出ではYOLO系モデルが優れた性能を維持しています。

しかし、この性能差は初期のLLMが経験した状況と類似しています。
GPT-3も発表当初は多くのタスクで微調整された特化モデルを下回る性能でした。
重要なのは、Veo 3がVeo 2から短期間で大幅な向上を示したことです。

汎用性の観点では、Veo 3は既存のどのモデルも達成していない幅広いタスク対応能力を実証しました。
単一のモデルで知覚から推論まで対応できる初の実例となりました。

また、推理時スケーリングの効果も確認されました。
複数回の生成試行により成功率の向上が示され、さらなる改善の可能性を示唆しました。

## 4. 実用性評価

### 4.1 実装の容易性

Veo 3の利用は比較的簡単です。
特別な訓練や微調整を必要とせず、プロンプト設計のみでタスクを実行できます。
これは、従来のタスク固有モデルの訓練や配置と比較して大幅な簡素化を意味します。

ただし、効果的なプロンプト設計には専門知識が必要です。
視覚タスクにおけるプロンプトエンジニアリングは、テキストプロンプトと視覚プロンプトの両方を最適化します。
同じタスクでも異なる表現方法により性能は大きく変化する可能性があります。

実装上の課題として、動画生成の計算コストがあります。
現在のところ、特化モデルよりも高い計算資源を必要とします。
しかし、汎用モデルの経済性は予測可能な軌道にあり、推論コストは急速に低下しています。

### 4.2 計算効率

現時点では、動画生成は特化モデルよりも計算コストが高いです。
しかし、NLP分野の経験から、この状況は改善される可能性が高いです。
Epoch AIの推定によると、LLMの推論コストは同一性能レベルで年間9倍から900倍のペースで低下しています。

初期のGPT-3も「サイズの大きさで配置が困難」と考えられていました。
しかし、急速な推論コスト削減と汎用モデルの魅力により、タスク固有言語モデルの多くを置き換えました。
NLPを参考にすれば、同様の傾向が視覚分野でも展開される可能性があります。

pass@10がpass@1を一貫して上回る結果は、推理時スケーリング手法の有効性を示します。
自動検証器との組み合わせにより、さらなる性能向上が期待できます。
現在のVeo 3は、指示チューニングやRLHFを施していない事前訓練モデルに相当します。

### 4.3 応用可能性

Veo 3の応用可能性は極めて広範囲にわたります。
教育分野では、視覚的な概念説明や実験シミュレーションに活用できます。
デザイン分野では、プロトタイプの視覚化や編集作業を支援できます。
研究分野では、仮説検証のための視覚実験を実施できます。

製造業では、品質検査や異常検出への応用が考えられます。
医療分野では、画像診断支援や治療計画の視覚化に活用できる可能性があります。
エンターテインメント分野では、インタラクティブなコンテンツ制作を支援できます。

特に注目すべきは、従来複数の専用ツールが必要だった作業を単一のモデルで実行できることです。
これにより、ワークフローの大幅な簡素化が実現できます。

## 5. まとめと所感

### 5.1 論文の意義

この研究は、コンピュータビジョンの歴史において重要な転換点を示す画期的な成果です。
NLPにおけるLLMの台頭と同様の変革が、動画モデルによって視覚分野でも始まる可能性を実証しました。
単一の汎用モデルが幅広い視覚タスクをゼロショットで解決できることは、従来のパラダイムに根本的な変化をもたらします。

研究の学術的価値は、体系的な評価フレームワークの構築にあります。
知覚、モデリング、操作、推論という4層構造は、視覚AI能力の分析における新しい標準となる可能性があります。
Chain-of-Framesという概念も、視覚推論研究の新しい方向性を示しています。

実用的観点では、この研究は視覚AIアプリケーションの開発アプローチを根本的に変える可能性があります。
タスクごとに専用モデルを開発する従来のアプローチから、汎用モデルをプロンプトで制御するアプローチへ転換することです。

### 5.2 今後の展望

この研究が示す方向性は、今後のコンピュータビジョン研究に大きな影響を与えるでしょう。
まず、動画モデルのスケーリングによるさらなる能力向上が期待されます。
Veo 2からVeo 3への急速な進歩は、この傾向が継続する可能性を示唆しています。

推理時スケーリング手法の発展も重要な研究方向です。
複数回の生成試行と自動検証の組み合わせにより、一貫性と精度の向上が期待できます。
また、指示チューニングやRLHFの適用により、さらなる性能向上が可能でしょう。

長期的には、この研究は「視覚のためのGPT-3モーメント」の到来を示唆しています。
タスク固有モデルから汎用基盤モデルへの転換により、視覚AI分野全体のアプローチの変革が可能になります。
これは、研究だけでなく産業応用においても大きな影響を与えるでしょう。