# SciReasoner: Laying the Scientific Reasoning Ground Across Disciplines

## 基本情報
- arXiv ID: 2509.21320v1 (https://arxiv.org/abs/2509.21320)
- 著者: Yizhou Wang, Chen Tang, Han Deng, Jiabei Xiao, Jiaqi Liu, Jianyu Wu, Jun Yao, Pengze Li, Encheng Su, Lintao Wang, Guohang Zhuang, Yuchen Ren, Ben Fei, Ming Hu, Xin Chen, Dongzhan Zhou, Junjun He, Xiangyu Yue, Zhenfei Yin, Jiamin Wu, Qihao Zheng, Yuhao Zhou, Huihui Xu, Chenglong Ma, Yan Lu, Wenlong Zhang, Chunfeng Song, Philip Torr, Shixiang Tang, Xinzhu Ma, Wanli Ouyang, Lei Bai
- 所属: Shanghai Artificial Intelligence Laboratory, The Chinese University of Hong Kong, The University of Sydney, University of Science and Technology of China, Beihang University, Fudan University, Shanghai Jiao Tong University, University of Oxford
- 投稿日: 2025年09月27日（推定）
- カテゴリ: cs.AI, cs.LG

## 簡単に説明すると

SciReasonerは、自然言語と科学データ（DNA/RNA配列、タンパク質配列、化学分子、材料データ）を統合した、科学推論に特化した大規模言語モデルである。従来の科学系AIモデルが特定分野に限定されていたり、単純なパターン認識に留まっていたのに対し、このモデルは複数の科学分野にまたがった103のタスクを1つのモデルで処理し、かつ段階的な推論過程（Chain-of-Thought）を生成できる点が画期的である。

206億トークンの多様な科学データで事前学習し、4000万の指示データで微調整、さらに強化学習による推論能力の向上を行っている。化学分子の性質予測、タンパク質機能解析、材料設計、科学文献の知識抽出など、幅広い科学研究ワークフローをサポートする。

関連リンク
- HuggingFace: https://huggingface.co/SciReason
- GitHub: https://github.com/open-sciencelab/SciReason

## 1. 研究概要
### 1.1 背景と動機

近年、GPT、Qwen、LLaMAなどの大規模言語モデルは自然言語処理、画像認識、音声処理において目覚ましい成果を上げている。一方で、化学、生物学、材料科学といった科学分野への適用は未だ発展途上の段階にある。

科学分野では、SMILES（分子構造表記）、FASTA（タンパク質配列）、結晶構造データなど、自然言語とは根本的に異なる構造と意味を持つドメイン固有の表現が多用されている。これらの科学的表現と自然言語を統合し、分子特性予測、生体分子工学、複雑な実験データの解釈などの応用を可能にするには、記号的、数値的、配列ベースの知識を自然言語理解と統合できる基盤モデルが必要である。

既存の科学系大規模言語モデルには課題がある。専門特化型（Bio-T5、ChemLLM等）は特定分野に限定され転移学習が困難である。多分野対応型（NatureLM、UniGenX等）はタスク数が限定的（30タスク程度）で科学推論能力が不足している。これらのモデルは浅いパターンベースの予測に留まり、科学者が理論とデータから結論を導く多段階推論プロセスを再現できていない。

### 1.2 主要な貢献

この研究は、多表現事前学習と指示調整、推論誘導後学習を組み合わせた初の科学推論大規模言語モデルを提案している。

以下が主要な技術的貢献である。

- 適応的科学推論機能: すべての科学タスクが明示的推論を必要とするわけではないことを観察し、答えベースマッチングの頑健性を活用して、推論が必要な場合のみ信頼性の高いCoT（Chain-of-Thought）教師データを生成する手法を開発した
- タスクグループ報酬システム: 距離ベース報酬（科学予測）、マッチングベース報酬（科学検索・抽出）、科学ツール検証報酬の3カテゴリに科学報酬を分類し、異なるタスク間での共通知識共有を促進する方式を提案した
- 科学報酬ソフト化手法: 従来の二値報酬（True/False）を連続的な[0,1]範囲にスケール変換し、強化学習の安定性と収束性を向上させた
- 包括的科学能力の実現: 5つの主要ファミリで最大103タスクをサポート（科学翻訳、テキスト・知識抽出、特性予測、特性分類、配列生成・設計）し、54タスクで最高性能、101タスクでトップ2性能を達成した

## 2. 提案手法
### 2.1 手法の概要

SciReasonerは3段階の学習パイプラインで構築されている。

事前学習段階では、206億トークンの混合「ウォームアップ」コーパスを使用し、科学的構文と配列にベースモデルを適用させる。このコーパスは科学テキストと一般テキスト、純粋配列、配列-テキストペア、配列-配列ペアを組み合わせ、DNA/RNA、タンパク質、小分子、材料データを包含している。

教師あり微調整（SFT）段階では、これらの領域にわたる100以上の厳選された科学サブタスクを集約し、特性予測や配列-テキスト変換などの実用的な研究目標にモデルを適用させる。

推論段階では、根拠拡張コーパスを導入し、高速回答モード（Instant）と段階的推論モード（Thinking）の2つの使用モードをサポートして複雑な問題を解決する。

### 2.2 技術的詳細

事前学習データの構成について説明する。

- 科学テキストデータ: PubMed、PubChem、教科書、材料データベースから収集
- 純粋配列データ: DNA/RNA（300億トークン）、タンパク質（400億トークン）、小分子SMILES/IUPAC/SELFIES（500億トークン）
- 配列ペアデータ: 学際間の例（タンパク質構造、材料化学、科学文献）
- 一般テキストデータ: C4データセットを使用してモデルの言語能力を維持

推論誘導手法の詳細は以下の通りである。

1. コールドスタート段階: DeepSeek-R1-Distill-Qwen-32Bを使用してCoT-回答ペアを生成し、正解のみを保持
2. アニール型コールドスタート適用: 推論タスクではCoT拡張データに完全置換、即答タスクでは元のSFTデータを保持
3. 強化学習段階: DAPO（Direct Advantage Policy Optimization）アルゴリズムを採用し、グループ標準化利得と報酬ソフト化を実装

報酬設計では3つのカテゴリに分類している。距離ベース報酬（回帰タスク）、マッチングベース報酬（検索・抽出）、ツール検証報酬（科学ソフトウェア検証）に分類し、各タスクメトリクスを[0,1]範囲に正規化する単調校正関数g(·)を適用している。

### 2.3 新規性

既存手法との主要な差別化ポイントを述べる。

統合アーキテクチャにおいて、従来の専門特化モデル（Bio-T5系、ChemLLM等）が単一分野に限定されるのに対し、SciReasonerは自然言語、DNA/RNA、タンパク質、分子、材料表現を単一バックボーンで統合している。

推論能力について、NatureLM、UniGenXなどの既存多分野モデルがパターンベース予測に留まるのに対し、明示的な多段階推論トレースを生成し、科学者の思考プロセスを再現している。

タスクカバレッジでは、既存モデルが30タスク程度に限定されるのに対し、103タスクという拡張を実現している。

適応的推論システムにより、タスク特性に応じて推論の必要性を判断し、リソース効率を最適化する「インスタント」と「シンキング」モードの切り替え機能を提供している。

物理制約対応機能として、単位整合性、化学量論的一貫性、制約満足を強化学習の報酬関数に組み込み、科学的妥当性を保証している。

## 3. 実験結果
### 3.1 実験設定

評価対象として、5つの科学能力ファミリーにわたる103タスクで包括的評価を実施している。

ベースライン比較では以下のモデルを使用している。

- 汎用クローズドソースモデル: Gemini-2.5-pro、GPT-o3
- 汎用オープンソースモデル: GPT-oss-120B
- 専門特化モデル: 非言語モデル（Transformerエンコーダベース）、専門LLM（各タスクの最高性能モデル）

データセットの詳細は以下である。

- 分子表現翻訳タスク: SMILES-IUPAC、SMILES-Formula等の相互変換
- 自然言語翻訳タスク: 分子記述、分子キャプション生成
- タンパク質機能翻訳タスク: CASPSimilarSeq、IDFilterSeq、UniProtSeq
- 特性予測・分類タスク: 化学特性、材料特性、DNA/RNA予測、タンパク質機能
- 生成・設計タスク: 無条件生成、条件付き設計タスク

評価指標として、タスク特性に応じてTop1 Split Match、Element Match、ROUGE-L、MENTOR、正確度等を使用している。大規模テストセット（1000サンプル超）では計算コスト削減のため1000サンプルをランダムサンプリングしている。

### 3.2 主要な結果

科学翻訳タスクでは圧倒的な性能を示している。

- SMILES-IUPAC変換: SciReasoner-8B 56.63% vs 専門LLM 29.00%
- IUPAC-SMILES変換: SciReasoner-8B 84.40% vs 専門LLM 70.10%
- 分子記述生成: SciReasoner-8B ROUGE-L 0.78 vs 専門LLM 0.29
- タンパク質機能翻訳: 全3タスクでROUGE-L 0.82-0.88を達成、専門LLMの0.70-0.74を上回る

汎用モデルとの比較結果を示す。Gemini-2.5-proは分子表現翻訳で4.70%（SMILES-IUPAC）という低性能を示し、GPT-oss-120Bは19.88%（SMILES-Formula）に留まる一方、SciReasonerは95%超の高精度を実現している。

モデルサイズ効果について、1.7Bモデルでも多くのタスクで専門LLMを上回る性能を示し、8Bモデルではさらに顕著な性能向上を確認している。小規模モデルでも科学推論能力が効果的に学習されることを実証している。

推論能力の定性的評価では、複雑な科学問題に対して段階的な推論プロセスを生成し、中間ステップの妥当性と最終回答の正確性を両立している。従来モデルが提供できない解釈可能な推論過程を実現している。

### 3.3 既存手法との比較

専門特化モデルとの比較を述べる。Bio-T5/T5+は21タスク、UniGenXは22タスクの対応に留まるのに対し、SciReasonerは103タスクという5倍のカバレッジを実現している。推論能力については、既存モデルが対応していない機能をSciReasonerのみが提供している。

多分野モデルとの比較について、NatureLMの30タスクに対しSciReasonerは103タスクと3倍以上の拡張性を示している。事前学習コーパスでは、NatureLMの140Bトークン（90%配列データ）に対し、SciReasonerは206Bトークンの多様性を重視した構成（配列-テキスト混合）を採用し、より均衡の取れた学習を実現している。

推論コーパスの観点では、SciReasonerのみが570K答え整合型長文科学CoTデータと72K難易度フィルタリングRLデータを保有し、他モデルは推論能力向上のための専用データを持たない。

性能ランキングでは、54タスクで最高性能、101タスクでトップ2性能を達成し、単一バックボーンによる自然言語と多表現科学データの統合が、固定タスクメニューを超えたクロスドメイン汎化と専門パイプラインの断片化削減を実現することを実証している。

## 4. 実用性評価
### 4.1 実装の容易性

高い実装容易性を実現している。モデルとデータセットがHuggingFace（https://huggingface.co/SciReason）とGitHub（https://github.com/open-sciencelab/SciReason）でオープンソース化されており、研究者は既存の推論コードと評価コードを直接利用可能である。

統一インターフェースにより利便性を向上させている。103の多様な科学タスクが一貫した入出力スキーマで統合されているため、新しいタスクへの適用や既存システムへの組み込みが簡略化されている。従来のように分野ごとに異なる専門モデルを個別に導入・管理する必要がない。

モジュラー設計を採用している。タスク認識型トークン化、配列タグ付け（&lt;SMILES&gt;、&lt;protein&gt;等）、適応的推論モード切り替えなど、各コンポーネントが独立して実装されており、段階的な導入と個別最適化が可能である。

### 4.2 計算効率

学習効率を最適化している。Qwen3の1.7Bおよび8BモデルをベースとしてファインチューニングすることでGPT-4レベルの科学推論能力を実現し、大規模モデルと比較して計算資源要求量を削減している。

推論効率を向上させている。インスタントモードでは従来の即答型処理を維持し、シンキングモードでは必要時のみ詳細推論を行う適応的設計により、タスク特性に応じた最適な計算資源配分を実現している。

高いスケーラビリティを確保している。事前学習で206億トークンを処理する大規模データ対応能力と、段階的学習（事前学習→SFT→RL）による効率的な能力構築により、将来的なデータ拡張とタスク追加に対する高いスケーラビリティを確保している。

ハードウェア要求については、1.7Bモデルは128台のA800 GPU、8Bモデルは256台のA800 GPUで学習されており、現実的なハードウェア環境での実装が可能である。

### 4.3 応用可能性

薬物発見への応用について、分子特性予測、毒性評価、薬物標的相互作用予測を統合したワークフローにより、候補化合物の初期スクリーニングから詳細解析まで一貫して支援可能である。

材料設計への応用では、結晶構造予測、物性評価、組成最適化を組み合わせることで、新材料の設計と性能予測を効率化できる。特に、制約付き生成機能により実現可能性を考慮した材料設計が可能である。

生物工学への応用について、タンパク質機能予測、配列設計、進化解析を統合し、酵素工学、抗体設計、バイオマーカー発見などの生物工学アプリケーションを包括的に支援する。

科学文献解析への応用では、大規模科学文献からの知識抽出、エンティティ認識、関係抽出により、研究トレンド分析や仮説生成を自動化できる。

教育・研究支援への応用について、段階的推論機能により、科学概念の説明、問題解決プロセスの可視化、研究提案の論理検証など、教育と研究の両面で活用可能である。

クロスドメイン創薬への応用では、複数の科学分野にまたがる知識を統合することで、従来の分野別アプローチでは発見困難な新しい治療法や材料の発見を促進できる可能性がある。

## 5. まとめと所感
### 5.1 論文の意義

この研究は科学AI分野において極めて重要な意義を持つ画期的な成果である。従来の科学系AIが分野特化型で断片化していた状況を、統一的なアーキテクチャによって変革している点が特筆される。

技術的意義について、自然言語と科学データ（配列、分子、材料）を単一バックボーンで処理する統合アプローチは、従来の「分野ごとに個別モデル」というパラダイムからの転換を示している。特に、適応的推論機能（インスタント/シンキングモード）と物理制約を考慮した強化学習は、科学AI分野の新しい技術標準を提示している。

学術的影響では、103タスクという前例のない規模でのベンチマーク評価と、54タスクでの最高性能達成は、科学AIの能力上限を押し上げた。論文の実証結果は、クロスドメイン学習の有効性と推論能力の重要性を明確に示し、今後の科学AI研究の方向性を決定づける可能性がある。

実用的価値について、オープンソース化により研究コミュニティ全体に貢献し、産業界での実装障壁を低減している。統一インターフェースによる利便性向上と計算効率の最適化は、科学研究の生産性向上に直接寄与する実用的価値を持つ。

方法論的革新では、報酬ソフト化、タスクグループ化、コールドスタート適用などの新しい学習手法は、科学分野に限らず汎用的なAI開発手法として波及効果が期待される。

### 5.2 今後の展望

技術的発展の方向性を以下に示す。

マルチモーダル拡張について、現在のテキスト・配列ベースから、分子3D構造、顕微鏡画像、スペクトラムデータなどの視覚的科学データの統合が次の発展段階として有望である。

因果推論の強化について、現在の相関ベース予測から、科学的因果関係の理解と操作能力の向上により、より深い科学的洞察の獲得が期待される。

実験設計支援について、予測と生成だけでなく、仮説検証のための実験デザイン提案機能の追加により、科学研究サイクル全体の自動化が可能になる。

改善が必要な領域を以下に示す。

計算効率の最適化について、より大規模な科学データと複雑なタスクに対応するため、モデル圧縮、効率的アーキテクチャ、分散処理の改善が必要である。

不確実性の定量化について、科学的予測における信頼区間と誤差評価の精度向上により、リスク評価を含む意思決定支援能力の強化が求められる。

ドメイン特化知識の深化について、各科学分野での専門性をさらに高めるため、分野専門家との協働による知識ベース拡充とドメイン特化ファインチューニングが重要である。

社会的インパクトについて述べる。

新薬開発期間の短縮、材料設計の効率化、気候変動対策技術の加速など、人類が直面する重要課題の解決において、このモデルの寄与は大きい。特に、発展途上国でも利用可能なオープンソースモデルとして提供されることで、グローバルな科学研究の民主化と格差解消に貢献する可能性がある。

ただし、科学的妥当性の検証、倫理的利用ガイドライン、誤用防止策の整備が並行して進められる必要がある。人間の科学者との協働関係を適切に構築し、AIが科学研究を支援しつつも、人間の創造性と批判的思考を補完する役割を果たすことが重要である。