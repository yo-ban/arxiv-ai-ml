# SD3.5-Flash: Distribution-Guided Distillation of Generative Flows

## 基本情報
- arXiv ID: 2509.21318v1 (https://arxiv.org/abs/2509.21318)
- 著者: Hmrishav Bandyopadhyay et al. (Stability AI, University of Surrey)
- 所属: Stability AI, SketchX University of Surrey
- 投稿日: 2025年09月27日（推定）
- カテゴリ: cs.LG, cs.CV

## 簡単に説明すると
SD3.5-Flashは、高品質な画像生成を消費者向けデバイスで実現する少ステップ蒸留フレームワークです。従来の修正フロー（rectified flow）モデルは25ステップ以上、16GB以上のVRAM、30秒以上の生成時間を要し、データセンターでしか動作しませんでした。この研究は4ステップ以下での高品質生成を可能にします。

主要な技術革新として、「タイムステップ共有」と「分割タイムステップファインチューニング」を提案しています。タイムステップ共有は従来の分布マッチング手法の問題点を解決します。分割タイムステップファインチューニングはモデル容量を一時的に拡張して美的品質と意味的忠実性の両立を図ります。

さらに、テキストエンコーダの再構築や6-16bit量子化により、スマートフォンからデスクトップまで幅広いハードウェアでの実用化を実現しています。大規模ユーザー研究により、既存の少ステップ手法を一貫して上回る性能を実証しており、高度な生成AIの実用的展開を民主化しています。

## 1. 研究概要
### 1.1 背景と動機

現在の最高品質の画像生成モデルは、データセンターに閉じ込められているという根本的な問題があります。修正フローモデルは前例のない品質を達成していますが、その計算要求（25以上のステップ、16GB以上のVRAM、画像1枚あたり30秒以上）により、日常的なデバイスではアクセス不可能な状況にあります。

タイムステップ蒸留は解決への道筋を提供しますが、少ステップフロー蒸留における分布マッチングの動作方法から核心的な課題が生じています。標準的なアプローチでは、軌道エンドポイントでサンプルを再ノイズ化して、さまざまなノイズレベルでの分布分岐を計算します。この再ノイズ化は流軌道を変更し、信頼性のない速度予測と破損した勾配推定をもたらします。

少ステップ領域では、後続の反復によってエラーを修正できないため、この問題が特に顕著になり、体系的な品質崩壊を引き起こします。さらに、少ステップ蒸留によって課される厳しい容量制約により、モデルは美的品質と意味的忠実性の両方を維持するのに苦労し、プロンプト-画像アライメントを犠牲にせざるを得なくなります。

### 1.2 主要な貢献

この論文の主要な技術的貢献は以下の通りです。

- タイムステップ共有の導入：ランダムな軌道ポイントへの推定ではなく、学生軌道サンプルで分布マッチングを計算し、既知のノイズレベルで安定した勾配信号を提供する
- 分割タイムステップファインチューニング：訓練中にモデル容量を一時的に拡張してプロンプトアライメントの課題へ対処し、統一されたチェックポイント統合前に異なるタイムステップ範囲でモデルを分岐させる
- 包括的なパイプライン最適化：エンコーダドロップアウト事前学習を活用したテキストエンコーダの再構築と、メモリフットプリントと推論速度のバランスを取る16ビットから6ビット精度の量子化スキームの適用
- ハードウェア全体での民主化：モバイルからデスクトップまでの全範囲のデバイスでアクセスを民主化し、各計算層に対応したカスタマイズされた構成を提供
- 実証的優位性：大規模ユーザー研究を含む広範な評価により、多様なハードウェア構成で既存手法を一貫して上回る性能を実証

## 2. 提案手法
### 2.1 手法の概要

SD3.5-Flashは、安定した4ステップ学生ネットワークの事前学習のために軌道ガイダンス目的関数を使用します。教師モデルの軌道上のタイムステップt∈[0,1]に対して、学生軌道と一致するポイントをサブサンプリングし、軌道ガイダンス目的関数を計算します。

分布マッチング目的関数（DMD）を使用して事前学習済み学生を改良し、プロキシとの教師・学生分布間のKL分岐の勾配を計算します。学生分布の正確な表現を可能にするため、生成された学生サンプルでプロキシと学生の分布を整列させます。

### 2.2 技術的詳細

タイムステップ共有は、DMD目的関数で要求される軌道エンドポイントからの再ノイズ化ではなく、学生軌道上の部分的にデノイズされたサンプルを速度推定に使用します。これにより、ノイズの多いタイムステップからの貧弱なx₀推定による低品質勾配が削減されます。

分割タイムステップファインチューニングでは、事前学習済みモデルをブランチM₁とM₂に複製します。それぞれを互いに素のタイムステップ範囲で学習させ、実効的なモデル容量を増加させます。ファインチューニング中、各ブランチは減衰率0.99の指数移動平均を使用して安定化し、重みを元のチェックポイントに近く保ちます。

### 2.3 新規性

既存の分布マッチング手法との主要な違いは、軌道エンドポイントの再ノイズ化による勾配汚染問題の解決にあります。従来手法では、ランダムノイズの追加がフロー軌道を変更し、信頼性のない速度予測を生成していました。

分割タイムステップファインチューニングは、マルチタスク学習にディフュージョンモデルを使用する既存研究からインスピレーションを得ています。タイムステップ蒸留における容量-品質トレードオフの解決に特化して適用されています。

## 3. 実験結果
### 3.1 実験設定

実装では、SD3.5 Large（8B）モデルを使用して32タイムステップとCFGスケール4.0で合成サンプルを生成し、高いプロンプト一貫性と品質の一致性を提供します。2K反復で事前学習し、その後4ステップと2ステップモデルをそれぞれ1200反復で学習させ、2.5B SD3.5Mを教師として使用します。

ベースラインとして、DMD2、Hyper-SD、SDXL-Turbo、Nitrofusion、SDXL-Lightningを含む様々な少ステップ生成パイプラインと比較しています。また、SWD、SANA-Sprint、SD3.5M-Turboなどの最新モデルとの比較も実施しています。

### 3.2 主要な結果

定性的比較では、SD3.5-Flash（16-bit + T5）は複雑なプロンプトにおける人間の相互作用を含む構成で、他の4ステップパイプラインを大きく上回る性能を示しています。SDXL-DMD2、SDXL-Lightning、NitroFusionは、プロンプトアライメントと構成において劣悪な性能を示し、しばしばアーティファクトを生成します。

124人の注釈者による大規模ユーザー研究では、507の多様なプロンプトセットを使用して画像品質とプロンプトアライメントを評価しました。SD3.5-Flashは他の少ステップモデルを上回り、画像品質において50ステップの教師モデルさえも凌駕しています。

### 3.3 既存手法との比較

ELOスコア比較では、すべての計算シナリオでSD3.5-Flashモデルがランキングの上位に位置し、様々な計算予算で高品質な画像生成を実証しています。2ステップパイプラインでは、SANA-Sprint 1.6Bとの比較で、SD3.5-Flashが生成忠実度で優れた性能を示しています。

量子化による推論最適化では、RTX 4090で4ステップ生成が2.1秒、M3 MacBook Proで6.8秒を達成しています。M4 iPadで9.2秒、iPhone 15 Pro Maxで9.7秒を達成し、消費者向けハードウェアでの実用的な生成時間を実現しています。

## 4. 実用性評価
### 4.1 実装の容易性

SD3.5-Flashの実装は、既存のStable Diffusion 3.5パイプラインを基盤とし、比較的容易です。3つのテキストエンコーダ（CLIP-L、CLIP-G、T5-XXL）、MM-DiTディフュージョンモデル、VAEで構成されています。T5-XXLは最大のコンポーネントですが、エンコーダドロップアウト事前学習により無効化可能です。

量子化実装では、16bit精度からMM-DiTモデルを8bitに量子化し、消費者向けグラフィックカードでも動作するよう8GiBまでメモリ要求を削減しています。Apple Silicon上のCoreMlでは6bit量子化を実現し、スマートフォンやタブレットでの動作を可能にしています。

### 4.2 計算効率

計算効率において革新的な成果を達成しています。16bit精度のフルモデルは18GiBのGPUメモリを要求していましたが、8bit量子化とT5無効化により約8GiBまで削減しました。6bit量子化では、さらなるメモリ削減とApple Neural Engineでの精度保持を両立しています。

推論時間では、RTX 4090で4ステップ生成が2.1秒、2ステップ生成が1.4秒を実現し、従来の25ステップ以上の生成時間から劇的な高速化を達成しています。モバイルデバイスでも10秒未満での生成が可能で、実用的なリアルタイム生成を実現しています。

### 4.3 応用可能性

SD3.5-Flashは、モバイルフォンから高性能デスクトップまで幅広いハードウェア構成での展開を可能にし、生成AIの民主化へ大きく貢献しています。アーティスト、デザイナー、コンテンツクリエイターが高価な専用ハードウェアなしで高品質な画像生成へアクセスできるようになります。

ソーシャルメディア、ゲーム開発、教育、広告などの分野での即座のコンテンツ生成が可能になり、創造的ワークフローの革新を促進します。特に、リアルタイムでの対話的な画像生成アプリケーションの開発が現実的になります。

## 5. まとめと所感
### 5.1 論文の意義

この論文は、高品質な画像生成の民主化において画期的な貢献をしています。従来データセンターに限定されていた高性能な生成技術を、消費者向けデバイスで実用的に動作させることで、生成AIの普及に大きな影響を与えます。

技術的には、タイムステップ共有と分割タイムステップファインチューニングという具体的で実装可能な解決策を提示しています。少ステップ蒸留における根本的な問題を解決しています。さらに、包括的なパイプライン最適化により、理論的改善を実用的な展開まで橋渡ししている点は特に価値があります。

### 5.2 今後の展望

今後の発展方向として、さらなる量子化技術の進歩や、異なるアーキテクチャでの適用が期待されます。また、動画生成や3D生成への拡張、より多様なモダリティへの対応も重要な研究方向となるでしょう。

エッジコンピューティング環境での最適化や、より小型のモバイルデバイスでの動作最適化も継続的な課題です。さらに、ユーザビリティの向上や、非専門家でも簡単に使用できるインターフェースの開発により、生成AIの真の民主化が進むと考えられます。
