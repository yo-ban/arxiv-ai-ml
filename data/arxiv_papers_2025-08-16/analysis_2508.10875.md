# A Survey on Diffusion Language Models

## 基本情報
- arXiv ID: 2508.10875v1 (https://arxiv.org/abs/2508.10875)
- 著者: Tianyi Li, Mingda Chen, Bowei Guo, and Zhiqiang Shen
- 所属: VILA Lab, Mohamed bin Zayed University of Artificial Intelligence; Tsinghua University
- 投稿日: 2025年08月16日
- カテゴリ: cs.CL, cs.LG, cs.AI

## 簡単に説明すると

この論文は、Diffusion Language Models（DLM）の包括的なサーベイ論文です。従来の自己回帰型の言語モデルに対する強力で有望な代替手段として注目されるDLMについて、初めて体系的な分析を提供しています。

DLMは並列生成によって「数倍の高速化」を実現しながら、自己回帰型モデルに「匹敵する性能」を示します。本サーベイは連続型、離散型、ハイブリッド型DLMの統一的な分類体系を確立し、176の文献を基に訓練手法からマルチモーダル拡張まで幅広くカバーしています。GitHub Repository: https://github.com/VILA-Lab/Awesome-DLMs

## 1. 研究概要

### 1.1 背景と動機

現代の言語モデリングにおいて、自己回帰（AR）パラダイムが支配的な地位を占めていますが、本質的に逐次的な生成プロセスによる推論速度の制約が問題となっています。DLMは並列生成、双方向コンテキスト、きめ細かい制御能力という固有の利点を持ち、この課題に対する解決策として急速に注目を集めています。

従来のMasked Language Models（MLM）は双方向コンテキストを持ちながら生成能力に限界があり、自己回帰モデルは逐次生成によるボトルネックを抱えています。DLMはこれらの限界を克服し、反復的なノイズ除去プロセスを通じて複数トークンを同時に生成する革新的なアプローチを提供します。

### 1.2 主要な貢献

本サーベイは、DLMエコシステム全体の最初の包括的かつ体系的な分析を提供します。主要な貢献は以下の通りです。

DLMの包括的分類法を初めて確立し、連続型、離散型、ハイブリッド型アプローチを統一的なフレームワークで整理しました。8つのベンチマークにわたる体系的な性能比較と176の文献による技術的深度を提供し、数学的定式化とアルゴリズム詳細を全パラダイムにわたって網羅しています。重要な課題と有望な研究方向を特定し、インフラ要件と実装上の考慮事項を含む実用的な洞察を提供しています。

## 2. 提案手法

### 2.1 手法の概要

本サーベイは、DLMを現代言語モデリングの文脈に位置づけ、多次元的なアプローチで分析しています。従来のMLMとARモデルとの比較から始まり、DLMの独自の利点を明確に特定しています。

DLMの核心的な利点として、反復的ノイズ除去による並列生成、双方向コンテキストの自然な組み込みが挙げられます。また、不確実な領域の段階的改善、条件付き生成における細かい制御、モダリティ横断でのノイズ除去フレームワークの統合も重要な利点です。

サーベイは基礎原理から最新のモデルまで、事前学習戦略から高度な後学習手法まで、幅広い技術領域を体系的にカバーしています。

### 2.2 技術的詳細

**連続型の拡散言語モデル**

離散トークンを連続埋め込み空間にマッピングする技術的アプローチを採用します。順方向プロセスは q(x₁:T | x₀) = ∏ᵗ q(xₜ | xₜ₋₁) でガウス遷移により定義されます。訓練目的は ℒ_simple = 𝔼[‖f_θ(xₜ, t) - z‖²] で表現されます。代表的モデルには Diffusion-LM、SED、LATENTOPS、Diffuseq、CDCD、TESS、SMOOTHIE があります。

**離散型の拡散言語モデル**

直接的なトークン空間操作により連続埋め込みの複雑さを回避します。D3PMフレームワークは吸収状態を持つ構造化された遷移行列を使用し、現代のMasked DLMはマスクされたトークンのみに交差エントロピー損失を適用します。LLaDAの定式化は ℒ(θ) = -𝔼[1/t ∑ᵢ 𝟙[xₜⁱ = M] log p_θ(x₀ⁱ|xₜ)] で表現されます。主要モデルには D3PM、DiffusionBERT、LLaDA、RDMs、MDLM、Dream-7B、DiffuLLaMA があります。

**ハイブリッドAR-拡散モデル**

ブロック間は自己回帰、ブロック内は拡散によるブロック単位生成を採用します。BD3-LMの目的関数は ℒ_BD(x,θ) = -∑ᵇ 𝔼[1/t log p_θ(xᵇ | xₜᵇ, x<ᵇ)] で表現されます。

### 2.3 新規性

本サーベイの主要な新規性は、DLM分野における初の包括的な分類体系の確立にあります。従来の断片的な理解を統一的なフレームワークに整理し、技術的詳細と実用的応用の両面から体系的な分析を提供しています。

連続型と離散型DLMの数学的基礎から実装上の考慮事項まで、176の文献による前例のない包括性を実現しています。また、並列生成の利点と制約、双方向コンテキストモデリングの革新、マルチモーダル統合アーキテクチャの可能性を明確に示しています。

## 3. 実験結果

### 3.1 実験設定

評価フレームワークは8つの主要ベンチマークにより構成されています。

言語理解と推論を評価するため、次のようなベンチマークを使用しました。一般理解では PIQA と HellaSwag を使用し、コード生成では HumanEval を評価しました。数学的推論では GSM8K、GPQA、MATH を採用し、マルチモーダル能力では GenEval、MME、MMMU、GQA を用いて包括的な評価を実施しました。

現在のDLMは1B未満から8Bパラメータの範囲にあり、限られた訓練リソースにもかかわらず「多くの実世界アプリケーションでARモデルの実行可能な代替手段としての強い可能性」を示しています。

### 3.2 主要な結果

**競争力のある一般性能**：DLMは一般的なベンチマークでARモデルとの性能で「わずかに下回るかほぼ同等」の結果を達成しています。

**優れた数学的推論**：「LLaDAやDreamなどのモデルは、同サイズのAR対応モデルを一貫して上回る」GSM8K、GPQA、MATHでの成果を示しています。

**強力なマルチモーダル能力**：MMaDAとLLaDA-Vは「ARベースのマルチモーダルモデルをしばしば上回る」結果を達成しています。

**商業的実用性**：MercuryとGemini Diffusionは「すべてのDLM中で最新技術の結果を達成し、GPT-4oなどのトップティアARモデルに匹敵する」性能を実現しています。

### 3.3 既存手法との比較

**応用領域での成果**：35以上の従来NLPタスクへの応用が確認されています。分類・認識では ROIC-DM、DiffusionNER、IPAD が開発され、要約では DiffuSum、TermDiffuSum が実装されました。スタイル転移では ParaGuide がプラグアンドプレイ分類器を使用し、制約付き生成では PLANNER、PoetryDiffusion が韻律制御を実現しています。

**コード生成での革新**：DiffuCoderは7Bモデルで高温度での柔軟な生成順序を実現し、Mercury Coderは「速度最適化されたARモデルより10倍高速でありながら同等の品質を維持」しています。DCoLTは横断的思考RLによりGSM8Kで+9.8%、HumanEvalで+19.5%の改善を達成しました。

**計算生物学での展開**：15以上の専門モデルが開発されました。分子設計では TransDLM、TGM-DLM がテキスト誘導による分子最適化を実現し、タンパク質工学では MeMDLM、DPLM、DPLM2 が配列と構造の共同生成を可能にしています。

## 4. 実用性評価

### 4.1 実装の容易性

DLMの実装は現在、重要な課題に直面しています。「主要なMLエコシステムはDLMに対するネイティブサポートをほとんどまたは全く提供していない」状況であり、ARモデル用のvLLMのような成熟したサービングインフラが不足しています。

Hugging Faceエコシステムと比較した最適化ライブラリの限界により、開発の障壁が高くなっています。しかし、反復的ノイズ除去プロセスの概念的明確さと並列生成の利点により、十分なツール支援があれば実装は比較的直感的です。

### 4.2 計算効率

DLMは「並列デコーディングの呪い」という根本的な課題に直面しています。独立トークンサンプリングはトークン間依存関係の捕捉に失敗します。その結果、並列性の増加に伴いコヒーレンスの劣化する現象が確認されています。

長系列制限として、ほとんどのDLMが4,096トークンに制限される一方、ARモデルははるかに長いコンテキストを処理可能です。双方向注意と線形ステップスケーリングによりO(N³)推論複雑性が生じ、動的生成では事前に決定されたシーケンス長が必要で計算オーバーヘッドを引き起こします。

### 4.3 応用可能性

スケーラビリティの制約として、最大の公開DLMが約8Bパラメータに留まる一方、ARモデルは100B-1T+パラメータを持ちます。多くのモデルがARベースから構築されるか限られたデータセットを使用し、クローズドソースDLMでも全ベンチマークでSOTA ARモデルに届かない現状があります。

しかし、6つのコア最適化戦略により大幅な改善が実現されています。並列デコーディングではFast-dLLM（27.6倍高速化）、APD、SlowFast Sampling（キャッシュ付きで34倍）が開発されました。キー値キャッシュではDualCache、dKV-Cache（2-10倍高速化）、特徴キャッシュではdLLM-Cache（9倍高速化）、FreeCache（34倍高速化）が実装されています。

## 5. まとめと所感

### 5.1 論文の意義

本サーベイは、新興分野であるDLMの初の体系的かつ包括的な分析として、極めて重要な学術的貢献を果たしています。176の文献による前例のない網羅性と、連続型・離散型・ハイブリッド型DLMの統一的な分類体系の確立は、この分野の基盤的な知識体系を構築しています。

特に印象的なのは、ARパラダイムの支配的地位に対する実用的な代替手段としてのDLMの可能性を、技術的詳細と実用的制約の両面から客観的に評価した点です。並列生成による高速化、双方向コンテキストモデリング、マルチモーダル統合の利点を明確に示す一方で、並列デコーディングの呪いやインフラ成熟度の課題も率直に指摘しています。

数学的推論におけるDLMの優越性（LLaDA、Dreamが同サイズAR対応モデルを一貫して上回る）やMercury Coderの10倍高速化など、具体的な性能指標による証拠を提示しています。これにより、DLMが研究上の興味から実用的価値を持つ技術へ進化していることを実証しています。

### 5.2 今後の展望

技術最適化の方向性として、訓練効率における損失計算時の限られたトークン使用を解決するハイブリッドアーキテクチャの開発、DLM特有の量子化・二値化・プルーニング・蒸留手法の探索が重要です。また、並列性-性能トレードオフに対するアーキテクチャ革新も必要となります。

応用拡張では、単一モダリティ限界を超える真のクロスモーダル推論、動的環境における双方向コンテキストと反復改善を活用したDLMベースエージェントの開発が期待されます。

インフラストラクチャの成熟として、主要MLエコシステムでのネイティブDLMサポートの実現、vLLMに匹敵するサービングインフラの開発が急務です。Hugging Faceレベルの包括的開発エコシステムの構築も重要な課題となっています。

本サーベイは、自己回帰パラダイムに代わる魅力的な選択肢としてのDLMの基盤を確立しました。並列生成・双方向コンテキストモデリング・マルチモーダル統合アーキテクチャにおける独自の利点を持つ技術として、この分野の今後の革新への道筋を示しています。DLMの実用化に向けた重要な研究資源として、長期にわたって参照される価値のある成果です。