# Searching for Privacy Risks in LLM Agents via Simulation

## 基本情報
- arXiv ID: 2508.10880v1 (https://arxiv.org/abs/2508.10880)
- 著者: Yanzhe Zhang (Georgia Tech), Diyi Yang (Stanford University)
- 所属: Georgia Institute of Technology, Stanford University
- 投稿日: 2025年08月16日
- カテゴリ: cs.AI, cs.LG

## 簡単に説明すると

この論文は、LLMエージェント同士が相互作用する際のプライバシーリスクを系統的に発見し、対策を開発するための革新的なフレームワークを提案しています。従来の研究が静的な脅威モデルに焦点を当てていたのに対し、本研究では悪意のあるエージェントが標的エージェントと能動的に複数ターンの対話をして、機密情報を抽出する動的なシナリオを扱っています。

提案手法は、シミュレーションベースの検索アルゴリズムを用いて攻撃戦略と防御メカニズムを交互に最適化します。なりすましや同意偽造といった巧妙な攻撃手法から、アイデンティティ検証ステートマシンなどの堅牢な防御手法まで自動的に発見します。コードとデータは https://github.com/SALT-NLP/search_privacy_risk で公開されています。

## 1. 研究概要

### 1.1 背景と動機

現代のAI技術の発展により、個人を代理してタスクを実行するLLMエージェントの普及が進んでいます。これらのエージェントは単独で動作するのではなく、他のエージェントと協力し、交渉し、情報を共有する環境で機能することが期待されています。この新しいパラダイムは、従来のLLMプライバシー研究が扱ってきた訓練データ保護やクエリ保護とは根本的に異なる課題を提起しています。

具体的には、「機密情報にアクセスできるAIエージェントが、他のエージェントと相互作用しながらプライバシー意識を維持できるか」という重要な問題に直面しています。従来の研究は主にユーザー・エージェント間や環境・エージェント間の相互作用に焦点を当てており、不十分に指定されたユーザー指示や悪意のある環境要素による静的な脅威を想定していました。

しかし、実世界では敵対者が積極的に機密情報を要求し、エージェントの応答に基づいて戦略を調整する動的なシナリオが存在します。このような evolving attack surfaces（進化する攻撃面）は、手動分析や静的テストでは予測困難であり、系統的なアプローチが必要です。

### 1.2 主要な貢献

本研究の主要な貢献は以下の4点に集約されます。

本研究では、攻撃者と防御者の指示を交互に最適化する新しいシミュレーションベースのフレームワークを提案し、多エージェント環境におけるプライバシーリスクの体系的発見を可能にしました。複数スレッドでの並列検索とクロススレッド伝播機能を実装し、微妙な攻撃戦略の包括的探索を実現しました。シンプルな直接要求から巧妙ななりすましや同意偽造まで攻撃が進化し、ルールベース制約からアイデンティティ検証ステートマシンまで防御が発展する過程を自動発見しました。発見された攻撃と防御が多様なシナリオとバックボーンモデル間で転移することを示し、実世界デプロイメントでの実用性を証明しました。

## 2. 提案手法

### 2.1 手法の概要

提案手法は、コンテキスト整合性理論（contextual integrity theory）に基づく3エージェントシミュレーション環境を構築し、その上で検索ベースの最適化を行います。各シミュレーションには data subject（データ主体）、data sender（データ送信者：防御者）、data recipient（データ受信者：攻撃者）の3つの役割が存在します。

データ主体は防御者に機密情報を共有し、攻撃者は指定された transmission principle（例：「メールを送信する」）を通じて防御者からその情報を引き出そうと試みます。防御者と攻撃者間の会話は複数ラウンド継続し、その間に防御者のアクションを調べることでプライバシー漏洩を検出します。

シミュレーション環境には Gmail、Facebook、Messenger、Notion の4つのモックアプリケーションが含まれます。それぞれがデータベースとAPI docstring付きのツールベース相互作用機能を提供します。これにより、プライバシー漏洩が正当なツール呼び出しを通じてのみ発生することを保証しています。

### 2.2 技術的詳細

すべてのエージェントは ReAct ベースの通知駆動実行モデルを採用しています。エージェントは通知を受信すると行動を開始し、必ず `end_cycle()` を呼び出してサイクルを終了します。

**検索問題の定式化**：プライバシーリスク発見を設定空間 $(\mathbf{a},\mathbf{d})$ での検索問題として定式化します。ここで $\mathbf{a}$ は攻撃者指示、$\mathbf{d}$ は防御者指示です。

**Sequential Search Process**：
```
ステップ k で: (a^k, d) で M 回シミュレーション実行
→ 結果 S^k = {(a^k, t_j^k, s_j^k)} を収集
→ 最高漏洩スコア例 E^k を選択
→ LLM オプティマイザー F が検索履歴を使用して a^{k+1} を生成
```

**Parallel Search Innovation**：従来の sequential search の限界を克服するため、N 個の並列スレッドを導入しました。各スレッドは多様な指示で初期化され、パフォーマンス向上時に最良の軌跡がスレッド間で共有されます。また、ステップごとの最良指示に対して P 回の追加シミュレーションを実行し、信頼性を確保します。

**リークスコア計算**：
```
s = (1/K) Σ(1 - log(l_i)/(log(l_i) + 1))
```
ここで K = 機密アイテム数、l_i = アイテム i が漏洩したアクション番号。

### 2.3 新規性

本手法の主要な新規性は以下の点にあります。

**動的対話の系統的分析**：従来研究が静的評価に留まっていたのに対し、本研究は敵対的エージェント間の動的な複数ターン対話を系統的に分析する初のフレームワークを提供します。

攻撃フェーズで Q 個のシナリオ固有攻撃戦略を更新し、防御フェーズで新しい攻撃に対する汎用防御を更新する交互最適化は、adversarial minimax game に類似した革新的アプローチです。

並列検索においてスレッド間でブレイクスルー発見を伝播させる仕組みは、従来の独立並列処理を超えた探索を実現します。

**転移可能性の実証**：発見された戦略が異なるモデルやシナリオ間で転移することを示したのは、実用的価値の観点から重要な貢献です。

## 3. 実験結果

### 3.1 実験設定

データセット構成として、次のような設定を使用しました。Testing-100 では PrivacyLens プライバシー規範から生成された100のシミュレーション設定を用意しました。Training-5 では検索最適化用の5つの設定を使用しました。これらは異なるプライバシー規範から o4-mini-high を使用して生成されています。

評価モデルとして、次のような設定を使用しました。バックボーンモデルには gpt-4.1-nano, gpt-4.1-mini, gpt-4.1, gemini-2.5-flash を使用しました。デフォルト設定では、エージェントに gpt-4.1-mini、最適化に gemini-2.5-pro を使用しました。評価には 1024トークン思考予算を持つ gemini-2.5-flash を使用しました。

ハイパーパラメータは次のように設定しました。攻撃検索では N=30, M=1, K=10, P=10 を使用しました。防御検索では N=1, M=30, K=10 を使用しました。

### 3.2 主要な結果

**基本シミュレーション結果**：基本指示での平均リークスコアは31.2%でした。モデル間の違いとして、より優秀なモデルは攻撃能力よりも防御能力を向上させる傾向が観察されました。具体的には、gpt-4.1 と gpt-4.1-mini 間で防御性能が 31.2% → 16.5% に向上しました。

検索進化の結果として、次のような変化が観察されました。A₀ から A₁ では、直接要求から同意偽造・緊急性戦術へ進化し、リークスコアが76.0%となりました。D₀ から D₁ では、基本ルールからルールベース同意検証へ発展し、リークスコアが2.5%となりました。A₁ から A₂ では、同意偽造から偽の同意メッセージを伴うなりすましへ進化し、リークスコアが42.2%となりました。D₁ から D₂ では、ルールベースからステートマシンアイデンティティ検証へ発展し、リークスコアが7.1%となりました。

**並列検索の効果**：スレッド数を N=1→30 に増加させることで、初期検索の効果性が向上しました。クロススレッド伝播は停滞状態の克服に不可欠であり、オプティマイザーバックボーンでは gemini-2.5-pro > gemini-2.5-flash > gpt-4.1 の順で性能が高くなりました。

### 3.3 既存手法との比較

転移性の分析結果として、次のような特性が確認されました。クロスモデル転移では、攻撃は非対称転移性を示し、防御モデル依存だが攻撃モデルに対しては堅牢でした。クロスシナリオ転移では、ICL ベース転移により A₁ → A₂ で 49.4% → 17.6% のリークスコア改善を達成しました。戦略ガイダンスでは、2段階なりすまし戦略により転移性能が 17.6% → 32.4% に向上しました。

**人間評価との一致**：プライバシー漏洩検出において人間注釈者との一致率は98.5%に達し、自動評価の信頼性が確認されました。

## 4. 実用性評価

### 4.1 実装の容易性

提案フレームワークは主にプロンプトベースのアプローチを採用しているため、実装の容易性に優れるという利点があります。LLM の指示従属能力の向上により、複雑な防御プロトコルよりもプロンプトベース防御の方が実装しやすくなっています。効果的でもあります。ただし、重要な計算要求として、シミュレーションと最適化の両方でLLM呼び出しが必要であり、これが計算制約となる可能性があります。

### 4.2 計算効率

検索プロセスは大規模な計算リソースを要求します。特に攻撃検索では N=30 スレッド、防御検索では M=30 シミュレーションを並列実行する必要があり、多数のLLM呼び出しが発生します。しかし、この計算コストは重要な脆弱性発見のために正当化されると論文では主張しています。計算制約により追加モデルファミリーのテストが制限されているのが現状です。

### 4.3 応用可能性

発見された攻撃と防御戦略の転移可能性が実証されました。これにより、実世界デプロイメントでの応用可能性の高さが示されています。異なるバックボーンモデルとプライバシーシナリオ間での転移成功は、プライバシー意識のあるエージェント構築のための実用的ツールとしての価値を表しています。

また、フレームワークはプライバシーを超えたロングテールリスクの広範なカテゴリーにも拡張可能です。エージェントアーキテクチャ、ガードレール設計、訓練目標の最適化にも応用できる可能性があります。

## 5. まとめと所感

### 5.1 論文の意義

本論文は LLM エージェントセキュリティ分野において、静的プライバシー評価から動的な敵対的発見への根本的変化を実現した重要な研究です。従来の研究が見落としていた multi-agent interaction における動的脅威を系統的に分析する初のフレームワークを提供しており、理論的貢献と実用的価値の両面で高く評価できます。

特に印象的なのは、シンプルな直接要求から巧妙な複数ターン戦術まで攻撃が進化し、それに対応して防御もルールベース制約からアイデンティティ検証ステートマシンまで発展する過程を自動発見した点です。これは人間の手動分析では困難な包括的探索を実現しており、敵対的訓練のコンセプトをマルチエージェントプライバシー領域に拡張した革新的な成果といえます。

98.5%の人間による評価の一致率と強い転移可能性は、実世界適用性の高さを示しています。LLMエージェントシステムの積極的セキュリティ評価のための実用的ツールとしての価値が確立されています。

### 5.2 今後の展望

将来的な発展方向として、以下の領域が特に期待されます。

スコープ拡張では、プライバシーを超えた広範なセキュリティ課題への適用、複数エージェントエコシステムでの複雑性スケーリング、現実的デプロイメントシナリオにおける検証が重要な課題となります。

技術的改良では、現在の計算制約を克服するための効率的アルゴリズム開発、より多様なモデルファミリーでの検証、推論モデルを含む高度なモデルへの対応が必要です。

実世界適用では、コンピュータ使用エージェントのような実際のデプロイメント環境での検証、人間監視を含むセキュリティ保護機能の統合、現実世界の複雑性の完全な把握が今後の重要な研究方向となるでしょう。

本研究は自動エージェントリスク発見と保護の基盤を確立し、複雑化するマルチエージェントAIシステムにおけるセキュリティ課題への明確な解決経路を提示した画期的な成果です。LLM エージェントの安全な社会実装に向けた重要なマイルストーンとして位置づけられます。