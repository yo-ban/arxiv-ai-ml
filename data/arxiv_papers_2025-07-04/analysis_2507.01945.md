# LongAnimation: Long Animation Generation with Dynamic Global-Local Memory

## 基本情報
- arXiv ID: 2507.01945v1 (https://arxiv.org/abs/2507.01945)
- 著者: Nan Chen、Mengqi Huang (University of Science and Technology of China)、Yihao Meng (Hong Kong University of Science and Technology)、Zhendong Mao† (University of Science and Technology of China)
- 所属: University of Science and Technology of China、Hong Kong University of Science and Technology
- 投稿日: 2025年7月2日
- カテゴリ: cs.CV

## 簡単に説明すると
この論文は、長期アニメーション（平均500フレーム）のカラー化を実現する新しいAIシステム「LongAnimation」を提案しています。
アニメーション制作では、まずキーフレーム（重要な1枚）に色を付け、その前後の長いスケッチシーケンスに同じ色彩を適用します。
従来の手法は短期間（100フレーム以内）のカラー化に限定されており、長期的な色の一貫性を保つことが困難でした。

例えば、300フレームのアニメーションで、最初は黄色だった帽子が100フレーム目で赤に変わってしまうような問題が発生していました。
LongAnimationは、過去の全ての生成履歴から現在の生成に関連する色情報を動的に抽出する「Dynamic Global-Local Memory」という仕組みを導入しています。
これにより、従来手法の5倍以上の長さ（平均500フレーム）のアニメーションで色の一貫性を保ちながら高品質なカラー化を実現しています。

## 1. 研究概要
### 1.1 背景と動機
アニメーション制作は映像産業において最も魅力的で美的な表現形式の1つです。
アニメーションのカラー化は実際の制作工程において重要な部分を占めています。
実際のアニメーション産業では、まずキーフレーム（最初のフレームだけでなく、シーケンス内の重要なフレーム）を描いて着色します。
その後、キーフレームの周囲のスケッチシーケンス、特に10～30秒（300～1000フレーム）に及ぶ長いシーケンスをキーフレームに基づいて着色します。

このような長いシーケンスの着色は非常に労働集約的であり、自動化された長期アニメーションカラー化の研究は高い意義を持っています。
長期アニメーションカラー化の主要な目標は、長期的な色の一貫性を維持することです。
つまり、同じオブジェクトが全てのフレームで一貫した色を持つ必要があります。

既存の手法は主に短期間（100フレーム以内）のアニメーションカラー化を探求しています。
これらの手法は固定された短期間のカラー化に限定されるか、隣接するセグメントの重複特徴を融合するローカルパラダイムを使用して限定的な拡張を実現しています。
しかし、グローバルな色の関係を無視しているため、より長いアニメーションで色の一貫性を維持することが困難です。

### 1.2 主要な貢献
本研究では、以下の3つの主要な貢献をしています。
- 概念: 動的にグローバルとローカルの一貫した色特徴を抽出することで、正確な長期アニメーションカラー化を実現する新しい動的グローバル・ローカルパラダイムを提案する
- 技術: LongAnimationを提案し、長期ビデオ理解モデルの動的圧縮に基づく新しいDGLMモジュールを設計して、現在の生成に関連する履歴色特徴を適用的に抽出する。
  DGLMモジュールを支援するため、DiTベースのビデオモデルを効率的に制御する新しいSketchDiTを設計する
- 実験: LongAnimationは、オープンドメインの長期アニメーションカラー化タスクで従来の先進モデルを上回る性能を示した。
  広く使用される指標FVD（Frechet Video Distance）で短期性能を35.1%、長期性能を49.1%改善する

## 2. 提案手法
### 2.1 手法の概要
LongAnimationは主に3つの部分から構成されています。
それらはSketchDiT、Dynamic Global-Local Memory (DGLM)、Color Consistency Rewardです。

訓練時には、参照画像I、Fフレームのスケッチ{Sf}、対応するテキスト記述が与えられます。
LongAnimationはSketchDiTを通じてこれらの入力のハイブリッド参照特徴を抽出します。
後続のセグメントを生成する際、DGLMは履歴特徴を動的に圧縮し、SketchDiTから得られた現在のハイブリッド特徴に関連するグローバル一貫性特徴を適用的に抽出します。
最終的に、Fフレームの長期一貫性アニメーションを生成します。

SketchDiTは、参照画像、スケッチ、テキストのハイブリッド表現を効率的に抽出する設計となっています。
スケッチはまず3D VAEエンコーダでエンコードされます。
次に、パディングされた参照画像トークンとチャネル次元で連結されます。
その後、テキスト特徴とシーケンス次元で連結されてSketchDiTの入力となります。

### 2.2 技術的詳細
Dynamic Global-Local Memory（DGLM）メカニズムの核心は、履歴アニメーションから現在の生成に関連する色一貫性特徴を抽出することです。

長期ビデオ理解（LVU）モデルVideo-XLを使用して履歴特徴を抽出します。
CLIPを使用して隣接フレーム間の視覚特徴変化を推定した後、異なるセグメント（2、4、8フレームなど）がビデオ用に動的に選択されます。
これらのフレームセグメントはマルチモーダル大規模言語モデル（MLLM）に送られ、各セグメントに対して視覚トークン<vs>を自己回帰的に生成します。

最近生成されたセグメントをローカルビデオVl、全ての履歴生成フレームをグローバルビデオVgと定義します。
これらのセグメントを包括的に考慮することで、より良い時間的一貫性を実現できます。
グローバルビデオとローカルビデオはLVUモデルに送られ、KVキャッシュに保存された視覚トークン<vs>のキーとバリューを抽出します。

Color Consistency Reward（CCR）は、アニメーションの長期的な色一貫性をさらに洗練するために提案されています。
TransformerのセルフアテンションがローパスフィルタとしてWebサイトし、低周波特徴（アニメの色など）を高周波特徴（スケッチなど）よりもよく捉えることを利用しています。
生成されたアニメのLVUモデルからのM層KVキャッシュ特徴を参照アニメのものと整列させることで、生成されたアニメの色を実際のアニメの色により近づけることができます。

### 2.3 新規性
既存手法との主な違いは、以下の点にあります。

第一に、従来のローカルパラダイムではなく、動的グローバル・ローカルパラダイムを導入している点です。
既存手法は隣接セグメントの重複部分を融合することで局所的な色の一貫性を達成していましたが、グローバルな色の関係を無視していました。
本手法は、履歴アニメーション全体から現在の生成に関連する色特徴を動的に抽出します。

第二に、長期ビデオ理解モデルを活用した動的圧縮メカニズムです。
Video-XLを使用して履歴特徴を効率的に圧縮し、現在の生成に必要な情報のみを適用的に抽出します。
これにより、メモリ効率を保ちながら長期的な一貫性を実現しています。

第三に、DiTベースのビデオモデルに対する新しい制御手法です。
SketchDiTは、参照画像、スケッチ、テキストを効率的に融合し、後続のDGLMメカニズムをサポートします。
テキスト制御を導入することで、背景生成などの追加的な制御も可能になっています。

## 3. 実験結果
### 3.1 実験設定
実装はCogVideoX-1.5-5Bをベースとしており、安定して81フレームを生成できます。
訓練データセットとしてSakuga-42Mを使用し、91フレーム以上の高美的価値と動的なビデオクリップをフィルタリングして、約80kのビデオを訓練に使用しました。

モデルは6つのA100 GPUを使用し、学習率1e-5で訓練されました。
解像度は1024×576で訓練されています。
SketchDiTレイヤーL=6、CogVideoX-1.5レイヤーN=42に設定しました。

テストデータセットとして、短期カラー化テストにはSakugaテストセットから3kサンプルをランダムに選択しました。
長期アニメーション生成には、300フレーム以上のビデオを選択し、美的スコア0.8以上、動的スコア0.4以上のサンプル（200ビデオ、約100kフレーム）をフィルタリングしました。

### 3.2 主要な結果
定量的評価では、LongAnimationは短期・長期両方のアニメーションカラー化タスクで優れた性能を達成しました。

短期アニメーション生成（14フレーム）では、フレーム類似性（LPIPS）で57.1%、ビデオ品質（FVD）で35.1%の改善を達成しました。
具体的な数値は、LPIPS: 0.054、SSIM: 0.867、PSNR: 27.22、FVD: 187.48、FID: 37.80です。

長期ビデオ生成（平均500フレーム）では、フレーム類似性（LPIPS）で58.0%、ビデオ品質（FVD）で49.1%の改善を達成しました。
具体的な数値は、LPIPS: 0.068、SSIM: 0.868、PSNR: 26.71、FVD: 240.57、FID: 40.75です。

LongAnimationは短期生成と比較して長期生成でより大きな改善を示しており、長期生成における本モデルの有効性を示しています。

### 3.3 既存手法との比較
ToonCrafter、LVCD、AniDocなどの既存手法と比較しました。
これらの手法は全てUNetベースのビデオ拡散モデルで訓練されています。

ToonCrafterは短期で564.48、長期で751.20のFVDスコアを記録しました。
LVCDは短期で520.51、長期で734.85のFVDスコアを記録しました。
AniDocは短期で427.03、長期で531.32のFVDスコアを記録しました。

LongAnimationはこれらを上回り、短期で187.48、長期で240.57のFVDスコアを達成しています。
特に長期生成において、既存手法と比較して約2倍以上の性能向上を実現しています。

アブレーション研究では、各モジュールの効果を検証しました。
SketchDiTのみを使用した場合のFVDスコアは321.62でした。
ローカルメモリを追加すると315.05、グローバルメモリを追加すると297.93に改善しました。
DGLMを使用すると261.76、さらにCCRを追加すると240.57まで改善しました。

## 4. 実用性評価
### 4.1 実装の容易性
LongAnimationはCogVideoXをベースとしており、既存のDiTベースビデオモデルに適用可能な設計となっています。
SketchDiTは最初のLレイヤーにCogVideoXの重みを使用して初期化されるため、短時間での学習が可能です。

DGLMメカニズムはVideo-XLを活用しており、既存の長期ビデオ理解モデルを効果的に活用しています。
実装はGitHubで公開される予定です。
研究コミュニティでの利用が期待されます。

### 4.2 計算効率
モデルは6つのA100 GPUで訓練可能で、現代的なGPUクラスターで実行可能です。
DGLMは履歴特徴を動的に圧縮するため、長期生成でもメモリ効率が保たれています。

Video-XLのKVキャッシュメカニズムを活用することで、履歴フレームの特徴を効率的に保存・アクセスできます。
推論時には、後期デノイジング段階でのみ潜在融合を行うことで、計算コストを抑えながら滑らかな遷移を実現しています。

### 4.3 応用可能性
LongAnimationは実際のアニメーション産業での応用に大きな可能性を持っています。
平均500フレーム（約16秒）の長期アニメーションのカラー化が可能で、これは従来手法の5倍以上の長さです。

テキスト制御機能により、背景生成などの追加的な制御が可能です。
マスクされた参照前景に基づいて長期的なテキスト誘導ビデオ背景生成を実現できるため、より柔軟な制作ワークフローをサポートします。

さらに、バイナリスケッチを使用することで、標準的なアニメーション制作パイプラインとの互換性も保たれています。
これにより、実際の制作現場での導入が容易になることが期待されます。

## 5. まとめと所感
### 5.1 論文の意義
この研究は、長期アニメーションカラー化という実用的な課題に対して革新的な解決策を提示しています。
動的グローバル・ローカルメモリという新しいパラダイムは、長期的な色の一貫性を保つという根本的な問題を効果的に解決しています。

特に、平均500フレームという長期間にわたって色の一貫性を維持できることは、実際のアニメーション制作において大きな価値があります。
労働集約的な作業を自動化することで、制作コストの削減と効率化に貢献する可能性があります。

技術的には、長期ビデオ理解モデルを生成タスクに活用するという新しいアプローチを示しており、他の長期ビデオ生成タスクへの応用も期待されます。

### 5.2 今後の展望
今後の改善点として、以下が考えられます。

第一に、より長いアニメーション（1000フレーム以上）への拡張です。
現在の平均500フレームも十分長いですが、実際の制作では30秒（約900フレーム）以上のシーケンスも一般的です。

第二に、多様なアニメーションスタイルへの対応です。
現在はSakuga-42Mデータセットで訓練されていますが、異なるスタイルのアニメーションへの汎化性を向上させることが重要です。

第三に、リアルタイム処理への最適化です。
現在の計算効率でも実用的ですが、インタラクティブな制作ツールとしての活用を考えると、さらなる高速化が求められます。

第四に、より細かい制御機能の追加です。
キャラクターごとの色管理や、シーンごとの色調整など、プロフェッショナルな制作現場で求められる機能の実装が期待されます。