# Thyme: Think Beyond Images

## 基本情報

- arXiv ID: 2508.11630v1 (https://arxiv.org/abs/2508.11630)
- 著者: Yi-Fan Zhang, Xingyu Lu, Shukang Yin, Chaoyou Fu, Wei Chen, Xiao Hu, Bin Wen, Kaiyu Jiang, Changyi Liu, Tianke Zhang, Haonan Fan, Kaibing Chen, Jiankang Chen, Haojie Ding, Kaiyu Tang, Zhang Zhang, Liang Wang, Fan Yang, Tingting Gao, Guorui Zhou（計20名）
- 所属機関: Kwai Keye、中国科学院、南京大学、清華大学、中国科学技術大学
- 投稿日: 2025年08月19日
- カテゴリ: cs.CV, cs.AI

## 簡単に説明すると

Thymeは、マルチモーダル大規模言語モデル（MLLM）が画像を「見るだけ」から「操作して理解する」へと進化させる革新的なフレームワークです。
従来の「画像で考える」アプローチとは異なり、Thymeは画像に対してクロッピング、回転、コントラスト調整などの多様な処理を実行し、さらに数学的計算も含めた包括的な推論が可能です。

実装はPythonコードの自動生成・実行を通じて行われ、セキュアなサンドボックス環境で動作します。
SFT（教師あり微調整）とRL（強化学習）の2段階学習により、わずか200GPU時間で基本機能を習得し、20近くのベンチマークで一貫した性能向上を実現している。

論文では詳細なデータセット構築手法、GRPO-ATS（適応温度サンプリング付きグループ相対政策最適化）アルゴリズム、さらにサンドボックス設計まで網羅的に記述されており、研究の再現性と実用性の両面で高い価値を持つ研究成果となっている。

## 1. 研究概要

### 1.1 背景と動機

近年のマルチモーダル大規模言語モデル（MLLM）の発展において、「画像で考える」（thinking with images）という概念が注目を集めている。
しかし、既存の手法は主に2つのカテゴリに分類され、それぞれに重要な制約がある。

第1のカテゴリは「生成画像による思考」である。このアプローチでは、モデルがまず画像を生成し、その画像を後続の推論プロセスで活用する。
数学問題における補助線の描画などの想像力を要する場面では有効だが、生成画像の品質制限により元画像の細部情報が失われがちである。
さらに、画像生成に伴う計算コストが推論時間を大きく延長し、リアルタイム応用における実用性を損なう。

第2のカテゴリは「クロッピングによる思考」で、モデルがバウンディングボックスを出力して関連領域を特定し、外部で切り取り処理を行う。
この手法は知覚精度の向上や幻覚の軽減に効果的だが、機能性が極めて限定的である。
バウンディングボックス出力によるクロッピングのみが可能で、OpenAI O3が示すような回転、コントラスト調整、プログラミングといった多機能性には及ばない。

研究チームは、これらの制約を克服するために、より包括的で自律的な画像操作・計算システムの必要性を認識した。
特に、高解像度画像や複雑な視覚タスクにおいて、単純なクロッピング以上の多様な画像処理が求められる現状を踏まえ、新しいパラダイムの開発に着手した。

### 1.2 主要な貢献

Thymeは「Think Beyond Images」というコンセプトの下、従来の制約を打破する包括的なソリューションを提供する。
研究の主要な貢献は4つの核心的原則に基づいて体系化されている。

- **豊富な機能性（Rich Functionality）**: モデルはクロッピング、スケーリング、回転、コントラスト調整といった多様な画像操作に加え、複雑な数学計算にも対応できます
- **高い自律性（High Autonomy）**: Thymeは画像操作の必要性判断、適用する操作の決定、動的なコード生成による実行を人間の介入なしに自律的に行います
- **効率的なエンドツーエンド学習（Efficient End-to-End Training）**: SFT+RLアルゴリズムにより学習コストを最小化し、SFT段階ではわずか200GPU時間で全機能を活性化します
- **安定した大幅な性能向上（Significant and Stable Performance Gains）**: 知覚、推論、一般タスクの3カテゴリ、約20ベンチマークで一貫した実質的な性能改善を実現します

## 2. 提案手法

### 2.1 手法の概要

Thymeの全体アーキテクチャは、**モデル**と**サンドボックス**の二つの主要コンポーネントで構成されます。
ユーザー入力に対し、モデルはまず推論プロセスを生成し、問題の性質と難易度に基づいてコード生成の必要性を判断します。

コード生成が不要と判断された場合、問題が単純であるか、過去の対話でコード操作により既に問題が解決済みであることを意味し、
この場合は直接回答を返します。

コード生成が必要と判断された場合、モデルは自律的にコードを生成します。
学習データは、クロッピング、ズーミング、回転、コントラスト調整、計算といった複数の画像操作タイプをカバーしており、
モデルはこれらの機能を単独で、または組み合わせて実装できます。
操作パラメータ（コントラスト調整係数、クロッピング座標、ズーム比率など）はすべてモデル自身が決定し、外部制約はありません。

生成されたコードは外部サンドボックスで実行され、その主機能は入力コードの安全な処理と実行結果の返却です。
サンドボックス内部では、Python組み込みモジュール（ast、autopep8など）を活用してコード整形、入出力変数プロパティの修正、
コード入力パラメータの修正を行います。これらの処理はコード機能に影響を与えることなく、些細なコード詳細によるエラーを回避し、
モデルのコード負担を軽減して使用性を向上させます。

最終的に、コード実行結果がモデルに返され、次の対話ラウンドのためのデータとして、モデルはこれらの結果に基づいて推論を行い、
相互作用を継続します。

### 2.2 技術的詳細

#### サンドボックス設計

Thymeフレームワークには、二つの重要な特性を持つ堅牢なサンドボックスが必要です。
第一に、基本的なセキュリティと頑健性を保証し、サンドボックス内で実行される画像処理や計算操作が合理的な時間内で完了するか、
適切なエラーを発生させることを確実にします。同時に、既存データやランタイム設定を破損する可能性のあるファイル削除や名前変更などの
不正なシステム変更を防止します。

第二に、小規模モデル（7Bパラメータなど）はしばしば完璧なコード生成に苦労し、
フォーマット問題（不適切なインデント）、境界条件エラー（画像寸法を超えるクロッピングボックス）、
入出力処理（入力変数の省略や出力印刷の忘れ）といった軽微な問題に頻繁に遭遇します。
サンドボックス設計は、可能な場合にこれらの軽微な問題を自動処理することで、モデルのコーディング負担を軽減することを目的としています。

**セキュリティと頑健性への対策:**
- システムデータや設定の障害を引き起こす可能性のある危険な操作（remove、unlink、move、renameなど）のリストを定義し、
  実行前にコードをスキャンしてこれらの操作が含まれている場合、実行をスキップしてエラーとして警告を発生
- 最大実行時間を制限（経験的に10秒に設定）し、この制限を超えるとタイムアウトエラーが発生

**モデルのコード生成負担軽減:**
- Pythonの組み込みautopep8を適用してコードのフォーマットとインデント調整を実行
- astモジュールを使用してコードを走査し、タプル形式の変数を特定。変数名に"box"や"coord"が含まれる場合、
  クロッピングパラメータと推定し、これらのパラメータを入力画像境界内に調整してエラーを回避
- 実行前にimage_pathなどのローカル変数を事前設定し、cv2などのパッケージをインポート。
  実行後、処理結果を示す新規作成変数（'processed_path'を含むものなど）をチェックして、
  入出力変数がモデル生成コードで明示的に定義されていない場合でも正しい実行を保証
- モデルが複数のコードセグメントを出力する際、コンテキストや変数依存関係が発生することを観察し、
  例えば特定のPythonパッケージが最初のセグメントでのみインポートされ、後続セグメントが直接それらに依存する場合があります。
  この問題に対処するため、モデルのコード実行プロセス全体を通じてすべての変数を記録し、
  マルチラウンドサンドボックス呼び出しで履歴コンテキストを組み込みます

#### 学習戦略

SFTプロセスでは、システムプロンプトとユーザープロンプトが明確に定義されています。
システムプロンプトでは、タスク形式、期待される出力コードスタイル、サンドボックス環境実行結果の形式を明示的に定義し、
モデルがタスク要件を明確に理解できるようにします。
ユーザープロンプトには画像パスと画像サイズが含まれ、適切な画像読み込みと範囲外操作の防止を促進し、必要な出力形式も指定されています。

学習プロセスでは、各サンプルが以下のように表現されます：
$$X = \{(I, Q); ([T_0, C_0, S_0], \ldots, [T_t, a])\}$$
ここで、$I$は画像、$Q$は質問、$T$は思考プロセス、$C$はコード、$S$はサンドボックス実行結果、$a$は最終回答、$t$は最大相互作用ラウンド数です。

学習中に遭遇した課題に対し、以下の戦略を考案しました：
- **最終ラウンドのみでの学習**: 二ラウンド以上のサンプルでは、最後の`<sandbox_output></sandbox_output>`タグまでの内容をマスクし、
  モデルは最終ラウンドの出力のみを学習
- **サンドボックス内容の除外**: すべての学習段階で、サンドボックス識別子とサンドボックス実行結果を学習対象から除外し、
  モデルがサンドボックス出力を直接予測することを防止
- **数学データのアニーリング**: 数学データが画像操作データに圧倒されることを防ぐため、まずすべての画像関連データで学習し、
  その後より低い学習率で数学データのみで微調整

### 2.3 新規性

Thymeの新規性は、従来の「画像で考える」パラダイムからの根本的な脱却にあります。
既存手法が生成画像の品質制限やクロッピング機能の制約に苦しむ中、Thymeは実行可能コードを通じた多様な画像操作と計算の統合を実現しました。

特に注目すべきは、GRPO-ATS（適応温度サンプリング付きグループ相対方策最適化）アルゴリズムの導入です。
このアルゴリズムは、テキストとコード生成に異なる温度設定を適用する革新的なアプローチです。
コード生成時には温度0を適用して決定論的出力を確保し、自然言語推論には温度1.0を使用して概念的探索と多様な表現を促進します。

また、セキュアサンドボックス環境の自動コード修正機能は、小規模モデルの限界を効果的に補完する実用的な新規性を提供します。
Pythonのast、autopep8モジュールを活用した自動フォーマット修正、境界条件調整、変数依存関係の管理は、
モデルの実用性を大幅に向上させる技術革新です。

## 3. 実験結果

### 3.1 実験設定

実験はQwen 2.5 VL 7Bをバックボーンとして選択し、32台のNVIDIA H800 GPUで実施されました。
総学習時間は約224GPU時間で、アニーリング段階が約8GPU時間、強化学習段階が1200GPU時間以上を要しました。

ハイパーパラメータは以下のように設定されました：
- **SFT段階**: 画像操作関連データの学習率は$1 \times 10^{-5}$、数学コード関連データのアニーリングは$1 \times 10^{-6}$
- **バッチサイズ**: 128、エポック数: 3、ウォームアップ比率: 0.05
- **RL段階**: 学習率$5 \times 10^{-7}$、エポック数: 1、KL発散係数: 0.001、バッチサイズ: 256、ロールアウト数: 4、繰り返しペナルティ: 1.05

評価には三つのカテゴリのベンチマークを使用しました：
1. **知覚タスク**: MME-RealWorldシリーズ、HR Bench、V*、RealWorld QAなど
2. **推論タスク**: MathVision、MathVista、MathVerse、LogicVista、WeMath、VisuLogicなど
3. **一般タスク**: Hallucination bench、MMStar、MMVet Hard、OCR Bench、Chart QA、BLINKなど

ベースラインとしてQwen-2.5-VL-7Bを主要比較対象とし、InternVL3-8B、Qwen-2.5-VL-32B、クローズドソースのGPT-4oとも比較しました。
公正な比較のため、VLMEvalKitを評価パイプラインとして採用しました。

### 3.2 主要な結果

実験結果は、Thymeが幅広いタスクカテゴリで一貫した優位性を示すことを明確に示しています。

**知覚タスクにおける成果:**
Thymeは、より大規模なモデル（Qwen2.5-VL 32Bなど）に対しても明確な優位性を示しました。
これは、単純なモデルサイズの拡大では知覚課題を効果的に解決できないことを示唆し、
Thymeのテスト時スケーリング戦略が知覚タスクに高い有効性を持つことを証明しています。

HR Bench-4Kでは、FSP（細粒度単一インスタンス知覚）で91.0%（ベースライン比+5.8%）、
FCP（細粒度交差インスタンス知覚）で63.0%（+10.8%）、全体で77.0%（+8.2%）の性能を達成しました。

MME-Realworldでは、知覚タスクで67.1%（+6.5%）、推論タスクで48.4%（+9.8%）、
全体で64.8%（+6.6%）の改善を示しました。

**推論タスクにおける成果:**
複雑な計算を実行可能コードに変換する学習により、Thymeは推論能力において顕著な改善を達成しました。
LogicVistaでは49.0%（+9.2%）、WeMathでは39.3%（+5.0%）の性能向上を記録しました。

ただし、この領域では大規模モデルの利点がより顕著であり、推論と論理推論能力がモデル内在知識に大きく依存することを示唆しています。
Thymeは主に視覚認識品質の向上と過度に複雑な計算の独立予測回避に貢献しています。

**一般タスクにおける成果:**
知覚と推論の改善により、Thymeは多くの一般タスクで重要な向上を示し、特に幻覚の大幅な減少を実現しました。
Hallucination benchmarkでは、全体で55.6%（+7.3%）の改善を達成し、
MMVet Hardでは58.3%（+5.5%）の性能向上を記録しました。

### 3.3 既存手法との比較

MME-Realworldの詳細分析では、ベースラインモデルが既に良好な性能を示すタスク（OCR、図表、テーブルなど、60%以上の精度）では、
Thymeの改善は限定的でした。

しかし、ベースラインの知覚性能が相対的に低い困難なタスク（監視、自動運転など）では、
Thymeは知覚と推論の両タスクで25%以上の改善を示し、推論タスクでの改善がより顕著でした。

監視タスクでは、知覚で27.14%、推論で81.57%の改善率を達成し、
自動運転タスクでは、知覚で64.99%、推論で33.16%の大幅な性能向上を実現しました。

これらの結果は、Thymeが特に困難で複雑な視覚理解タスクにおいて真価を発揮することを示しており、
実世界の複雑なシナリオでの実用性を強く示唆しています。

## 4. 実用性評価

### 4.1 実装の容易性

Thymeの実装容易性は、研究の再現性と実用展開の観点から高く評価できます。
論文では、データセット構築からサンドボックス環境設計まで、実装に必要なすべての詳細が体系的に記述されています。

特に注目すべきは、SFT段階でわずか200GPU時間という効率的な学習時間です。
これは、限られた計算資源を持つ研究機関や企業でも実装可能な現実的な要件となっています。
バックボーンモデルとしてオープンソースのQwen 2.5 VL 7Bを使用している点も、実装のハードルを大幅に下げています。

サンドボックス環境の設計では、Python標準ライブラリ（ast、autopep8）を主に活用しており、
特殊な依存関係や複雑な外部ツールを必要としません。コードの自動修正機能も、
既存のPythonエコシステムを効果的に活用した実装アプローチです。

論文では完全なデータセット、サンドボックス環境、学習コードのオープンソース化を約束しており、
研究コミュニティでの採用と更なる研究を促進する姿勢を示しています。

### 4.2 計算効率

Thymeの計算効率は、段階的学習アプローチと動的なコード生成により最適化されています。

SFT段階の効率性は特筆すべき点で、約500Kサンプルの学習により多様な画像操作と計算能力を活性化し、
200GPU時間という比較的短時間で基本機能を習得できます。
これは、従来の大規模マルチモーダルモデルの学習時間と比較して非常に効率的です。

RL段階では、GRPO-ATSアルゴリズムの適応温度サンプリングが計算効率の向上に大きく貢献しています。
コード生成時の温度0設定により、無効なコード生成による計算資源の浪費を大幅に削減し、
サンプル効率性を改善しています。

推論時における計算効率も配慮されており、モデルは問題の複雑さを評価して必要な場合のみツールを使用する自律性を持ちます。
単純な問題では直接回答を生成し、複雑な問題でのみコード実行による処理を行うため、
不要な計算オーバーヘッドを回避しています。

サンドボックス環境の10秒実行制限や、繰り返しエラーの早期終了メカニズムも、
計算資源の効率的利用に寄与しています。

### 4.3 応用可能性

Thymeの応用可能性は、その多機能性と汎用性により極めて広範囲に及びます。

**教育分野での応用:**
数学教育において、Thymeは複雑な計算問題をコードに変換して解決し、
視覚的な図形問題では画像操作（回転、クロッピング）を通じて理解を深める支援が可能です。
多言語対応（CJKutf8パッケージの使用）により、グローバルな教育環境での展開も期待できます。

**産業応用での可能性:**
監視システムや自動運転分野での実験結果は、Thymeの実世界応用における高いポテンシャルを示しています。
高解像度画像の詳細分析、複雑な視覚シーンの理解、リアルタイム画像処理など、
産業級アプリケーションで求められる機能を包括的にカバーしています。

**研究ツールとしての活用:**
OCR、図表解析、科学文献の視覚的コンテンツ解析など、研究支援ツールとしての応用が期待されます。
特に、arXivQAデータセットでの学習実績は、学術文献の自動解析システム構築の基盤となり得ます。

**拡張性と適応性:**
モジュラー設計により、新たな画像操作機能やドメイン特化の計算処理を比較的容易に追加できます。
サンドボックス環境の設計も、セキュリティを保ちながら機能拡張を可能にする柔軟な架構を提供しています。

## 5. まとめと所感

### 5.1 論文の意義

Thymeは、マルチモーダル大規模言語モデルの発展において画期的な転換点を示す研究成果です。
従来の「画像を見る」から「画像を操作する」への発想転換は、AI・機械学習分野における重要なパラダイムシフトを表しています。

技術的な意義として、実行可能コードを通じた画像操作と計算の統合は、これまで分離されていた視覚理解と計算処理を
統一的なフレームワークで実現した点で革新的です。
GRPO-ATSアルゴリズムの適応温度サンプリングは、強化学習における新しい技術貢献として、
今後の多様なタスクへの応用が期待されます。

実用的な意義として、わずか200GPU時間での機能習得という効率性は、
研究機関の計算資源制約を大幅に緩和し、この分野の研究参入障壁を下げる重要な成果です。
約20ベンチマークでの一貫した性能向上は、提案手法の汎用性と実用性を強く示しています。

学術的な意義として、詳細な実装記述とオープンソース化の約束は、研究の再現性を高め、
コミュニティ全体の発展に大きく貢献するものです。特に、サンドボックス設計の詳細や
データ構築パイプラインの公開は、後続研究の基盤として極めて価値があります。

### 5.2 今後の展望

**技術的発展の方向性:**
Thymeの核心概念は、より大規模で強力な基盤モデルとの組み合わせにより、さらなる飛躍が期待されます。
現在の7Bパラメータモデルの制約（精密な物体定位、高度なコード生成）を克服することで、
より精緻で信頼性の高いツール使用が実現できるでしょう。

**評価手法の革新:**
既存ベンチマークの制約（高品質で正しい向きの日常画像中心）により、
画像回転補正や低コントラスト画像改善などThymeの先進的な画像処理能力を
適切に評価できていない現状があります。
これらの高度な画像処理操作を評価する新しいベンチマークの開発が急務です。

**応用領域の拡大:**
教育、産業、研究支援への応用可能性に加えて、医療画像解析、衛星画像解釈、
アート・クリエイティブ分野での創作支援など、専門分野での活用が期待されます。
特に、ドメイン特化の画像操作機能の開発により、各分野の専門的ニーズに対応できるでしょう。

**コミュニティ協力の重要性:**
オープンソース化により、世界中の研究者がThymeの改良と拡張に参加することで、
急速な技術発展が見込まれます。特に、多様な言語・文化背景からの貢献により、
より汎用的で包括的なシステムの実現が期待されます。

Thymeは、マルチモーダルAIの次世代発展における重要な礎石として、
技術革新と実用化の両面で長期的な影響を与える研究成果であると評価できます。
