# AccidentBench: Benchmarking Multimodal Understanding and Reasoning in Vehicle Accidents and Beyond

## 基本情報
- **arXiv ID**: 2509.26636v1 (https://arxiv.org/abs/2509.26636)
- **著者**: Shangding Gu, Xiaohan Wang, Donghao Ying, Haoyu Zhao, Runing Yang, Ming Jin, Boyi Li, Marco Pavone, Serena Yeung-Levy, Jun Wang, Dawn Song, Costas Spanos
- **所属**: UC Berkeley, Stanford, UCL, Virginia Tech, Nvidia
- **投稿日**: 2025年09月26日
- **カテゴリ**: cs.CV, cs.AI

## 簡単に説明すると
この論文は車両事故シナリオを中心とした安全重要な状況でのマルチモーダル理解と推論を評価するための大規模ベンチマークAccidentBenchを提案しています。約2,000本の動画と19,000以上の人手アノテーション質問応答ペアで構成され、時間的・空間的・意図的理解の3つの推論タイプを3つの難易度レベルで評価します。GPT-5やGemini-2.5 Proといった最先端モデルでも最難度タスクと長時間動画では約18%の精度しか達成できず、安全重要分野でのAIシステムの重大な限界を明らかにしています。コードとデータセットはGitHubで公開されています（https://github.com/SafeRL-Lab/AccidentBench）。

## 1. 研究概要
### 1.1 背景と動機
マルチモーダル大規模モデルは視覚・言語・動画ドメインで目覚ましい能力を示していますが、自動運転、ロボティクス、航空・海洋操作といった安全重要なアプリケーションでの実世界展開には重大な課題が残されています。制約された環境や模擬環境では優れた性能を示すものの、高リスクで動的なシナリオでの堅牢性と理解の深さは十分ではありません。

ミッション重要ドメインでの展開には、不確実性、物理的相互作用、因果関係を含む実世界条件下でのモデルの理解と推論能力の厳密な評価が必要です。既存のベンチマークは時間的理解（MVBench、REXTIME）やドメイン固有知識（MMMU、DriveLM）といった特定の側面を進歩させましたが、多様な車両事故やその他の開放空間ドメインでの理解と推論を評価する統一プラットフォームは不足していました。

単一フレーム入力に基づく評価では推論の不確実性が生じ、安全重要問題を扱うマルチモーダルモデルの能力を信頼性高く評価するには不十分です。このため、動画ベースの包括的評価が必要となっています。

### 1.2 主要な貢献
本研究の主要な貢献は以下の3点です。

- **車両事故焦点のベンチマーク構築**: 多様な車両事故シナリオに重点を置きつつ航空・水路ドメインにも拡張したAccidentBenchを開発。車両事故の評価は実世界アプリケーションでのLLMの安全な展開において特に重要で、自動運転での広範囲な利用に向けた重要なステップとなります。

- **実世界限界と安全ギャップの明確化**: 開放空間ドメイン（自動運転、航空、海洋）における現在のAIシステムの理解と推論の弱点を明確化し、より安全で信頼性の高いマルチモーダルモデルの発展を促進する挑戦的テストベッドを提供。

- **統一評価スイートの開発**: 陸上交通、航空、水路シナリオを統合し、動的で安全重要な環境内での時間的理解、空間的理解、意図・目標推論を体系的に評価する大規模動画ベースベンチマークを構築。

## 2. 提案手法
### 2.1 手法の概要
AccidentBenchは車両事故を中心とした安全重要シナリオでマルチモーダルモデルの理解と推論を厳密に評価するベンチマークです。主要な対象は車両事故シナリオ（83%）で、航空（10.2%）と水路（6.8%）ドメインも含みます。

ベンチマークは時間的理解と推論（拡張期間にわたるイベントシーケンスと因果関係の追跡）、空間的理解と推論（動的空間関係とマルチエージェント軌道の理解）、意図・目標推論（エージェント意図と計画目標の推定、複雑な戦略的・反実仮想推論を含む）の3つの重要な能力を体系的に評価します。

車両事故シナリオには交差点衝突、都市道路事故、夜間事故、農村道路事故、雪道衝突、高速道路事故などが含まれ、多様な道路環境、天候条件、交通参加者を網羅しています。

### 2.2 技術的詳細
各理解・推論次元において、2つの形式を用いて3つの難易度レベルでタスクを構築しています。易タスク（約6,300 QAペア）では約3つの粗粒度区間オプション、中タスク（約6,300 QAペア）では6つの中間レベル区間、難タスク（約6,300 QAペア）では正解との完全一致を要求する細粒度離散オプションを提示します。

データセット構成は以下の通りです：
- 車両事故シナリオ: YouTubeなどの公開プラットフォームから収集された動画を使用、多様な車両タイプ（バス、オートバイ、セダン、トラック）と道路環境（高速道路、農村道路等）を含む
- 船舶運動シナリオ: 河川・海洋設定で多様な船舶・ボートを対象、公開データセットから収集
- 航空ナビゲーションシナリオ: 離着陸イベントに重点、多様な航空機サイズと運動動学を含む

評価にはlmms-evalフレームワークを基盤として使用し、AccidentBenchの特定要件をサポートするよう拡張しています。

### 2.3 新規性
AccidentBenchの新規性は複数の観点から評価できます。

理論的新規性として、安全重要シナリオに特化した動画ベースマルチモーダル評価の体系的フレームワークを初めて構築しました。従来のベンチマークが一般的なドメインや単一フレーム評価に限定されていた中で、車両事故という具体的で重要な安全ドメインに焦点を当てた包括的評価を実現しています。

実装的新規性として、3つの異なる物理環境（陸上・航空・水上）を統一的に評価するマルチドメインアプローチを採用し、難易度と推論タイプの組み合わせによる階層的評価設計により、モデルの能力を多角的に診断できるシステムを構築しました。

応用的新規性として、実世界の安全重要アプリケーションでの実用性を重視した評価指標とタスク設計を実現し、学術的評価にとどまらず自動運転・航空・海洋分野での実際の展開可能性を評価できるベンチマークとして設計されています。

## 3. 実験結果
### 3.1 実験設定
実験は車両事故シナリオを中心に、船舶運動と航空ナビゲーションシナリオでも実施されました。評価は3つの難易度（易・中・難）と3つの推論タイプ（時間的・空間的・意図的）で組織化されています。

高コストを考慮し、統一サンプリング戦略を採用してタスク数が500未満の場合は50タスク、500超の場合は100タスクを各理解・推論タイプから抽出し、総計3,798タスクを評価しました。

評価対象モデルには GPT-5、GPT-4o、Gemini 2.5 Pro、Gemini 2.5 flash、Claude 3.5、InternVL2.5（4B/8B/26B）、LLaVA Next、LLaVA Video、LLaVA OneVision、Qwen2.5 VL などの最先端モデルを含めています。

### 3.2 主要な結果
車両事故シナリオの評価では、GPT-5が最強の総合性能を達成し、難設定で平均37.33%、中設定で48.34%、易設定で54.86%を記録しました。Gemini 2.5 Proも一貫して良好な性能を示し、易設定で57.90%を達成しました。

重要な発見として、全モデルでタスク難易度の増加に伴って性能が大幅に低下しています。特に難設定での意図推論が最も困難な課題となっており、動画長別分析では長時間動画の難タスクにおいて最高性能モデルでも平均40%以下の精度しか達成できませんでした。

最も重要な結果として、最難タスクと最長動画シナリオでは最先端モデルでも約18%の精度にとどまっており、現在のマルチモーダルモデルの深刻な限界が明らかになりました。プロプライエタリモデルがオープンソース対応モデルを上回る性能を示しているものの、全難易度レベルと推論タイプで堅牢な性能を達成するモデルは存在しません。

### 3.3 既存手法との比較
船舶運動シナリオではGPT-5が最高総合性能（難：38.36%、中：51.80%、易：63.00%）を達成し、Gemini 2.5 Proが競争力のある結果と強力な空間・意図推論を示しました。航空ナビゲーションシナリオでも同様の傾向が観察されています。

既存ベンチマークとの比較では、AccidentBenchが安全考慮とトラフィック特化の両方を含む唯一のベンチマークであることが明確になりました。多くの既存ベンチマーク（MovieChat-1K、MMWorld、MLVU等）が一般的なドメインに焦点を当てる中、AccidentBenchは実世界の安全関連シナリオに特化した動画ベース質問応答を提供しています。

質的エラー分析では、Gemini 2.5やGPT-4oといった最先端モデルでも空間関係の特定（車両の相対位置）、動的オブジェクトの経時的カウント（動く車両）、目標指向相互作用の理解（航空機の通過イベント）において一貫した失敗ケースが見られることが判明しました。

## 4. 実用性評価
### 4.1 実装の容易性
AccidentBenchは lmms-eval フレームワークを基盤として構築されており、既存の評価インフラストラクチャとの互換性が確保されています。ベンチマークのコードとデータセットはGitHubで公開されており、研究者や開発者が容易にアクセス・活用できる環境が整備されています。

評価プロセスは標準的なマルチモーダルモデル評価パイプラインに統合可能で、特殊なハードウェアや依存関係を必要としません。サンプリング戦略により評価コストを削減しながら信頼性の高い結果を得ることができ、実用的な評価環境を提供しています。

### 4.2 計算効率
統一サンプリング戦略により、全データポイントの評価と比較して計算コストを大幅に削減しています。アブレーション研究では、InternVL2.5を用いた検証において、サンプル化されたサブセットでの性能が完全データセットでの性能と同等またはそれ以上であることが示されており、この手法の有効性が検証されています。

ベンチマークは3,798タスクの評価を通じて包括的な評価を提供しながら、実用的な計算時間内での実行を可能にしています。多様な動画長（短・中・長）での評価により、モデルの計算効率と精度のトレードオフも分析できます。

### 4.3 応用可能性
AccidentBenchの応用可能性は安全重要分野において極めて高く評価されます。自動運転システムの安全性評価、航空・海洋分野でのAI支援システムの信頼性検証、ロボティクスにおける環境理解能力の評価などに直接活用できます。

ベンチマークが明らかにした現在のモデルの限界は、より安全で堅牢なマルチモーダルシステムの開発指針を提供します。特に、時間的・空間的・意図的推論における具体的な弱点の特定により、研究開発の優先度設定に寄与できます。

実世界の変動性を含む物理的に根拠のあるテストベッドとして、AccidentBenchは学術研究から産業応用まで幅広い用途での活用が期待されます。

## 5. まとめと所感
### 5.1 論文の意義
この論文は安全重要分野でのマルチモーダルAI評価において画期的な貢献を成し遂げています。車両事故という具体的で重要な安全ドメインに焦点を当てたベンチマークの構築により、従来の一般的評価では見えなかった重大な能力ギャップを明らかにしました。

理論的には、安全重要シナリオでのマルチモーダル理解と推論の体系的評価フレームワークを確立し、時間的・空間的・意図的推論の3次元評価アプローチを提案しました。この枠組みは他の安全重要ドメインにも拡張可能な一般的価値を持ちます。

実用的には、現在の最先端モデルの深刻な限界を定量的に示し、安全な実世界展開に向けた具体的な研究課題を特定しました。GPT-5やGemini 2.5 Proといった最高性能モデルでも18%程度の精度にとどまるという結果は、この分野の研究の緊急性を浮き彫りにしています。

### 5.2 今後の展望
技術的発展の方向性として、より高度な時間的・空間的推論能力を持つアーキテクチャの開発が急務です。特に長時間動画での意図理解や複雑な物理的相互作用の理解において、根本的な改善が必要です。マルチモーダル表現学習の改良、物理法則を考慮した推論システムの開発、安全制約下での学習手法などが重要な研究方向となります。

評価手法の発展として、より細粒度な診断能力を持つベンチマーク拡張や、因果推論・反実仮想推論といった高次認知能力の評価項目追加が考えられます。また、リアルタイム性能や不確実性定量化といった実用的側面の評価も重要になります。

応用面では、AccidentBenchで明らかになった課題に対応するため、マルチモーダル融合技術の改良、時系列パターン認識の高度化、意図予測アルゴリズムの開発などが期待されます。長期的には、この研究が示した評価手法と課題認識が、真に安全で信頼性の高いマルチモーダルAIシステムの実現に向けた重要な基盤となることが期待されます。