# Stitch: Training-Free Position Control in Multimodal Diffusion Transformers

## 基本情報
- arXiv ID: 2509.26644v1 (https://arxiv.org/abs/2509.26644)
- 著者: Jessica Bader, Mateusz Pach, María A. Bravo, Serge Belongie, Zeynep Akata
- 所属: Technical University of Munich, Helmholtz Munich, Munich Center for Machine Learning, University of Copenhagen
- 投稿日: 2025年09月26日
- カテゴリ: cs.CV, cs.AI

## 簡単に説明すると
この論文は、テキストから画像を生成するAIモデル（T2I）において、「右側にある」「上にある」といった空間関係を正確に描画するのが苦手という問題を解決する新しい手法「Stitch」を提案している。
Stitchは学習不要で既存のモデル適用が可能です。LLMが生成したバウンディングボックス内で個別オブジェクトを生成し、アテンション機構による前景抽出・合成により、空間的に正確で視覚的に魅力的な画像を生成します。
また、位置制御の評価のために新しいベンチマーク「PosEval」も提案しています。
コードはGitHubで公開されています（https://github.com/ExplainableML/Stitch）。

## 1. 研究概要
### 1.1 背景と動機
テキストから画像を生成するT2I（Text-to-Image）モデルは近年急速に発展してきたが、「上にある」「右側にある」といった基本的な空間関係の表現においても依然として大きな課題を抱えている。
GenEvalベンチマークなどでも指摘されている通り、既存のT2Iモデルは複雑ではない位置関係プロンプトでさえ正確に解釈し画像として生成することが困難である。

従来はバウンディングボックスを用いた位置制御手法が存在したが、これらの手法は古いU-NetやDiffusion Transformerアーキテクチャを対象として設計されており、最新のMulti-Modal Diffusion Transformer（MMDiT）ベースのモデル（FLUX、SD3.5、Qwen-Imageなど）には適用が困難であった。
一方でMMDiTアーキテクチャは画像品質と生成速度において大幅な改善を実現しており、これらの利点を活かしつつ位置制御機能を追加することが強く求められていた。

現実世界のシーンでは稀だが物理的に妥当なオブジェクト配置や、言語的にニュアンスのある位置記述の解釈など、ユーザーの要求はますます高度化している。
そのため、基本的な位置理解能力の向上は単なる技術的改善ではなく、T2Iモデルの実用性向上において不可欠な要素となっている。

### 1.2 主要な貢献
本論文の主要な貢献は以下の3点に集約されます。

第一に、Stitchという学習不要の位置制御手法を提案しています。
この手法はMMDiTベースのT2Iモデルに対して、推論時のみで位置ベースプロンプトから正確な画像を生成する能力を218%向上させます。
Stitchは外部のマルチモーダルLLMを活用してプロンプトを分解し、オブジェクトごとのバウンディングボックスを自動生成する。
その後、各オブジェクトを指定された領域内で個別に生成し、アテンション機構を利用した前景抽出により最終的な合成画像を作成する。

第二に、アテンションヘッドによる前景セグメンテーションの発見である。
研究では特定のアテンションヘッドが、画像生成が完了する前の段階で前景オブジェクトと背景を分離するのに十分な情報を保持していることを明らかにした。
この発見により、外部のセグメンテーションモデルを使用することなく、生成プロセス中に直接オブジェクトの切り出しが可能となった。

第三に、PosEvalベンチマークの構築である。
既存のGenEvalベンチマークの基本的なPositionタスクを拡張し、より挑戦的で多様な位置関係評価を可能にする5つの新しいタスクを追加した。
これらのタスクは3オブジェクト・4オブジェクトの複雑な配置、属性と位置の結合、否定関係、相対関係など、実用的なシナリオを包括的にカバーしている。

## 2. 提案手法
### 2.1 手法の概要
Stitchは大きく分けて3つの段階で構成される位置制御フレームワークである。

まず分解段階では、マルチモーダルLLMを使用して入力プロンプトを解析し、各オブジェクトに対応するサブプロンプトとバウンディングボックスのペアを生成する。
例えば「蝶がスケートボードの上にいる公園の写真」というプロンプトは、「蝶」「スケートボード」「公園」の3つのサブプロンプトと、それぞれに対応する空間的制約に分解される。

次にRegion Binding段階では、最初のS ステップ（FLUXとSD3.5では10ステップ、Qwen-Imageでは6ステップ）において、各オブジェクトを指定されたバウンディングボックス内でのみ生成するようアテンションマスクによる制約を適用する。
この制約により、オブジェクト間の干渉を防ぎながら、各領域内で適切な形状と特徴を持つオブジェクトの生成が促進される。

最後にCutout段階では、特定のアテンションヘッドから得られる前景情報を利用して、各オブジェクトの前景部分のみを抽出し、共通の背景と合成する。
残りの生成ステップでは制約を解除し、元の完全なプロンプトを条件として自然な画像仕上げを行う。

### 2.2 技術的詳細
MMDiTアーキテクチャにおいて、視覚トークンとテキストトークンは共有埋め込み空間で処理される。
Stitchはこの構造を活用し、特定の空間領域に対してアテンションマスクを適用することで位置制御を実現する。

Region Bindingでは、以下の3つのマスキング制約を全レイヤー・全ヘッドに適用する：
（1）バウンディングボックス内から外への視覚アテンションをブロック
（2）バウンディングボックス外からテキストへのアテンションをブロック  
（3）テキストからバウンディングボックス外への視覚アテンションをブロック

これにより各オブジェクトは指定領域内でのみ生成され、他の領域や無関係なテキスト情報の影響を受けない。

Cutoutプロセスでは、事前に選択されたアテンションヘッドにおいて、各視覚トークンがテキストトークンから受けるアテンション重みの平均を計算する。
重みの高い順にトークンを選択し、総アテンション重みの η（通常0.95）の割合に達するまでのトークンを前景マスクとして使用する。
このマスクは2Dmax poolingによって平滑化され、より自然な境界線を作成する。

### 2.3 新規性
Stitchの新規性は主に2つの観点から評価できる。

技術的新規性の面では、MMDiTアーキテクチャに特化した初の学習不要位置制御手法である点が挙げられる。
従来の位置制御手法はU-NetベースのモデルやLegacy Diffusion Transformerを対象としており、MMDiTの共有埋め込み空間における視覚・テキスト情報の相互作用を活用した手法は存在しなかった。
また、生成途中のアテンションヘッドから前景セグメンテーション情報を直接抽出するアプローチも新しい。

方法論的新規性としては、オブジェクト単位での制約付き生成と後段での制約解除を組み合わせたハイブリッドアプローチが特徴的である。
これにより位置精度と画像品質の両立を実現している。
従来手法では位置制御と画像品質がトレードオフの関係にあることが多かったが、Stitchは段階的アプローチによりこの問題を解決している。

## 3. 実験結果
### 3.1 実験設定
実験はPosEval、GenEval、T2I-CompBench、HRS-Benchという複数のベンチマークで実施された。
対象モデルはFLUX.1 [Dev]、SD3.5 Large、Qwen-Imageの3つの最新MMDiTベースモデルである。

PosEvalでは各タスクにつき100プロンプト、プロンプトあたり4画像を生成し、Mask2Formerベースのオブジェクト検出と手続き的関係検証により評価を行った。
生成パラメータはT=50ステップ、グリッドサイズ32×32、カーネルサイズκ=5で統一され、バウンディングボックスの生成にはGPT-4とGPT-5を使用した。

アテンションヘッドの選択は、GenEvalの80オブジェクトを用いた単一オブジェクト生成実験により決定された。
SAMから得られるマスクをground truthとして、各ヘッドとη値の組み合わせのIoUを評価し、最適な組み合わせを選択した。

### 3.2 主要な結果
PosEvalにおいて、Stitchは全ての基底モデルで大幅な性能向上を達成した。
最も顕著な改善はFLUXで見られ、基本のPositionタスク（2 Obj）で22%から70%へと48ポイント（218%の相対改善）の向上を示した。
PosEval全体の平均では37ポイント（206%の相対改善）の向上を記録した。

Qwen-ImageとStitchの組み合わせが最高性能を達成し、6タスク中5タスクで1位、残り1タスクでも同率1位となった。
PosEval平均スコア0.71は、従来最高のLMD（0.46）を54%上回る成果である。

複雑なタスクほど改善効果が顕著で、4オブジェクトタスクではFLUXが2%から38%へ、Qwen-Imageが21%から61%へと大幅に向上した。
相対関係タスクでもFLUXが3%から48%へ改善するなど、言語的複雑性に対する理解能力の向上が確認された。

### 3.3 既存手法との比較
既存の学習ベース手法（GoT、LayoutGPT）と比較して、Stitchは学習不要でありながら大幅に優れた性能を示した。
GoTのPosEval平均0.17、LayoutGPTの0.23に対して、Stitch+Qwen-Imageは0.71を達成している。

学習不要手法のLMD（0.46）と比較しても、Stitch+Qwen-Imageは25ポイントの優位性を保持している。
特に複雑なタスクにおける差は顕著で、4オブジェクトタスクではLMDの23%に対してStitch+Qwen-Imageは61%を達成した。

画像品質の評価では、Aesthetic Scoreがベースモデルと比較して僅かな変化（Qwen-Image: 6.2→6.1、FLUX: 6.3→6.1、SD3.5: 5.3→5.1）に留まり、位置制御の向上が画像品質を犠牲にしていないことが確認された。
多様性の面でもDINOv2埋め込み空間での距離測定により、多様性が保持または改善されることが示された。

## 4. 実用性評価
### 4.1 実装の容易性
Stitchは既存のMMDiTベースモデルに対する推論時の後処理として実装されるため、導入コストが極めて低い。
学習や追加パラメータの調整が不要で、既存のモデルの重みを変更することなく適用可能である。

必要な前処理は適切なアテンションヘッドの選択のみで、この選択も80画像程度の小規模実験で決定できる。
一度決定されたヘッドは同一モデルアーキテクチャに対して再利用可能であり、運用時の計算コストはわずかなアテンション重み計算とマスク生成のみである。

コードの可用性も高く、GitHubでの公開により研究者や開発者が容易に実装・検証できる環境が整備されている。
実装に必要な依存関係も標準的なディープラーニングライブラリ（PyTorch等）に限定されており、特殊なハードウェアや環境設定を必要としない。

### 4.2 計算効率
計算効率の面でStitchは優秀な特性を示している。
追加の計算コストは主にアテンション重みの計算とマスク生成に限定され、全体の生成時間に対する影響は微小である。

特に重要な点は、外部のセグメンテーションモデル（SAMなど）を使用せずにアテンションヘッドから直接前景情報を抽出することで、追加の推論コストを最小限に抑えていることである。
メモリ使用量の増加も制限的で、既存のモデルの推論メモリ要件からわずかな増加に留まる。

Region Bindingフェーズでの制約適用は既存のアテンション計算に対するマスキング操作として実装されるため、計算グラフの大幅な変更や追加の前向き計算を必要としない。
これにより本格的な位置制御機能の追加にも関わらず、実用的な推論速度を維持している。

### 4.3 応用可能性
Stitchの応用可能性は多岐にわたる。
最も直接的な応用としては、UI/UXデザイン、プロトタイピング、創作活動における位置制御の必要性に対応できる。
特定の位置関係を持つオブジェクト配置が要求される場面で、従来より遥かに精確な結果を得ることが可能となる。

教育分野では、物理現象や空間関係の視覚的説明において、正確な位置関係を保持した図表生成に活用できる。
例えば「太陽の右側にある地球」といった天体配置や、「机の上にあるリンゴの左側のペン」といった日常的な物体関係の図示が可能である。

技術的な観点では、建築設計や都市計画における初期コンセプトの視覚化、製品デザインにおける部品配置の検討など、専門分野での活用も期待される。
また、自動運転における状況説明画像の生成や、ロボティクスにおける環境理解の補助ツールとしての応用も考えられる。

さらに重要な点として、Stitchは現在のMMDiTアーキテクチャに特化しているが、同様の原理は将来のアーキテクチャにも適用可能である可能性が高い。
アテンション機構を利用した制御手法という概念は、今後のT2I技術発展においても有効性を保持すると考えられる。

## 5. まとめと所感
### 5.1 論文の意義
この論文はT2I技術における重要な技術的ブレークスルーを達成している。
最新のMMDiTアーキテクチャに対する初の実用的位置制御手法として、学習不要でありながら大幅な性能向上を実現している点は特に評価に値する。

理論的な意義としては、アテンションヘッドが生成途中で前景セグメンテーション情報を保持しているという発見が重要である。
この発見はMMDiTの内部動作に関する理解を深めるだけでなく、今後の生成モデル研究における新たな研究方向を示唆している。

実用的な意義では、既存の高品質モデル（FLUX、SD3.5、Qwen-Image）をそのまま活用しながら位置制御機能を追加できることで、実際のアプリケーション開発における選択肢を大幅に拡大している。
学習不要という特性は、計算資源やデータの制約が厳しい環境での活用を可能にし、T2I技術の民主化に貢献している。

さらに、PosEvalベンチマークの提案により、従来のベンチマークでは見過ごされていた位置制御の複雑な側面を明らかにし、この分野の研究発展に必要な評価基盤を提供している。
これにより今後の位置制御手法の開発と比較が促進されると期待される。

### 5.2 今後の展望
技術的な発展の方向性として、より複雑な空間関係への対応が挙げられる。
現在のStitchは主に2D平面での位置関係を扱っているが、3次元空間での奥行き関係や重なり関係への拡張が今後の課題となる。
また、動的な位置関係（移動や回転を含む関係）への対応も興味深い研究方向である。

アテンション機構の活用に関しては、前景セグメンテーション以外の情報抽出の可能性を探求する価値がある。
例えば、オブジェクトの形状、サイズ、向きなどの属性情報を同様にアテンションから抽出できれば、より包括的な制御が可能となる。

実用化の観点では、リアルタイム生成への最適化が重要である。
現在の手法でも計算効率は良好だが、さらなる高速化により対話的なアプリケーションでの活用が現実的となる。
また、ユーザビリティの向上として、自然言語での位置指定をより直感的に処理する仕組みの開発も期待される。

長期的には、Stitchの原理を他の生成タスク（動画生成、3D生成など）に拡張する可能性も考えられる。
アテンション機構を利用した制御という基本概念は、様々な生成モデルアーキテクチャに適用可能であり、生成AI技術全般の制御性向上に寄与する可能性を秘めている。
