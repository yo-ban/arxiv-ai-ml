# Lost in Translation? Vocabulary Alignment for Source-Free Domain Adaptation in Open-Vocabulary Semantic Segmentation

## 基本情報
- arXiv ID: 2509.15225v1 (https://arxiv.org/abs/2509.15225)
- 著者: Silvio Mazzucco, Carl Persson, Mattia Segu, Pier Luigi Dovesi, Federico Tombari, Luc Van Gool, Matteo Poggi
- 所属: The Good AI Lab, ETH Zurich, Google, Technical University of Munich, INSAIT Sofia University, University of Bologna
- 投稿日: 2025年09月23日
- カテゴリ: cs.CV, cs.LG

## 簡単に説明すると
この論文は、大規模なウェブデータで事前訓練されたビジョン・ランゲージモデル（VLM）を用いた
オープンボキャブラリーセマンティックセグメンテーションにおいて、
ソースデータにアクセスできない状況での効率的なドメイン適応手法「VocAlign」を提案している。
プロジェクトページも公開されている（https://thegoodailab.org/blog/vocalign）。

## 1. 研究概要
### 1.1 背景と動機
オープンボキャブラリーセマンティックセグメンテーションは、固定されたクラス集合の制約を取り除き、
画像の各ピクセルにクラスラベルを割り当てることを目指す技術である。
この技術はVLMによって実現されており、マルチモーダルな相乗効果を活用して
ウェブスケールのデータセットで事前訓練されている。

しかし、この能力により広範な汎化が可能になる一方で、VLMはドメインシフトに対してより敏感になっている。
特に、より複雑な視覚・テキスト結合空間でのドメインシフトは、
異なるカテゴリを持つ未知のデータセットでの性能低下を引き起こすことが多い。

従来の教師なしドメイン適応（UDA）手法は、元のモデルが訓練されたソースデータへのアクセスを前提としているが、
これは独自のウェブスケールデータセットで訓練されたVLMには実用的ではない。

ソースフリードメイン適応（SFDA）はこの制限を解決するが、
既存のSFDA手法はオープンボキャブラリー機能やマルチモーダル視覚・言語相互作用を持たないモデル向けに設計されており、
VLMへの適用性が限定されている。

### 1.2 主要な貢献
本研究では、VLMにおけるオープンボキャブラリーセマンティックセグメンテーション向けの
初めてのSFDAフレームワーク「VocAlign」を提案する。

第一に、VLM向けに特別に設計されたオープンボキャブラリーセマンティックセグメンテーションの
初めてのSFDAフレームワークを提案した。

第二に、VLMのマルチモーダル機能を活用して擬似ラベルの品質を改善する
語彙アライメント戦略を導入した。

第三に、LoRAモジュールとTop-Kクラス選択の組み合わせにより計算複雑性を削減し、
メモリ効率を達成しながらさらなる性能向上を実現した。

## 2. 論文構造の詳細
### 2.1 論文の構成
本論文は以下の6つの主要セクションから構成されている：

1. **Abstract**: VocAlignフレームワークの概要と+6.11 mIoUの性能向上を報告
2. **Introduction**: オープンボキャブラリーセマンティックセグメンテーションとSFDAの課題を説明
3. **Related Work**: 3つの関連分野を詳述
   - VLMを用いたセマンティックセグメンテーション 
   - 教師なしドメイン適応（UDA）
   - パラメータ効率的ファインチューニング手法
4. **Method**: VocAlignフレームワークの4つの技術コンポーネント
   - CAT-Segバックボーンの説明
   - Student-teacherフレームワーク
   - 語彙アライメント戦略
   - Top-K クラス選択機構
5. **Experiments**: 実装詳細、主要結果、アブレーション研究
6. **Conclusions**: 手法の意義と今後の展望

### 2.2 技術的特徴
**CAT-Segベースライン**: 
- CLIP エンコーダーとコスト集約モジュールを組み合わせたアーキテクチャ
- 空間集約とクラス集約の2つの機構でコストボリュームを洗練

**VocAlignの主要技術**:
- Student-teacher蒸留フレームワーク
- 語彙拡張による擬似ラベル品質向上
- LoRAモジュールによるパラメータ効率的適応
- Top-Kクラス選択によるメモリ効率化

### 2.3 実験設定の特徴
**主要データセット**: CityScapes（メインベンチマーク）、ADE20K-150、PASCAL-Context 59
**評価指標**: mean Intersection over Union (mIoU)
**実装**: mmsegmentationフレームワークベース、ResNet-101 + ViT-B エンコーダー使用

## 3. 導入部と関連研究の詳細分析
### 3.1 Introduction詳細分析

**問題設定の明確化**
論文は、オープンボキャブラリーセマンティックセグメンテーションにおけるドメインシフト問題を中心に据えている。
VLMが広範な汎化を可能にする一方で、複雑な視覚・テキスト結合空間でのドメインシフトに対してより敏感になる点を指摘。

**従来手法の限界**
従来のUDA手法は元のモデルが訓練されたソースデータへのアクセスを前提としているが、
独自のウェブスケールデータセットで訓練されたVLMには実用的ではない。
SFDAは制限を解決するが、既存手法はオープンボキャブラリー機能やマルチモーダル相互作用を持たないモデル向けに設計されている。

**VocAlignの技術的貢献**
1. Teacher-studentフレームワークの拡張：語彙拡張による擬似ラベル生成の改善
2. パラメータ効率的適応：LoRAモジュールによる計算コスト管理
3. Top-Kクラス選択：メモリ要件の大幅削減

**実験結果の概要**
CityScapesデータセットで6.11 mIoUの改善を達成。
特に認識困難クラスの完全回復を含む大幅な性能向上を実現。

### 3.2 Related Work詳細分析

**1. VLMセマンティックセグメンテーション**
- CLIP（Radford et al., 2021）とその派生手法が基盤
- Zhou et al.は低解像度セグメンテーションマップの直接抽出を実現
- Li et al.はテキスト埋め込みと視覚表現の明示的アライメントフレームワークを導入
- CAT-Seg（Cho et al., 2023）は空間・クラス次元でのコストボリューム集約を提案

**2. 教師なしドメイン適応**
- 画像分類、物体検出、セマンティックセグメンテーションで広く研究
- 従来手法はソースデータアクセスを前提（実用性の問題）
- SFDA・テスト時適応への拡張：プライバシーとアクセシビリティ懸念への対応
- VLM向け手法：Samadh et al.は学習可能プロンプトアライメント、Choe et al.はオープンセットドメイン適応

**3. パラメータ効率的ファインチューニング**
- LoRA（Hu et al., 2021）：低ランク変換による数十億パラメータモデルの適応
- Zhang et al.：LoRA行列ランクの動的調整
- アダプター・プロンプトベース手法：最小オーバーヘッドでのVLM精度向上

### 3.3 技術的課題と解決アプローチ
**既存研究の限界**
- SFDA手法のVLMへの適用性不足
- マルチモーダル相互作用への対応不備
- ウェブスケールデータセットでの分布シフト・重複ラベル問題

**VocAlignの技術革新**
語彙拡張戦略によりVLMのマルチモーダル機能を活用した擬似ラベル品質向上を実現。
計算効率性とメモリ効率性を両立する設計により、実用的な大規模モデル適応を可能にした。

## 4. 提案手法の詳細分析
### 4.1 CAT-Segバックボーンアーキテクチャ

**基本構成**
CAT-Segは3つの主要コンポーネントから構成されます。
- 特徴抽出器：修正されたCLIP画像エンコーダーと標準CLIPテキストエンコーダー
- コスト集約モジュール：空間・クラス次元での集約機構
- アップサンプリングデコーダー：入力解像度への復元

**コストボリューム構築**
テキスト・視覚特徴間のコサイン類似度によりコストボリュームC ∈ R^(H×W×P×Nc)を構築。
C(i,n) = (D^V(i) · D^L(n)) / (||D^V(i)|| ||D^L(n)||)
ここで、iはピクセル座標、nはNcクラスのうちのテキスト埋め込みを表します。

**プロンプト拡張**
テキスト埋め込みはP個の多様なプロンプト（「a painting of a class」など）で拡張され、
φ^L ∈ R^(Nc×P×dL)の形状になります。

### 4.2 Student-Teacherフレームワーク

**基本知識蒸留**
事前訓練されたモデルがteacher g_φとして機能し、擬似ラベルを生成してstudent f_θを監督します。
擬似ラベル生成: p^T_i,j = [c = argmax_c' g_φ(x^T)_i,j,c']

**信頼度重み付け**
閾値τを超える信頼度の画素比率により損失を重み付けします。
q^T_i,j = [Σ^H_i=1 Σ^W_j=1 max_c' g_φ(x^T)_i,j,c' > τ] / (H·W)

**指数移動平均更新**
teacherは勾配なしで固定されますが、studentの重みの指数移動平均として更新されます。
φ_t+1 ← αφ_t + (1-α)θ_t

**Student入力マスキング**
MiCに従い、studentへの入力画像にマスキングを適用して適応を改善します。
マスク: M_mb+1:(m+1)b,nb+1:(n+1)b = [v > r], v ~ U(0,1)

### 4.3 語彙アライメント戦略

**テキスト空間でのデータ拡張**
画像拡張に依存せず、テキスト空間でのデータ拡張を導入。
ターゲットデータセットクラスを「概念」（追加テキスト記述・同義語）で拡張。

**概念の具体例**
事前訓練で「animal」が存在した場合、ターゲットクラス「cat」に概念として追加することで性能向上。
特に他の動物関連クラスが存在しない場合に効果的です。

**概念集約プロセス**
擬似ラベル生成前に概念を元クラスに集約：
p^c_ij = e^x^c_ij / Σ^n_tot_c'=1 e^x^c'_ij  （概念レベル確率）
p^n_ij = Σ^C(n)_h=1 p^c_h(n)_ij  （元クラス確率）

**自動概念生成**
大規模データセット向けにChatGPT o1を使用した自動概念生成により効率化を実現。

### 4.4 Top-Kクラス選択機構

**計算効率化の必要性**
多数クラスへの適応は計算的に禁止的になるため、teacher予測を使用して画像内の可能性の高いクラスを特定。

**選択プロセス**
teacher確率ŷ ∈ R^(Nc,H,W)からクラス毎の平均活性化を計算し、最高平均値を持つTop-Kクラスを選択。
残りクラスは集約前にコストボリュームから除去されます。

**品質向上効果**
イテレーション毎にクラスの部分集合のみが監督を受けますが、teacherによる高品質擬似ラベルが存在クラスの信頼性を確保し、より強力な監督を提供。

### 4.5 技術的新規性の要約

**1. VLM特化SFDA**
オープンボキャブラリーセマンティックセグメンテーション向け初のSFDAフレームワーク。

**2. 語彙拡張による品質向上**
VLMのマルチモーダル機能を活用した擬似ラベル品質改善戦略。

**3. 効率性の実現**
LoRAとTop-K選択の組み合わせにより計算・メモリ効率を達成しながら性能向上。

## 5. 実験と評価の詳細分析
### 5.1 実験設定の詳細

**実装フレームワーク**
mmsegmentationフレームワークとMiCコードを統合したCAT-Seg実装を使用。
ResNet-101とViT-Bエンコーダーを採用し、効率性のため80プロンプトテンプレートを10プロンプト×8回に削減。

**LoRA設定**
CLIPバックボーンのみに適用：ViT画像エンコーダーとテキストエンコーダーの最初4層のアテンション射影行列。
標準設定でLoRAランク2を使用、残りのモデルは凍結。

**データセット構成**
- **CityScapes**: 2975訓練画像、500検証サンプル、19クラス（メインベンチマーク）
- **ADE20K-150**: 20k訓練画像、2k検証画像、150クラス
- **PASCAL-Context 59**: 5k訓練・検証画像、59クラス
- **評価指標**: mean Intersection over Union (mIoU)

**CityScapes訓練設定**
- 40k反復、AdamW最適化器、学習率5×10^-5（500反復ウォームアップ後）
- バッチサイズ2、Top-K選択値15
- データ拡張：512×512ランダムクロップ、カラージッター
- マスキング比率0.7、EMA更新α=0.99

**マルチデータセット訓練設定**
- 15k反復、バッチサイズ2（適用可能時）、学習率3×10^-5
- マスキング比率0.5、ChatGPT-o1による概念生成
- Top-K値：10プロンプト版で50、フル版で35

### 5.2 主要実験結果

**CityScapesでの成果**
VocAlignは6.11 mIoUの総合改善を達成、特に性能の悪いクラスで顕著な改善。
「terrain」クラスは0.02から45.95 mIoUへ大幅向上（+45.93%）。
「wall」クラスは9.77から34.32 mIoUへ改善（+24.55%）。

**性能低下の分析**
「car」クラスで8.9%の性能低下を観察。
原因：訓練時にマスクされない車両フード部分による学習バイアス。
検証時にフードがマスクされ、道路の一部が車として誤分類される現象。

**マルチデータセット結果**
汎用設定で他データセットへの適応性を実証。
CityScapes: +2.02%、PASCAL-Context 59: +1.49%、ADE20K-150: +0.51%の改善。
フルCAT-Segモデルでも適度な適応性を維持。

**ベースライン比較**
エントロピー最小化ベースラインと比較してVocAlignが優位性を実証。
オープンボキャブラリーセマンティックセグメンテーション向けSFDAの初の手法として評価。

### 5.3 アブレーション研究と分析

**コンポーネント効果分析**
- Teacher-Student基本設定：適応効果限定
- マスキング追加：ベースラインから大幅改善
- 語彙アライメント：CityScapesとPASCAL-Context 59で顕著な効果
- Top-K選択：全データセットで安定した性能向上

**Top-K選択の効果**
計算コスト削減目的で実装されたが、性能向上効果も確認。
ランダム選択との比較でTop-K選択の優位性を実証。
最関連クラスが相対的に強い勾配を受け、除去クラスは誤った監督を受けない。

**メモリ制約の影響**
フルCAT-Segモデルでは64GB A100 GPU制約によりTop-K値35に制限。
より控えめな性能向上となったが、CityScapesで強い改善、他データセットで適度な改善を維持。

### 5.4 技術的洞察と限界

**語彙アライメントの効果**
クラス名の曖昧性解決に特に有効。
例：CityScapesの「wall」は「建物の一部でない独立した壁」だが、モデルには「wall」のみ提供され追加情報が失われる。

**手法の限界**
ADE20K-150での性能向上が限定的：大量クラス数により適切な概念発見が困難。
ChatGPT生成概念とマニュアル概念の品質差が影響。

**計算効率性の実現**
LoRAとTop-K選択の組み合わせにより、大規模VLMの実用的適応を可能にする効率的フレームワークを構築。

## 6. 実用性評価と総合的考察
### 6.1 実装の容易性
VocAlignは既存のCAT-Segアーキテクチャ上に構築され、比較的容易な実装を実現しています。
mmsegmentationフレームワークとの統合により実用的な開発環境を提供。
LoRAの適用範囲が限定的（CLIPバックボーンの最初4層のみ）で、実装複雑性を軽減。

### 6.2 計算効率性
従来のSFDA手法と比較して大幅な効率改善を達成。
Top-K選択機構により、多クラス環境でのメモリ要件を大幅削減。
パラメータ効率的ファインチューニングにより、全パラメータ更新を回避。

### 6.3 応用可能性
複数データセット（CityScapes、ADE20K-150、PASCAL-Context 59）での有効性を実証。
汎用設定での適応性により、新しいドメインへの展開が容易。
ChatGPT-o1による自動概念生成により、大規模データセットへのスケーラビリティを確保。

### 6.4 技術的限界と課題
クラス数が大幅に増加する環境（ADE20K-150など）での性能向上が限定的。
概念生成の品質がマニュアル作成とChatGPT生成で異なり、自動化の精度向上が課題。
特定クラス（車など）での性能低下問題に対する根本的解決策が未完成。

## 7. まとめと所感
### 7.1 論文の意義
本研究は、VLMにおけるオープンボキャブラリーセマンティックセグメンテーション向けの初のSFDAフレームワークとして、重要な技術的ブレークスルーを実現しました。
語彙アライメント戦略によるVLMのマルチモーダル機能活用は、従来のSFDA手法にはない独創的なアプローチです。

実用的な観点から、計算効率性とメモリ効率性を両立した設計により、大規模VLMの実用的適応を可能にした点が特に評価されます。
CityScapesでの6.11 mIoU改善は定量的に意義深く、特に困難クラスでの大幅向上は実用価値の高さを示しています。

### 7.2 今後の展望
手法のさらなる発展には、以下の方向性が考えられます。

第一に、大規模クラス環境での性能向上が重要な課題です。
概念生成の自動化精度向上と、より効率的なクラス選択戦略の開発が求められます。

第二に、他のVLMアーキテクチャへの適用拡張が期待されます。
CAT-Seg以外のオープンボキャブラリーセグメンテーションモデルでの検証により、手法の汎用性が確認できるでしょう。

第三に、リアルタイム応用への最適化が実用性向上に寄与します。
推論時間の短縮とメモリ使用量のさらなる削減により、実世界での展開が促進されると考えられます。

本研究は、VLMのドメイン適応における新しい研究領域を開拓し、今後のマルチモーダルAI技術発展に大きく貢献することが期待されます。
