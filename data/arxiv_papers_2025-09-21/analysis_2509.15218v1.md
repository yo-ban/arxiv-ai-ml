# LNE-Blocking: An Efficient Framework for Contamination Mitigation Evaluation on Large Language Models

## 基本情報
- **arXiv ID**: 2509.15218v1 (https://arxiv.org/abs/2509.15218)
- **著者**: Ruijie Hou, Yueyang Jiao, Hanxu Hu, Yingming Li, Wai Lam, Huajian Zhang, Hongyuan Lu
- **所属**: Zhejiang University, FaceMind Corporation, University of Zurich, The Chinese University of Hong Kong, Westlake University
- **投稿日**: 2025年09月23日
- **カテゴリ**: cs.CL, cs.LG

## 簡単に説明すると
この論文は、大規模言語モデル（LLM）の評価において深刻な問題となっているデータ汚染（data contamination）を効率的に軽減する新しいフレームワーク「LNE-Blocking」を提案している。
従来の手法では、汚染されたベンチマークデータでモデルを公正に評価することが困難であったが、本研究では汚染検出と生成妨害操作を組み合わせることで、
汚染前の真の性能を復元することを可能にした。コードはGitHubで公開されている（https://github.com/RuijieH/LNE-Blocking）。

## 1. 研究概要
### 1.1 背景と動機
大規模言語モデル（LLM）の発展において、データ汚染（data contamination）は避けられない深刻な問題となっている。
これは、モデルの訓練データに評価用ベンチマークのデータが意図せず含まれることで発生する現象である。
LLMの事前訓練データセットは膨大で多様な出所を持つため、開発者が意図的に汚染を導入しなくても、
LLMはデータ汚染に対して脆弱になりやすい。

従来のアプローチでは、汚染のないデータセットを新たに構築することで対応してきたが、
これらの手法は多大な労力を要し、新しく公開されるモデルで再び汚染される可能性を完全に排除できない。
本研究では、既に汚染リスクのあるデータセットを用いて汚染のない評価を行う「汚染軽減評価」という
あまり研究されていない重要な問題に取り組む。

### 1.2 主要な貢献
本研究では、LNE-Blockingフレームワークを通じて以下の3つの主要な貢献を行う。

第一に、汚染軽減を汚染検出と生成妨害操作に分離することで、サンプリング手法に依存しない
汚染のないモデル評価を可能にするLNE-Blockingフレームワークを提案した。

第二に、汚染軽減評価タスクにおいて、貪欲デコーディング下でのモデルの真の性能を評価する
初めての手法を実現した。これは現在の研究における重要なギャップを埋めるものである。

第三に、広範な実験により、提案手法が多様なタスクとLLMにわたって高い堅牢性を示すことを実証した。

## 2. 提案手法
### 2.1 手法の概要
LNE-Blockingフレームワークは、汚染軽減を汚染検出と生成妨害操作の2つのコンポーネントに明示的に分離する。
汚染検出戦略であるLNE（Length Normalized Entropy：長さ正規化エントロピー）が、モデルの出力に基づいて汚染の程度を判定し、
生成妨害操作であるBlockingが、デコーディング中に最高確率のトークンを抑制することで元の生成プロセスに介入する。

フレームワーク全体は、モデルの汚染レベルに基づいて妨害操作の頻度を調整することで、
現在のサンプルに対してモデルが記憶されていない内容を生成するよう促進する。
これにより、サンプリング手法に依存することなく、貪欲デコーディング下でのモデルの真の性能を評価することが可能となる。

### 2.2 技術的詳細
**LNEによる汚染度評価**

プロンプトxとモデルMが与えられた場合、まず貪欲デコーディング推論を実行してy^greedyを取得する。
長さNの生成されたy^greedyの推論中の各位置での確率分布に基づいて、
長さ正規化エントロピー（LNE）を以下のように計算する：

LNE(M, x) = -1/N × Σ(i=1→N) Σ(j=1→V) p(yi=j) log p(yi=j)

ここで、p(yi=j)は、i番目の位置でモデルが語彙からj番目のトークンを生成する確率を表し、
Vはトークン語彙のサイズを表す。モデルの汚染度が増加するにつれて、LNE(M, x)は減少する。

**Blocking操作による生成妨害**

Blocking操作は、デコーディング中の特定の位置で最高確率のトークンを抑制する。
モデルMとプロンプトxに対して、デコーディングプロセスのi番目の位置でBlocking操作が適用された場合、
結果として得られる応答は以下のように定義される：

y^Blocking(M,x,(i)) = (y1:i-1^greedy, yi^block, yi+1:l^greedy)

複数回のBlocking操作の場合、記憶された回答トークンの生成をできるだけ早期に中断するため、
生成の最初からn回のBlocking操作を適用する。

**LNEに基づく妨害強度の決定**

汚染レベルによって検出されたLNE(M, x)に基づいてBlocking強度を決定する。
正規化されたLNE(M, x) = 1 - LNE(M, x)/2を用いて、
Blocking操作の回数を以下のように定義する：

Cnt(M, x) = round(LNE(M, x) × Threshold_Task)

ここで、Threshold_Taskは指定されたタスクに依存するハイパーパラメータである。

### 2.3 新規性
本手法の主要な新規性は以下の3点に集約される。

第一に、汚染検出と生成妨害を明示的に分離した初めてのフレームワークである。
従来のTED手法などは多重サンプリングに依存していたが、LNE-Blockingはデコーディング中にオンラインで
制御可能にトリガーできるため、サンプリング手法の本質的なランダム性と時間集約的な性質を効果的に克服している。

第二に、Length Normalized Entropy（LNE）という新しい汚染検出指標を導入した。
これは各デコーディング位置での分布全体からの情報を活用し、
既存のPerplexityやMin-k% Probよりも効果的にBlocking強度を調整できる。

第三に、貪欲デコーディング下でモデルの真の性能を評価する初めての手法を実現した。
これまでの研究では、汚染軽減評価において貪欲デコーディングでの真の性能評価は重要なギャップとして残されていた。

## 3. 実験結果
### 3.1 実験設定
実験は2つの主要タスクで実施された。コード生成タスクでは、4つのモデル（CodeGen-6B、Llama 2-7B、CodeLlama-7B、Llama 3.1-8B）を用いてHumanEvalデータセットで評価した。
各モデルは20エポック訓練し、20個のLoRA重みを生成して異なる汚染レベルに対応させた。
汚染シミュレーションは、HumanEvalテストセットとStarCoderデータを1:1,000の比率で混合した継続事前訓練により実施された。

算術推論タスクでは、Llama 2-7BとLlama 3.1-8Bの基本バージョンを使用し、GSM8KとGSM-Plusデータセットで評価した。
GSM8Kテストセットを用いた継続事前訓練により汚染をシミュレートし、20エポック実行した。
汚染レベルは軽度（1-7エポック）、中度（8-13エポック）、重度（14-20エポック）に分類された。

評価指標として、コード生成にはPass@1、算術推論には正確一致精度を使用した。
また、新しい指標である性能ギャップ（PG）を導入し、これは汚染軽減後のモデル性能と元の汚染されていないモデル性能の絶対差として定義される。

### 3.2 主要な結果
**コード生成タスクでの結果**

LNE-Blockingは全てのモデルと汚染レベルにわたって安定した性能復元を実現した。
特に重度汚染モデルのCodeLlamaとLlama 3.1において、本手法はTEDを大幅に上回る性能を示した。
例えば、CodeLlama-7Bの重度汚染では、LNE-BlockingのPGが0.045であったのに対し、TEDは0.137であった。

一方、軽度汚染のCodeGenやLlama 2では、TEDの方が良好な性能を示した。
これは軽度汚染レベルでは、多重サンプリングがより多様な結果を生成し、記憶を軽減するためと考えられる。

**算術推論タスクでの結果**

算術推論においても同様の傾向が観察された。LNE-Blockingは異なるモデルと汚染レベルにわたって
比較的安定した性能復元を達成した。特に注目すべきは、重度汚染のLlama 3.1でTEDが完全に失敗した場合
（PGが0.694に達する）でも、LNE-BlockingはPG 0.065という良好な結果を維持したことである。

GSM-Plusデータセットでの実験では、Llama 2において全ての汚染レベルでPGが最大5%以内という
優れた性能復元を実現した。

### 3.3 既存手法との比較
**TEDとの比較**

TED手法は多重サンプリングに基づく汚染軽減評価手法である。実験結果から、TEDは軽度汚染では効果的だが、
汚染が深刻になるにつれて性能が大幅に劣化することが明らかになった。これは、重度汚染モデルでは
記憶された回答の確率が高くなり、多様な非記憶サンプルを十分に生成できないためである。

LNE-Blockingは、サンプリングの本質的なランダム性を回避し、制御された生成戦略により
一貫した性能を実現する。この違いは、特に重度汚染シナリオで顕著に現れる。

**アブレーション研究**

固定されたBlocking操作数を用いた実験では、異なる汚染レベルのモデルで復元程度が大きく異なることが示された。
軽度汚染では少ないBlocking操作で復元可能だが、重度汚染では多くの操作が必要となる。
これは、汚染検出戦略を用いてBlocking強度を調整することの有効性を実証している。

PerplexityやMin-k% Probなど他の汚染検出手法と比較した場合、LNEを用いた場合の性能復元が
最も効果的であった。これは、LNEが各デコーディング位置での分布全体からの情報を活用することに起因する。

## 4. 実用性評価
### 4.1 実装の容易性
LNE-Blockingは既存のLLMに容易に統合できる設計となっている。
フレームワークは2つの明確な段階に分かれており、まず標準的な貪欲デコーディングでLNEを計算し、
次にBlocking操作を適用するという単純な流れである。

実装に必要な計算は軽量で、各トークン位置でのエントロピー計算と最高確率トークンの抑制のみである。
これらの操作は既存の推論パイプラインに最小限の変更で組み込むことができる。
Threshold_Taskパラメータはタスク依存だが、モデルに依存しないため、一度設定すれば同じタスクの異なるモデルに適用可能である。

### 4.2 計算効率
本手法は計算効率の面で大きな利点を持つ。従来のTED手法が最低50回のサンプリングを必要とするのに対し、
LNE-Blockingは1回の貪欲デコーディングと数回のBlocking操作のみで済む。
これにより、評価時間を大幅に短縮できる。

論文中の実験では、コード生成タスクで2時間、算術推論タスクで20時間の訓練時間が報告されており、
実際の推論時のオーバーヘッドは最小限である。
また、GPU要件も単一の4090GPUで実行可能であり、比較的低い計算資源で実現できる。

### 4.3 応用可能性
実験では3つの異なるタスク（コード生成、算術推論、要約）で有効性が確認されており、
手法の汎用性が示されている。特に重要なのは、Threshold_Taskがタスク固有であることで、
新しいタスクへの適用時にはこのパラメータの調整が必要になる点である。

論文では、異なるサイズ（1.3B～8B）やアーキテクチャのモデルで一貫した結果が得られており、
モデルの種類に関わらず適用可能であることが示されている。
ただし、軽度汚染の場合には既存のサンプリング手法の方が効果的な場合があり、
汚染レベルの事前検出が重要となる。

## 5. まとめと所感
### 5.1 論文の意義
本研究は、LLM評価における深刻な課題であるデータ汚染問題に対して、実用的で効率的な解決策を提供している。
従来の新データセット構築アプローチとは異なり、既存の汚染リスクのあるデータセットでの評価を可能にする点で画期的である。

特に注目すべきは、貪欲デコーディング下での真の性能評価を初めて実現したことである。
これまでの研究では、汚染軽減評価においてこの問題は重要なギャップとして残されていた。
LNE-Blockingによって、実用的な推論設定での公正な評価が可能になった。

手法の設計も優れており、汚染検出と生成妨害の明確な分離により、それぞれのコンポーネントの貢献を理解しやすくしている。
LNEという新しい汚染検出指標の導入も、従来指標より効果的であることが実証されている。

### 5.2 今後の展望
本研究にはいくつかの改善の余地がある。第一に、軽度汚染での性能改善が課題として残されている。
より細かい汚染レベル検出戦略の開発により、この問題は解決可能と考えられる。

第二に、現在の評価は主にコード生成と算術推論に集中しているため、
より多様なNLPタスクでの検証が必要である。
論文中でも言及されているように、計算資源の制約からLoRAを用いた汚染シミュレーションが行われているが、
フルパラメータ微調整での検証も重要である。

第三に、実際の大規模モデルでの汚染は事前訓練段階で発生することが多いため、
継続事前訓練以外の汚染シミュレーション手法の開発も望まれる。

しかし、これらの制限事項にもかかわらず、本研究はLLM評価の公正性向上に向けた重要な一歩であり、
今後の汚染軽減評価研究の基盤となることが期待される。
