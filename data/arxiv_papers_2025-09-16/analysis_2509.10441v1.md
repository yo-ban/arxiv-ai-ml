# InfGen: A Resolution-Agnostic Paradigm for Scalable Image Synthesis

## 基本情報
- arXiv ID: 2509.10441v1 (https://arxiv.org/abs/2509.10441)
- 著者: Tao Han, Wanghan Xu, Junchao Gong, Xiaoyu Yue, Song Guo, Luping Zhou, Lei Bai
- 所属: Hong Kong University of Science and Technology, Shanghai Artificial Intelligence Laboratory, The University of Sydney
- 投稿日: 2025年09月16日
- カテゴリ: cs.CV, cs.LG

## 簡単に説明すると
この論文は、既存の拡散モデルを変更することなく任意の解像度で高品質な画像を高速生成できる新しいフレームワーク「InfGen」を提案しています。従来の拡散モデルでは4K画像の生成に100秒以上かかっていましたが、InfGenはVAEデコーダを新しいジェネレータに置き換えることで、同じタスクを10秒以下で実行できます。研究成果とコードはGitHubで公開されています：https://github.com/taohan10200/InfGen

## 1. 研究概要
### 1.1 背景と動機
近年の画像生成技術において、拡散モデルは高品質な画像生成で大きな成果を上げています。
しかし、高解像度画像生成には重大な課題があります。
現在の拡散モデルは解像度に対して計算量が二次的に増加するため、4K画像の生成には100秒以上の時間を要します。

この問題の根本原因は、既存の手法が拡散モデルの第一段階（生成モデル）に焦点を当てすぎており、
第二段階である潜在表現から画素値への変換（デコーダ）の改善を軽視していることにあります。
拡散モデルは数千のサンプリングステップを必要とするのに対し、
デコーダは単一の順伝播のみで処理が完了するため、デコーダの機能強化による効率化が最も効果的なアプローチです。

任意の高解像度画像生成は、デバイス間での一貫した視覚体験を提供し、
制作者と消費者の両方にとって広範囲な応用を持つ重要な技術です。
現在の手法は特定のネットワーク構造や推論プロセスに密接に結びついており、
特定の生成モデルに限定され、他のモデルへの汎用性が制限されています。

### 1.2 主要な貢献
この研究では、任意解像度画像生成のための革新的なパラダイムとして3つの重要な技術的貢献を提示しています。

第一に、生成済み潜在表現に基づく二次生成という未開拓な領域における新しいパラダイムを導入しました。
InfGenは拡散モデルをコンテンツジェネレータとして位置づけ、
固定サイズの圧縮コンテンツ潜在zを生成し、この潜在表現を任意のサイズの画像に拡張します。
この過程で細部とテクスチャの洗練に焦点を当てることで、
高い推論速度と柔軟性を同時に実現しています。

第二に、プラグアンドプレイの特性を持つジェネレータを開発しました。
VAEに基づくすべてのモデルに追加訓練なしで適用可能であり、
既存の生成モデルの任意解像度対応において大幅な改善を示します。
同一の潜在空間を共有するあらゆるモデルに統合可能で、
既存の生成モデルと異なるタスクの解像度機能を拡張できます。

第三に、最先端の手法と比較して高い生成品質を達成しながら、
生成速度を10倍以上向上させる高品質かつ高速な生成を実現しました。
4K以上の画像生成における推論遅延で大きな優位性を提供し、
従来最速のUltraPixelと比較して10倍の高速化を達成しています。

- 生成済み潜在表現に基づく二次生成という新しいパラダイムの提案
- VAEベースモデルへの追加訓練不要なプラグアンドプレイ対応
- 4K画像生成時間を100秒以上から10秒以下への大幅短縮
- 既存拡散モデルの構造や訓練を変更せずに任意解像度対応を実現

## 2. 提案手法
### 2.1 手法の概要
InfGenは、拡散モデルの二段階パラダイムにおける第二段階の革新的な改良を提案しています。
従来のアプローチでは、第一段階で生成モデル（LDMやDiT）が画像表現を生成し、
第二段階でオートエンコーダモデル（VAEやVQGAN）が表現をデコードしていました。

InfGenのアーキテクチャは、VAEエンコーダを変更せずに保持し、
既存の拡散モデルとの互換性を維持しながら、デコーダ内に二次ジェネレータを組み込みます。
訓練フェーズでは、高解像度画像を固定次元にクロップ・リサイズし、
VAEエンコーダで固定サイズ潜在zにエンコードします。
InfGenモデルは任意解像度生成を実現し、動的パラメータ(h,w)で期待画像サイズを指定して
任意サイズの出力画像x_(h,w)を生成します。

推論フェーズでは、互換性のある拡散モデル（DiT、SDXL、SiT、FiTなど）で生成された
潜在ベクトルを入力として、任意サイズの画像を生成できます。
この仕組みにより、クラス誘導生成、テキスト条件生成、インペインティングなど
様々なタスクでの解像度機能を効率的に拡張できます。

### 2.2 技術的詳細
InfGenの核心となる技術革新は、任意解像度デコーダアーキテクチャと
Implicit Neural Positional Embedding（INPE）の組み合わせです。

任意解像度デコーダでは、従来のVAE構造を基に、トランスフォーマーベースの潜在ジェネレータを導入しています。
潜在変数をプロンプトとして扱い、キーと値として利用します。
潜在zによって誘導され、期待画像次元(h,w)に対応するマスクトークンをクエリとして作成し、
画像サイズ(h,w)に対してマスクトークンの形状を(⌈h/8⌉, ⌈w/8⌉)とします。
この構成により、トランスフォーマブロックのMulti-Head Self-Attention機構に適用可能な
キー・クエリ・値のトリプレットを形成します。

INPEは、マスクトークン数が動的な場合に対応する革新的な位置エンコーディング手法です。
まず、各マスクトークン(x^m, y^m)と潜在トークン(x^l, y^l)の座標を標準化し、
異なるサイズを統一スケールにマッピングします。
標準化された2D座標を単位球面上の3D直交座標に変換し、
球面幾何学を活用して複雑な空間関係を捉え、滑らかな特徴学習の連続性を向上させます。

3D座標はフーリエ変換を通じて高周波フーリエ特徴に変換され、
モデルのパターン捉獲能力を向上させます。
ガウス分布からランダムサンプリングされた対角行列Bを使用して座標を高次元空間にマッピングし、
これらのフーリエ特徴を暗黙ニューラルネットワークに供給して動的位置エンコーディングを生成します。

### 2.3 新規性
InfGenの主要な新規性は、生成済み潜在表現からの二次生成という未開拓領域への取り組みにあります。
従来の高解像度生成手法は、低解像度画像を生成してから超解像度手法でアップスケールするか、
拡散推論プロセスを変更してアーキテクチャを再設計する必要がありました。
これに対してInfGenは、拡散モデル自体を変更せずに、
VAEデコーダのみを置き換えることで任意解像度生成を実現する革新的なアプローチを提案しています。

VAEとInfGenの根本的な違いは、再構築ターゲットの特性にあります。
VAEでは再構築ターゲットが入力と同じ画素空間にあるため、
ターゲット復元に必要な情報は完全に保持されています。
しかしInfGenでは、再構築ターゲットのサイズが入力画像より大きく、
情報損失を補完するための生成能力が必要となります。

訓練フリー解像度外挿という独自の手法も重要な新規性です。
訓練解像度を超える画像を生成するために、反復生成手法を導入し、
生成された潜在表現を任意の超高解像度に段階的にスケーリングします。
各反復でスケーリング係数を適用し、推奨範囲内で反復することで、
4K以上の超高解像度での高品質画像生成を実現しています。

## 3. 実験結果
### 3.1 実験設定
実験評価では、高解像度訓練データセットとしてLAION-Aestheticから
1024²以上の解像度を持つ1000万画像を選択し、訓練セットとして使用しました。
さらなるフィルタリングにより2048²以上の解像度を持つ500万画像のサブセットを作成し、
高解像度訓練データを2つの部分に分割しました。

実装では、事前訓練されたVAEのエンコーダを凍結し、
異なるバッチで画像をランダムに異なるサイズにクロップします。
第一訓練段階では512²から1024²の解像度でバッチサイズ32を使用し、
第二段階では512²から2048²の解像度でバッチサイズ8に縮小しました。
訓練反復は各々500kと100kで、8台のA100 GPUで15日間実行しました。

評価指標として、FID、sFID、precision、recallを主に使用しました。
高解像度画像評価の特殊性を考慮し、UltraPixelで提案された手法に従い、
高解像度画像を229×229パッチにクロップしてテストし、
FID_p、sFID_p、Pre._p、Rec._pとして表記しました。
再構築品質の指標としてPSNRとSSIMも報告しています。

### 3.2 主要な結果
InfGenは既存の画像トークナイザと比較して競争力のある再構築性能を達成しました。
ImageNet-50k検証セットでの評価において、VQGAN、SD VAE、SDXL VAEといった
一般的に使用される連続・離散画像トークナイザと同等以上の性能を示しています。

拡散モデル性能改善の実験では、InfGenが全ての解像度で既存の潜在ベース拡散モデルの
全指標において性能向上を実現することが実証されました。
特に高解像度での改善が顕著で、DiT-XL/2モデルでは1024×1024解像度でFID_pが32%改善、
SiT-XL/2では36%の改善を達成しています。

推論時間の比較では、InfGenが高解像度画像生成手法の中で最も高速な結果を示しました。
4K画像生成においてわずか7.4秒で完了し、
従来最速のUltraPixelと比較して10倍以上の速度向上を実現しています。
この大幅な高速化は、高解像度潜在空間での多段階ノイズ除去を回避し、
コンパクトな潜在zでの一段階推論により実現されています。

### 3.3 既存手法との比較
訓練フリー手法であるScaleCrafterやFouriScaleと比較して、
InfGenはより汎用的で安定した性能を提供します。
これらの手法は特定のネットワーク構造や推論プロセスに密接に結びついているのに対し、
InfGenは同一潜在空間を共有するあらゆる拡散モデルに適用可能です。

ネットワーク構造再設計アプローチのInf-DiTやUltraPixelと比較して、
InfGenは既存モデルの変更を必要とせず、
プラグアンドプレイ方式で簡単に統合できる利点があります。
性能面でも、特に高解像度生成においてこれらの手法を上回る結果を示しています。

LAION-50kデータセットでの評価においても、
InfGenは複雑なシーンを含む現実的な画像に対して
ImageNet検証セットと整合性のある結果を示し、
オブジェクト中心画像とシーン中心画像の両方を効果的に処理できることが実証されました。

推論速度の面では、InfGenが他の全ての高解像度生成手法を大幅に上回る性能を示しています。
対数スケールでの比較において、従来手法が数十秒から数百秒を要するのに対し、
InfGenは一桁秒での生成を実現し、実用的なアプリケーションでの利用可能性を大幅に向上させています。

## 4. 実用性評価
### 4.1 実装の容易性
InfGenの実装は比較的容易で、特にプラグアンドプレイの特性により既存システムへの統合が簡単です。
VAEエンコーダを変更せずに既存の拡散モデルとの互換性を維持しているため、
SDXL、DiT、SiTなど広く使用されているモデルにそのまま適用できます。

コードとモデルがGitHubで公開されており、研究者や開発者が容易にアクセスできます。
訓練プロセスも比較的標準的で、8台のA100 GPUで15日間という計算資源要件は、
大規模機械学習プロジェクトとしては合理的な範囲内にあります。

ただし、高品質な結果を得るためには高解像度訓練データセットの準備が必要で、
LAION-Aestheticから1000万画像を選択・フィルタリングする作業が含まれます。
また、二段階訓練アプローチとバッチサイズの調整など、
メモリ効率を考慮した実装上の工夫が求められます。

### 4.2 計算効率
InfGenの最大の強みは計算効率の大幅な改善にあります。
従来の拡散モデルが4K画像生成に100秒以上要していたのに対し、
InfGenは同等品質の画像を10秒以下で生成可能です。
この10倍以上の高速化は、高解像度潜在空間での多段階サンプリングを回避し、
固定サイズ潜在表現からの一段階生成により実現されています。

メモリ使用量の面でも、固定サイズの潜在表現（通常64×64）で動作するため、
解像度に対して二次的に増加する従来手法と比較して大幅に効率的です。
訓練フリー解像度外挿により、訓練時の最大解像度を超える画像生成も可能で、
追加的な計算コストを最小限に抑えながら超高解像度生成を実現しています。

推論時の計算コストは主にトランスフォーマーベースのデコーダ部分に集中し、
クロスアテンション機構による効率的な情報統合により、
高品質な結果を維持しながら高速処理を実現しています。

### 4.3 応用可能性
InfGenの応用可能性は非常に広範囲で、特にマルチメディア制作、
エンターテインメント、デザイン分野での実用化が期待されます。
任意解像度での高速生成能力により、異なるデバイスや用途に応じた
柔軟な画像制作ワークフローを実現できます。

クラス誘導生成、テキスト条件生成、インペインティングなど
様々なタスクへの適用が可能で、既存の拡散モデルベースアプリケーションに
簡単に統合できる汎用性を持ちます。
特に、リアルタイム性が要求されるアプリケーションや、
大量の高解像度コンテンツ生成が必要な用途での活用が見込まれます。

デモWebサイトの提供により、実際の生成結果を体験可能で、
商用利用や研究開発における評価が容易になっています。
また、オープンソースでの公開により、コミュニティによる拡張や改良、
新しい応用分野の開拓が促進されることが期待されます。

## 5. まとめと所感
### 5.1 論文の意義
この論文は、高解像度画像生成における根本的な課題に対して、
従来のアプローチとは異なる革新的な解決策を提示した重要な研究です。
拡散モデル自体を変更せずにVAEデコーダのみを置き換えるという
シンプルかつ効果的なアプローチは、既存システムへの影響を最小限に抑えながら
大幅な性能向上を実現する実用的な価値があります。

特に、計算効率の劇的な改善（4K画像生成時間の10分の1短縮）は、
高解像度画像生成の実用化において画期的な進歩です。
これにより、従来は計算コストの制約で困難だった
リアルタイム高解像度生成や大規模コンテンツ制作が現実的になりました。

プラグアンドプレイの特性により、既存の多様な拡散モデルに適用可能であることも、
研究コミュニティと産業界の両方にとって大きな価値を持ちます。
新しいモデル開発の必要性を減らし、既存投資を活用しながら
機能拡張を実現できる経済的なソリューションとして評価できます。

### 5.2 今後の展望
技術的な発展方向として、訓練フリー解像度外挿手法のさらなる改良が期待されます。
現在の反復的アプローチをより効率化し、
より高い解像度での安定した生成を実現する手法の開発が重要です。

Implicit Neural Positional Embedding（INPE）の応用範囲拡張も有望な研究方向です。
他の生成タスクや異なるモダリティへの適用により、
より汎用的な位置エンコーディング技術として発展する可能性があります。

商用アプリケーションの観点では、動画生成への拡張、
3D生成との統合、インタラクティブな編集機能の追加などが
実用性をさらに向上させる重要な発展方向となるでしょう。
また、モバイルデバイスや組み込みシステムでの軽量化実装も、
普及拡大において重要な課題です。

長期的には、InfGenのアプローチが他の生成モデルアーキテクチャにも適用され、
より広範囲な任意解像度生成エコシステムの構築につながることが期待されます。
