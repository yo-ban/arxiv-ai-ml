# DeepDive: Advancing Deep Search Agents with Knowledge Graphs and Multi-Turn RL

## 基本情報
- **arXiv ID**: 2509.10446v1 (https://arxiv.org/abs/2509.10446)
- **著者**: Rui Lu, Zhenyu Hou, Zihan Wang, Hanchen Zhang, Xiao Liu, Yujiang Li, Shi Feng, Jie Tang, Yuxiao Dong
- **所属**: Tsinghua University, Northeastern University
- **投稿日**: 2025年09月16日
- **カテゴリ**: cs.AI, cs.LG

## 簡単に説明すると
この論文は、大規模言語モデル（LLM）にWebブラウジング機能を組み合わせた「深層検索エージェント」を改善する研究です。従来の検索エージェントは簡単な質問にしか対応できませんでしたが、DeepDiveは知識グラフから自動生成した難しい質問データセットと、マルチターン強化学習を使って、複雑で見つけにくい情報を探し出せるエージェントを開発しました。研究成果とコードはGitHubで公開されています：https://github.com/THUDM/DeepDive

## 1. 研究概要
### 1.1 背景と動機
大規模言語モデルが複雑な推論タスクにおいて優れた性能を示している一方で、実世界の問題を解決するためには外部ツール、特にWebブラウジング機能との統合が重要となっています。しかし、現在のオープンソースモデルは「深層検索エージェント」としての性能が低く、数百のオンラインソースから複雑で見つけにくい情報を探し出すタスクにおいて、プロプライエタリなLLMに大きく劣っています。

この性能差の主な原因として、既存のQAデータセットの多くが比較的簡単な質問で構成されており、真の「見つけにくい」ケースを反映していないこと、そして長期間にわたる推論と深層検索ツールの使用を効果的に組み合わせる訓練方法が確立されていないことが挙げられます。HotpotQAのような従来のデータセットでは、明確なエンティティを検索するだけで解答できることが多く、BrowseCompのような深層検索タスクで要求される複数の曖昧なエンティティにわたる長期推論とは大きく異なります。

### 1.2 主要な貢献
この研究では、深層検索エージェントを発展させるために二つの重要な技術的貢献を行っています。

第一に、オープンな知識グラフから複雑で難易度の高い見つけにくい質問を自動的に合成する戦略を提案しました。知識グラフの構造的特性を活用し、ランダムウォークによって多ホップ推論パスを抽出し、エンティティの属性を意図的に曖昧化することで「ぼやけたエンティティ」を作成します。これにより、モデルが反復的に推論、検索、検証、反省を行わなければ正確な答えに到達できないような質問を生成できます。

第二に、LLMの長期推論能力と深層検索能力を向上させるためのエンドツーエンドマルチターン強化学習フレームワークを導入しました。このフレームワークでは、Web環境との相互作用を通じて最終回答に基づく報酬を受け取り、テスト時におけるツール呼び出しのスケーリングと並列サンプリングを可能にします。

- オープン知識グラフからの深層検索QAペア自動合成手法
- 内部推論と外部Web検索を効果的に組み合わせるエンドツーエンドマルチターンRL フレームワーク
- オープンモデルベースでBrowseCompにおいて14.8%の精度を達成し、新たなオープンソース競争モデルを実現
- ツール呼び出しのテスト時スケーリングと並列サンプリングの深層検索における有効性の実証

## 2. 提案手法
### 2.1 手法の概要
DeepDiveの手法は、データ構築段階と強化学習段階の2つの主要コンポーネントで構成されています。データ構築段階では、知識グラフを用いて大規模で挑戦的な深層検索QAペアのコーパスを自動合成します。強化学習段階では、構築されたデータを活用してエンドツーエンドマルチターンRL訓練を実行し、エージェントの長期推論とブラウジング能力を向上させます。

エージェントとWeb環境との相互作用フレームワークでは、各決定が推論、ツール呼び出し、観察の反復サイクルに従います。ステップtにおいて、エージェントは思考の連鎖c_t を生成し、ブラウジングアクションa_t を実行し、Webコンテンツo_t を観察します。このプロセスは、エージェントが十分な情報を収集したと判断し、最終回答を提供する終了アクションa_eos を実行するまで継続されます。

アクション空間には、キーワードでWebページ要約を取得するsearch、検索結果から特定ページにアクセスするclick、指定URLに直接アクセスするopenの3つの核心操作が含まれます。特に、clickとopen操作は単一呼び出しで複数ページの取得をサポートし、情報収集の効率を向上させます。

### 2.2 技術的詳細
知識グラフからの自動データ合成では、構造化された意味的に豊富な環境を活用して多ホップ推論のための監視データを生成します。知識グラフの利点として、検証可能性（事実的なエンティティ-関係トリプルによる客観性）、多ホップ構造（異なる長さのランダムウォークによる推論深度の制御）、推論制御可能性（属性の選択的隠蔽による曖昧性の増加）があります。

具体的な合成プロセスでは、まずKILTとAMinerの公開知識グラフからk∈[5,9]、d=3、d_min=4、d_max=8のパラメータで長鎖パスを生成します。次に、Gemini-2.5-Proの優れた長コンテキスト能力を活用してエンティティを曖昧化し、QAペアを合成します。この過程で3,250の深層検索QAペアを生成し、1,016サンプルを教師ありファインチューニング（SFT）用、2,234を強化学習用にランダム分割します。

強化学習訓練では、まずClaude-4-Sonnet-Thinkingを教師モデルとしてコールドスタートフェーズを実行し、ブラウジングツールとの相互作用によって858の高品質SFTトレースを生成します。その後、SFTモデルの性能をpass@8で評価し、精度率0.125から0.75のデータ974サンプルを選択してRL訓練に使用します。

### 2.3 新規性
既存の研究との主要な違いは、真の「見つけにくい」情報を扱う能力の向上にあります。従来のHotpotQAのようなデータセットでは予測可能な推論ステップが多いのに対し、DeepDiveは人間の研究者のように反復的に検索、フィルタリング、分散した証拠の合成を行うエージェントの開発を目指しています。

知識グラフベースの合成手法は、従来の完全モデル生成QAペアと比較して、
事実の追跡可能性と客観性を30%向上させます。また、エンティティ属性の選択的曖昧化により
モデルによるショートカット解法の利用を防ぎ、より深い推論を要求します。

マルチターンRL訓練の新規性は、単なるツール使用の学習ではなく、長期推論とWebツールの統合に焦点を当てている点です。従来のR1-SearcherやReSearchなどのシステムが主に直接的な検索タスクに設計されているのに対し、DeepDiveは複雑な多ホップ推論を伴う深層検索能力の向上を目指しています。

## 3. 実験結果
### 3.1 実験設定
実験では4つの公開された挑戦的な深層検索ベンチマークで評価を実施しました：BrowseComp、BrowseComp-ZH、Xbench-DeepSearch、SEAL-0です。比較対象として、プロプライエタリモデル（GPT-4o、Claude-3.7-Sonnet、o1など）とオープンソースモデル（Search-o1、WebThinker、R1-Searcher、WebDancer、WebSailorなど）の両方を含む多様なモデルセットを使用しました。

データ合成では、KILTとAMinerの公開知識グラフからGemini-2.5-Proを使用して3,250の深層検索QAペアを生成し、SFT用とRL用に分割しました。訓練では、Serper APIによる検索とJina APIによるclickおよびopen操作を統合し、GLM-Z1-9B-0414とQwQ-32Bをバックボーンモデルとして選択しました。

評価では、LLM-Judgeフレームワークに従い、Llama-3.1-70Bを使用してモデルの最終出力と正解との照合を評価しました。RL訓練中の高速評価のため、各チェックポイントはBrowseComp-266のランダムサブセットで評価され、訓練が収束した後、完全なBrowseCompデータセット（1,266インスタンス）で評価されました。

### 3.2 主要な結果
DeepDive-32BはBrowseCompにおいて14.8%の精度を達成し、WebSailor、Search-o1、DeepSeek-R1-Browseなどすべての既存オープンシステムを上回り、新たなオープンソース競争結果を実現しました。この性能は、プロプライエタリモデルの中でも競争力のあるレベルに位置しています。

複数のベンチマークでの結果分析により、マルチターンRL訓練がDeepDive-32Bの性能向上に大きく貢献していることが実証されました。4つの深層検索ベンチマークすべてにおいて、RL訓練後のモデルが一貫して改善を示しています。

テスト時スケーリングの分析では、最大ツール呼び出し数の増加とともにBrowseCompでの性能が向上することが確認されました。また、並列サンプリングによる追加的な性能向上も観察され、深層検索タスクにおけるこれらの手法の有効性が実証されました。

### 3.3 既存手法との比較
オープンソースモデルとの比較では、DeepDive-32BがWebSailor（13.2%）、Search-o1（12.1%）、DeepSeek-R1-Browse（11.5%）を大幅に上回る性能を示しました。特に、より大きなパラメータ数を持つ一部のモデルと比較しても競争力のある結果を達成しています。

プロプライエタリモデルとの比較では、Grok-DeepResearch（16.8%）やDoubao with Deep Think and Search（15.3%）など一部のモデルには及ばないものの、オープンソースモデルとしては画期的な性能を実現しています。

重要な発見として、単純にブラウジング機能を追加した既存モデル（例：QwQ-32B + function calling: 8.9%）と比較して、DeepDiveの専用設計された訓練手法が大幅な性能向上をもたらすことが確認されました。これは、深層検索能力の獲得には単なるツール統合以上の sophisticated な訓練アプローチが必要であることを示しています。

## 4. 実用性評価
### 4.1 実装の容易性
DeepDiveの実装は比較的容易で、研究チームがすべてのデータセット、モデル、コードをGitHubで公開しています。知識グラフからのデータ合成パイプラインは自動化されており、既存のLLMバックボーンに適用可能な設計となっています。Slimeフレームワークを使用したRL訓練も、明確なパラメータ設定とともに提供されています。

ただし、高品質な結果を得るためには、知識グラフの準備、大規模なGPUリソース（32 NVIDIA H100 GPU使用）、および適切なWebブラウジングAPIの統合が必要です。特に、Serper APIとJina APIの組み合わせによるWeb環境の構築は、実装において重要な考慮事項となります。

### 4.2 計算効率
計算効率の面では、32Bパラメータモデルでの訓練により、実用的なレベルでの深層検索能力を実現しています。RL訓練では、rollout size 8、sample size 16、global batch size 128という設定で効率的な学習を達成しています。

テスト時におけるツール呼び出しのスケーリングは、性能向上と計算コストのトレードオフを可能にします。最大ツール呼び出し数を調整することで、要求される精度レベルに応じた計算資源の配分が可能です。並列サンプリングによる追加的な性能向上も、適切なリソース管理により実現できます。

### 4.3 応用可能性
DeepDiveの応用可能性は幅広く、特に複雑な情報検索が必要な分野での実用化が期待されます。研究支援、ジャーナリズム、法的調査、市場調査など、多様な情報源から深い洞察を得る必要がある分野において有用です。

また、知識グラフベースのデータ合成手法は、他のドメイン特化型検索エージェントの開発にも転用可能です。医療、金融、技術文書など、特定分野の知識グラフを使用することで、ドメイン固有の深層検索能力を持つエージェントの開発が可能になります。

エンドツーエンドRL訓練フレームワークは、他のツール統合タスクにも適用できる汎用性を持ちます。計算ツール、データベースアクセス、API呼び出しなど、様々な外部ツールとの統合において同様のアプローチが有効である可能性があります。

## 5. まとめと所感
### 5.1 論文の意義
この論文は、オープンソースLLMにおける深層検索能力の向上という重要な課題に対して、実用的で効果的な解決策を提示しています。知識グラフを活用した自動データ合成とマルチターンRL訓練の組み合わせは、従来のアプローチと比較して大幅な性能向上を実現しており、オープンソースコミュニティにとって価値の高い貢献となっています。

特に、「見つけにくい」情報を扱う能力の向上は、実世界のAIアプリケーションにおいて極めて重要です。多くの実際のタスクでは、単純な検索では得られない複雑で散在した情報の統合が求められており、DeepDiveのアプローチはこのような要求に応える可能性を示しています。

研究の透明性と再現性の観点からも、すべてのコード、データ、モデルの公開は学術コミュニティにとって大きな価値があります。これにより、他の研究者が手法を検証し、さらなる改善を図ることが可能になります。

### 5.2 今後の展望
今後の発展の方向性として、まず難易度上限の向上が挙げられます。著者らも認めているように、現在の合成データの難易度はBrowseCompと比較してまだ低く、より挑戦的なデータ生成手法の開発が必要です。

また、「過検索」現象の解決も重要な課題です。適切な訓練ステップの決定と、より適切な報酬メカニズムの設計により、効率的で正確な検索行動の学習が期待されます。

長期的には、他の外部ツールとの統合拡張、ドメイン固有の知識グラフを用いた専門分野への適用、リアルタイム情報更新への対応などが重要な研究方向となるでしょう。特に、動的に変化するWeb環境における継続的学習能力の向上は、実用的なシステムの実現において不可欠です。
