# Canvas-to-Image: Compositional Image Generation with Multimodal Controls

## 基本情報
- arXiv ID: 2511.21691v1 (https://arxiv.org/abs/2511.21691)
- 著者: Yusuf Dalva, Guocheng Gordon Qian, Maya Goldenberg その他のSnap Inc・UC Merced・Virginia Tech研究者
- 所属: Snap Inc, UC Merced, Virginia Tech
- 投稿日: 2025年11月28日
- カテゴリ: cs.CV, cs.AI

## 簡単に説明すると
この論文は、異質な制御信号を単一のキャンバスインターフェースに統合する統一フレームワーク「Canvas-to-Image」を提案しています。
多様な制御信号を単一の複合キャンバス画像にエンコードし、モデルが統合的な視覚空間推論を直接解釈できるようにします。
マルチタスクデータセットと「マルチタスクキャンバス訓練」戦略により、拡散モデルが異質な制御を理解し統合できるよう最適化されています。
プロジェクトWebページが提供されています。

## 1. 研究概要
### 1.1 背景と動機
現代の拡散モデルは高品質で多様な画像生成に優れていますが、複数の制御モダリティを同時に指定する際の高忠実度な構成的・マルチモーダル制御に困難を抱えています。
特にユーザーがテキストプロンプト、被写体参照、空間配置、ポーズ制約、レイアウト注釈を同時に指定する場合に課題が顕著です。
デジタルアートやコンテンツ作成などのクリエイティブな応用分野では、ユーザーは空間レイアウト、被写体参照、ポーズ制約など、複数の制御信号を協調させる必要があります。

既存の制御メカニズムは通常、画像合成の個別の側面のみを扱い、単一入力内での複数制御を扱うことができません。
核心的な困難は、被写体参照、バウンディングボックス、テキストタグなど、構造と意味論の両面で異なる異質な入力を調整することです。
また、これらの信号を共同で解釈しバランスを取ることができるモデルを訓練することも課題となっています。

### 1.2 主要な貢献
この研究では3つの主要な貢献をしています。

第一に、統一キャンバスフレームワークとして、異質な制御を単一のcanvas-to-image定式化に統合する汎用的な「マルチタスクキャンバス」表現を導入しました。
これにより、モダリティ間での一貫した推論が可能になります。

第二に、多様な制御モダリティをカバーする包括的なマルチタスクデータセットを構築しました。拡散モデルをこれらのタスク全体で共同ファインチューニングする統一的フレームワークを提案しました。
実験により、共同訓練が推論時の混合制御を可能にすることが判明しています。

第三に、困難なベンチマークでの包括的評価において、既存手法と比較してアイデンティティ保持と制御遵守の明確な改善を実証しました。
アブレーション研究により、統一的なマルチタスク設計が柔軟で一貫した異質制御を達成するための鍵であることが確認されています。

## 2. 提案手法
### 2.1 手法の概要
Canvas-to-Imageは、マルチモーダルで構成的に制御された画像合成のための統一フレームワークです。
モデルは汎用化された「マルチタスクキャンバス」を入力として受け取り、これは異質なユーザー制御をエンコードするために使用される単一のRGB画像です。
これらの制御には、パーソナライゼーションのための被写体アイデンティティ、空間レイアウト、人間のポーズ、バウンディングボックスが含まれます。

マルチタスクキャンバス定式化により、拡散モデルがこれらの多様な制御モダリティを解釈できるようになります。
すべてがこの単一の画像形式で統一され、一貫した訓練設定で処理されます。
各キャンバスバリアントは、被写体参照を使用したパーソナライゼーションから細粒度構造ガイダンスの適用まで、モデルに異なるタイプの構成的推論を教えます。

### 2.2 技術的詳細
Canvas-to-Imageは、3つの主要なキャンバスバリアントに基づいて構築されています。

**Spatial Canvas**: モデルが明示的な構成に基づいて完全なシーンをレンダリングするよう訓練します。
この入力キャンバスは、セグメント化された被写体のカットアウトをマスクされた背景上の所望の位置に視覚的に貼り付けることで作成される複合RGB画像です。
この戦略は、より単純な構成手法で一般的なコピーペーストアーティファクトを回避するために重要です。

**Pose Canvas**: 関節の強力な視覚的制約を提供することでSpatial Canvasを強化します。
グラウンドトゥルースポーズスケルトンを特定の透明度ファクターを使用してSpatial Canvas上にオーバーレイします。
この半透明オーバーレイが重要な設計選択です。ポーズスケルトンが構造ガイドとして明確に認識可能で、基礎となる被写体セグメントからの視覚的アイデンティティもモデルによる復元・解釈が可能です。

**Box Canvas**: バウンディングボックスとテキスト注釈を直接キャンバス上に配置することで、明示的なレイアウト仕様を解釈するようモデルを訓練します。
各ボックスには、その空間領域に現れるべき被写体とそのサイズを指定するテキスト識別子が含まれています。

モデルはVLM–拡散アーキテクチャに基づいて構築されています。
Vision-Language Model（VLM）が統一キャンバスをトークン化された表現にエンコードします。この表現がキャンバスのVAE潜在表現と連結され、拡散モデルに条件入力として提供されます。

### 2.3 新規性
従来研究との主な違いは以下の点にあります。

**統一キャンバス表現**: 従来手法が個別のモジュールや複雑な組み合わせに依存していたのに対し、Canvas-to-Imageは異質な制御を単一のRGB画像に統合する革新的なアプローチを採用しています。

**マルチタスク学習**: 単一タスクでの訓練から複数制御シナリオへの汎化を可能にするマルチタスクキャンバス訓練戦略を開発しました。
訓練中には見たことのない制御の組み合わせでも、推論時の自然な汎化が可能です。

**統一インターフェース**: 追加のモジュールやアーキテクチャ変更を必要とせず、すべての制御要素が共通のピクセル空間で表現される汎用的な視覚インターフェースを提供します。

**タスク指示器**: モード混合を防ぐために、ユーザープロンプトに短いテキストトークン（「[Spatial]」、「[Pose]」、「[Box]」など）を前置するタスク指示器プロンプトを導入しました。

## 3. 実験結果
### 3.1 実験設定
実験は4つの異なるベンチマークで実施されました。

4P Compositionベンチマーク（Spatial Canvas使用）を実施しました。
Pose-Overlaid 4P Composition（Pose Canvas使用）も評価しました。
Layout-Guided Composition（Box Canvas使用）とMulti-Control Benchmark（CreatiDesignから構築）でも検証しました。

ベースラインとして、Qwen-Image-Edit、高性能な商用編集モデルGemini 2.5 Flash Image、CreatiDesign、Overlay Kontextなどと比較しました。
評価指標には、ArcFace ID Similarity、HPSv3、VQAScore、Control-QAスコアを使用しました。

### 3.2 主要な結果
Canvas-to-Imageはすべてのベンチマークで優れた性能を示しました。

**4P Compositionベンチマーク**: 複数のパーソナライズされた被写体を構成する際の優れたアイデンティティ保持と空間アライメントを実証し、すべてのベースラインを上回りました。
Nano-Bananaは一貫してコピーペーストされた人間セグメントを生成し、Overlay KontextとQwen-Image-Editは被写体アイデンティティの保持に失敗しました。

**Pose-overlaid benchmark**: Canvas-to-Imageのみが、高いアイデンティティ忠実度と視覚的リアリズムを維持しながら、ターゲットポーズを正確に追従しました。

**Layout-Guided Composition**: ボックス制約に従う意味的に一貫した構成を生成し、専用の最先端モデルCreatiDesignさえも上回りました。

**Multi-Control Benchmark**: アイデンティティ保持、ポーズガイダンス、ボックス注釈を共同で満たす優れた構成忠実度を達成しました。
参照被写体と複数の制御手がかりを継ぎ目なく統合しました。

### 3.3 既存手法との比較
定量的結果により、統一フレームワークの有効性が検証されました。
制御遵守とアイデンティティ保持にわたるバランスの取れた性能により、異質な信号を単一キャンバスにエンコードすることが空間、ポーズ、アイデンティティ制約の同時実行を成功させることが確認されました。

すべてのベンチマークでの結果は同一の統一Canvas-to-Imageモデルによって生成されており、単一制御訓練サンプルから複雑な制御シナリオへの強力な汎化を実証しています。
特に、訓練時には個別に学習した制御が、推論時には組み合わせで使用できる汎化特性が重要な特長です。

## 4. 実用性評価
### 4.1 実装の容易性
Canvas-to-Imageは比較的実装しやすい設計となっています。
単一のRGB画像をキャンバスとして使用するため、既存の拡散モデルとの統合がコード変更最小限で容易です。
LoRAを使用したファインチューニング手法により、事前訓練済みモデルの画像品質を保持しながらメモリ使用量を削減した適応が可能です。
タスク指示器プロンプトによるシンプルな制御機構も実装の簡易性に貢献しています。

### 4.2 計算効率
Qwen-Image-Editを基盤として、注意機構、画像調整、テキスト調整レイヤーのみをLoRAでファインチューニングし、フィードフォワード層は凍結することで計算効率を確保しています。
32のNVIDIA A100 GPUで20万ステップの訓練という現実的な計算要求です。
単一モデルで複数の制御タイプに対応できるため、複数の専用モデルを維持する必要がなく、推論時の計算効率も良好です。

### 4.3 応用可能性
Canvas-to-Imageの応用可能性は非常に幅広いです。
デジタルアート、コンテンツ作成、広告、映画制作、ゲーム開発など、クリエイティブ産業での活用が期待されます。
複数の制御モダリティを統一インターフェースで扱えるため、非専門家でも直感的に使用できます。
また、マルチタスク学習による汎化能力により、訓練時に見たことのない制御の組み合わせでも適応可能で、様々な新しいアプリケーションへの拡張が容易です。

## 5. まとめと所感
### 5.1 論文の意義
この研究は、画像生成における制御性の分野で重要な進歩を示しています。
従来の個別制御モダリティから統合的なマルチモーダル制御への移行を実現し、ユーザビリティとクリエイティビティの大幅な向上をもたらしています。
統一キャンバス表現というエレガントな解決策は、複雑な制御問題をシンプルに統合する優れたアプローチです。

また、単一タスク学習から複数制御シナリオへの創発的汎化という興味深い特性を示しており、機械学習における転移学習や汎化能力の理解に新しい洞察を提供しています。
実用的な観点から見ても、クリエイティブ業界での実際のニーズに応える技術として高い価値があります。

### 5.2 今後の展望
今後の発展方向として、より多様な制御モダリティの統合が期待されます。
動画生成への拡張、3D空間での制御、音声や他の感覚モダリティとの統合などが考えられます。
また、ユーザーインターフェースの更なる改善により、より直感的で生産性の高い創作プロセスの実現が可能になるでしょう。

技術的には、より少ない訓練データでの汎化能力の向上、計算効率の最適化、リアルタイム生成への対応などが重要な課題です。
この研究が示したマルチタスクキャンバスのアプローチは、将来の創造的AI技術の基盤となる可能性が高く、人間とAIの協創における新しいパラダイムを切り開くものと考えられます。