# ToolOrchestra: Elevating Intelligence via Efficient Model and Tool Orchestration

## 基本情報
- arXiv ID: 2511.21689v1 (https://arxiv.org/abs/2511.21689)
- 著者: Hongjin Su, Shizhe Diao, Ximing Lu その他多数のNVIDIA・香港大学の研究者
- 所属: NVIDIA, University of Hong Kong
- 投稿日: 2025年11月28日
- カテゴリ: cs.AI, cs.LG

## 簡単に説明すると
この論文は、小さな「指揮者モデル」が様々な専門的なツールやより大きなモデルを戦略的に組み合わせて使うことで、
複雑なタスクを効率的に解決する手法「ToolOrchestra」を提案している。
8Bパラメータの小さなモデルが、GPT-5やQwen3-32Bのような強力なモデルを含む多様なツールセットを状況に応じて使い分けることで、
単一の大きなモデルよりも高い性能を低コストで実現している。
強化学習を用いてタスクの正確性、計算効率、ユーザー嗜好の3つの観点から最適化されており、
「人類最後の試験」ベンチマークでGPT-5を上回る37.1%のスコアを2.5倍の効率で達成している。
関連リンク：GitHub、Hugging Faceモデル、データセット、プロジェクト公式サイトが利用可能です。

## 1. 研究概要
### 1.1 背景と動機
大規模言語モデル（LLM）は強力な汎用性を持つものの、人類最後の試験（HLE）のような複雑なタスクの解決においては、概念的な困難さと計算コストの高さが課題となっています。
従来のツール使用エージェントは、単一の強力なモデルにWebサーチや計算器などのユーティリティツールを装備する手法が主流でした。
しかし、この手法では利用可能なツールの潜在能力を十分に活用できていません。
人間が推論する際には、専門家や高度なソフトウェアシステムなど、自分よりも優れた知能を持つリソースを活用することが一般的です。

本研究では、この観察に基づいてオーケストレーション（指揮）パラダイムを提案しています。
このパラダイムでは、知能は単体のモデルからではなく、複合システムから創発します。
システムの中心には「オーケストレーターモデル」があります。その責任は与えられたタスクに対して最適なツールを最適な順序で呼び出すことです。
従来の単一強力モデル設定との重要な違いは、Webサーチ機能やコードインタープリターなどの決定論的ユーティリティに加えて、様々な能力を持つモデルが「インテリジェントツール」として利用可能であることです。

### 1.2 主要な貢献
この論文では3つの主要な貢献をしています。

第一に、小さな言語モデルを多様なツールキットの指揮者として訓練する手法「ToolOrchestra」を導入しました。
これは、従来のツールと知的モデルの両方を含む包括的な環境での調整を可能にします。
この手法は、小さな言語モデルがエージェント系において十分に強力で、はるかに経済的であるという最近の開発と歩調を合わせています。

第二に、精度を超えた新たな報酬訓練設計を開発しました。
結果として得られるOrchestratorは、タスク結果の正確性、コストと遅延の効率性、ユーザーのコストとツール選好への適応をバランスよく取るよう、エンドツーエンドで訓練されています。

第三に、ToolOrchestraで訓練されたOrchestratorが困難な推論ベンチマークで高い性能を達成しました。フロンティアモデルを上回りながら、計算時間とウォールクロック時間を約60-70%削減し、未知のタスクやツールに頑健に汎化することを実証しました。

## 2. 提案手法
### 2.1 手法の概要
ToolOrchestraは、小さな言語モデルを複雑なタスクを解決する知的エージェントモデルとして訓練することを中心としています。
小さな言語モデルが、より知的なツールを戦略的に調整することを学ぶなら、この目的には十分であるという仮説のもと、8Bモデルの訓練を選択しています。
ToolOrchestraは、訓練中のモデル（Orchestratorと呼ばれる）が最適な多段階推論とツール使用軌跡を生成することを学習する、エンドツーエンドの強化学習設定で構成されています。

システムでは、統一されたツール呼び出しインターフェースを通じて多様なツールセットにアクセスできます。これには従来のツール、専門モデル、汎用LLMが含まれます。
各ツールはJSON形式で指定され、ツール名、説明、型付きパラメータスキーマが定義されています。

### 2.2 技術的詳細
強化学習の報酬設計は、3つの主要コンポーネントから構成されています。

**結果報酬（Outcome Reward）**: 各ロールアウト軌跡τに対して、タスクが解決されるかどうかに基づいてバイナリ精度報酬r_outcome(τ) ∈ {0,1}が与えられます。
GPT-5を判定者として使用し、名前や日付などの回答を比較することで、多様な予測の処理により大きな柔軟性を提供します。

**効率性報酬**: 過度な計算や遅延に対してペナルティを課します。r_compute(τ) = -$(τ)（金銭的コスト）、r_latency(τ) = -Clock(τ)（ウォールクロック時間）を使用します。
オープンソースモデルと所有権モデル両方の計算を統一測定するため、第三者APIプライシングシステムに従って入力トークンと出力トークンの両方を金銭的コストに変換します。

**嗜好報酬（Preference Reward）**: ユーザーの嗜好を考慮してツール選択を促進するよう設計されています。
ツールセット{t₁, t₂, ..., tₙ}とロールアウト軌跡τが与えられると、ベクトルM^τが計算され、各ツールの使用回数と結果・コスト・遅延報酬を組み合わせた最終報酬が算出されます。

### 2.3 新規性
従来の研究との主な違いは、以下の点にあります。

**多様なツールタイプの統合**: 従来のツール使用エージェントが決定論的ツールに焦点を当てていたのに対し、ToolOrchestraは専門モデルと汎用LLMを統合する包括的アプローチを取ります。

**多目的最適化**: 単純な精度最適化を超えて、コスト効率性とユーザー嗜好適応を考慮した多目的な報酬設計を採用しています。

**小規模オーケストレーター**: 大きな単体モデルではなく、小さなモデル（8B）が複雑なツールセットを効率的に調整できることを実証しています。

**バイアス軽減**: 従来のプロンプトベース手法で観察される自己強化バイアスと他者強化バイアスを強化学習によって軽減しています。

## 3. 実験結果
### 3.1 実験設定
実験は3つの困難なベンチマークで実施されました。

**Humanity's Last Exam（HLE）**: 数学、人文科学、自然科学にわたるPhDレベルの質問で構成される大規模ベンチマークです。
反復検索と集約的推論を評価する設計となっており、単純なWebサーチでは解決できない明確な問題が含まれています。

**FRAMES**: 事実性と推論にわたるモデル能力を評価するデータセットです。
2-15のWikipedia記事を必要とする824の多段階質問を含み、数値的、表形式、時間的、多制約推論をカバーしています。

**τ²-Bench**: 通信、小売、航空の3つのドメインでユーザーとの会話でツールを使用して問題を解決するモデル能力を評価するベンチマークです。

評価では、GPT-5、Claude Opus 4.1、Llama-3.3-70B-Instruct、Qwen3-235B-A22Bなどの強力なベースラインと比較しました。

### 3.2 主要な結果
Orchestrator-8Bは全てのベンチマークで優れた性能を示しました。

**HLE**: Orchestrator-8Bは37.1%のスコアを達成し、GPT-5の35.1%を上回りました。
これは報告されている既存のSOTA（GPT-5の35.2%）をも超える結果です。

**FRAMES**: 76.3%のスコアでGPT-5の74.0%を上回り、最高性能を記録しました。

**τ²-Bench**: 80.2%のスコアでGPT-5の77.7%を2.5%上回る性能を示しました。

特に注目すべきは、これらの性能向上がコストと遅延の大幅な削減と同時に達成されていることです。
Orchestrator-8Bは平均して9.2セントのコストと8.2分の遅延で動作し、GPT-5の30.2セント、19.8分と比較して約70%のコスト削減と58%の時間短縮を実現しています。

### 3.3 既存手法との比較
ツールを使用しない設定では、Qwen3-235B-A22BやLlama-3.3-70Bなどの大きなモデルでも性能が低く、これらのベンチマークの本質的な困難さが示されています。

基本ツール（Webサーチ、コードインタープリター）を提供すると性能が向上しますが、一貫性に欠けます。
例えば、Claude Opus 4.1はHLEで11.7から19.8に改善しますが、2.8倍のコストと4倍の遅延が必要です。

専門LLMと汎用LLMの両方を含むツール使用では、ほとんどのモデルで結果が改善されますが、GPT-5は固有のバイアスにより性能が低下しました。
これは、GPT-5がGPT-5-miniにデフォルト設定することが多いためです。

対照的に、Orchestrator-8Bは一貫して全てのベースラインを大きなマージンで上回り、特にコストと時間の使用量が約60-70%削減されています。

## 4. 実用性評価
### 4.1 実装の容易性
Orchestrator-8Bは相対的に実装が容易です。
8Bパラメータという小さなサイズにより、一般的なハードウェア環境での展開が可能であり、大規模な計算リソースを必要としません。
統一されたJSON形式のツールインターフェースにより、新しいツールの追加も簡単に行えます。
また、多様なツール構成での訓練により、異なる環境への適応性も高くなっています。

### 4.2 計算効率
実験結果は、Orchestrator-8Bが優れた計算効率を持つことを示しています。
平均コストが9.2セント、平均遅延が8.2分と、GPT-5と比較して約3分の1のコストと半分以下の時間で動作します。
これは、オーケストレーションアプローチが大きな単体モデルよりもはるかに効率的であることを実証しています。
コスト-性能分析では、予算が与えられた場合に一貫してGPT-5、Claude Opus 4.1、Qwen3-235B-A22Bを上回る性能を示しています。

### 4.3 応用可能性
ToolOrchestraの応用可能性は非常に高いです。
未知のツールに対する汎化能力実験では、訓練時に見たことのないモデルを含む構成でも優れた性能を維持しました。
また、ユーザー嗜好への適応能力により、企業や個人のニーズに合わせてカスタマイズ可能です。
複雑な推論タスク、科学研究支援、教育アシスタント、企業の意思決定支援など、幅広い領域での活用が期待されます。

## 5. まとめと所感
### 5.1 論文の意義
この論文は、AI分野において重要な方向転換を示しています。
従来の「より大きなモデルがより良い」というパラダイムから、「小さなモデルによる戦略的な調整」への移行を実証しました。計算資源を60-70%削減しながら高い性能を実現する道筋を提供しています。
これは計算資源の制約下でより高い知能を実現する実用的な道筋を提供しており、AIシステムの民主化にも貢献します。
また、多目的最適化（精度、効率性、ユーザー嗜好）のアプローチは、実世界でのAI展開において極めて重要な考慮事項を取り入れています。
強化学習を用いた包括的な訓練手法も、複雑なマルチエージェントシステムの訓練において新しい標準を設定しています。

### 5.2 今後の展望
今後の研究方向としては、より洗練された再帰的オーケストレーターシステムの開発が期待されます。
これにより、さらに複雑なタスクに対処しながら計算効率を向上させることができるでしょう。
また、ツールの動的発見と適応、リアルタイム学習機能の追加により、さらに柔軟なシステムの構築が可能になります。
多言語・多モダリティ対応の拡張、専門ドメイン（医療、法律、工学など）への特化も重要な発展方向です。
この研究は、将来的にはより汎用的で計算効率に優れた人工知能エージェントの実現に向けた重要な基盤を提供していると考えられます。