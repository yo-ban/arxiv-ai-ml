# Closer to Reality: Practical Semi-Supervised Federated Learning for Foundation Model Adaptation

## 基本情報
- **arXiv ID**: 2508.16568v1 (https://arxiv.org/abs/2508.16568)
- **著者**: Guangyu Sun, Jingtao Li, Weiming Zhuang, Chen Chen, Chen Chen, Lingjuan Lyu 
- **所属**: Sony AI, University of Central Florida
- **投稿日**: 2025年08月26日
- **カテゴリ**: cs.LG, cs.AI

## 簡単に説明すると
この論文は、ファウンデーションモデル（大規模事前学習済みモデル）をエッジデバイスで安全に活用するための新しい手法を提案しています。

現実的な状況では、エッジデバイス（スマートフォンやIoTデバイスなど）は計算リソースが限られており、またラベル付きデータを持っていません。一方で、プライバシー保護のためクラウドに生データを送ることはできません。

この論文では「PSSFL（Practical Semi-Supervised Federated Learning）」という新しい設定を提案し、エッジデバイスはラベルなしの低解像度データのみを持ち、サーバーは限られたラベル付き高解像度データを持つという現実的なシナリオを想定しています。

FedMox（Federated Mixture of Experts）という手法で、特に物体検出タスクを例に、メモリ使用量を大幅に削減しながら高性能を実現しています。例えば、従来手法では8.89GBのメモリが必要だったのに対し、本手法では1.25GBのみで動作し、2GBのRaspberry Piでも実行可能です。

## 1. 研究概要
### 1.1 背景と動機
ファウンデーションモデルは大規模な公開データセットで事前学習されており、幅広いタスクで高い汎用性を示しています。しかし、特定のドメインやプライバシーに関わるデータを含むタスクに適用するためには、さらなる適応が必要です。

近年、データプライバシーに対する関心の高まりとGDPR、CCPAなどの厳しい規制の導入により、センシティブなプライベートデータの収集と集約がより困難になっています。連合学習（FL）は、分散したデータソースを横断して協調的なモデル訓練を可能にし、生データをクライアントでローカルに保持することでプライバシー保護メカニズムを提供します。

しかし、FLにおけるファウンデーションモデルの展開には、ラベル付きデータの不足とエッジデバイスの計算制約という重大な課題があります。従来のFL研究は、クライアントが全モデル訓練に十分なリソースを持ち、ラベル付きデータにアクセスできるという理想的なシナリオに主に焦点を当ててきました。

### 1.2 主要な貢献
本研究の主要な貢献は、ファウンデーションモデルの連合学習における現実的な制約を考慮した新しいフレームワークと手法の提案です。特に、従来研究が見落としていたエッジデバイスの計算リソース制約とラベル付きデータの不足を同時に解決したことが高く評価されます。

- **実用的な半教師連合学習（PSSFL）の提案**: エッジデバイスはラベルなし低解像度データ、サーバーは限られたラベル付き高解像度データを持つ現実的なシナリオを定義。
- **FedMox（Federated Mixture of Experts）フレームワークの開発**: 解像度ミスマッチと計算制約を同時に解決するスパースMoEアーキテクチャ。
- **空間ルーターの導入**: 解像度の異なる特徴マップ間での特徴アライメントを可能にする革新的なメカニズム。
- **Soft-Mixture戦略の導入**: 半教師学習における順次更新の不安定性を緩和し、知識伝達を改善。
- **メモリ効率性の大幅改善**: 凍結バックボーンと低解像度訓練により、8.89GBから1.25GBへのメモリ使用量削減を達成。

## 2. 提案手法
### 2.1 手法の概要
FedMoxは、PSSFL設定での3つの主要な課題を解決するために設計されたフレームワークです。第一に、凍結されたバックボーンによる学習能力の制限。第二に、サーバーとクライアント間の解像度ミスマッチ。第三に、半教師連合学習における順次更新の問題です。

システムの中核はスパースMixture of Experts（MoE）アーキテクチャで、複数のタスクヘッドを用いて凍結されたバックボーンの制限を補完します。特に空間ルーターを導入し、異なる解像度の入力に対応できるようにしました。さらに、Soft-Mixture戦略を導入して半教師学習の不安定性を緩和しています。

### 2.2 技術的詳細
スパース空間MoEの設計において、従来のグローバルルーティングは特徴マップをフラット化して一定の高さ、幅、チャンネル数を前提としているため、異なる解像度での使用ができません。本研究では、特徴マップの各ピクセルを個別にルーティングする空間ルーティングを採用し、チャンネル数のみを固定することで異なる解像度に対応しています。

計算コストを制御するために、top-1スパースルーティング戦略を採用し、訓練時に最も適切な1つのエキスパートのみをアクティベートします。これにより、単一のエキスパートを訓練するのと同等の計算コストで訓練が可能です。

Soft-Mixture戦略は、連合学習の集約プロセスにおいて重要な役割を果たします。従来のハードシェアリングとは異なり、ソフトミキシングではクライアント間でエキスパートの重みを部分的に共有し、各エキスパートの重要性を考慮した集約を実現します。

### 2.3 新規性
FedMoxの主要な革新性は、ファウンデーションモデルの連合学習において現実的な制約を初めて本格的に考慮したことです。従来の連合学習研究は、クライアントが十分な計算リソースとラベル付きデータを持つ理想的なシナリオを想定していましたが、本研究はエッジデバイスのメモリ制約とラベルなしデータという現実を直視しました。

空間MoEアーキテクチャは、異なる解像度の入力に対応できる点で独創的です。特徴マップの各ピクセルを個別にルーティングすることで、解像度に依存しない柔軟なアーキテクチャを実現しています。

また、Soft-Mixture戦略は、半教師連合学翕における特有の課題である順次更新の不安定性を解決する革新的なアプローチです。中央集中型設定とは異なり、教師なし学習と教師あり学習が順次実行される連合学習の特性を考慮し、知識伝達の効率を改善しています。

## 3. 実験結果
### 3.1 実験設定
実験は、自動運転分野の現実的なデータセットであるBDD100KとSODA10Mを使用して物体検出タスクで実施しました。BDD100Kは天候条件（曇り、曇天、雨、雪）ごとに分類され、SODA10Mは異なる照明条件で構成されています。

実験設定では、サーバーが高解像度（1280x720）のラベル付きデータを保持し、クライアントは低解像度（640x360）のラベルなしデータを持つというPSSFL設定を採用しました。クライアント数は3台と9台の2つの設定で評価し、mAP@50を主要な評価指標として使用しました。

ベースラインとしては、FedAvg、FedProx、FedSTOなどの代表的な連合学習手法、および中央集中型の教師あり学習（SCL）を使用しました。

### 3.2 主要な結果
BDD100Kデータセットでの結果では、FedMoxが全ての天候条件でベースラインを上回る性能を示しました。特に、N=3の設定ではmAP@50が0.486を達成し、最も近いベースラインであるFedAvgの0.432と比較して約12.5ポイントの大幅な改善を示しました。

特に注目すべきは、雪のような困難な条件でも高い性能を維持したことです。これは、空間MoEアーキテクチャが異なる条件に適応的に対応できることを示しています。また、N=9の設定でも一貫して高い性能を維持し、スケーラビリティの面でも優秀であることが確認されました。

メモリ効率の面では、従来の高解像度全モデル訓練が8.89GBのメモリを必要としていたのに対し、FedMoxは低解像度・凍結バックボーン設定で1.25GBまで削減し、約86パーセントのメモリ節約を達成しました。

### 3.3 既存手法との比較
中央集中型の教師あり学習（SCL）との比較では、バックボーンを凍結したSCLが0.434のmAP@50を達成しているのに対し、FedMoxは0.486という優秀な性能を示しました。これは、プライバシーを保持しながらも中央集中型の手法を上回る性能を達成していることを示しています。

他の連合学習手法との比較では、FedAvg、FedProx、FedSTOのいずれと比較しても大幅な性能向上を達成しました。特に、従来の連合学習手法が異なる条件で性能にバラつきがあるのに対し、FedMoxはどの条件でも一貫して高い性能を維持しています。

アブレーションスタディの結果では、空間ルーターとSoft-Mixture戦略の両方が性能向上に重要な役割を果たしていることが確認されました。特に、解像度ミスマッチを適切に処理する空間ルーターの有効性が明確に示されました。

## 4. 実用性評価
### 4.1 実装の容易性
FedMoxの実装は、既存の連合学習フレームワークに組み込みやすい構造を持っています。主要なコンポーネントであるスパースMoEアーキテクチャと空間ルーターは、標準的な深層学習ライブラリで実装可能です。

特にPyTorchやTensorFlowなどの主要なフレームワークでは、MoEモジュールの実装がすでに支援されており、空間ルーターも簡単な畔み込み層で実現できます。また、バックボーンの凍結によりパラメータ数が大幅に削減されるため、実装とデバッグが比較的容易です。

### 4.2 計算効率
FedMoxの最大の利点の一つは、メモリ効率の大幅な改善です。従来の高解像度全モデル訓練が8.89GBのメモリを必要としていたのに対し、FedMoxは1.25GBまで削減し、約86パーセントのメモリ節約を達成しました。

この効率性により、2GBのRaspberry PiやNVIDIA Jetson Nanoなどの一般的なエッジデバイスでもファウンデーションモデルの訓練が可能になります。また、スパースルーティングにより、計算コストを単一エキスパートと同等に保ちながら、複数のエキスパートの恐恵を活用できます。

### 4.3 応用可能性
FedMoxのアプローチは、自動運転以外の様々な分野でも応用可能です。特に、プライバシーが重要で、エッジデバイスが計算リソースに制限を持つシナリオでの応用が期待されます。

医療分野では、病院間での患者データを共有せずに診断支援AIの性能を向上させること、金融分野では銀行間での顧客データを保護しながら不正検知モデルを共同学習することなどが考えられます。また、IoTデバイスやスマートシティアプリケーションでも、本手法のアプローチが有効であると考えられます。

特に、異なる解像度やデータ品質を扱う必要があるシナリオでは、空間MoEアーキテクチャの柔軟性が大きなアドバンテージとなります。

## 5. まとめと所感
### 5.1 論文の意義
本研究は、ファウンデーションモデルの連合学習において、現実的な制約を初めて本格的に考慮した重要な貢献です。従来の連合学習研究が理想的な条件を前提としていたのに対し、PSSFLという新しい設定を提案し、エッジデバイスのメモリ制約とラベルなしデータという現実的な課題に組み織的に取り組みました。

技術的革新の観点からは、空間MoEアーキテクチャとSoft-Mixture戦略の組み合わせが特に高く評価されます。異なる解像度の入力に柔軟に対応する空間ルーターのアイデアは、他のマルチモーダルタスクにも応用可能な汎用性を持っています。

実験結果でも、メモリ使用量を約86パーセント削減しながら、性能の大幅向上を達成するという驚くべき結果を示しており、実用的な価値が非常に高いと評価できます。

### 5.2 今後の展望
今後の研究方向として、いくつかの有望な領域が考えられます。第一に、より高度なモデル圧縮技術との組み合わせです。量子化やプルーニングなどの技術を組み合わせることで、さらなるメモリ効率化と高速化が期待されます。

第二に、他のコンピュータビジョンタスクへの応用拡大です。物体検出での成功を受け、セグメンテーション、姿勢推定、顔認証などの他の構造化予測タスクでの有効性が期待されます。

第三に、適応的なルーティング戦略の進化です。現在のtop-1スパースルーティングから、より洗練された適応的ルーティング戦略への発展が、更なる性能向上をもたらす可能性があります。

最後に、プライバシー保護技術とのさらなる統合です。差分プライバシーや同態圧暗号などの技術と組み合わせることで、更に強固なプライバシー保護を実現しながら、実用的なファウンデーションモデルの連合学習が期待されます。
