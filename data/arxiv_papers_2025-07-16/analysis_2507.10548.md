# EmbRACE-3K: Embodied Reasoning and Action in Complex Environments

## 基本情報
- arXiv ID: 2507.10548 (https://arxiv.org/abs/2507.10548)
- 著者: Mingxian Lin、Wei Huang、Yitang Li、Chengjie Jiang、Kui Wu他
- 所属: The University of Hong Kong, Tsinghua University, LIGHTSPEED, Beijing Normal University
- 投稿日: 2025年07月15日
- カテゴリ: cs.CV, cs.AI, cs.CL, cs.LG

## 簡単に説明すると
この論文は、AIエージェントが仮想環境で人間のように行動する能力を評価するための大規模なデータセット「EmbRACE-3K」を提案しています。
このデータセットは、物を見つけたり、指示された場所に移動したりするタスクを含んでいます。
従来のAIモデルは画像や動画を「見る」ことは得意でしたが、実際に環境の中で「動いて探索する」ことは苦手でした。
このデータセットには3,000以上のタスクと26,000のステップが含まれており、各ステップにはAIがなぜその行動を取ったかの説明も付いています。
GPT-4oやGemini 2.5 Proなどの最先端モデルの成功率は20%以下でした。
しかし、このデータセットを用いた学習により顕著に改善されました。
プロジェクトページは https://mxllc.github.io/EmbRACE-3K/ で公開されています。

## 1. 研究概要
### 1.1 背景と動機
近年のVision-Language Models（VLMs）は、画像キャプション生成や動画理解などの受動的なタスクで優れた性能を示してきました。
しかし、これらのモデルを実際に環境内で行動するエージェントとして使用する「embodied AI」の場面では、大きな課題に直面しています。
現実世界や仮想環境のエージェントは、自分の行動によって次に見えるものが変わる「閉ループ」の状況で動作します。

著者らの事前実験によると、GPT-4oやQwen2.5-VLなどの最先端モデルも3つの根本的な問題を抱えていることが判明しました。
それらは「短視眼的な探索行動」、「動的な空間認識の欠如」、「一時的に見えなくなった目標の忘却」です。
これらの問題は、従来のVLMsが静的な画像や受動的な動画から学習していることに起因します。
能動的な探索や行動の経験の欠如が根本的な原因です。

### 1.2 主要な貢献
本研究では、embodied AIの能力を向上させるために以下の貢献をしています。
- Unreal Engineで構築された写実的な環境から収集した3,000以上のタスクと26,000の意思決定ステップを含む大規模データセット「EmbRACE-3K」の構築
- 各行動ステップに対する自然言語による思考過程の注釈（Chain-of-Thought）を含む、きめ細かな監督信号の提供
- 探索、動的空間・意味推論、多段階の目標実行という3つの中核的なembodied能力を評価するベンチマークの確立
- 教師あり学習（SFT）と強化学習（RL）を組み合わせた2段階の学習パイプラインの提案と、その有効性の実証

## 2. 提案手法
### 2.1 手法の概要
EmbRACE-3Kデータセットは、4段階のデータ収集パイプラインを通じて構築されています。
まず、UnrealCV-Zooフレームワークを使用して、100の利用可能な環境から24の高品質な写実的環境を選択しました。
これらの環境は、屋内外の設定、照明条件、オブジェクト密度、空間的複雑さにおいて多様性を持っています。

データ収集プロセスは以下の4段階で構成されています。
第1段階では、エージェントの6自由度ポーズをサンプリングし、各位置での一人称の視点画像を記録します。
第2段階では、Gemini 2.5 Proモデルを使用して、視覚的コンテキストに基づいた自然言語タスク指示を生成します。
第3段階では、人間のアノテーターがタスクを実際に実行し、行動軌跡を記録します。
第4段階では、各行動ステップに対して、なぜその行動を選択したかの自然言語説明を生成します。

### 2.2 技術的詳細
タスクは5つのカテゴリに分類されています。
Basicタスクは、目標が明確に見えており、最小限の推論で到達可能なものです。
Explorationタスクは、目標が初期状態では見えず、能動的な探索が必要なものです。
Dynamic Spatial-Semanticタスクは、相対的または順序的な空間参照を使用して目標を記述するものです。
Multi-stageタスクは、特定の順序で複数のサブゴールを完了する必要があるものです。
Interactionタスクは、ドアを開ける操作や、オブジェクトを拾ったり落としたりする操作を必要とするものです。

学習パイプラインは2段階で構成されています。
第1段階のSFTでは、Qwen2.5-VL-7Bモデルを基盤として、2,344の高品質な推論軌跡で学習します。
第2段階では、Group Relative Policy Optimization（GRPO）アルゴリズムを使用した強化学習を実施します。
報酬関数は、フォーマットの正確性と行動の正確性を評価するルールベースの設計となっています。

### 2.3 新規性
既存のembodiedベンチマークと比較して、EmbRACE-3Kは複数の重要な特徴を持っています。
第一に、ステップレベルでの詳細な推論注釈を提供する唯一のデータセットです。
第二に、写実的な環境での閉ループインタラクションをサポートしています。
第三に、時空間的な認識と長期的な計画能力を明示的に評価できるよう設計されています。

ALFREDやOctopusなどの既存データセットと比較して、EmbRACE-3Kは知覚、言語、推論、行動の間のマルチモーダルな整合性をより細かい粒度で提供します。
これにより、エージェントが「なぜ」その行動を取るのかを学習できるようになり、より解釈可能で制御可能な基盤を提供します。

## 3. 実験結果
### 3.1 実験設定
実験では、UnrealZoo環境からサンプリングされたin-domainとout-of-domainの両方のタスクで評価しました。
評価は6つのタスクタイプをカバーしています。
Basic、Exploration、Dynamic Spatial-Semanticの3種類です。
その他にMulti-stage、Interaction - Open Door、Interaction - Pick and Dropもあります。

評価指標として以下の5つを使用しました。
Success Rate（SR）は、エージェントがタスクを正常に完了した割合を測定します。
Goal Distance Error（GDE）は、エージェントの最終位置と目標位置間のユークリッド距離（cm単位）を測定します。
Step-based Success weighted by Path Length（SSPL）は、成功したエピソードの効率性を評価します。
Stepsは、エピソードあたりの平均アクション数を報告します。
Timeout Rate（TR）は、最大ステップ数を超えてタスクを完了できなかったエピソードの割合を測定します。

### 3.2 主要な結果
ゼロショット設定では、最先端モデルの性能は非常に低いことが明らかになりました。
out-of-domainタスクにおいて、GPT-4oの成功率はExplorationで3.6%、Dynamic Spatial-Semanticで10.2%、Multi-stageで2.7%でした。
Gemini 2.5 ProとQwen2.5-VL-originalも同様に低い性能を示しました。

EmbRACE-3Kデータセットでファインチューニングを行ったQwen2.5-VLモデルは、顕著な性能向上を示しました。
SFT+RLモデルは、out-of-domainのExplorationタスクで30.9%、Spatial-Semanticタスクで42.4%の成功率を達成しました。
これはGPT-4oやGemini 2.5 Proを上回る結果です。
Goal Distance Errorも大きく減少しました。
Explorationタスクでは9978.3から1162.8へ（88.4%減少）、Spatial-Semanticタスクでは7844.0から824.6へ（89.5%減少）です。

### 3.3 既存手法との比較
推論注釈の効果を検証するため、Chain-of-Thoughtなしで学習したモデル（no-thinking）と比較しました。
Dynamic Spatial-Semanticタスク（in-domain）では、成功率が27.1%から42.4%に向上し、SSPLは0.268から0.405に増加しました。
この結果は、ステップごとの推論監督が空間的な基盤化とタスクコンテキストの維持に有効であることを示しています。

汎化能力の分析では、SFT-onlyモデルはin-domainで良好な性能を示しましたが、out-of-domainでは大幅な性能低下が見られました。
例えば、Explorationタスクの成功率は71.4%から22.8%に低下しました。
一方、RL拡張モデルはより良い汎化を示し、out-of-domainでも30.9%の成功率を維持しました。
これは、軌跡レベルの強化学習信号がポリシーの堅牢性を促進することを示しています。
特に訓練環境とは異なる空間レイアウトで有効です。

## 4. 実用性評価
### 4.1 実装の容易性
EmbRACE-3Kデータセットは、UnrealCV-Zooフレームワークに基づいて構築されており、標準的なAPIを通じてアクセスできます。
データは統一されたフォーマットで提供されます。
順序付けられた一人称の視点フレーム、離散アクションシーケンス、6自由度ポーズ、言語フィールドが含まれています。

学習パイプラインは、Llama-FactoryフレームワークとR1Vフレームワークを使用して実装されており、既存の深層学習インフラストラクチャと互換性があります。
Qwen2.5-VLベースのモデルは7Bパラメータサイズであり、現代的なGPUクラスタで扱いやすいサイズです。

### 4.2 計算効率
SFT段階の学習は8つのGPUで実行され、2,344の高品質な推論軌跡（合計10,000の学習可能なアクション）を使用します。
GRPO強化学習段階も8つのGPUで実行され、各ステップで6つの候補応答を生成します。

推論時には、各タスクプロンプトに現在の一人称の視点画像、最新の5フレーム、初期フレームを含めます。
これにより、時間的コンテキストと計算効率のバランスを取っています。
完全な軌跡を含めることは過度のレイテンシとモデルのタイムアウトにつながるため、この制限されたフレーム戦略を採用しています。

### 4.3 応用可能性
EmbRACE-3Kは、embodied AIの研究と開発において幅広い応用可能性を持っています。
第一に、ロボティクスにおける視覚的ナビゲーションとタスク実行の改善に直接適用できます。
第二に、仮想アシスタントやゲームAIなど、インタラクティブな環境で動作するエージェントの開発に活用できます。

データセットに含まれる詳細な推論注釈は、解釈可能なAIシステムの開発に貢献します。
エージェントがなぜ特定の行動を選択したかを説明できることは、信頼性の高いAIシステムの構築に必要です。

さらに、このデータセットは、視覚と言語の統合理解、長期的な計画立案、動的環境での適応など、AI研究の基礎的な問題に取り組むための貴重なリソースとなります。

## 5. まとめと所感
### 5.1 論文の意義
この論文は、embodied AIの分野において重要な貢献をしています。
従来のVLMsが抱える根本的な問題を明確に特定し、それらを解決するための包括的なソリューションを提供しています。
特に、ステップレベルでの推論注釈を含む大規模データセットの構築は重要です。
これにより、エージェントの行動の解釈可能性が向上します。

実験結果は、現在の最先端モデルがembodiedタスクにおいて深刻な制限を持っていることを明確に示しています。
同時に、高品質なデータセットと体系的な学習方法によってこれらの制限を克服できることも実証しています。
SFTとRLを組み合わせたアプローチは、特に汎化能力の向上において効果的であることが示されました。

### 5.2 今後の展望
今後の研究方向として、いくつかの重要な課題が残されています。
第一に、より複雑な環境や現実世界への転移学習の可能性を探る必要があります。
第二に、マルチエージェント環境での協調的な行動や、人間との相互作用を含むタスクへの拡張が考えられます。

計算効率の改善も重要な課題です。
現在のアプローチは8つのGPUを必要とします。
そのため、より少ない計算リソースで動作する学習方法の開発が求められます。
推論時の効率化では、時間的コンテキストを保持しつつレイテンシを削減します。

長期的には、このようなembodied AIの研究が、より自然で直感的な人間とAIのインタラクションを可能にし、日常生活で真に役立つAIアシスタントの実現につながることが期待されます。
