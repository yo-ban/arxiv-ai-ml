# HyCodePolicy: Hybrid Language Controllers for Multimodal Monitoring and Decision in Embodied Agents

## 基本情報
- arXiv ID: 2508.02629v1 (https://arxiv.org/abs/2508.02629)
- 著者:
  - Yibin Liu (NEU, D-Robotics)
  - Zhixuan Liang (HKU MMLab, Shanghai AI Lab)
  - Zanxin Chen (Shanghai AI Lab, SZU)
  - Tianxing Chen (HKU MMLab, SZU)
  - Mengkang Hu (HKU MMLab)
  - Wanxi Dong (SUSTech)
  - Congsheng Xu (SJTU ScaleLab)
  - Zhaoming Han (D-Robotics)
  - Yusen Qin (D-Robotics, THU)
  - Yao Mu (SJTU ScaleLab, Shanghai AI Lab)
- 所属: SJTU ScaleLab、HKU MMLab、NEU、D-Robotics、Shanghai AI Lab、SZU、SUSTech、THU
- 投稿日: 2025年8月6日
- カテゴリ: Robotics、Computer Vision、Artificial Intelligence

## 簡単に説明すると
この論文は、エンボディドエージェント（ロボット）のための自己修正プログラム合成を実現する「HyCodePolicy」というハイブリッド言語ベースの制御フレームワークを提案しています。コード合成、幾何学的グラウンディング、知覚的モニタリング、ターゲット修復を統合し、人間の介入を最小限に抑えながらロボットの動作を改善します。

主な成果として、RoboTwin 1.0でのタスク成功率を47.4%から63.9%に、Bi2Codeインターフェースでは62.1%から71.3%に向上させました。また、収束に必要な反復回数を2.42回から1.76回に削減し、学習プロセスを27%高速化しています。

この研究は、生成されたコードを進化可能な仮説として扱い、知覚的手がかりと構造化された実行ログを組み合わせて失敗を診断し、修正する点が革新的です。

## 1. 研究概要
### 1.1 背景と動機
現在のLLMベースのロボット計画システムには、以下の課題があります。
- タスク実行の適応的モニタリング機構の欠如
- 失敗の検出と診断能力の不足
- 閉ループでのロボット動作修復機能の不在

これらの課題に対して、HyCodePolicyは生成されたコードを動的に検証・評価・修正可能な進化する仮説として扱います。これにより、ロボットが自律的に失敗から学習し、動作を改善できるようになります。

### 1.2 主要な貢献
本研究の主要な貢献は以下の4点です。

- **統合的フレームワーク**：コード合成、幾何学的グラウンディング、知覚的モニタリング、ターゲット修復を1つのループで統合
- **ハイブリッドフィードバック機構**：構造化された実行ログとVLM（Vision-Language Model）由来の知覚的フィードバックを組み合わせた二重フィードバック
- **Bi2Codeインターフェース**：デュアルアームAPIサポート、分解可能な構造化プロンプト、標準化されたシンボリックロギング機能を持つ再設計されたモジュラーインターフェース
- **実証的検証**：10種類のロボット操作タスクでの大幅な性能改善を実証

## 2. 提案手法
### 2.1 手法の概要
HyCodePolicyは4つの統合されたフェーズで構成されています。

1. **高レベル意図のコードへのグラウンディング**
2. **シミュレート実行とマルチモーダルモニタリング**
3. **ハイブリッドフィードバックと失敗帰属**
4. **閉ループ自律性**

### 2.2 技術的詳細
**フェーズ1：高レベル意図のコードへのグラウンディング**
- 自然言語をN個の意味的に一貫したサブゴールに分解
- API リスト、例示、サブゴール制約を使用した構造化プロンプティング
- 幾何学的操作プリミティブの統合：
  - ポイントプリミティブ：把持点、配置点、ユーティリティ点
  - 軸プリミティブ：アプローチ軸、方向軸、動作軸

**フェーズ2：シミュレート実行とマルチモーダルモニタリング**
- 確率的変動を考慮して10回のプログラム実行
- 結果とエラーメッセージを記録する構造化シンボリックログの生成
- 戦略的な観察ポイント挿入によるVLMエージェントのモニタリング
- 状態変化操作での視覚的コンテキストのキャプチャ

**フェーズ3：ハイブリッドフィードバックと失敗帰属**
- VLMによる視覚フレームの評価とサブゴール完了判定
- 正確な失敗ポイントの特定と因果仮説の推論
- VLM診断とシンボリックログの融合による共同解釈
- 検出から因果理解への移行を可能に

**フェーズ4：閉ループ自律性**
- 選択的観察とログ誘導再検査による適応的モニタリング
- 複数実行から最も診断的に重要な試行の選択
- 失敗モードに基づく反復的プログラム修復
- 診断-修復サイクルを通じたポリシーの進化

### 2.3 新規性
HyCodePolicyの主要な新規性は以下の点にあります。

- **構造化プログラム合成とシンボリック-知覚的フィードバックの統合**：従来の内省や静的ロジックに依存する手法とは異なり、閉ループ計画と自己修正を実現
- **Bi2Codeインターフェース**：コードトークン長を54%削減し、人間のコードとのAST類似性を21.06%向上
- **ハイブリッドデュアルフィードバック**：シンボリックログとVLM知覚フィードバックを組み合わせることで、より正確な失敗診断と修復を実現

## 3. 実験結果
### 3.1 実験設定
- RoboTwinプラットフォームでの10種類のロボット操作タスク
- 3つの構成の比較：
  - Code as Policies（ワンショット、フィードバックなし）
  - CodeAct（シンボリックフィードバックのみ）
  - HyCodePolicy（完全なハイブリッドフィードバック）
- DeepSeek-V3をプログラム合成に、moonshot-v1-32k-visionをマルチモーダル観察に使用

### 3.2 主要な結果
**Bi2Code効率性**
- コードトークン長：569.4 vs 1236.6（54%削減）
- 人間コードとの構造的類似性：AST類似性が21.06%向上
- デュアルアーム並列処理の実現

**性能改善**
- RoboTwin 1.0：平均成功率（ASR）47.4% → 60.4% → 63.9%
- Bi2Code：ASR 62.1% → 66.7% → 71.3%
- 収束速度：1.76反復 vs 2.42反復

**タスク別分析**
- 空間的に複雑なタスク（ブロック積み上げ、空のカップ配置）で最大の改善
- 決定論的タスク（デュアルボトルピック）では最小限の改善
- 視覚的に複雑な設定でマルチモーダルフィードバックが重要

### 3.3 既存手法との比較
**一般化研究（50タスク）**
- 全タスクスイートでの平均成功率：43.34%
- 構造化配置とスタッキングで強力な性能
- 以下の点で失敗：
  - 非剛体操作
  - 関節動作
  - 時間的シーケンシング
- スキルベース分析で高度な操作の限界を示す（press: 0%、scan: 0%）

## 4. 実用性評価
### 4.1 実装の容易性
HyCodePolicyは、既存のロボットプラットフォームに統合しやすいモジュラー設計を採用しています。Bi2Codeインターフェースは標準化されたAPIを提供し、新しいタスクやロボットへの拡張が容易です。

### 4.2 計算効率
- コード生成の効率化：トークン数を54%削減
- 収束速度の向上：必要な反復回数を約27%削減
- 並列処理：デュアルアーム操作の同時実行による処理時間の短縮

### 4.3 応用可能性
HyCodePolicyは以下の分野で応用可能です。

**産業用ロボット**：組み立てラインでの適応的タスク実行、品質管理での異常検出と自動修正。

**サービスロボット**：家庭環境での物体操作、予期しない状況への適応的対応。

**研究開発**：新しいロボットタスクの迅速なプロトタイピング、人間-ロボット協調作業の改善。

## 5. まとめと所感
### 5.1 論文の意義
この研究は、ロボットが自律的に失敗から学習し、動作を改善する能力を16.5%（RoboTwinプラットフォームで）向上させる重要な成果です。特に、コード合成と知覚的フィードバックを統合することで、より堅牢で適応的なロボットシステムの実現に貢献しています。

HyCodePolicyの最も重要な貢献は、生成されたコードを静的なものではなく、動的に進化可能な仮説として扱う点です。これにより、ロボットは実行時の知覚的フィードバックを活用して、継続的に動作を改善できます。

### 5.2 今後の展望
今後の研究方向として、以下の点が重要になると考えられます。

まず、現在の限界である関節物体操作や変形可能物体のダイナミクスへの対応が必要です。これには、より高度な物理モデルの統合や、触覚フィードバックの活用が有効でしょう。

次に、時間推論能力の強化が重要です。複雑な長期タスクでは、現在の状態だけでなく、過去の状態履歴を考慮した意思決定が必要になります。

また、外部知識源の統合により、ロボットがより広範な状況で動作できるようになる可能性があります。例えば、オンラインデータベースや人間の専門知識を活用することで、未知のタスクへの対応能力が向上するでしょう。

最後に、生涯学習メカニズムの開発により、ロボットが長期的に経験を蓄積し、継続的に性能を向上させることが可能になります。これは、実世界での長期運用において特に重要な要素となるでしょう。