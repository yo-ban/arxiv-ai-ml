# Merge-of-Thought Distillation

## 基本情報
- arXiv ID: 2509.08814 (https://arxiv.org/abs/2509.08814)
- 著者名: Zhanming Shen, Zeyu Qin, Zenan Huang, Hao Chen, 
  Jiaqi Hu, Yihong Zhuang, Guoshan Lu, Gang Chen, Junbo Zhao
- 所属機関: Zhejiang University, Inclusion AI (Ant Group)
- 投稿日: 2025年09月12日
- カテゴリ: cs.LG, cs.AI

## 簡単に説明すると
この論文は、複数の教師モデルから効率的に推論能力を蒸留する
革新的な手法「Merge-of-Thought（MoT）蒸留」を提案しています。

従来の知識蒸留は単一の教師モデルに依存していましたが、
実際には複数の候補教師が存在し、学生や課題によって
最適な教師が異なることが明らかになりました。
MoTは教師固有の教師付き学習と重み空間マージを交互に行い、
複数教師の推論能力を統合して衝突を解決します。

わずか200の高品質思考連鎖サンプルを用いて、
Qwen3-14B学生がDeepSeek-R1やQwen3-32B、OpenAI-O1を上回り、
数学競技ベンチマークで大幅な性能向上を実現しました。

## 1. 研究概要
### 1.1 背景と動機
長い思考連鎖（CoT）推論モデルの効率的蒸留において、
単一の最適教師という従来の前提が実際の状況と乖離していることが問題となっています。
実際には複数の候補教師が利用可能であり、
学生モデルやデータセットによって最適な教師が異なります。

図1の分析により、学生-データセット組み合わせ全体で普遍的な
「最良教師」は存在しないことが明らかになりました。
教師の効果は文脈依存的であり、単純なスケーリング仮定に挑戦しています。

従来の単一教師蒸留手法では、この多様性を活用できず、
複数教師の統合では相反する監視信号の衝突が問題となります。
長いCoTではノイズや冗長なステップが蓄積され、
マルチ教師設定でこれが増幅される課題があります。

### 1.2 主要な貢献
この研究は、複数教師からの知識蒸留における根本的課題を解決し、
実践的で効率的な解決策を提供する重要な貢献をしています。

第一に、「最良教師なし」という重要な洞察を実証的に確立しました。
異なる学生が異なる最良教師を持ち、同じ学生でも
データセット間で最良教師が変動することを示しています。

第二に、MoT（Merge-of-Thought）蒸留框組を開発しました。
教師特化教師付き学習と重み空間マージを交互実行し、
複数教師の推論能力を統合しながら衝突を解決します。

第三に、わずか200サンプルでの大幅性能向上を実現しました。
Qwen3-14B学生がDeepSeek-R1、Qwen3-32B、OpenAI-O1を上回る
競技数学ベンチマークでの成果を達成しています。

第四に、頑健性と汎化性能を実証しました。
分布シフト教師や同等レベル教師に対する耐性、
破滅的忘却の軽減、数学外領域への推論転移を確認しています。

第五に、合意フィルタリング推論の理論基盤を構築しました。
重み空間マージによる合意特徴抽出と
個別の偶発性抑制のメカニズムを明らかにしています。

## 2. 提案手法
### 2.1 手法の概要
MoT蒸留は、2つの基本ステップを交互実行する軽量框組です。

教師特化ブランチ教師付き学習では、現在のマージ済み学生からK個のブランチを初期化し、
各ブランチを教師特化データセットD^(k)で訓練します。
目的関数は教師の推論軌跡に対するトークンレベル交差エントロピーです。

重み空間マージでは、単純なパラメータ平均化を実行します。
θ^(t) = (1/K)∑θ^(t,k) により共有推論特徴を統合し、
教師特化の特異性を平滑化します。

このプロセスをT回反復することで、
合意推論ランドスケープへの段階的収束を実現します。

### 2.2 技術的詳細
教師付き学習目的関数は以下で定式化されます：
L_SFT^(k)(θ) = E_{(x,r^(k),y)~D^(k)} ∑_{t=1}^{L(x,k)} -log p_θ(z_t | x, z_<t)

重みマージは次式で実行されます：
θ^(t) = (1/K) ∑_{k=1}^K θ^(t,k)

データフィルタリングでは、参照解答が利用可能な場合に
正解最終答に到達する教師軌跡のみを保持します。

反復プロセスにより、教師間で強化される合意特徴を抽出し、
個別の偶発性やノイズを抑制する理論的根拠があります。
重みマージが複雑なアンサンブル手法より単純で効果的である点が特徴です。

### 2.3 新規性
この研究の技術的新規性は複数の次元で展開されています。

方法論レベルでは、知識蒸留への重み空間マージの初回適用により、
同一データセット上の異なる教師推論からの学習を可能にしました。
従来のモデルマージが異なるタスクの統合に焦点を当てていたのに対し、
本研究は同一タスクでの多様な推論パス統合を実現しています。

理論的には、「普遍的最良教師なし」の実証により
従来の単一教師最適化パラダイムに挑戦しています。
教師-学生動的関係の新しい理解を提供し、
文脈依存的教師選択の重要性を明らかにしています。

実践的には、極小データ要件（200サンプル）での
大幅性能向上を実現する効率性を示しています。
標準訓練基盤での実装可能性と
既存蒸留パイプラインとの互換性を提供します。

## 3. 実験結果
### 3.1 実験設定
実験は数学競技ベンチマークに焦点を当てて設計されています。

BOBA-200とS1K-200データセットを使用し、
それぞれ200の高品質数学問題を含んでいます。
教師モデルとして、QWEN3-32B、QWQ、DEEPSEEK-R1、QWEN3-235Bを採用し、
学生モデルはQWEN3-8B、QWEN3-14B、QWEN3-30B-A3Bを検証しています。

評価はAIME24/25ベンチマークで実施し、16回実行の平均値を報告しています。
訓練プロトコルは、MoTで5ラウンド×教師コーパス当たり50ステップをマージと交互実行し、
ベースラインとして単一教師蒸留（STD）と複数教師蒸留（MTD）を比較しています。

ハードウェアは8×H800 GPU、実効バッチサイズ64、bfloat16精度で統一しています。

### 3.2 主要な結果
性能実績において、QWEN3-14B + BOBA-200（MoT）は
AIME24で79.38、AIME25で76.88、平均78.13を達成しました。
これはDeepSeek-R1（74.90）、Qwen3-32B（76.77）、OpenAI-O1（76.75）
を上回る強力なベースライン超越を実現しています。

すべての学生モデルスケールで一貫した3-5ポイントの改善を示し、
MoTは最良単一教師選択と単純複数教師統合の両方を
持続的に上回る性能を発揮しています。

訓練動力学において、MoTはより高い性能上限を達成し、
過学習軽減効果も示しています。
MTDの恩恵が学生-教師スケールギャップ縮小とともに減少する一方、
MoTは頑健性を維持しています。

### 3.3 既存手法との比較
分布シフト分析では、DEEPSEEK-R1を分布シフト教師として使用した際、
STD性能はBOBA-200でQWEN3-8Bが-7.50、QWEN3-14Bが-3.65の低下を示しました。
対照的に、MoTはR1を含める場合でも除外する場合より性能が向上し、
分布シフト教師からも有益な推論特徴を抽出できることを証明しています。

同等レベル教師分析では、直観に反して同等パラメータ数のモデルも
効果的教師として機能することが判明しました。
QWQとQWEN3-32BをQWEN3-30B-A3Bの教師とした場合に改善が見られ、
純粋なモデル能力を超えて推論軌跡多様性が重要であることを示しています。

破滅的忘却評価では、9つの一般ベンチマークで評価を実施しました。
MoTは知識敏感タスクでの性能低下が小さく、
推論タスクでは最良STDより大きな向上を示し、
数学外への推論転移優位性を確認しています。

## 4. 実用性評価
### 4.1 実装の容易性
実装容易性は高く、実用的な展開に適しています。

技術要件として、2段階交互プロセスの実装は簡単で、
標準訓練基盤で対応可能です。
ハイパーパラメータは基本設定に対して安定しており、
複雑な調整を必要としません。

既存蒸留パイプラインとの互換性があり、
複雑なアンサンブル手法に比べて単純なパラメータ平均化で済みます。
産業環境での展開準備が整っており、
基本設定選択に対する頑健性を示しています。

### 4.2 計算効率
計算効率は実用的レベルで優秀です。

データ効率において、200の高品質CoTサンプルで大幅向上を実現し、
単純パラメータ平均化により複雑アンサンブル手法を回避しています。
訓練オーバーヘッドは大幅性能改善に対して適度なコストです。

スケール特性として、8B-30Bパラメータ範囲で効果的であり、
異種教師プールからの恩恵を受けます。
標準訓練基盤要件で済み、特殊なハードウェアを必要としません。

### 4.3 応用可能性
応用可能性は広範囲かつ実践的です。

即座適用として、産業推論システムでのスケーラブルアプローチ、
複数源知識転移の研究ツール、
教育分野での複数専門家知識統合が可能です。

拡張適用では、コード生成、科学推論への適用、
理論的理解のための数学的解析、
漸進的教師導入戦略が期待されます。

実証された汎化性において、数学外領域への推論改善、
破滅的忘却軽減による基底モデル能力保持、
合意推論の広範転移可能性を示しています。

## 5. まとめと所感
### 5.1 論文の意義
この研究は、知識蒸留分野における重要な進歩を示しています。

方法論的意義として、単一教師最適化から複数教師合意抽出への
パラダイム転換を実現しました。
知識蒸留への重み空間統合の新規適用により、
教師-学生動的関係の実証的洞察を提供しています。

実践的意義では、最小データ要件と大幅性能向上により
産業応用への実用的ツールを提供しています。
効率的推論モデル開発のスケーラブル経路を示し、
重要な破滅的忘却と汎用推論転移課題に対処しています。

理論的意義として、合意ベース学習の基盤的貢献により、
多源知識転移研究の新分野を開拓しています。

### 5.2 今後の展望
この研究が開拓した領域には多数の発展方向があります。

技術発展として、重み付き、注意ベース、学習ベースマージアプローチ等の
高度マージ戦略開発が期待されます。
最適教師組み合わせの原理的アプローチと
漸進的教師導入戦略の研究が重要です。

応用拡張では、クロスドメイン拡張への適用、
カリキュラム学習、理論理解のための数学的分析が必要です。

この手法は、複数教師からの合意ベース学習の有効性を実証し、
従来の単一教師限界を克服する実用的解決策を提供しました。
最小データ要件と大幅性能向上の組み合わせにより、
より有能な推論システムへのスケーラブル経路を提示しています。
