# Beyond Fixed: Variable-Length Denoising for Diffusion Large Language Models

## 基本情報
- arXiv ID: 2508.00819v1 (https://arxiv.org/abs/2508.00819)
- 著者: Jinsong Li, Xiaoyi Dong, Yuhang Zang, Yuhang Cao, Jiaqi Wang, Dahua Lin
- 所属: The Chinese University of Hong Kong, Shanghai AI Laboratory
- 投稿日: 2025年08月02日
- カテゴリ: cs.CL, cs.LG

## 簡単に説明すると
この論文は、拡散型の大規模言語モデル（Diffusion Large Language Models, DLLMs）における固定長生成の制約を解決する新しい手法「DAEDAL」を提案している。従来のDLLMsは事前に決められた固定長でテキストを生成する必要があり、短すぎると複雑なタスクで性能が低下し、長すぎると計算コストが増大するという問題がありました。DAEDALは、モデル自身が持つ内部信号（特にEnd-of-Sequence（EOS）トークンの予測信頼度）を活用して、タスクに応じて動的に生成長を調整します。これにより、各タスクに最適な長さで効率的にテキスト生成が可能になる。実装コードはGitHubで公開されている（https://github.com/Li-Jinsong/DAEDAL）。

## 1. 研究概要
### 1.1 背景と動機
拡散型の大規模言語モデル（DLLMs）は、従来の自己回帰型（Autoregressive, AR）言語モデルとは異なるアプローチでテキスト生成を行う新しいパラダイムとして注目を集めている。ARモデルが次のトークンを逐次的に予測していくのに対し、DLLMsは完全にマスクされたシーケンスから始めて、複数ステップの反復的なデノイジングプロセスを通じてテキストを生成します。このアプローチには、グローバルなコンテキストを活用できる、並列生成が可能、推論ステップ数と生成品質のトレードオフを柔軟に調整できるなどの利点がある。

しかし、DLLMsには重大な制約がある。それは、生成開始時に出力長を固定する必要があることである。ARモデルがタスクに応じて柔軟に出力長を調整できるのに対し、DLLMsは事前に定められた長さに合わせてタスクの出力を適応させる必要がある。この制約により、以下のようなジレンマが生じる。
- 短すぎる長さでは、複雑な問題を解くのに十分なトークンが確保できない。
- 長すぎる長さでは、双方向アテンションの二次的な計算の複雑性により大きな計算オーバーヘッドが発生する。
- さらに、過度に長い初期長は、モデルの性能を低下させる可能性がある。

### 1.2 主要な貢献
本研究の主要な貢献は以下の通りである。

- 問題の発見と洞察: DLLMsが持つ内部信号、特にEOSトークンの予測信頼度が、現在の生成長が十分かどうかを示す強力な指標として機能することを発見した。
- DAEDALの提案: Dynamic Adaptive Length Expansion for Diffusion LaLsという新しい学習不要のデノイジング戦略を提案した。これにより、固定長の制約を克服できる。
- 二段階アプローチ: 初期長調整（Initial Length Adjustment）と反復的マスク挿入（Iterative Mask Insertion）という2つの相補的なメカニズムを組み合わせた。
- 実験的検証: 4つのベンチマーク（GSM8K、MATH500、MBPP、HumanEval）で、DAEDALが慎重に調整された固定長ベースラインと同等またはそれ以上の性能を達成することを実証した。
- 計算効率の向上: 高い有効トークン比を実現し、計算リソースの利用効率を約3倍改善した。

## 2. 提案手法
### 2.1 手法の概要
DAEDALは、DLLMsの固定長制約を解決するために設計された、学習不要の二段階戦略である。この手法により、モデルは各タスクに適したシーケンス長を割り当て、必要に応じて推論のための追加スペースを挿入できるようになる。

第一段階の「初期長調整」では、短い初期長から始めて、シーケンス完了メトリック（EOSトークンの予測信頼度）に基づいて、タスクに適した大まかな長さまで反復的に拡張する。第二段階の「反復的マスク挿入」では、デノイジングプロセス中に動的にシーケンスを拡張し、より良い出力を生成する。これは、モデルが計画を立てるのに苦労し、対応する予測信頼度が非常に低い不十分な領域にマスクトークンを挿入することで実現される。

### 2.2 技術的詳細
初期長調整（Stage 1）について説明する。
このステージの核心的な洞察は、シーケンス末尾でのEOSトークン生成に対するモデルの信頼度が、現在のトークン長が十分かどうかの内部信号として解釈できるということである。具体的なアルゴリズムは以下の通りである。

1. 短い初期生成長（例：64トークン）から開始。
2. 各推定反復で、現在のシーケンス（プロンプト + [MASK]トークン）に対してフォワードパスを実行。
3. シーケンス末尾のウィンドウ（デフォルト：32トークン）におけるEOSトークンの平均的な予測信頼度を計算。
4. この信頼度が閾値τ_eos（デフォルト：0.1）を下回る場合、「長さ不足」と判断。
5. 追加の[MASK]トークンをシーケンス末尾に追加（拡張因子E_factor、デフォルト：16）。
6. EOS信頼度が閾値を超えるか、最大長に達するまで繰り返し。

反復的マスク挿入（Stage 2）について説明する。
このステージでは、デノイジングプロセス中にシーケンスを動的に拡張する。

1. 各デノイジングステップで、高信頼度（τ_high = 0.6以上）のトークンを特定して埋める。
2. 同時に、非常に低い信頼度（τ_low = 0.1未満）を持つマスク位置を特定。
3. 最も低い予測信頼度を持つ位置を「拡張ポイント」としてマーク。
4. この位置の単一の[MASK]トークンを複数の[MASK]トークンのブロックで置き換え。
5. これにより、複雑な推論や詳細な記述が必要な場所に「呼吸空間」を提供。

### 2.3 新規性
既存手法との主な違いは以下の通りである。

- 動的長さ調整: 従来のDLLM推論戦略（Fast-dLLM、dLLM-Cache、Dimpleなど）は計算の高速化に焦点を当てていたが、生成長自体を動的に調整する問題には取り組んでいなかった。
- 内部信号の活用: モデル自身の予測信頼度を、長さの十分性を判断する汎用的な信号として利用する新しいアプローチである。
- 二段階の相補的メカニズム: グローバルな長さ調整（Stage 1）とローカルな拡張（Stage 2）を組み合わせることで、柔軟性と効率性を両立している。
- 学習不要: 追加の学習やファインチューニングを必要とせず、既存のDLLMに直接適用可能である。

## 3. 実験結果
### 3.1 実験設定
実験では、LLaDA-Instruct-8BとLLaDA-1.5-8Bをベースラインモデルとして使用しました。評価は以下の4つのベンチマークで行いました：

- **数学的推論**: GSM8K（小学校レベルの数学文章題）、MATH500（競技レベルの数学問題）
- **コード生成**: MBPP（エントリーレベルのPythonタスク）、HumanEval（手書きのプログラム合成タスク）

評価指標として、精度（Accuracy）、総トークン数（N_token）、有効トークン数（E_token、末尾のEOSパディングを除いた実際の応答長）、有効トークン比（E_ratio = E_token / N_token）を使用しました。

### 3.2 主要な結果
LLaDA-Instruct-8Bでの結果：
- GSM8K: 85.8%（ベースライン最高83.8%、初期長64での比較: 48.0% vs 85.8%）
- MATH500: 44.2%（ベースライン最高39.6%）
- MBPP: 40.8%（ベースライン最高38.8%）
- HumanEval: 48.2%（ベースライン最高46.3%）

平均精度は54.75%で、ベースラインの最高値51.73%を上回りました。特に注目すべきは、DAEDALが短い初期長（64トークン）から始めても、ベースラインが最適な長さで達成する性能を上回ることです。

### 3.3 既存手法との比較
固定長デノイジングベースラインとの比較において、DAEDALは以下の優位性を示しました：

- **性能**: 全てのベンチマークで、慎重に調整された固定長ベースラインの最高性能と同等またはそれ以上の精度を達成
- **効率性**: 同等の有効トークン数で、より少ない総トークン数を使用（例：GSM8Kで363 vs 1024トークン）
- **有効トークン比**: 大幅に高い比率を達成（GSM8Kで73.5% vs 27.7%）
- **汎用性**: 単一の初期長設定で、異なるタスクに対して自動的に適応

アブレーション研究では、DAEDALの二つのステージが個別でも効果的であり、組み合わせることで相乗効果が得られることが示されました。また、初期長、拡張因子、EOSウィンドウサイズ、各種閾値に対して高いロバスト性を持つことが確認されました。

## 4. 実用性評価
### 4.1 実装の容易性
DAEDALは学習不要の手法であり、既存のDLLMに対して推論時の変更のみで適用可能です。実装に必要な主な要素は：

- EOSトークンの予測信頼度を計算する関数
- シーケンスに[MASK]トークンを追加する機能
- 既存のデノイジングループへの条件分岐の追加

公開されているコード（https://github.com/Li-Jinsong/DAEDAL）により、研究者や開発者は容易に手法を再現・適用できます。

### 4.2 計算効率
DAEDALは計算効率の面で大きな利点を提供します。

- 動的リソース割り当て: 簡単なタスクには短い長さ、複雑なタスクには長い長さを自動的に割り当て
- 無駄の削減: 不要なパディングトークンの生成を避け、有効トークン比を約2.6倍向上
- 二次複雑性の緩和: 双方向アテンションの計算コストを、必要最小限の長さに抑制

実験結果では、同等の性能を達成しながら、総トークン数を約37%削減できることが示されました（例：HumanEvalで813 vs 512トークン）。

### 4.3 応用可能性
DAEDALの応用可能性は以下の点で高く評価されます。

- タスク非依存: 数学的推論からコード生成まで、幅広いタスクで有効性を実証
- モデル非依存: LLaDA-InstructとLLaDA-1.5の両方で同様の改善を達成
- パラメータロバスト性: 広範なハイパーパラメータ設定で安定した性能
- 実用的価値: ユーザーがタスクごとに最適な長さを手動で調整する必要がなくなる

今後の応用として、他のDLLMアーキテクチャへの適用、マルチモーダルタスクへの拡張、さらなる効率化手法との組み合わせなどが考えられます。

## 5. まとめと所感
### 5.1 論文の意義
この研究は、拡散型大規模言語モデルの実用化における重要な障壁の一つを取り除く画期的な成果です。固定長生成という根本的な制約に対して、モデル自身の内部信号を活用するというエレガントな解決策を提示しています。

技術的な貢献として特に評価できるのは、問題の本質的な理解に基づいたアプローチです。EOSトークンの予測信頼度が長さの十分性を示すという洞察は、モデルの内部動作に対する深い理解から生まれたものであり、この発見自体が将来の研究に重要な示唆を与えます。

実用面では、学習不要でありながら大幅な性能向上を達成している点が特筆されます。これにより、既存のDLLMユーザーは追加の計算コストなしに、即座にDAEDALの恩恵を受けることができます。

### 5.2 今後の展望
本研究は多くの可能性を開きますが、同時にいくつかの課題や改善の余地も残されています。

技術的発展の方向性について、以下の点が挙げられます。
- より洗練された長さ予測メカニズムの開発（例：タスクの複雑性を事前に推定）
- 多段階の拡張戦略（現在の二段階から、より細かい制御へ）
- 他の内部信号の活用（アテンションパターン、中間層の活性化など）

応用領域の拡大について、以下の点が考えられます。
- 対話システムへの適用（会話の文脈に応じた動的な応答長調整）
- 多言語・多モーダルタスクへの拡張
- リアルタイムアプリケーションでの最適化

理論的な探求について、以下の点が重要です。
- なぜEOS信頼度が長さの十分性を示すのかの理論的解明
- 最適な拡張戦略の数学的定式化
- 他のデノイジング戦略との統合可能性

この研究は、拡散型言語モデルと自己回帰型言語モデルの間の重要な能力ギャップを埋める一歩となり、より柔軟で効率的な非自己回帰型言語生成への道を開いています。