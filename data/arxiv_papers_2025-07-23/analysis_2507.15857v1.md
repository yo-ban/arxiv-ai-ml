# Diffusion Beats Autoregressive in Data-Constrained Settings

## 基本情報
- arXiv ID: 2507.15857v1 (https://arxiv.org/abs/2507.15857)
- 著者: Mihir Prabhudesai, Menging Wu, Amir Zadeh, Katerina Fragkiadaki, Deepak Pathak
- 所属: Carnegie Mellon University, Lambda
- 投稿日: 2025年07月22日
- カテゴリ: cs.LG, cs.AI

## 簡単に説明すると
この論文は、データが限られている状況（データ制約環境）において、拡散モデルが従来の自己回帰（AR）モデルよりも優れた性能を発揮することを実証した研究です。従来、言語モデルの学習では各データを1回だけ使用する（1エポック）のが一般的でしたが、高品質なデータの枯渇が予想される中、限られたデータを繰り返し使用する必要性が高まっています。本研究では、200個のモデル（拡散モデル100個、ARモデル100個）を様々な条件で学習させ、データを繰り返し使用する環境では拡散モデルがARモデルを著しく上回ることを示しました。プロジェクトのウェブサイトとコードは https://diffusion-scaling.github.io で公開されています。

## 1. 研究概要
### 1.1 背景と動機
大規模言語モデル（LLM）の成功は、計算資源とデータの両方をスケールアップすることで達成されてきました。しかし、計算資源が着実に増加している一方で、高品質なデータの成長は停滞しています。Villalobosらの予測によると、公開されている人間が生成したデータは2028年までに枯渇する可能性があり、これが今後のスケーリングの深刻なボトルネックとなることが懸念されています。

さらに、ロボティクスや医療などの分野では、データが最初から希少な資源である場合も多く、データ効率の良いモデリング戦略の開発が急務となっています。従来のLLM開発では自己回帰（AR）モデルが主流でしたが、これは固定された左から右への順序でテキストの同時分布を因数分解する手法です。最近では、ランダムな順序で因数分解するマスク拡散モデルが代替手法として登場していますが、その実用的な利点はまだ十分に解明されていませんでした。

### 1.2 主要な貢献
この研究の主要な貢献は以下の5点にまとめられます。
- 十分な計算資源がある場合、拡散モデルがARモデルを上回ることを実証
- 拡散モデルがデータの繰り返し使用から遥かに多くの利益を得ることを発見（最大100エポックまで効果的）
- 拡散モデルの有効エポック数（R_D*）が約500であることを示し、ARモデルの約15に比べて33倍以上高いことを発見
- 拡散モデルがARモデルを上回るために必要な計算量（臨界計算点）がデータセットサイズのべき乗則に従うことを発見
- 拡散モデルの優位性が下流タスクのパフォーマンスにも反映されることを実証

## 2. 提案手法
### 2.1 手法の概要
本研究では、ARモデルと拡散モデルの根本的な違いは、シーケンスの同時分布の因数分解方法にあると捉えています。ARモデルは固定された左から右への順序で因数分解するのに対し、マスク拡散モデルはランダムな順序で因数分解します。この違いを純粋に評価するため、アーキテクチャやデータパイプラインは両モデルで統一し、因数分解方法のみを変えて比較実験を行いました。

両モデルとも、GPT-2スタイルのTransformerバックボーンにRotary Positional Embeddings（RoPE）を組み込んだアーキテクチャを使用しました。パラメータ範囲は7Mから2Bで、同一のハイパーパラメータを用いて学習しました。

### 2.2 技術的詳細
ARモデルは因果的注意マスクを使用して、各トークンをその前のトークンのみに基づいて予測します。損失関数は次トークン予測のクロスエントロピー損失となります。

一方、マスク拡散モデルでは、まずマスキング率を一様分布U(0,1)からサンプリングします。各トークンを確率的に[MASK]トークンに置き換えます。そして、完全な双方向注意を使ってマスクされた位置のトークンを予測します。この手法により、モデルは学習中に膨大な種類のトークン順序付けタスクに露出されます。ARモデルの固定された左から右への順序付けは、この集合の中の1つの順序に過ぎません。

### 2.3 新規性
本研究の新規性は、データ制約環境における拡散モデルとARモデルの系統的な比較にあります。従来の研究では、各トークンを1回だけ見る単一エポック環境での比較が主流でしたが、本研究では明示的にモデルのスケーリングとデータの再利用を分離し、計算効率とデータ効率の影響を切り分けました。

また、拡散モデルがデータを繰り返し使用する際に、ARモデルとは質的に異なる振る舞いを示すことを発見しました。具体的には、拡散モデルはランダムマスキングによる暗黙的なデータ拡張効果により、同じデータから より多くの学習信号を抽出できることが明らかになりました。

## 3. 実験結果
### 3.1 実験設定
実験では、25M、50M、100Mトークンの3つのユニークデータレジームで、幅広い学習計算予算にわたってARモデルと拡散モデルの大規模なスイートを学習させました。モデルサイズは7Mから2Bパラメータまで変化させ、エポック数も1から数百まで変化させて、合計200個のモデルを学習しました。

評価には検証損失を主要指標として使用しました。さらに下流タスクとして、HellaSwag、PIQA、WinoGrande、ARC-Easy、ARC-Challenge、COPA、BoolQの7つのベンチマークでゼロショット性能を評価しました。

### 3.2 主要な結果
実験結果から、ARモデルは最初に拡散モデルよりも優れた性能を示しました。しかし、この優位性は計算量が増えるにつれて消失することが明らかになりました。Chinchillaスケーリング則で規定される計算最適予算において、ARモデルが優位ですが、それを超えて学習を続けると、拡散モデルが一貫してARモデルを上回りました。

特に注目すべき結果として、100Mトークンレジームでは、拡散モデルが500エポックで最良の損失を達成したのに対し、ARモデルは50エポックで最良となりました。ARモデルは高エポック数でオーバーフィッティングを示し始めましたが、拡散モデルは実験した計算予算内ではオーバーフィッティングの兆候を示しませんでした。

### 3.3 既存手法との比較
単一エポック環境では、拡散モデルの検証損失は10.65でARモデルの7.07よりも約50%高い結果となりました。これは先行研究の知見と一致しています。しかし、数百エポックまで学習を延長すると、拡散モデルは継続的に改善しました。最終的に3.55の検証損失を達成し、ARモデルの最良値3.71を上回りました。

これは拡散モデルが67%の損失削減を達成したことを意味し、ARモデルの48%と比較して、繰り返しデータを活用する優れた能力を示しています。また、下流タスクのパフォーマンスでも、拡散モデルは7つのベンチマークのうち5つでARモデルを上回る結果を示しました。

## 4. 実用性評価
### 4.1 実装の容易性
実装面では、拡散モデルはARモデルと同じTransformerアーキテクチャを使用するため、既存のインフラストラクチャを大きく変更することなく導入できます。主な違いは、因果的注意マスクの代わりに完全な双方向注意を使用し、学習時にランダムマスキングを適用する点です。

ただし、推論時には拡散モデルは反復的なデノイジングプロセスを必要とするため、ARモデルの単一パスでの生成と比較して複雑性が増します。この点は実用化において考慮すべき要素となります。

### 4.2 計算効率
計算効率の観点では、拡散モデルは短期的にはARモデルよりも非効率です。本研究の分析によると、拡散モデルがARモデルを上回るためには、データセットサイズに応じた臨界計算点を超える必要があります。この臨界点は、ユニークトークン数Dに対してC_critical ∝ D^αというべき乗則に従うことが示されました。

しかし、データが制限されている環境では、この追加の計算コストは、より良い最終性能を達成するための価値ある投資となります。特に、高品質なデータの取得コストが計算コストよりも高い場合には、拡散モデルの選択が経済的に合理的となる可能性があります。

### 4.3 応用可能性
本研究の知見は、言語モデリングを超えて、ロボティクス、医療、科学研究など、データが希少な領域での序列モデリングタスクに広く適用できる可能性があります。特に、専門的なドメインでは高品質なデータの収集が困難かつ高価であるため、限られたデータから最大限の価値を引き出せる拡散モデルのアプローチは魅力的です。

また、本研究で示されたスケーリング則は、実務者が自身のデータセットサイズと利用可能な計算資源に基づいて、ARモデルと拡散モデルのどちらを選択すべきかを定量的に判断するための指針を提供します。

## 5. まとめと所感
### 5.1 論文の意義
この論文は、データ制約環境における生成モデルの選択に関する従来の常識を覆す重要な発見を提示しています。ARモデルが普遍的に優れているという信念に挑戦し、データが主要なボトルネックである場合には拡散モデルが魅力的な代替手段となることを実証しました。

特に重要な洞察は、拡散モデルの利点がランダムマスキングによる暗黙的なデータ拡張から生じているという仮説です。これは、コンピュータビジョンで長年使用されてきたデータ拡張技術の言語モデリングへの自然な拡張と見ることができます。理論的、実践的の両面で説得力があります。

### 5.2 今後の展望
著者らは、実務者への簡潔なアドバイスとして「計算資源が制約されている場合はARモデルを、データが制約されている場合は拡散モデルを使用すべき」と述べています。しかし、将来的にはこの二者択一ではなく、両アプローチの利点を組み合わせたハイブリッドモデルの開発が期待されます。

また、本研究のスケーリング則は限られたデータサイズ範囲でフィッティングされているため、より大規模なレジームへの拡張により、予測精度の向上とさらなる洞察を得られる可能性があります。高品質データの枯渇が現実のものとなりつつある今、限られたデータを最大限活用することは、深層学習のスケーリングにおける次のフロンティアを定義する可能性があります。