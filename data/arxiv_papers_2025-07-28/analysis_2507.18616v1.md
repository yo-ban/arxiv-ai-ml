# SynC: Synthetic Image Caption Dataset Refinement with One-to-many Mapping for Zero-shot Image Captioning

## 基本情報
- arXiv ID: 2507.18616 (https://arxiv.org/abs/2507.18616)
- 著者: Si-Woo Kim, MinJu Jeon, Ye-Chan Kim他
- 所属: Hanyang University, AI R&D Division CJ Group
- 投稿日: 2025年07月26日
- カテゴリ: cs.CV, cs.CL

## 簡単に説明すると
この論文は、ゼロショット画像キャプション生成（Zero-shot Image Captioning: ZIC）のための合成データセットの品質を向上させる手法「SynC」を提案しています。
テキストから画像を生成するモデル（T2I）で作成された合成データセットでは、生成された画像がキャプションの内容を正確に反映していない問題があります。
SynCは、既存の合成画像プールから各キャプションに最も適した画像を再割り当てすることで、この問題を解決します。
実験では、MS-COCO、Flickr30k、NoCapsなどのベンチマークで大幅な性能向上を実現しています。

## 1. 研究概要
### 1.1 背景と動機
ゼロショット画像キャプション生成は、推論時に見たことのない画像に対してキャプションを生成するタスクです。
最近の研究では、大規模な合成データセットを使用してZICモデルを訓練することが有効とされています。
しかし、T2Iモデルで生成された合成画像は、しばしばキャプションの内容を正確に反映していません。
例えば、「オレンジ色のジャケットを着た男性」というキャプションに対して、男性はいるもののジャケットは生成されない画像となることがあります。
この意味的な不整合は、ZICモデルの性能を制限する要因となっています。

### 1.2 主要な貢献
- 合成データセット特有のノイズパターン（キャプションは高品質だが画像が不整合）を明確化
- One-to-many mapping戦略による高速な画像-キャプション再割り当て手法の提案
- 複数のZICモデルとベンチマークでの一貫した性能向上の実証
- 既存のデータフィルタリング手法との相補的な効果の確認
- 2.3GPU時間で542,401ペアを処理できる高速アプローチ

## 2. 提案手法
### 2.1 手法の概要
SynCは、合成データセットD_SynthImgCapの品質を向上させるフレームワークです。
各キャプションに対して、データセット全体から最も意味的に整合した画像を見つけて再割り当てします。
この過程で、整合性の低いペアはフィルタリングされます。

### 2.2 技術的詳細
One-to-many Mapping戦略（S_one-to-many）の処理手順は以下のとおりです。
1. 各キャプションに対して、text-to-image検索を使用してK個の候補画像を取得
2. Vision-Languageモデル（SigLIP2など）のエンコーダを使用して画像とテキストの埋め込みを計算
3. コサイン類似度に基づいて上位K個の画像を選択

Retrieval-based Multi-modal Scorer関数（f_ret）の処理手順は以下のとおりです。
1. 各候補画像に対してimage-to-text検索する
2. 検索されたキャプション集合と元のキャプションの意味的類似度を計算
3. Sentence Transformerを使用してテキスト空間での類似度を評価
4. 最も高いスコアを持つ画像を選択

フィルタリングプロセスでは、以下の処理を行います。
- 全ペアをスコアでソートし、下位α%（例：50%）を除去
- 残ったペアで新しいデータセットD_SynCを構成

### 2.3 新規性
- 合成データセットのノイズパターンに特化した初のアプローチ
- 新しい画像を生成せずに既存の画像を再利用する省計算コストな方法
- dual cross-modal retrievalによる堅牢な意味的な整合性評価
- 既存のフィルタリング手法と相補的に機能する設計

## 3. 実験結果
### 3.1 実験設定
データセットには以下を使用しました。
- 合成データ：D_SynthImgCap（542,401ペア、CITSIで生成）
- 評価データ：MS-COCO、Flickr30k、NoCaps（in-domain、near-domain、out-of-domain）

**ベースラインモデル：** PCM-Net（最新のZICモデル）
**評価指標：** BLEU@4、METEOR、ROUGE-L、CIDEr、SPICE

### 3.2 主要な結果
In-domainパフォーマンス（MS-COCO）の結果は以下のとおりです。
- ViT-B/32：CIDEr 76.9 → 85.1（+8.2向上）
- ViT-L/14：CIDEr 84.0 → 90.2（+6.2向上）

Cross-domainパフォーマンス（Flickr30k）の結果は以下のとおりです。
- ViT-B/32：CIDEr 47.2 → 51.7（+4.5向上）
- ViT-L/14：CIDEr 50.4 → 56.6（+6.2向上）

他のZICモデルへの適用結果は以下のとおりです。
- CapDec、ViECap、IFCapでも一貫した改善を確認
- 全てのモデルで5-10%のCIDEr向上

### 3.3 既存手法との比較
Webデータフィルタリング手法との比較結果は以下のとおりです。
- VeCLIP、LaCLIP、Sieve、CLIPScoreを上回る性能
- 合成データ特有のノイズパターンへの対応が優位性の要因

計算効率の比較結果は以下のとおりです。
- 処理時間：2.3GPU時間（542,401ペア）
- 他の手法（LaCLIP：6.4時間、VeCLIP：6.3時間）より高速

組み合わせ効果として、既存手法と組み合わせることで追加の性能向上を実現しました。

## 4. 実用性評価
### 4.1 実装の容易性
既存のVision-Languageモデルとテキスト埋め込みモデルを使用するため、実装は比較的簡単です。
特別なモデルの訓練は不要で、事前学習済みモデルをそのまま使用できます。

### 4.2 計算効率
54万ペアの処理を2.3GPU時間で完了できる高速性を実現しています。
新しい画像生成が不要なため、T2Iモデルの推論コストを削減できます。

### 4.3 応用可能性
- 他のZICモデルへの適用が容易
- より大規模な合成データセットへのスケーラビリティ
- 他のVision-Languageタスク（VQA、画像検索など）への拡張可能性
- 異なるT2Iモデルで生成されたデータセットへの適用

## 5. まとめと所感
### 5.1 論文の意義
この研究は、合成データセットの品質問題に対する実用的で効果的な解決策を提供しています。
特に、合成データ特有のノイズパターンを明確にし、それに特化したアプローチを開発した点が重要です。
SynCは、ゼロショット画像キャプション生成の性能を8%以上向上させるだけでなく、計算効率も優れており、実用性が高い手法です。

### 5.2 今後の展望
- より大規模な合成データセット（数千万ペア）への適用
- 他のVision-Languageタスク（セグメンテーション、VQAなど）への拡張
- 異なるT2Iモデル（Stable Diffusion、DALLEなど）で生成されたデータへの適用
- 動的なフィルタリング比率の最適化手法の開発
- マルチモーダル大規模言語モデルへの応用

SynCは、合成データの活用において重要なブレークスルーとなる可能性があり、今後のVision-Language研究に大きな影響を与えることが期待されます。