# RefTok: Reference-based Tokenization for Efficient Video Generation

## 基本情報
- arXiv ID: 2507.02862v1 (https://arxiv.org/abs/2507.02862)
- 著者: Kilian Ahmed他8名（Carnegie Mellon University、ByteDance Inc.）
- 所属: Carnegie Mellon University, ByteDance Inc.
- 投稿日: 2025年07月03日
- カテゴリ: cs.CV, cs.AI, cs.LG

## 簡単に説明すると
RefTokは、ビデオ生成において参照フレームを活用する新しいトークナイゼーション（符号化）手法です。従来の手法がビデオの各フレームを独立に圧縮するのに対し、RefTokは前のフレーム（参照フレーム）の情報を活用して後続フレームを効率的に圧縮します。これにより、同じ圧縮率でも従来手法より36.7%高い品質でビデオを再構成できます。特にテキストや人の顔、細かいパターンなどの再現性が36.7%向上し、処理速度も2.29倍高速化されています。

## 1. 研究概要
### 1.1 背景と動機
ビデオ生成技術の発展において、高品質なビデオトークナイゼーション（ビデオを離散的なトークンに変換する技術）は重要な基盤技術です。しかし、従来のVQGANベースの手法は各フレームを独立に処理するため、ビデオの時間的な冗長性（連続するフレーム間の類似性）を活用できていませんでした。

特に高圧縮率（1024:1など）では、テキストが読めなくなったり、顔が歪んだり、細かいパターンが失われるという問題がありました。一方で、ビデオには隣接フレーム間で多くの情報が共有されているという特性があります。この時間的冗長性を活用すれば、従来より高品質で高速な圧縮が可能になります。

### 1.2 主要な貢献
- 参照フレームベースの新しいビデオトークナイゼーション手法RefTokの提案
- 参照フレームの情報を量子化層をバイパスさせて保持する新しいアーキテクチャ
- 従来手法と比較して36.7%の再構成品質の向上を達成
- 処理速度を2.29倍、メモリ効率を2.38倍改善
- 簡易なゼロショットビデオ編集機能の実現

## 2. 提案手法
### 2.1 手法の概要
RefTokの核心的なアイデアは、参照フレームとターゲットフレームを異なる方法で処理することです。具体的には次のような手順になります。
1. 参照フレームの特徴表現は量子化（離散化）せずに連続的な表現のまま保持
2. ターゲットフレームは参照フレームとの差分情報のみを量子化
3. デコーダーは量子化されたターゲット情報と連続的な参照情報を組み合わせて再構成

この設計により、参照フレームの詳細な情報を保持しながら、ターゲットフレームは差分情報のみを符号化すればよいため、高圧縮率でも高品質な再構成が可能になります。

### 2.2 技術的詳細
アーキテクチャの主要コンポーネントは以下のとおりです。
- エンコーダー：ViTMAEベースのTransformerアーキテクチャを3Dに拡張
- パッチ化：ビデオを4×16×16のcuboidに分割
- 量子化戦略：
  - 参照フレーム：エンコーダー出力h_rを量子化せずに保持
  - ターゲットフレーム：h_tをVQ-VAEで離散コードz_tに変換
- デコーダー：z_tとh_rを条件として受け取り、ターゲットフレームを再構成
- 因果性の保証：attention maskにより、参照→ターゲットの一方向の情報流のみを許可

Reference posterior collapseを防ぐための工夫として、次の手法を採用しています。
- フレーム間隔を広げて学習（類似度が高すぎる隣接フレームを避ける）
- Codebook splittingによる初期学習の安定化

### 2.3 新規性
- 時間的相関の活用：従来の独立フレーム処理から、参照ベースの条件付き処理へ
- ハイブリッド表現：連続表現（参照）と離散表現（ターゲット）の組み合わせ
- アーキテクチャ：CNNベースではなくTransformerベースを採用し、長距離の依存関係をモデル化
- 編集機能：参照フレームの編集により簡易なビデオ編集が可能

## 3. 実験結果
### 3.1 実験設定
- データセット：BAIR Robot Pushing、Kinetics-600、UCF-101、DAVIS
- 評価指標：再構成品質（PSNR、SSIM、LPIPS）、生成品質（FVD）、効率性（処理速度、メモリ使用量）
- ベースライン：MAGVIT、Cosmos、CogVideoX、VideoGPT、OmniTokenizer

### 3.2 主要な結果
再構成品質（圧縮率1024:1）について、以下の改善を達成しました。
- PSNR：平均34%向上
- SSIM：平均14%向上  
- LPIPS：平均62%改善

具体的な改善例は次のとおりです。
- BAIR：PSNR 24.1→28.8、SSIM 0.834→0.950
- UCF-101：PSNR 22.0→41.4、SSIM 0.701→0.942

処理の効率性については、以下の結果が得られました。
- Cosmosと比較：3.12倍高速、2.87倍メモリ効率的
- MAGVITと比較：1.46倍高速、1.89倍メモリ効率的

### 3.3 既存手法との比較
定性的評価では、次のような改善が確認されました。
- テキスト：Cosmosでは判読不能だった文字がRefTokでは明瞭に再現
- 顔：不気味の谷現象を回避し、自然な顔の再構成を実現
- 細部：ドル紙幣の顔、遠くのビルのドア、フラフープの斜めパターンなども正確に再現

生成モデルでの性能については、以下の結果を示しています。
- BAIR datasetでの生成タスク：FVD 62→57（8%改善）
- MAGVIT-L（4倍のパラメータ数）を上回る性能

## 4. 実用性評価
### 4.1 実装の容易性
- ViTMAEベースの標準的なアーキテクチャを採用
- 既存の生成モデル（MaskGITなど）との互換性が高い
- 特殊なハードウェア要件なし

### 4.2 計算効率
- 推論速度：従来手法の2-3倍高速
- メモリ効率：約2倍改善
- 純粋なTransformerアーキテクチャによる並列化の恩恵
- マルチスケールのCNN downsampling不要

### 4.3 応用可能性
- ビデオ生成：高品質な動画生成モデルの基盤技術として
- ビデオ圧縮：高圧縮率と高品質を両立するビデオコーデックとしての応用
- ビデオ編集：参照フレーム編集による簡易編集機能
- リアルタイム処理：高速処理によりストリーミング応用も視野に

## 5. まとめと所感
### 5.1 論文の意義
RefTokは、ビデオトークナイゼーションにおける重要な技術的転換を提案しています。時間的冗長性を活用するという自然なアイデアを、参照フレームのバイパスという巧妙な方法で実現し、品質と効率の両立を達成しました。

特に印象的なのは、シンプルなアイデアでありながら大幅な性能向上を実現している点です。複雑な3D畳み込みや階層的構造を使わず、純粋なTransformerアーキテクチャで高性能を達成したことは、今後のビデオ処理研究に大きな影響を与えるでしょう。

### 5.2 今後の展望
改善の余地がある点は以下のとおりです。
- 適応的な参照フレーム選択（現在は固定的に最初のフレームを使用）
- より長いビデオへの対応（参照フレームの更新戦略）
- 参照フレームに存在しない新規オブジェクトへの対応

今後の発展の可能性として、次のような方向性が考えられます。
- マルチモーダル拡張（音声との同期など）
- より高度な編集機能（オブジェクト単位の編集など）
- リアルタイムビデオ配信への応用
- 他のビデオ理解タスクへの転用

この研究は、効率的で高品質なビデオ処理の新たな方向性を示しており、今後のビデオAI技術の発展に大きく貢献することが期待されます。