# Generalizable Geometric Image Caption Synthesis

## 基本情報
- arXiv ID: 2509.15217v1 (https://arxiv.org/abs/2509.15217v1)
- 著者: Yue Xin、Wenyuan Wang、Rui Pan、Ruida Wang、Howard Meng、Renjie Pi、Shizhe Diao、Tong Zhang
- 所属: University of Illinois Urbana-Champaign、Shanghai Jiao Tong University、Rutgers University、NVIDIA
- 投稿日: 2025年09月22日
- カテゴリ: cs.CV, cs.AI

## 簡単に説明すると

この論文は、幾何学画像のキャプション生成における革新的な研究です。従来の手法では、幾何図形の視覚情報とテキスト情報が十分に一致しないという根本的な問題がありました。例えば、「AB = AC」という情報はテキストでは記述されていても、画像からは直接観察できないことがありました。

本研究では、この問題を解決するために、「Geo-Image-Textualization」という新しいフレームワークを提案しています。この手法では、幾何図形に特別な視覚記号を追加します。具体的には、等しい線分には直交マーク、等しい角には弧マークなどを用いて、視覚情報とテキスト情報を高度に一致させます。

さらに、RLVR（Reinforcement Learning with Verifiable Rewards）を用いたデータ精製プロセスで、キャプションの品質を反復的に改善します。結果として、GeoReasoning-10Kという高品質なデータセット（10,000の画像-キャプションペア）を構築しました。

実験結果では、MathVistaやMathVerseなどの数学的推論ベンチマークで性能向上を示しました。さらに非幾何学的なタスク（算術、統計、代数）やMMMUの芸術・デザイン、技術・工学領域でも改善が確認されました。具体的には2.4-4.8%の性能向上を実現しています。

本研究の主要なリソースとして、プロジェクトページ、データセット、コードが公開されています。具体的には、Project Page、Dataset、Codeが利用可能です。それぞれのURLは以下の通りです。Project Page: https://machinephoenix.github.io/GeoReasoning_blog/、Dataset: https://huggingface.co/datasets/ScaleMath/GeoReasoning、Code: https://github.com/MachinePhoenix/GeoReasoning

## 1. 研究概要

### 1.1 背景と動機

マルチモーダル大規模言語モデル（MLLMs）は、視覚質問応答、視覚グラウンディング、画像キャプションなど、様々な視覚関連タスクで顕著な成果を示しています。Qwen2.5-VL、Intern2.5-VL、LLaVA-Nextなどの最新のMLLMsは、特化された視覚モデルを上回る性能を示し、統一マルチモーダルアーキテクチャの可能性を浮き彫りにしています。

しかし、数学的推論において、MLLMsは重大な課題を抱えています。MathVerseの研究によると、MLLMsは純粋なテキスト入力で優秀な性能を発揮する一方、視覚のみの入力では性能が著しく低下します。このことは、MLLMsにおいて強力なクロスモーダル推論能力の開発が必要であることを示しています。

既存の幾何・数学データセットは数多く提案されていますが、クロスモーダル推論を明示的に意図した高品質データセットは依然として不足しています。この課題の主要因は、画像とキャプションの間のアライメントが非対称であることです。例えば、幾何問題では、等長の2本の線はテキストで簡単に記述できます。しかし画像上では、等長関係を示す注釈や視覚的な明確な区別がされない場合も多く見られます。

### 1.2 主要な貢献

本研究の主要な貢献は以下の通りです。

- GeoReasoning-10Kデータセットの提案: 視覚情報とテキスト情報が高度に等価な10,000の幾何画像-キャプションペアを持つ新しいデータセットである。このデータセットはクロスモーダル推論モデルの訓練に適した高品質リソースとして機能する。

- Geo-Image-Textualizationフレームワークの開発: 幾何学領域で高品質な合成画像-キャプションペアを生成・精製するためのスケーラブルRLベースフレームワークである。反復的なRL主導最適化がデータアライメントと意味的精度を顕著に向上させ、ドメイン外幾何タスクへの汎化を実証している。

- 幅広い汎化能力の実証: 広範囲な実験により、GeoReasoningによる改善が幾何タスクを超えて非幾何数学タスク、さらには芸術や工学などの非数学領域にまで及ぶことが示された。

## 2. 提案手法

### 2.1 手法の概要

提案手法は、主に3つの主要コンポーネントから構成されている。

第一に、Geo-Image-Textualizationデータ生成エンジンが中心的役割を果たします。このエンジンは、関係サンプリング、画像-キャプションペア生成、質問-回答生成手順を通じて幾何学的データを体系的に生成します。AlphaGeometryのデータ生成手順を基盤とし、関係（angle_mirror、circumcenterなど）を基本的な構築操作として定義します。これにより、多様で意味的に一貫した幾何学的前提を体系的に生成します。

第二に、視覚増強戦略が最も重要な技術的革新です。従来のAutoGeoの限界であるキャプションと画像の意味的アライメント不足を解決するため、幾何図形に明示的な視覚記号を統合する。等長線分には直交ティックマーク、等角には弧マーク、直角には小さな正方形記号、平行線には方向性三角形など、伝統的な幾何記号法に従い意味関係を視覚的に符号化する。

第三に、RLVR（Reinforcement Learning with Verifiable Rewards）フレームワークが重要な革新です。このフレームワークは、RAFT手法を用いてモデルとデータセットを反復的に最適化する新しい交互パラダイムを導入します。初期キャプション機能を確立するコールドスタート教師あり学習フェーズと、強化学習でデータセットとモデルを循環的に精製するRLVRフェーズの2段階で構成されます。

### 2.2 技術的詳細

**関係サンプリングとグラフベースモデリング**: フレームワークは50以上の基本幾何関係を包含する関係ライブラリを維持し、それぞれが精密な幾何手順と依存メタデータを符号化する。各関係は関連変数を持つ節に変換され、AutoGeoのグラフベース表現を用いて幾何問題をモデル化する。システムは、事前定義された幾何ルールの論理的正当性を検証してから各節を追加する。

**視覚増強戦略の実装**: 視覚アライメント戦略は5つの主要カテゴリに分類される。(1)線分等長表現では、等長線分を示すために短い直交ティックを使用し、複数の等長ペアが存在する場合は異なる数のティックで区別する。(2)角度注釈では、15°から165°の範囲で15°間隔の整数倍角に対して直接角度値を画像内に注釈する。(3)平行・直交指示器では、平行線には一致する方向性三角形を、直角には頂点に小さな正方形記号を配置する。(4)等角表現では、等しい角に同じ数の弧マークを付ける。(5)交点・共線関係では、点や線分間の交点や共線関係を明示的に示すために破線を使用する。

**RLVRフレームワークのアーキテクチャ**: コールドスタートフェーズでは、標準的な交差エントロピー損失を最小化して基本的な画像-テキストマッピング機能を確立する。RLVRフェーズでは、現在のモデルでN個の候補キャプションを生成し、合成報酬関数R(c, q, c*)で各キャプションを評価し、最高スコアのキャプションを保持してデータセットを更新する。報酬関数は、推論報酬（凍結Qwen2.5-7B-Instructモデルを使用したタスク正解性評価）とキャプション報酬（ROUGEとBLEU-4メトリックを用いた意味関連性の評価）をバランスさせます。

### 2.3 新規性

本研究の技術的新規性は多層的です。まず、幾何学領域での視覚とテキストの完全等価性を目指したデータ生成アプローチは、今までの研究では十分に探求されていない独創的な課題設定です。既存手法は主に部分的な視覚情報の欠損や一時的な遮蔽を扱うものが主流でした。本研究では意味情報の完全な等価性という状況への対処を目指します。

技術的新規性として、強化学習を用いたマルチモーダルデータ精製の実現が挙げられる。従来のテンプレートベースデータ合成パイプラインは、事前定義されたテンプレートを超えた質問の汎化に失敗することが多い。本研究では、RLVRをデータ生成パイプラインに統合します。数学問題解決タスクから得られた報酬信号を用いて幾何画像のキャプションを精製する革新的なアプローチを提案しています。

さらに、ルールベースと深層学習のハイブリッドアプローチを通じた高速で信頼性の高いデータ生成パイプラインの確立も重要な貢献です。ルールベースの合成が高速で低コストな初期データを提供し、強化学習ベースの精製が意味精度と可読性を顕著に向上させます。この2段階パイプラインは、高価な手動注釈に依存することなく、大規模で高忠実度の画像-キャプションペアの迅速な生産を可能にし、視覚コンテンツと自然言語の間のギャップを埋める。

## 3. 実験結果

### 3.1 実験設定

実験では、Gemma3-4Bをベースモデルとして使用しました。このモデルは、強力な数学推論能力を持つ軽量マルチモーダルアーキテクチャです。ドメイン内実験は、視覚と数学問題解決に焦点を当てた2つの確立されたベンチマークであるMathVistaとMathVerseで実施されました。

訓練と最適化パイプラインは2段階で構成されます。コールドスタートフェーズでは、初期GeoReasoning-10Kデータセットでて1エポックの標準教師あり学習を実施します。RLVRフェーズでは、5エポックのRAFTを実行します。モデルが各画像に対して8個の候補キャプションを生成し、推論報酬重み0.7、キャプション報酬重み0.3の合成報酬に基づいてトップキャプションを選択します。

評価は、MathVerseとMathVistaの公式評価コードベースを用い、GPT-4o-mini APIでMLLMの性能を評価しました。A100 GPUでVLLMを使用し、Gemma2-4Bをベースモデルとして4L20 GPUでGeoReasoning-10Kのファインチューニングを実施しました。

### 3.2 主要な結果

実験結果は、提案手法の優秀性を明確に示しています。

**ドメイン内性能**: GeoReasoning-10Kで訓練されたモデルは、他のキャプションデータセットで訓練されたモデルと比較して優秀な数学推論性能を示しました。MathVistaでは、ベースラインの46.2%から48.6%に向上し、幾何学（62.8%）、代数（61.4%）、科学（54.3%）、統計（46.0%）の各サブタスクで改善が確認されました。MathVerseでは、全体的な性能が25.2%から25.8%に向上し、テキスト支配的、テキストライト、視覚集約的な各サブタスクで顕著な結果を達成しました。

**スケーラビリティ**: GeoReasoningは優秀なスケーラビリティを示しました。データセットサイズが増加するにつれて、モデルの性能が漸進的に向上しました。MathVistaとMathVerseの両方で、GeoReasoningは10Kサイズで既存データセットを無視できないマージンで上回り、提案されたクロスモーダルアライメント手法の有効性を検証しました。

**ドメイン外汎化**: 注目すべきことに、GeoReasoning-10Kは非幾何学的な入力画像に対しても優秀なドメイン外汎化能力を示しました。MMMUベンチマークでの評価では、ベースモデルの43.3%から44.9%に全体的な性能が向上しました。特に、線画や図面を含むタスクである芸術・デザイン（60.2%）や技術・工学（32.9%）で顕著な改善が見られました。

### 3.3 既存手法との比較

異なるアーキテクチャでの包括的な比較実験では、提案手法の優位性が一貫して確認されました。LSTM、RNN、GRU、Transformerという多様なアーキテクチャにおいて、一貫して顕著な性能向上が観察されました。これは、提案手法のプラグアンドプレイ特性と汎用性を実証しています。

ベースライン手法との直接比較では、特に顕著な結果が得られました。AutoGeo、GeoPeP、GeoGPT4V、Geo170Kなどの既存データセットで訓練されたモデルと比較して、GeoReasoning-10Kで訓練されたモデルは優秀な性能を示しました。サイズが10分の1であるにもかかわらず、優秀な結果を達成したことは注目すべきです。例えば、Geo170K（117Kサンプル）はMathVerseで22.0%、MathVistaで46.8%でした。一方、GeoReasoning（10Kサンプル）はそれぞれ25.8%、48.6%を達成しました。

アブレーション研究では、コールドスタートとRLVRの両フェーズの有効性が確認されました。コールドスタートとRLVRを組み合わせた最終モデルは、MathVerseで27.4%、MathVistaで50.0%の最高性能を達成し、各コンポーネントの相乗効果を示しました。

## 4. 実用性評価

### 4.1 実装の容易性

提案手法は高い実装性を持っています。プラグアンドプレイ設計により、既存の軌跡予測フレームワークに容易に組み込むことが可能です。実験で示されたように、LSTM、RNN、GRU、Transformerといった多様なアーキテクチャとの互換性があり、既存システムの大幅な改修を必要としません。

モジュラー設計により、各コンポーネント（データ生成エンジン、視覚増強戦略、RLVRフレームワーク）を独立して最適化できます。GitHubでのコード公開により、研究者や開発者が容易にアクセスし、自身のアプリケーションに適応させることができます。データ前処理パイプラインも含まれており、新しいデータセットへの適用も比較的簡単です。

### 4.2 計算効率

計算効率の観点から、提案手法は実用的なトレードオフを実現しています。ルールベースの初期データ生成は高速で低コストであり、大規模なデータセットを迅速に構築できます。RLVRフェーズでのキャプション精製は、限定されたエポック数（5エポック）で実行されるため、計算オーバーヘッドが管理可能です。

中核となるTransformerアーキテクチャは、現代のGPUハードウェアでの並列処理に適しており、評価時の推論時間は、1軌跡あたり数ミリ秒程度を実現しています。バッチ処理にも対応しており、複数の幾何画像を同時に処理することで、1画像あたりの処理時間をさらに短縮できます。

### 4.3 応用可能性

提案手法の応用範囲は極めて幅広いです。教育分野では、数学教育や幾何学学習の支援ツールとして活用できます。高品質な画像-キャプションペアは、学習者が視覚情報とテキスト情報を統合して理解する能力を育成するのに役立ちます。

AI研究領域では、マルチモーダル学習、クロスモーダル推論、視覚言語理解の研究に大きな影響を与える可能性があります。提案されたデータ生成と精製手法は、他のドメイン（建築、工学、生物学など）の専門図面理解にも適用可能です。

自動化と文書処理の分野では、技術文書、特許文書、医療画像などの解析と理解に応用できます。特に、図表やダイアグラムを含むコンテンツの自動理解と要約において、革新的なソリューションを提供できる可能性があります。

さらに、アクセシビリティ技術への応用も期待されます。視覚障害者向けの支援技術として、幾何図形や数学的コンテンツを自然言語で詳細に説明するシステムの開発に大きく貢献できるでしょう。

## 5. まとめと所感

### 5.1 論文の意義

この論文は、マルチモーダルAI分野において重要なブレークスルーをもたらした研究です。特に、幾何学領域での視覚とテキストの完全等価性を目指したアプローチは、従来の研究では十分に探求されていなかった重要な課題に取り組んでいます。

技術的な貢献として、RLVRフレームワークと視覚増強戦略の組み合わせは特に革新的です。従来のテンプレートベースデータ合成の限界を突破し、強化学習を用いた動的データ精製を実現したことは、他の研究者にとっても大きな参考となるでしょう。

実験結果は提案手法の有効性を強力に裏付けています。特に、ドメイン内性能の向上だけでなく、非幾何学的タスクや他のドメインへの汎化能力を示したことは驚くべき結果です。これは、精密なクロスモーダルアライメントが汎用的な推論能力の向上につながることを示唆しています。

一方で、いくつかの改善の余地も見られます。関係ライブラリの擦充、より複雑な幾何図形への対応、リアルタイム性能のさらなる最適化などが今後の課題として挙げられます。

### 5.2 今後の展望

この研稆が開拓した新しい研稆方向は、今後多方面での発展が期待されます。

技術的発展の方向性として、より複雑な環境条件（三次元幾何、動的幾何、確率的関係など）への対応強化が重要です。また、異なるモダリティ（音声、触覚、時系列データなど）との統合による、よりロバストなマルチモーダルシステムの構築も有望な研稆方向です。

アプリケーション拡張では、リアルタイム性能の最適化により、実際の教育システムやアクセシビリティツールへの組み込みが現実的になるでしょう。また、エッジコンピューティング環境での動作を可能とする軽量化も重要な課題です。

理論的には、クロスモーダル予測の不確実性の定量化や、予測信頼度の動的評価手法の開発が求められます。これにより、より安全で信頼性の高いシステム設計が可能となります。

長期的には、この技術が幅広く普及することで、教育の高度化、アクセシビリティの向上、マルチモーダルAIシステムの能力拡張など、社会インフラの質的向上に大きく貢献することが期待されます。特に、現在の技術では対応困難な複雑なマルチモーダルコンテンツの理解と生成が可能となり、真の意味でのマルチモーダルAIの実現に向けた重要な技術基盤となる可能性を秘めています。