# Teaching Time Series to See and Speak: Forecasting with Aligned Visual and Textual Perspectives

## 基本情報
- arXiv ID: 2506.24124v2 ([https://arxiv.org/abs/2506.24124](https://arxiv.org/abs/2506.24124))
- 著者: Sixun Dong, Wei Fan, Teresa Wu, Yanjie Fu
- 所属: Arizona State University, University of Oxford
- 投稿日: 2025年6月（v2）
- カテゴリ: cs.LG (Machine Learning), cs.AI (Artificial Intelligence)

## 簡単に説明すると
この論文は、時系列データを視覚的表現（画像）と言語的表現（テキスト）の両方に変換する新しいフレームワーク「TimesCLIP」を提案しています。
マルチモーダル対照学習を通じて予測精度を向上させます。
医師がECGを視覚的に読み取って診断するような人間の直感的理解を模倣したアプローチです。

## 1. 研究概要
### 1.1 背景と動機
時系列予測は、過去のデータから未来の値を予測する重要なタスクです。
気象予報、エネルギー需要予測、医療診断、金融投資など幅広い分野で活用されています。
従来の深層学習ベースの手法では、様々なアーキテクチャが提案されてきました。
これらはすべて時系列データを純粋に数値配列として扱う「ユニモーダル」フレームワークでした。

しかし、ユニモーダルアプローチは複雑なパターンの認識に限界があります。
文脈的意味の理解や長期依存関係のモデリングも困難で、脆弱なモデルになりがちです。
最近、大規模言語モデル（LLM）の成功により、時系列を「外国語」として扱う研究も現れました。
ただし人間は通常、時系列データを視覚的に解釈します。
医師のECG診断や金融アナリストの株価チャート分析がその例です。

本研究は、この問題を解決するため、時系列データを視覚表現と言語表現の両方に変換し、マルチモーダル対照学習を通じて両者を整合させる新しいアプローチを提案しています。

### 1.2 主要な貢献
本研究の主要な貢献は以下の3点に集約されます。
- 数値的な多変量時系列データを視覚表現と言語表現に変換し、視覚言語マルチモーダル空間に整合させる革新的なマルチモーダル対照学習フレームワークの提案
- 整合されたマルチモーダル特徴を活用して、多変量時系列の中から最も関連性の高い変数を特定する変数選択モジュールの導入
- 短期・長期両方の時系列予測タスクにおいて、提案手法TimesCLIPが強力な性能を達成することを広範な実験により実証

## 2. 提案手法
### 2.1 手法の概要
TimesCLIPは、以下の3つの主要コンポーネントから構成されています。

1. 視覚モジュール：時系列データを画像に変換し、事前学習済みの視覚エンコーダで特徴を抽出する
2. 言語モジュール：時系列をパッチ化してトークン化し、事前学習済みの言語エンコーダで処理する
3. 変数選択モジュール：マルチモーダル特徴を活用して最も重要な変数を選択する

視覚モジュールでは、各変数を固定ウィンドウサイズで正規化した後、異なる色で可視化して画像を生成します。この色分けにより、視覚的に変数を区別できるようになります。言語モジュールでは、PatchTSTのようにパッチ化戦略を採用し、時系列をサブシリーズレベルのパッチに分割してトークン化します。

### 2.2 技術的詳細
視覚表現の生成では、数値範囲の違いを適切に扱うため、固定ウィンドウサイズ内で各変数を正規化し、変数ごとに異なる色を割り当てて可視化します。これにより、事前学習済みのCLIP視覚エンコーダ（ViT-B）を活用できます。

言語表現の生成では、まずLayerNormalizationで非定常性に対処した後、パッチ化戦略により時系列をトークン列に変換します。ドメインギャップに対応するため、学習可能な線形層を時系列用トークナイザとして導入し、各変数のトークン列の先頭に[class]トークンを追加します。

マルチモーダル対照学習では、InfoNCE損失をベースとした対照学習を行い、同一サンプルから得られた視覚・言語表現を正例、異なるサンプル間を負例として学習します。変数選択モジュールでは、言語モジュールの[class]トークンを「Query」として、クロスアテンション機構により最も相関の高い変数特徴を特定します。

### 2.3 新規性
既存手法との主な違いは、時系列予測を言語モデリングタスクとして扱うのではなく、視覚と言語の両方の観点から時系列を表現し、対照学習により両者を整合させる点にあります。これにより、離散的なトークン列の制約を回避し、複数の視点にわたって連続的な意味を保持できます。

また、視覚的な区別のための色分け戦略と、マルチモーダル特徴を活用した変数選択メカニズムも、本手法の重要な新規性です。これらにより、人間の直感的な時系列理解の方法をモデルに組み込むことができています。

## 3. 実験結果
### 3.1 実験設定
実験では、短期予測用と長期予測用の複数のデータセットを使用しました。
短期予測用には、M4データセット（6つのサブデータセット）とEPFデータセットを使用しました。
長期予測用には、6つの標準データセットを使用しました。
評価指標として、長期予測ではMAEとMSE、短期予測ではSMAPE、MASE、OWAを採用しています。

ベースラインとして、LLMベースのTime-LLMやGPT4TSを使用しました。
また、エンドツーエンドモデルのiTransformer、PatchTST、TimesNet、DLinearなど、最新の19種類のモデルと比較しました。

### 3.2 主要な結果
短期予測において、TimesCLIPはM4データセットのすべてのサブセットで最高性能を達成しました。例えば、M4-YearlyではSMAPEで13.090、MASEで2.977、OWAで0.777という優れた結果を示し、既存手法を大きく上回りました。

長期予測でも、6つのデータセット中5つで最高性能を達成し、特にExchangeデータセットでは96ステップ予測でMSE 0.083、MAE 0.204という優れた精度を示しました。これは次点のモデルと比較して、MSEで3.5%、MAEで1.0%の改善となっています。

### 3.3 既存手法との比較
LLMベースの手法と比較して、TimesCLIPは一貫して優れた性能を示しました。例えば、Time-LLMと比較してExchangeデータセットでは平均MSEで26.4%の改善を達成しています。また、最新のエンドツーエンドモデルであるiTransformerと比較しても、ほぼすべてのデータセットで上回る性能を示しました。

アブレーション研究により、マルチモーダル対照損失と変数選択モジュールが性能向上に重要であることが確認されました。特に、色分けによる視覚的区別が対照学習の効果を大きく向上させることが明らかになりました。

## 4. 実用性評価
### 4.1 実装の容易性
TimesCLIPは事前学習済みのCLIPモデルをベースとしています。
ゼロからの学習は不要で、実装も比較的容易です。
すべてのベンチマークで同一のアーキテクチャを使用できるという利点もあります。

ただし、Parameter-Efficient Fine-Tuning（PEFT）などの高速化技術を使用していないため、学習には一定の計算リソースが必要です。

### 4.2 計算効率
本手法の主な計算コストは、各変数を画像に変換する処理と、画像特徴の抽出にあります。多変量時系列の変数数が増えるにつれて、GPU メモリ要求量も増加します。また、トークン長が変数数とともに増加するため、メモリ使用量はさらに増大します。

実験では、ViT-Bベースのエンコーダを使用しました。
これはTransformerベースの視覚モデルとして広く使われているアーキテクチャです。
大規模なデータセットでは相当な計算リソースが必要となります。

### 4.3 応用可能性
TimesCLIPのマルチモーダルアプローチは、様々な時系列予測タスクに適用可能です。特に、視覚的パターンが重要な意味を持つ医療データ（ECG、EEGなど）や金融データ（株価チャートなど）において有効と考えられます。

また、提案されたフレームワークは、視覚ベースの大規模言語モデルや時系列基盤モデルへの拡張可能性も持っています。CLIPのような成功事例に倣い、より大規模なデータセットでの事前学習により、さらなる性能向上が期待できます。

## 5. まとめと所感
### 5.1 論文の意義
本研究は、時系列予測における新しいアプローチを提案する重要な論文です。従来の数値のみを扱うアプローチから、人間の直感的理解に近い視覚的・言語的表現を活用するマルチモーダルアプローチへの転換は、時系列分析の新たな方向性を示しています。

実験結果は説得力があり、短期・長期両方の予測タスクで優れた性能を達成していることは注目に値します。特に、事前学習済みモデルを効果的に活用している点は、実用的な観点からも評価できます。

一方で、計算コストの高さや、なぜ視覚表現が有効なのかについての理論的説明の不足など、改善の余地も見られます。また、色分けの効果についてより深い分析があれば、手法の理解がさらに深まったと考えられます。

### 5.2 今後の展望
今後の研究方向として、視覚表現の生成に必要な計算時間を短縮する方法の開発が考えられます。
また、動的な変数選択メカニズムの導入も有望です。
異なるドメインの時系列データに対する転移学習の可能性も興味深い研究テーマです。

さらに、本手法を基盤として、時系列専用の大規模マルチモーダルモデルの開発も期待されます。これにより、様々な時系列タスクに対して統一的なアプローチが可能になり、時系列分析の新たな標準となる可能性があります。