# How Many Instructions Can LLMs Follow at Once

## 基本情報
- arXiv ID: 2507.11538v1 (https://arxiv.org/abs/2507.11538)
- 著者: Daniel Jaroslawicz、Brendan Whiting、Parth Shah、Karime Maamari
- 所属: Distyl AI
- 投稿日: 2025年07月16日
- カテゴリ: cs.CL、cs.AI

## 簡単に説明すると
この論文は、LLM（大規模言語モデル）が一度にどれだけ多くの指示に従えるかを測定する新しいベンチマーク「IFScale」を提案しています。ビジネスレポートを書きながら特定のキーワードを含めるというシンプルなタスクで性能を評価しました。10から500個の指示で評価した結果、最も優れたモデルでも500個の指示では68%の精度しか達成できませんでした。さらに、モデルのサイズや推論能力によって、3つの異なる性能劣化パターン（闾値型、線形型、指数型）が存在することも発見されました。

## 1. 研究概要
### 1.1 背景と動機
現在のLLMはコンテキストウィンドウが数百万トークンに拡張され、推論能力も向上しているため、理論上は同時に数百の指示を処理できるはずです。しかし、実際のプロダクションシステムでは、スタイルガイドライン、ビジネスルール、コンプライアンス基準など、数十から数百の指示に同時に従う必要があります。

既存のベンチマークは主に少数の指示（1〜数個）での評価に留まっており、高密度の指示下での性能劣化を理解するには不十分でした。このギャップを埋めるため、指示密度が増加するにつれてモデルの認知負荷がどのように増大し、性能がどう劣化するかを特徴付けるベンチマークが必要でした。

### 1.2 主要な貢献
- IFScaleベンチマークの提案: 指示密度が10から500に増加するにつれて指示追従性能がどのように劣化するかを評価するベンチマーク
- 包括的な評価: 7つの主要プロバイダーから20の最先端モデルを評価し、性能ヒエラルキーと劣化パターンを明らかにした
- 3つの劣化パターンの発見: 闾値型劣化（推論モデル）、線形劣化、指数型劣化（小型モデル）の識別
- プライマシー効果の分析: モデルが前半の指示を優先する傾向が150-200指示でピークになることを発見
- 実用的な知見: レイテンシと精度のトレードオフ、エラータイプの分析、コアタスクパフォーマンスへの影響を詳細に分析

## 2. 提案手法
### 2.1 手法の概要
IFScaleは、ビジネスレポート作成タスクをベースにしたシンプルかつ効果的なベンチマークです。モデルに対して、プロフェッショナルなビジネスレポートを生成しながら、指定されたキーワードを含めるよう指示します。

各指示は「正確な単語 'accountability' を含めてください」のような形式で、指示密度は10から500まで10刻みで変化させます。これにより、指示数が増えるにつれて性能がどう変化するかを系統的に評価できます。

評価は自動化されており、正規表現マッチングでキーワードの含有をチェックします。このシンプルさにより、大規模な評価が可能になり、再現性も高くなっています。

### 2.2 技術的詳細
語彙構築プロセスは以下のように進められました。

1. データソース: 米国SECの10-Kファイリング（企業の年次報告書）からビジネス関連の単語を抽出
2. 清浄化プロセスは以下の手順で実施されました。
   - o4-miniを使用して各ファイルから上位500個の候補用語を抽出
   - ファジーマッチングで重複を除去
   - 生の10-Kコーパスで完全一致する単語のみを保持
   - Zipf頻度フィルター（≥ 1.0）で標準英語に存在する単語を確保
   - WordNetを使用して形態素変異を統一
   - 埋め込みベクトルで意味的冗長性を除去
3. 難易度評価: gpt-4.1-nanoの平均対数確率を使用して各単語の生成難易度を推定
4. 最終選定: 難易度の高い順に上位500単語を選定

実験設計の詳細として、以下のような点があります。

- プロンプト構成: N個のキーワードをランダムに選択し、「正確な単語 '{keyword}' を含めてください」形式の指示リストを作成
- リトライロジック: 以下の場合に再試行を実施
  - 制約リスト形式の出力（10個以上のコンマ区切り単語）
  - 応答拒否（20単語未満の出力）
  - 非一貫性のあるレポート（o4-miniでの一貫性チェック）
- 評価: ワイルドカード対応の正規表現でキーワードの完全一致を確認

### 2.3 新規性
IFScaleの主要な新規性は以下の通りです。

1. 指示密度の系統的なスケーリング: 既存ベンチマークが1〜数個の指示で評価するのに対し、IFScaleは10から500まで系統的に変化させて評価

2. 自動評価が可能なタスク設計: キーワード含有というシンプルな制約により、人間の評価を必要とせず大規模な実験が可能

3. 実用的なビジネスコンテキスト: SEC 10-Kファイリングから抽出したビジネス語彙を使用し、実際のビジネス文書作成シナリオに近い評価

4. 劣化パターンの分類: 単なる精度の測定ではなく、性能劣化のパターンを闾値型、線形型、指数型に分類

5. 総合的な分析: 精度だけでなく、プライマシー効果、エラータイプ、レイテンシ、コヒーレンスなど多面的に評価

## 3. 実験結果
### 3.1 実験設定
実験では、7つのプロバイダーから20の最先端モデルを評価しました。評価モデルには以下が含まれます。
  - OpenAI: o3、o4-mini、gpt-4.5、gpt-4.1、gpt-4.1-mini、gpt-4.1-nano、gpt-4o、gpt-4o-mini
  - Anthropic: claude-opus-4、claude-sonnet-4、claude-3.7-sonnet、claude-3.5-haiku
  - Google: gemini-2.5-pro、gemini-2.5-flash
  - DeepSeek: deepseek-r1
  - x.ai: grok-3、grok-3-mini
  - Qwen: qwen3-235b
  - LLaMA: llama-4-maverick、llama-4-scout

評価プロトコルは以下の通りです。
- 指示密度: N ∈ {10, 20, ..., 500}、10刻みで変化
- 統計的有意性: 各密度レベルで5つのランダムシードで実施
- APIアクセス: OpenRouter APIを使用、デフォルト生成パラメータ
- 推論モード: 該当する場合は推論努力を「high」に設定

評価指標として、以下の項目を使用しました。
- 主要指標: キーワード含有精度（完全一致のみカウント）
- エラー分類には次の2種類がある。
  - 省略エラー: 指示された単語が一切含まれていない
  - 修正エラー: 形態素変異を含める（例: "accountability"の代わりに"accountable"）
- プライマシー効果: 指示リストを前・中・後の3つに分割し、エラー率を比較
- レイテンシ: 出力生成にかかる時間を測定

### 3.2 主要な結果
500指示時の性能ヒエラルキーは以下の通りです。
1. gemini-2.5-pro: 68.9%
2. o3: 62.8%
3. grok-3: 61.9%
4. gemini-2.5-flash: 56.2%
5. claude-3.7-sonnet: 52.7%

最下位: llama-4-scout (7.3%)、claude-3.5-haiku (8.7%)

性能劣化には3つのパターンが観察されました。

1. 闾値型劣化（Threshold decay）
   - 特徴: 一定の闾値まで非常に高い性能を維持し、その後急激に劣化
   - 代表例: gemini-2.5-pro、o3（主に推論モデル）
   - 闾値: 約150-250指示

2. 線形劣化（Linear decay）
   - 特徴: 指示密度に比例して一定の速度で劣化
   - 代表例: gpt-4.1、claude-3.7-sonnet
   - 予測可能性が高い

3. 指数型劣化（Exponential decay）
   - 特徴: 初期に急速に劣化し、低い精度で安定
   - 代表例: claude-3.5-haiku、llama-4-scout
   - 下限値: 約7-15%で収束

重要な発見として、以下の点が挙げられます。
- 推論モデルが一般的に優れた性能を示す
- モデルサイズと世代が性能に大きく影響
- grok-3は推論モードでないにもかかわらずo3に近い性能を示す

### 3.3 既存手法との比較
プライマシー効果の分析について説明します。

モデルが指示リストの前半にある指示を優先的に実行する傾向を分析した結果、以下のことが分かりました。
- 低密度ではほとんどバイアスなし
- 150-200指示でピークに達する
- 300指示以上では効果が減少し、均一的な失敗パターンに収束

エラータイプの分析結果を以下に示します。

指示密度が増加するにつれて、次のような傾向が見られます。
- 省略エラー（単語の欠落）が修正エラー（形態素変異）より圧倒的に多くなる
- llama-4-scoutは500指示時にO:M比率34.88（省略エラーが30倍以上）
- 推論モデルはO:M比が低く、修正を試みる傾向

レイテンシと効率性について説明します。

推論モデルのレイテンシ増加は以下の通りです。
- o4-mini: 12.40秒 → 436.19秒（250指示時）
- o3: 26.30秒 → 219.58秒（250指示時）

一般モデルのレイテンシは安定しています。
- claude-3.5-haiku: 9.32秒 → 10.54秒
- gpt-4o: 9.29秒 → 13.20秒

効率性ランキングでは、小型・高速モデルが有利な場合もある。

## 4. 実用性評価
### 4.1 実装の容易性
IFScaleの実装は非常にシンプルで再現性が高いです。

実装の容易さには以下の特徴があります。
- タスクがシンプル（キーワード含有のチェック）
- 評価が完全自動化（正規表現マッチング）
- 特殊なツールやライブラリ不要

オープンソース化について、以下の情報が公開されています。
- ベンチマークコードと全結果が公開
- URL: https://distylai.github.io/IFScale
- 語彙リストや詳細な実験結果も入手可能

拡張性については、以下の点が挙げられます。
- 他のドメインや言語への適用が容易
- 指示タイプの変更（例：スタイル指示、数値制約など）も可能

### 4.2 計算効率
レイテンシの分析結果を以下に示します。

一般モデルについては、以下の特徴があります。
- 指示密度が増えてもレイテンシはほぼ一定
- 例: claude-3.5-haikuは約10秒で安定

推論モデルについては、以下の特徴があります。
- 指示密度に応じて劇的に増加
- o4-mini: 35倍のレイテンシ増加（250指示時）
- o3: 8倍のレイテンシ増加（250指示時）

効率性の考慮事項として、精度とレイテンシの比率で評価すると、以下のような結果が得られました。
- 高効率: grok-3-mini、gemini-2.5-flash、gpt-4.1-nano
- 低効率: o3、gemini-2.5-pro（高精度だが計算コスト大）
- バランス型: grok-3（高精度かつ高効率）

実用的なアプリケーションでは、性能要件とレイテンシ制約のバランスが重要です。

### 4.3 応用可能性
実用的な応用シナリオとして、以下が考えられます。

1. コンテンツ生成システム
   - ブランドガイドライン、SEO要件、法的制約など数十の制約を満たす必要がある場合
   - 推奨: 闾値型劣化モデル（gemini-2.5-pro、o3）

2. カスタマーサービスチャットボット
   - リアルタイム応答が重要で、中程度の制約（10-50個）を扱う場合
   - 推奨: 高効率モデル（grok-3、gemini-2.5-flash）

3. 自動化ワークフロー
   - ビジネスルール、コンプライアンス基準を統合したタスク
   - 予測可能性が重要な場合: 線形劣化モデル（gpt-4.1）

4. エージェントシステム
   - 複数のツール使用ルール、メモリ管理、タスク追跡など
   - 高い信頼性が必要: 低分散のモデルを選択

プロンプトエンジニアリングへの示唆として、以下の点が重要です。
- 50-200指示: 重要な指示を前半に配置すると効果的
- 300指示以上: 指示の順序効果はほぼ消失、別の戦略が必要

## 5. まとめと所感
### 5.1 論文の意義
IFScaleは、LLMの指示追従能力の限界を明らかにした点で重要な貢献をしています。

学術的意義として、以下の点が挙げられます。
- LLMの認知負荷に関する初めての体系的研究
- モデルアーキテクチャと性能パターンの関係を解明
- 注意機構の根本的限界を示唆
- プライマシー効果の普遍的パターンを発見

産業的意義として、以下の点が挙げられます。
- プロダクションシステム設計のガイドライン提供
- モデル選定の定量的基準を確立
- コストと性能のトレードオフを明確化
- 指示密度に応じたシステム設計指針

今後の研究への影響として、以下の点が期待されます。
- 指示追従における能力向上のための明確な目標設定
- 新たな評価指標の標準化
- アーキテクチャ改善の方向性提示

### 5.2 今後の展望
今後の研究方向として、以下の点が重要です。

1. 劣化メカニズムの解明
   - なぜ3つの異なるパターンが生じるのか
   - 注意機構の内部動作の分析
   - モデルアーキテクチャとの関係性

2. 指示タイプの拡張
   - 単純なキーワード含有以外の制約
   - 数値制約、スタイル指示、論理制約など
   - 相互依存する指示の影響

3. クロスタスク評価
   - 他のタスクドメインでの検証
   - 劣化パターンの一般化可能性
   - ドメイン固有の特性分析

4. 多言語対応
   - 英語以外の言語での評価
   - 言語特性が性能に与える影響
   - クロスリンガル指示の処理

5. 改善手法の開発
   - 指示追従における能力向上のための訓練手法
   - プロンプトエンジニアリング技術
   - アーキテクチャレベルの改善

6. コアタスクとのバランス
   - 指示追従とタスク品質のトレードオフ
   - 特にOpenAIのoシリーズの動作分析
   - 最適なバランスの探索

これらの研究により、より実用的で信頼性の高いLLMシステムの開発が進むと期待されます。