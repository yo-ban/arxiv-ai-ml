# Spiffy: Multiplying Diffusion LLM Acceleration via Lossless Speculative Decoding

## 基本情報
- **arXiv ID**: 2509.18085v1 (https://arxiv.org/abs/2509.18085)
- **著者**: Sudhanshu Agrawal, Risheek Garrepalli, Raghavv Goel, Mingu Lee, Christopher Lott, Fatih Porikli
- **所属**: Qualcomm AI Research
- **投稿日**: 2025年09月24日
- **カテゴリ**: cs.LG, cs.CL

## 簡単に説明すると
この論文は、拡散言語モデル（dLLM）の推論速度を大幅に向上させる「Spiffy」という新しいスペキュレーティブデコーディングアルゴリズムを提案しています。従来の自己回帰型LLMと異なり、dLLMは並列生成の可能性を持ちながらも、実際には1トークンずつしか生成していませんでした。Spiffyは、dLLM自体の分布を活用して複数の候補状態を「推測」し、それらを並列検証することで、出力品質を厳密に保ちながら2.8-3.1倍の高速化を実現しています。特に、新しい有向ドラフトグラフ構造とオフライン較正アルゴリズムを導入し、最大7.9倍の総合高速化を達成しています。

## 1. 研究概要
### 1.1 背景と動機
[詳細な説明]

### 1.2 主要な貢献
[詳細な説明]
- [貢献1]
- [貢献2]
- ...
- [貢献n]

## 2. 提案手法
### 2.1 手法の概要
[詳細な説明]

### 2.2 技術的詳細
[アルゴリズムや数式の説明]

### 2.3 新規性
[既存手法との違い]

## 3. 実験結果
### 3.1 実験設定
[データセット、評価指標など]

### 3.2 主要な結果
[定量的・定性的結果]

### 3.3 既存手法との比較
[比較結果と分析]

## 4. 実用性評価
### 4.1 実装の容易性
[評価]

### 4.2 計算効率
[評価]

### 4.3 応用可能性
[評価]

## 5. まとめと所感
### 5.1 論文の意義
[考察・総合評価]

### 5.2 今後の展望
[将来性や改善点]