# Deep Reactive Policy: Learning Reactive Manipulator Motion Planning for Dynamic Environments

## 基本情報
- arXiv ID: 2509.06953v1 (https://arxiv.org/abs/2509.06953v1)
- 著者: Jiahui Yang, Jason Jingzhou Liu, Yulong Li他
- 所属: Carnegie Mellon University
- 投稿日: 2025年09月10日
- カテゴリ: cs.RO, cs.AI

## 簡単に説明すると
この論文は、動的で部分観測可能な環境においてロボットマニピュレータが衝突回避しながら反応的に動作できる新しい視覚運動ニューラル政策を提案しています。提案手法は「Deep Reactive Policy（DRP）」と命名されています。

DRPは点群入力から直接動作を生成します。大規模な事前訓練と学習者・教師の微調整を実施し、局所反応モジュールと組み合わせています。これにより、複雑で動的な環境での優れた汎化性能を実現しています。

関連リンクについて、以下の情報が公開されています。
- Website: https://deep-reactive-policy.com/

## 1. 研究概要
### 1.1 背景と動機
ロボットが自然な人間環境である家庭やキッチンで動作するためには、急速に変化する部分観測可能な環境で安全にナビゲートする能力が必要です。この能力の中核となるのが衝突を回避する運動生成技術です。動作生成は、視覚言語モデルや行動クローニングエージェントなどの高レベル政策レイヤーの下で動作し、ロボットの行動が安全かつ物理的に実現可能であることを保証します。

従来のロボット動作計画では、主に2つのアプローチが採用されてきました。第一に、A*やAIT*などの探索ベース手法は、グローバルに最適な解を見つけることができます。ただし環境の完全な知識と静的条件を仮定しており、長い実行時間のため動的障害物の回避には限界がありました。第二に、Riemannian Motion Policies（RMP）やGeometric Fabricsなどの反応コントローラベースアプローチは、動的シーンでの反応的な衝突回避を提供します。一方でグローバルシーン認識が欠けており、複雑な環境では局所最適に陥りやすい問題を抱えていました。

これらの限界を克服するため、生の視覚観測を直接行動にマッピングする視覚運動ニューラル政策として動作生成を定式化するアプローチが注目されています。開ループプランナーとは異なり、学習された視覚運動政策は点群などのライブセンサ入力を継続的に処理し、既知の環境モデルを必要とせずにその場で行動を適応させることができます。このリアルタイム閉ループ適応能力は、目標が動的障害物によって一時的に遮られる場合や突然の環境変化において極めて重要です。

### 1.2 主要な貢献
本研究では、多様な動的環境での反応的な動作生成を目的とした視覚運動ニューラル動作政策Deep Reactive Policy（DRP）を提案しています。主要な技術的貢献について、以下のような革新的要素が含まれています。

第一に、大規模な運動データ生成によるIMPACTの訓練が実現されています。点群観測に条件づけられた新しいエンドツーエンドTransformerベース ニューラル動作政策を構築しました。cuRoboを活用して1,000万軌道の多様な学習データを生成し、従来手法を上回る規模での事前訓練を実施しています。

第二に、反復的な学習者・教師蒸留による障害物の回避性能向上が図られています。事前訓練されたIMPACT政策とGeometric Fabricsを組み合わせた教師政策から、点群入力のみで動作する学習者政策への知識蒸留を実施しました。これにより特権情報への依存なしで局所的な障害物の回避能力を改善しています。

第三に、局所反応の目標提案モジュールDCP-RMPによる動的な障害物の回避能力強化が達成されています。従来のRMPが真実状態情報を必要としていた制約を克服し、点群入力から直接に動的障害物を検出して反応的な回避動作を生成します。K-D木を用いた動的点検出アルゴリズムにより、リアルタイム性能を維持しながら高精度な動的反応を実現しています。

## 2. 提案手法
### 2.1 手法の概要
Deep Reactive Policy（DRP）は、多様で動的な実世界環境において衝突回避の目標到達を可能にするニューラル視覚運動政策です。システム全体のアーキテクチャは、点群入力と関節空間目標に条件づけられて関節位置ターゲットを生成するTransformerベース政策IMPACTを中核としています。

DRPの動作フローは3段階で構成されています。第一段階では、局所反応DCP-RMPモジュールが高速移動する動的障害物を処理するために関節目標を調整します。第二段階では、IMPACTがシーン点群、修正された関節目標、現在のロボット関節位置を入力として受け取り、リアルタイム実行用の行動シーケンスを出力します。第三段階では、生成された動作がロボットの低レベルコントローラに送信され、実際の関節制御が実行されます。

IMPACTの訓練は2段階のプロセスで実施されます。最初に、cuRoboによって生成された1,000万以上の専門家軌跡を用いた大規模な事前訓練を実施します。この段階では、多様で複雑な訓練シーンと専門家軌跡解のペアが生成され、一般的な衝突回避行動を学習する教師あり事前訓練が可能になります。続いて、静的な障害物の回避能力を向上させるための学習者・教師微調整を実施します。

### 2.2 技術的詳細
IMPACTアーキテクチャは、点群処理と高精度な行動予測を両立するように設計されています。入力処理において、障害物点群とロボット点群は、PointNet++のset abstractionを用いてダウンサンプリングされ、計算複雑性を削減しながらリアルタイム推論を可能にします。具体的には、シーン点群とロボット点群がそれぞれ潜在トークンに変換され、現在と目標の関節角度もMLPを通じてエンコードされます。

Transformerエンコーダ・デコーダ構造では、各入力に学習可能な埋め込みが付与され、エンコーダ入力を形成します。デコーダは学習可能な行動トークンを処理し、エンコーダ出力をメモリとして使用してデルタ関節行動のシーケンスを出力します。これらのデルタ行動は、真実行動に対する平均的な二乗誤差損失で監督され、絶対関節ターゲットに変換された後、ロボットの低レベルコントローラに送信されます。

学習者・教師微調整プロセスでは、事前訓練されたIMPACT政策の局所的な障害物の回避能力を改善するため、Geometric Fabricsとの組み合わせを活用します。教師政策は事前訓練IMPACTとGeometric Fabricsの組み合わせで構成され、学習者政策は点群ベースIMPACTのみで動作します。Geometric Fabricsは真実障害物モデルを使用して関節ターゲットに従いながら近くの障害物を回避し、動的制約を尊重します。この特権情報を点群ベース学習者政策に蒸留することで、実環境展開時の性能向上を図っています。

DCP-RMPモジュールは、従来のRMPが真実状態情報を必要とする制約を克服し、点群入力から直接に動的障害物の回避を実現します。K-D木を用いたアルゴリズムにより、現在フレームと前フレームの点群間で最近傍クエリを実行し、移動点を特定して動的障害物として分類します。検出された動的障害物に対して反発加速度を計算し、元の関節目標を仮想的に調整することで、動的な障害物回避を優先する修正目標を生成します。

### 2.3 新規性
本提案手法の新規性は、従来の動作計画手法が抱える根本的制約を克服する統合アプローチにあります。既存の探索ベース手法は完全環境知識と静的条件を前提とし、反応コントローラベース手法は局所最適問題に悩まされていました。DRPは学習ベースアプローチにより、これらの制約を同時に解決しています。

技術的な差別化要因として、超大規模データセット生成による強力な事前訓練が挙げられます。cuRoboのGPU加速を活用することで、従来研究では不可能だった1,000万軌跡規模での訓練データ生成を実現しました。この規模の違いは、政策の汎化能力と複雑環境での性能へ直接的な影響を与えています。

アーキテクチャ面での革新として、点群処理に最適化されたTransformerベース設計が導入されています。PointNet++との統合により、生の3D点群から特徴抽出し、リアルタイム制約下でも高精度な行動予測を可能にしています。従来手法では、環境の完全な再構築や既知の幾何学的表現が必要でしたが、DRPは部分観測点群から直接動作できます。

訓練手法においても独創性が見られます。学習者・教師蒸留フレームワークにより、特権情報（完全環境知識）を持つ教師から点群のみで動作する学習者への知識転移を実現しています。これにより、実環境展開時の性能向上と訓練時の安定性を両立させています。

## 3. 実験結果
### 3.1 実験設定
評価実験は、DRPの反応性とロバスト性を包括的に検証するため、シミュレーション環境と実世界環境の両方で実施されました。新たに設計されたDRPBenchは、実世界のロボット動作生成における3つの重要課題を標的とした挑戦的ベンチマークタスクセットです。具体的には、雑然とした静的環境でのナビゲーション、動的障害物への迅速な反応、一時的に遮蔽された目標の慎重で精密な処理が評価されます。

DRPBenchは5つの異なるタスクカテゴリで構成されています。Static Environments（SE）では固定障害物による挑戦的シナリオが設定され、予測可能で変化のない環境での政策性能が評価されます。Suddenly Appearing Obstacle（SAO）では、ロボットの経路を直接遮断する障害物が突然出現し、動的な軌跡適応能力がテストされます。Floating Dynamic Obstacles（FDO）では、環境全体をランダムに移動する障害物によってロボットの反応能力と実時間での衝突回避能力が評価されます。

Goal Blocking（GB）とDynamic Goal Blocking（DGB）は特に挑戦的なシナリオです。GBでは目標が障害物によって一時的に遮蔽され、ロボットは衝突せずに可能な限り接近します。DGBでは目標到達後に移動障害物と遭遇し、タスク完了後も反応性を維持して安全に目標へ戻る能力がテストされます。

評価指標として成功率が採用され、エンドエフェクタが位置と方向の閾値内で目標姿勢に到達し、衝突なしで試行が完了した場合に成功と判定されます。具体的には、並進誤差1cm以内、方向誤差15度以内が成功条件として設定されています。

### 3.2 主要な結果
シミュレーション実験において、DRPは古典的手法と学習ベース手法の両方に対して一貫した優位性を示しました。動的および目標遮蔽シーンでの性能が特に優秀で、AIT*などのサンプリングベースプランナーは動的環境で失敗し、全ての動的タスクで0%の成功率となりました。延長された計画期間でも性能向上は見られず、動的環境での根本的限界が明らかになっています。

cuRoboやRMPなどの最適化ベースアプローチは静的設定では良好な性能を示し、それぞれStatic Environment（SE）で82.97%と32.97%を達成しました。しかし、より困難なシナリオでは性能が劣化し、cuRoboはDynamic Goal Blocking（DGB）で3.00%まで低下しています。対照的に、RMPはDGBで50.50%を達成し、反応制御モジュールとしてDRPに統合する動機を提供しています。

学習ベース手法の比較では、狭いデータセットで訓練されたMπNetsやMπFormerは分布外シーンでの汎化に失敗し、DRPBenchタスクで0-2.5%の性能にとどまりました。NeuralMPはテスト時最適化（TTO）に依存してより良い性能を示しましたが、静的環境のみで効果があり、反応コンテキストでは苦戦しています。微調整なしでも、IMPACTはより表現力豊かでスケーラブルなアーキテクチャと多様なデータセットでの訓練により、他の学習ベース手法を上回る性能を示しました。

実世界実験では、DRPがシミュレーションから現実への転移において優れた能力を実証しました。Static EnvironmentとSudden Appearing Obstructionタスクで、DRPとIMPACTの両方がほぼ理想的な成功率を達成しました。ノイズの多い知覚下で性能が劣化するcuRobo-VoxやNeuralMPを上回る結果を示しています。Goal Blocking タスクでは、DRPとIMPACTが92.86%に達し、cuRoboとNeuralMPが失敗した一方で優秀な性能を示しています。

### 3.3 既存手法との比較
包括的な比較実験では、DRPが古典的な計画手法と最新学習ベース手法の両方に対して優位性を実証しました。アーキテクチャ設計と訓練多様性による汎化能力の向上が確認され、狭いデータセットで訓練された既存学習モデルが分布外環境で失敗する一方、DRPは優れた汎化性能を示しました。

微調整プロセスの効果も顕著に現れています。DRPは古典的プランナー（cuRobo）で事前訓練されていますが、そのソース性能を上回っています。これは、データ生成時の成功軌跡フィルタリングと、元データを超えて行動生成を洗練・蒸留する学習者・教師の微調整段階の効果によるものです。結果として、有用な行動を継承するだけでなく、複雑な設定でより効果的に汎化する政策が得られています。

DCP-RMPモジュールの統合効果も実証されています。DRPのDCP-RMP統合により、高速な局所応答性が追加され、動的タスクで強力な結果を生み出しています。Floating Dynamic Obstacle（FDO）で75.50%、Dynamic Goal Blocking（DGB）で65.25%を達成しました。IMPACTのみでは同じタスクでそれぞれ32.00%と0.25%に低下し、cuRoboも39.50%と3.00%にとどまっています。これらの向上は、動的障害物と変化する目標をリアルタイムで処理するため、高レベル学習と反応モジュールを組み合わせる必要性を強調しています。

## 4. 実用性評価
### 4.1 実装の容易性
DRPの実装アプローチは、既存の高性能ツールと技術を活用することで実現されています。データ生成フェーズでは、cuRoboのGPU加速機能を利用して大規模な訓練データセット生成を実現し、従来手法では不可能だった1,000万軌跡の規模を達成しています。この規模は、政策の汎化能力向上に直接的な影響を与えており、実装の実用性と性能向上の両立を図っています。

点群処理において、PointNet++の既存実装を活用することで、3D特徴抽出を実現しています。生のセンサデータから直接動作できるため、詳細な環境再構築や既知幾何モデルが不要となり、実世界展開の複雑性を削減しています。校正済みRGB-Dカメラを使用した多視点セットアップにより、部分観測や閉塞の問題を緩和しています。

学習者・教師蒸留フレームワークは、IsaacGymの並列化機能を活用して実装されており、訓練プロセスを実現しています。静的シーンでのSigned Distance Fields（SDF）をオフラインでバッチ事前計算することで、オンライン計算負荷を削減し、スケーラブルな訓練を可能にしています。このアプローチにより、特権情報から実用的な点群ベース政策への知識転移が達成されています。

### 4.2 計算効率
DRPの計算効率は、リアルタイム展開要件を満たすように最適化されています。推論時の計算負荷削減のため、PointNet++によるset abstractionが採用され、大規模点群を小さな潜在トークンセットに変換します。この処理により、計算複雑性を削減しながら、必要な空間情報を保持しています。

Transformerアーキテクチャの効率化では、行動チャンキング手法を採用して複数ステップの行動を一度に予測し、推論頻度を削減しています。これにより、単一の行動予測手法と比較して計算オーバーヘッドを削減しながら、時間的一貫性を維持しています。メモリ効率の観点では、エンコーダ・デコーダ構造により、必要な情報のみをメモリとして保持し、不要な計算を回避しています。

DCP-RMPモジュールの実装では、K-D木アルゴリズムによる近傍探索により、動的点検出の計算複雑性を最小化しています。オイラー積分による目標修正は軽量な計算で実現され、制御ループあたり複数回の積分ステップを実行してもリアルタイム性能を維持しています。全体として、DRPはリアルタイム制御要件を満たしながら高精度な動作生成を実現するよう設計されています。

### 4.3 応用可能性
DRPの応用可能性は、多様な実環境での実証実験によって検証されています。実世界ベンチマークでは、傾斜した棚や高い引き出しなど、意味的に意味のある分布外障害物を含む50以上の実世界インスタンスで評価が実施されました。シミュレーションのみで訓練されたにも関わらず、実世界設定によく適応し、sim-to-real転移の有効性を実証しています。

人間との協調作業シナリオでの応用性も示されています。Dynamic Goal Blocking（DGB）タスクでは、ロボットが引き出しの前で待機し、人間作業者を回避し、開いた後に到達するという複雑な相互作用が成功しています。このシナリオは、製造業や家庭用ロボティクスにおける実用的応用を示唆しており、人間環境でのロボット展開の実現可能性を支持しています。

拡張性の観点では、現在の実装がFranka Pandaマニピュレータに限定されているという制約が存在します。しかし、手法の基本原理は他のロボットプラットフォームも適応可能であり、将来的には複数実体への汎化や単一政策による多実体対応が期待されます。点群ベースアプローチは、ロボット固有の幾何表現に依存せず、異なる実体への転移を支援する可能性があります。

## 5. まとめと所感
### 5.1 論文の意義
本論文は、ロボット動作計画分野において従来手法の根本的限界を克服する包括的解決策を提供しています。探索ベース手法の計算複雑性と動的環境での制約を解決し、反応コントローラの局所最適問題を同時に解決するアプローチは、学術的及び実用的にも重要な貢献です。超大規模データセット生成による事前訓練と学習者・教師蒸留の組み合わせは、ロボット学習分野の新しい方向性を示しています。

技術的革新性も高く評価されます。点群処理に最適化されたTransformerアーキテクチャは、従来の環境再構築や既知モデル依存を排除し、実環境展開の複雑性を削減しています。DCP-RMPによる点群ベース反応制御は、特権情報に依存しない動的な障害物回避の新しいパラダイムを確立しており、他の研究への応用可能性も高い技術です。

実験的検証の包括性と実用性が特筆されます。DRPBenchの設計は、実世界ロボティクスの重要課題を的確に捉えており、評価フレームワークとして他の研究活用可能です。シミュレーションから実世界まで一貫した優位性を示したことは、提案手法の実用的価値を強く支持しています。特に、人間との相互作用を含む複雑なシナリオでの成功は、実際のロボット展開への道筋を明確に示しています。

### 5.2 今後の展望
本研究の発展方向として、複数ロボット実体への拡張が最も重要な課題です。現在Franka Pandaに限定されている実装を他のマニピュレータに拡張することで、手法の汎用性がさらに検証されることになります。単一政策による多実体対応の実現は、産業応用において極めて価値の高い発展となるでしょう。

知覚モダリティの拡張も有望な方向性です。現在の点群ベースアプローチをRGBやRGB-D入力と組み合わせることで、より構造化されていない環境での性能向上が期待されます。特に、閉塞の多い狭い環境や照明条件の変化する環境での堅牢性向上は、実用展開において重要な改善点となります。

長期自律性と継続学習の統合も興味深い研究方向です。現在の手法は事前訓練とオフライン微調整に依存していますが、展開後の継続的な改善機構の導入により、新しい環境や予期しない状況への適応能力を向上させることができます。人間からのフィードバック学習や強化学習との統合により、より適応的で学習可能なシステムの実現が期待されます。