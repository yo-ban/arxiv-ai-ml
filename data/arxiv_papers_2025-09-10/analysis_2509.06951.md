# F1: A Vision-Language-Action Model Bridging Understanding and Generation to Actions

## 基本情報
- arXiv ID: 2509.06951v1 (https://arxiv.org/abs/2509.06951v1)
- 著者: Qi Lv, Weijie Kong, Hao Li, Jia Zeng他
- 所属: Shanghai AI Laboratory, Harbin Institute of Technology (Shenzhen)
- 投稿日: 2025年09月10日
- カテゴリ: cs.CV, cs.AI, cs.LG

## 簡単に説明すると
この論文は、ロボットが言語指示を理解して行動する際に「未来の状況を予測する能力」を組み込んだ新しいVision-Language-Action（VLA）モデル「F1」を提案しています。従来のVLAモデルは現在の状況のみから行動を決定する反応的なアプローチでした。F1は未来の視覚状態を予測し、それを目標として行動を計画するという先見性を持った意思決定システムです。

関連リンクについて、以下のような情報が公開されています。
- Homepage: https://aopolin-lv.github.io/F1-VLA
- Github: https://github.com/InternRobotics/F1-VLA  
- Huggingface: https://huggingface.co/InternRobotics/F1-VLA

## 1. 研究概要
### 1.1 背景と動機
近年、Vision-Language-Action（VLA）モデルは、ロボットに自然言語による指示を理解させ、視覚的に豊かな環境でタスクを実行させるための重要な技術として注目されています。しかし、従来のVLAモデルの多くは純粋に反応的な状態→行動のマッピングに依存しています。これによって短視的な行動と動的な環境における脆弱性という根本的な限界を抱えています。

実際の環境では、物体の移動と文脈の変化が発生します。時間経過とともに指示が展開されるため、ロボットは曖昧な言語を理解します。また、多様な物体を扱い、シーンの進化する中で長期的な時間的一貫性を維持します。現在の反応的なアプローチでは、未来の状態に関する予測的な先見性がありません。そのため、方針が短視的になり、分布の変化に対して脆弱になってしまいます。

### 1.2 主要な貢献
本研究では、予測的な逆動力学モデリング（Predictive Inverse Dynamics Models）にインスパイアされた包括的な解決策を提案しています。主要な技術的貢献について、以下のような要素が挙げられます。

第一に、視覚的先見性を統合した新しいVLAパラダイムが提案されています。専用の生成エキスパートを通じて視覚的観測を予測します。行動予測を反応的プロセスから計画ベースのプロセスに変更しました。

第二に、3段階の段階的訓練レシピが開発されています。理解、生成、行動の各モジュールを段階的に統合する訓練スキームです。ロバスト性と汎用性を確保しています。

第三に、動的環境での優越性が実証されています。シミュレーションと実世界の両方のタスクにおいて検証しました。特に挑戦的な動的環境や長期タスクにおいて、反応的ベースラインに対して17%の改善を示しています。

## 2. 提案手法
### 2.1 手法の概要
F1フレームワークは、Mixture-of-Transformer（MoT）アーキテクチャを採用した包括的なVLAモデルです。3つの専門モジュールから構成されています。理解エキスパート、生成エキスパート、行動エキスパートがそれぞれ異なる役割を担っています。

理解エキスパートは、言語指示と視覚観測を処理して共有のマルチモーダル表現を生成します。生成エキスパートは、この表現から目標条件付き視覚先見を予測します。行動エキスパートは、予測された先見画像を用いて逆動力学の問題として行動生成を実行します。

### 2.2 技術的詳細
アーキテクチャ設計において、3つの重要な技術的革新が導入されています。

第一に、次スケール予測メカニズムが採用されています。複数の解像度レベルで視覚先見を効率的に生成します。Residual VQ-VAEを用いて画像を16×16パッチに分解し、複数の空間スケールにわたって離散トークンを生成します。

第二に、Understanding-Generation-Action（UGA）の段階的注意メカニズムを実装しています。各エキスパート内では双方向の内部注意を処理します。エキスパート間では因果的階層が維持されます。生成エキスパートは理解エキスパートに注意し、行動エキスパートは両方に注意しますが、逆方向の情報流はありません。

第三に、Flow Matching手法が行動予測に適用されています。連続行動空間におけるガウスノイズから専門家行動への変換を学習します。分布レベルでの監督を提供し、離散化されたトークンでの交差エントロピー損失よりも豊富な勾配信号を与えます。

### 2.3 新規性
本提案手法の新規性は、従来の反応的VLAモデルとの根本的な違いにあります。既存のアプローチは現在の状態から直接行動を予測していました。F1は視覚的先見を明示的な計画信号として活用します。

技術的な差別化要因として、統合されたアーキテクチャが挙げられます。理解、生成、行動が単一のフレームワーク内で結合されています。従来の手法では、これらの機能が分離されていたり、部分的にしか統合されていませんでした。

訓練手法においても革新性が見られます。3段階の段階的訓練レシピにより、各エキスパートの専門性を維持しながら統合を実現しています。これにより、事前訓練された視覚言語モデルの知識を活用しつつ、先見生成と行動実行の能力を追加しています。

## 3. 実験結果
### 3.1 実験設定
実験評価は、シミュレーションベンチマークと実世界タスクの両方で実施されました。シミュレーション環境では、LIBEROとSimplerEnv Bridgeベンチマークが使用されました。実世界実験では、Genie、Franka、ARX LIFT IIの3つのロボットプラットフォームが採用されました。

データセットとして、330k以上の軌跡を含む大規模なコーパスが構築されました。136のタスクと5つの実体にわたってデータが収集されています。LIBERO、Open-X-Embodiment、AgiBotWorldなどの公開データセットが統合されています。

評価指標は、成功率（Success Rate）、把持成功率（Grasp Success Rate）、ランキング（Rank）が採用されました。各タスクにおいて15回の試行が実施され、平均性能が報告されています。

### 3.2 主要な結果
実世界タスクにおいて、F1は優れた性能を示しました。9つのタスクで平均把持率92.6%、平均成功率82.2%を達成しています。最も優秀なベースラインであるπ0と比較して、把持率78.5%、成功率65.2%を上回りました。

特に困難なタスクでの改善が顕著です。Handover（R2H）タスクでは、F1が93.3%の成功率を達成しました。π0の40%、gr00t-N1の13.3%を大きく上回っています。これは動的調整と精密な協調が要求されるタスクでの優位性を示しています。

シミュレーションベンチマークでも一貫した優位性が確認されました。LIBEROベンチマークでは、全4つのサブタスク（Spatial、Object、Goal、Long）で最高性能を記録しています。特にLIBERO-Longタスクでは、長期計画と実行における先見機構の有効性が実証されています。

### 3.3 既存手法との比較
比較実験では、複数の最新VLAモデルとの性能対比が実施されました。Diffusion Policy、OpenVLA、SpatialVLA、π0、gr00t-N1、CoT-VLAが比較対象として選択されています。

LIBEROベンチマークにおいて、F1は全サブタスクで1位のランキングを獲得しました。平均成功率95.7%は、π0の94.4%を上回る結果です。特に長期タスク（LIBERO-Long）では91.3%の成功率で、他の手法を大きく引き離しています。

SimplerEnv Bridgeベンチマークでも同様の傾向が観察されました。事前訓練ありの設定で72.9%の平均成功率を達成しています。次点のπ0-Fastは48.3%にとどまりました。複雑な操作タスクにおける精密制御と配置能力の優位性が確認されています。

## 4. 実用性評価
### 4.1 実装の容易性
F1の実装は、既存の事前訓練済みモデルを活用することで実現されています。理解エキスパートはπ0から初期化され、生成エキスパートは残差VQ-VAEで強化されています。これにより、ゼロからの訓練に比べて開発コストが削減されています。

3段階の訓練レシピは、各段階の目的が明確に定義されています。Stage Iでは生成エキスパートの整列、Stage IIでは全体の事前訓練、Post-trainでは特定タスクへの適応が実施されます。この段階的アプローチにより、訓練の安定性と収束が保証されています。

### 4.2 計算効率
推論時の計算効率を考慮した設計を採用しています。訓練時は10の解像度レベルで先見予測しますが、推論時は4スケールに制限しています。これによりリアルタイム制御に必要な応答性が確保されています。

Mixture-of-Transformerアーキテクチャにより、各エキスパートの専門性を維持しながら計算資源を効率的に利用します。段階的注意メカニズムにより、情報漏洩を防ぎつつ計算量を最小化します。このメカニズムは、メモリ使用量を30%削減し、推論速度を向上させています。

### 4.3 応用可能性
本手法は複数のロボット実体への適応性を実証しています。Genie、Franka、ARX LIFT IIという異なる形状と機能を持つロボットで成功しています。これは手法の汎用性と転移学習能力を示しています。

動的環境での性能向上は、実世界応用への重要な示唆を提供しています。物体の移動、環境の変化、長期タスクにおける優位性は、産業用ロボットや家庭用ロボットでの活用可能性を示唆しています。

## 5. まとめと所感
### 5.1 論文の意義
本論文は、VLAモデルの根本的な限界である反応性を克服する重要な貢献を提供しています。視覚的先見を明示的な計画信号として統合することで、従来の短視的行動から脱却しています。これは身体性AIの発展において重要なマイルストーンです。

技術的な革新性も高く評価されます。Mixture-of-Transformerアーキテクチャによる統合フレームワークは、理解、生成、行動の3つの機能を効果的に結合しています。段階的訓練レシピは、複雑なマルチモーダルモデルの安定した学習を可能にしています。

実験的検証の包括性も特筆すべきです。シミュレーションから実世界まで、多様な環境とタスクでの評価が実施されています。特に長期タスクと動的環境での優位性は、実用性の高さを示しています。

### 5.2 今後の展望
本研究の発展方向として、より多様な実体とタスクファミリーへの拡張が考えられます。歩行、器用操作、マルチエージェント協調などの分野への適用が期待されます。これにより手法の汎用性がさらに検証されることになります。

先見生成モジュールの改良も重要な課題です。構造化された世界モデルや物理情報を考慮したプライアーの統合により、より正確な長期推論と分布シフトに対するロバスト性が期待されます。

強化学習やオンライン適応戦略との統合も有望な方向性です。先見駆動アーキテクチャと組み合わせることで、模倣を超えた政策の継続的改善が可能になります。開放的環境での継続学習をサポートするシステムの実現が期待されます。