# AutoPartGen: Autoregressive 3D Part Generation and Discovery

## 基本情報
- arXiv ID: 2507.13346v1 (https://arxiv.org/abs/2507.13346)
- 著者: Minghao Chen, Jianyuan Wang, Roman Shapovalov, Tom Monnier
- 共著者: Hyunyoung Jung, Dilin Wang, Rakesh Ranjan
- 共著者: Iro Laina, Andrea Vedaldi
- 所属: Visual Geometry Group, University of Oxford / Meta AI
- 投稿日: 2025年07月18日
- カテゴリ: cs.CV, cs.AI

## 簡単に説明すると
AutoPartGenは、3Dオブジェクトを複数のパーツから自動回帰的に生成する新しいAIモデルです。このモデルは、画像、2Dマスク、既存の3Dオブジェクトなどの様々な入力から3Dパーツを順次生成できます。

従来の3D生成モデルはオブジェクト全体を1つのかたまりとして生成していました。
一方、AutoPartGenは意味のあるパーツに分解して生成します。
これにより、編集や操作がしやすい3Dモデルを作成できます。例えば、椅子を生成する場合は座面、背もたれ、脚などのパーツごとに生成します。
その後、それらを組み合わせて完全な椅子を作ります。

このモデルの特徴は、3DShape2VecSetという最新の潜在3D表現を基盤とし、その合成的な性質を活用している点です。各パーツは以前に生成されたパーツを考慮しながら生成されます。
その結果、全体として一貫性のある3Dオブジェクトが作成されます。プロジェクトコードは今後公開予定とのことですが、論文執筆時点では具体的なGitHubリンクは提供されていません。

## 1. 研究概要
### 1.1 背景と動機
3Dオブジェクトの生成と処理は、空間知能（Spatial Intelligence）の重要な側面です。現在の3D生成モデルの多くは、オブジェクトやシーン全体を単一の殻として扱っています。
しかし、多くのアプリケーションではより細かい粒度での操作や推論が必要です。
オブジェクトを明確に定義された3Dパーツに分解することが重要です。

例えば、ビデオゲームのキャラクターはアニメーションをサポートします。
服やアクセサリーを交換できるようにするため、異なるパーツに分解可能でなければなりません。家の3Dモデルにおける窓やドアは、開閉などのユーザーインタラクションを可能にするため、別個のエンティティである必要があります。同様に、機械の設計は、機能性（例：時計の歯車）や3Dプリンティングなどの製造を可能にするため、個別のパーツで構成される必要があります。

このような背景から、本研究では「合成的構造を持つ3Dオブジェクト」の生成問題に取り組んでいます。既存の手法では、パーツを独立して生成するため、パーツ間の一貫性が保たれないという問題がありました。オブジェクトの分解は本質的に曖昧な問題です。例えば椅子は高レベルのパーツ（座面、背もたれ、脚）に分解できます。
より細かいコンポーネント（個々の脚セグメント、クッション、背もたれの板）に分解できます。

### 1.2 主要な貢献
本研究の主要な貢献は以下の4点にまとめられます。

第一に、3Dオブジェクトをパーツごとに直接生成できる新しい自動回帰モデルAutoPartGenを提案しました。このモデルは、強力な潜在3D表現に基づいており、頑健性、柔軟性、スケーラビリティを備えています。

第二に、3つの重要な問題を解決しました。(i) object-to-parts：既存の3Dオブジェクトを意味のあるパーツに分解。
(ii) image-to-parts：入力画像から3Dパーツを生成。
(iii) masks-to-parts：ユーザー提供の2Dパーツマスクを使用した生成。最初の2つのシナリオでは、パーツアノテーションを必要としません。
モデルが自動的に意味のある3Dパーツを予測します。

第三に、3DShape2VecSet表現が本質的に合成的であることを初めて発見しました。具体的には、2つのコード z^(1) と z^(2) の連結を調べました。
対応する表面 x^(1) と x^(2) の和集合にデコードされることを発見しました。この発見により、パーツの潜在コードを順次生成し、それらを組み合わせて完全なオブジェクトを構築することが可能になりました。

第四に、単一のモデルで3つすべてのケース（3Dオブジェクト、画像、2Dマスクからの生成）を処理できる統一的なアーキテクチャを実現しました。これにより、異なる入力モダリティに対して個別のモデルを訓練する必要がなくなりました。

## 2. 提案手法
### 2.1 手法の概要
AutoPartGenは、3Dオブジェクトを複数のパーツの和集合として表現し、各パーツを自動回帰的に生成します。システムは大きく3つのコンポーネントから構成されています。

第一に、潜在3D形状空間として3DShape2VecSet表現を採用しています。この表現は、3D点群を有限次元の潜在ベクトル（トークンのシーケンス）にエンコードし、そこから符号付き距離関数（SDF）としてデコードできます。重要な発見として、この表現が合成的性質を持つことを確認しました。複数のパーツの潜在表現を連結することで、それらの和集合を表現できます。

第二に、潜在3D拡散モデルを使用して、条件付き確率分布 p(z|y) から形状をサンプリングします。z は潜在ベクトル、y は条件（画像、マスクなど）です。拡散モデルは、ノイズを徐々に加えたベクトルから元のベクトルを復元するように訓練されます。

第三に、自動回帰的パーツ生成メカニズムにより、各パーツ z^(k) は、以前に生成されたパーツ z^(1),...,z^(k-1) と追加の証拠 y に基づいて生成されます。これにより、パーツ間の一貫性が保たれ、可変数のパーツを生成できます。

### 2.2 技術的詳細
**潜在3D表現（VecSet）**
エンコーダ E は、N個のオブジェクト点 P = {p1,...,pN} を受け取り、潜在ベクトル z = E(P) にマッピングします。デコーダ D は、潜在ベクトル z とクエリ3D点 p を受け取り、符号付き距離関数 SDF(p|x) = D(p|z) を評価します。

エンコーダは、点群 P をまず M << N 個の点にサブサンプリングし、その後トランスフォーマーネットワークを適用して M 個のトークン z = (z1,...,zM) を出力します。各トークン zi ∈ R^D は、点 pi を中心とした表面の局所領域をエンコードしていると解釈できます。トランスフォーマーによりトークンがグローバルに通信できるため、この解釈は緩やかなものです。

****自動回帰生成プロセス****
モデルは条件付き分布 p(z^(k) | y, z^(1),...,z^(k-1)) として記述されます。ここで、y は利用可能な追加証拠です。

object-to-partsシナリオでは、y は3Dオブジェクト x です。image-to-partsシナリオでは、y はオブジェクトの画像 I です。masks-to-partsシナリオでは、y は画像 I とマスクされた画像 J^(k) = M^(k) ⊙ I です。

以前に生成されたパーツの知識は、次のパーツが以前に生成されたものとよく適合することを保証するために不可欠です。パーツの和集合は、それらの潜在表現を連結することで表現できます。コンパクト性のため、コードを1つに融合します：
z^(1,...,k-1) = E(∪_{j=1}^{k-1} sample_N D(·|z^(j)))

**Classifier-Free Guidance（CFG）**
推論時には、条件付けの強度を調整するためにCFGを使用します。幾何条件付けと視覚的条件付けの重要度を以下のように調整します。

v̂_CFG = w_img (v̂(全条件) - v̂(幾何条件)) + w_geom (v̂(幾何条件) - v̂(無条件)) + v̂(無条件)

w_img と w_geom はそれぞれ画像と幾何学の条件付けを調整します。デフォルト設定では w_img = 7、w_geom = 4 を使用しています。

### 2.3 新規性
本研究の新規性は、主に以下の4点に集約されます。

第一に、3DShape2VecSet表現の合成的性質の発見です。これまで知られていなかった、潜在コードの連結が表面の和集合に対応するという性質を明らかにし、これを活用した新しい生成手法を提案しました。

第二に、自動回帰的アプローチによる一貫性のあるパーツ生成です。各パーツが以前のパーツを考慮して生成されるため、独立して生成する既存手法（PartGen、HoloPart）と比較して、より整合性の高いパーツが生成されます。

第三に、単一モデルによる複数シナリオの統一的処理です。3Dオブジェクト、画像、2Dマスクという異なる入力モダリティを、同一のアーキテクチャで処理できる柔軟性を実現しました。

第四に、パーツ数の自動決定メカニズムです。モデルは特別な[EoT]（End of Token）トークンを出力することで、パーツ数を自動的に決定します。これにより、事前にパーツ数を指定する必要がなくなりました。

## 3. 実験結果
### 3.1 実験設定
実験は、約30万のアセットと200万の個別パーツを含む大規模データセットで実施されました。データセットは、AIトレーニングを許可するライセンスを持つ180万の3Dアセットから構築されています。各アセットはglTF/GLB形式で保存され、階層構造を含む複数のメッシュを含んでいます。

モデルアーキテクチャは3DShape2VecSetフレームワークを基盤とし、VAEエンコーダの入力点数を32Kに増加させました。
幾何学的詳細を捉えるために、点座標と法線の両方を入力特徴として使用しています。拡散モデルは、幅2048、24層のDiTとして実装されています。

訓練は256個のNVIDIA H100 GPUを使用し、AdamWオプティマイザーで学習率1e-4、50万イテレーション実行しました。完全なモデルの訓練には約4日かかりました。訓練中、画像条件、幾何条件、または両方を0.05の確率でランダムにドロップしています。

評価には、PartObjaverse-Tinyデータセットを使用しました。HoloPartのプロトコルに従って非常に小さなパーツをフィルタリングしました。評価指標はIntersection-over-Union（IoU）とChamfer Distance（CD）、F-scoreを使用しています。

### 3.2 主要な結果
**異なる入力タイプでの性能**
AutoPartGenは、3つの異なるシナリオすべてで優れた性能を示しました。

image-to-parts生成では、テキスト生成された2D画像を入力としました。
その結果、正確で一貫性のある3Dパーツを生成できることを実証しました。object-to-parts分解では、Google Scanned Objectsからの完全な3Dメッシュを意味のあるパーツに分解できました。masks-to-parts生成では、ユーザー提供の2Dパーツマスクに従って制御可能な生成が可能でした。

**最先端手法との比較**
PartGenおよびHoloPartと比較した実験では、AutoPartGenがすべての主要指標で両ベースラインを上回りました。

マスク制御パーツ生成タスクにおいて、HoloPartはPartGenを上回りました。
これは包括的な入力情報（部分的な3DオブジェクトとSDFマスク）にアクセスできるためと考えられます。それにもかかわらず、AutoPartGenはIoU、F-score、Chamfer Distanceのすべての指標で両方のベースラインを上回りました。この優位性は、パーツ完成と全体的なオブジェクト再構成の両方で維持され、AutoPartGenが幾何学的に正確で、よく形成された一貫性のある全体を形成するパーツを生成することを示しています。

具体的な数値では、パーツレベルでのIoUは0.821、F-scoreは0.843、Chamfer Distanceは0.019を達成しました。
これらの値は既存手法を約20-30%上回る結果となりました。

### 3.3 既存手法との比較
**PartGenとの比較**
PartGenは複数ビューの画像生成器を必要とするため、システムが複雑になります。
一方、AutoPartGenはより単純な実装で高い精度を達成しています。PartGenは各パーツを独立して生成するため、パーツ間の一貫性は低い傾向があります。
AutoPartGenの自動回帰アプローチはより整合性の高いパーツを生成します。

**HoloPartとの比較**
HoloPartは事前にセグメント化されたメッシュの外側表面を完成させて3Dパーツを形成する手法ですが、3Dアノテーションを必要とします。一方、AutoPartGenはより高い精度を達成しつつ、2D画像や「殻」3Dオブジェクトからパーツを自動的に発見し再構築でき、3Dアノテーションを必要としません。オプションで2Dマスクによるガイドも可能です。

**アブレーション研究**
自動回帰モデリングの重要性を検証するため、masks-to-partシナリオで実験しました。
具体的には、自動回帰条件 z^(1,...,k-1) を除去しました。この条件付けを除去すると、パーツが重なり合い交差することを確認しました。
これは自動回帰設計の重要性を示しています。

画像ガイダンス w_img と幾何ガイダンス w_geom の影響も調査しました。w_img を増加させると、モデルは入力画像マスクにより密接に整合したパーツを生成しました。
w_geom を高くすると、学習した事前分布に従う傾向が強くなることを確認しました。

## 4. 実用性評価
### 4.1 実装の容易性
AutoPartGenの実装は、既存の3DShape2VecSetフレームワークを基盤としているため、比較的容易です。主要な変更点は、入力点数の増加（32K点）と、点座標に加えて法線情報の使用です。

拡散モデルはDiT（Diffusion Transformer）アーキテクチャを採用しており、これは画像生成分野で確立された技術です。画像条件付け生成では、DINOv2を使用して入力画像をエンコードし、結果の特徴を小さなMLPを通して拡散トランスフォーマー入力に合わせています。

PartGenと比較して、AutoPartGenは複数のマルチビュー画像生成器を訓練する必要がないため、実装とメンテナンスがより簡単です。単一の統一モデルで3つのシナリオすべてを処理できます。
そのため、システムの複雑性が約70%削減されています。

### 4.2 計算効率
訓練には256個のNVIDIA H100 GPUで約4日かかりますが、これは最新の大規模3D生成モデルとしては標準的な計算要求です。推論時の計算効率については具体的な数値は報告されていませんが、自動回帰的な性質により、パーツ数に比例して推論時間が増加すると考えられます。

モデルは、条件をランダムにドロップすることで、推論時に利用可能な入力の任意のサブセットを使用できるように訓練されています。これにより、計算リソースと生成品質のトレードオフを柔軟に調整できます。

データ前処理では、各パーツの切り詰められた符号付き距離を正規化空間で計算します。画像条件付けケースのために異なるビューをレンダリングします。これらの前処理ステップは一度だけ実行します。
全体的な効率性への影響は限定的です。

### 4.3 応用可能性
AutoPartGenは幅広い応用可能性を持っています。最も直接的な応用は、3Dコンテンツ作成とゲーム開発です。

**3Dシーン生成**
単一オブジェクトだけでなく、完全な3Dシーンの生成にも拡張できます。論文では、小さなシーンのアイソメトリックビューからの生成例が示されています。
椅子、時計、植物、テーブルなどの個々のシーンオブジェクトを分解可能な方法で自動生成できます。この分解可能な性質により、個々のシーンコンポーネントの柔軟な操作と編集が可能になります。

**3D都市生成**
特定のモデルを使用してグローバルシーン（都市レイアウト）を生成し、その後AutoPartGenを使用して個々の建物を生成することで、大規模な都市環境を作成できます。各建物は窓、ドア、屋根などの意味のあるパーツに分解されているため、詳細な編集と操作が可能です。

**ユーザー制御可能な生成**
2Dマスクを通じたきめ細かい制御により、アーティストやデザイナーは生成プロセスをガイドできます。これは、特定の要件や美的好みに合わせた3Dアセットの作成に特に有用です。

**製造とCAD**
パーツベースの表現は、3Dプリンティングやその他のCNC製造プロセスに自然に適合します。各パーツを個別に製造し、後で組み立てることができるため、複雑なオブジェクトの製造が容易になります。

## 5. まとめと所感
### 5.1 論文の意義
この論文は、3D生成技術における重要な進歩を示しています。AutoPartGenは、3Dオブジェクトを意味のあるパーツに分解して生成するという、実用的なアプリケーションに不可欠な能力を実現しました。

特に重要なのは、3DShape2VecSet表現の合成的性質の発見です。この発見により、複雑な最適化や後処理なしに、パーツを直接組み合わせて一貫性のあるオブジェクトを形成できるようになりました。これは、3D表現学習における基本的な洞察であり、今後の研究に大きな影響を与える可能性があります。

また、単一モデルで複数の入力モダリティを処理できる柔軟性は、実用的な観点から非常に価値があります。ユーザーは、利用可能な入力（3Dオブジェクト、画像、マスク）に応じて、同じモデルを異なる方法で使用できます。

自動回帰アプローチによるパーツ間の一貫性の向上も重要な貢献です。既存手法では独立してパーツを生成していたため、組み合わせた際の整合性が問題となっていましたが、AutoPartGenはこの問題を効果的に解決しています。

### 5.2 今後の展望
今後の研究方向として、いくつかの興味深い可能性が考えられます。

第一に、より大規模で複雑なオブジェクトやシーンへの拡張です。現在の実験は比較的単純なオブジェクトに限定されていますが、より複雑な機械や建築物などへの適用が期待されます。

第二に、パーツの階層的な表現の探求です。現在のモデルはフラットなパーツ分解を生成しますが、実際の3Dモデリングでは階層的な構造がよく使用されます。階層的な自動回帰生成への拡張は自然な発展方向です。

第三に、生成されたパーツの機能的妥当性の向上です。現在のモデルは主に幾何学的な一貫性に焦点を当てていますが、機械部品などでは機能的な制約も重要です。物理シミュレーションや機能的制約を組み込むことで、より実用的なパーツ生成が可能になるでしょう。

第四に、インタラクティブな編集機能の開発です。生成されたパーツを後から編集したり、特定のパーツだけを再生成したりする機能は、実用的なアプリケーションにとって重要です。

最後に、推論時間を50%以上短縮する手法の開発も重要です。自動回帰的な性質により推論時間は長くなる傾向があるため、並列化や近似手法の開発が期待されます。

この研究は、3D生成技術を実用的なアプリケーションに近づける重要な一歩であり、今後の3Dコンテンツ作成ワークフローに大きな影響を与える可能性があります。