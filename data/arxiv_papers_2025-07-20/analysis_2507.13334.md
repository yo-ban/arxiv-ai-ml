# A Survey of Context Engineering for Large Language Models

## 基本情報
- **arXiv ID**: 2507.13334v1 (https://arxiv.org/abs/2507.13334)
- **著者**: Lingrui Mei, Jiayu Yao, Yuyao Ge, Yiwei Wang, Baolong Bi, Yujun Cai, Jiazhi Liu, Mingyu Li, Zhong-Zhi Li, Duzhen Zhang, Chenlin Zhou, Jiayi Mao, Tianze Xia, Jiafeng Guo, Shenghua Liu
- **所属**: Institute of Computing Technology, Chinese Academy of Sciences; University of California, Merced; The University of Queensland; Peking University; Tsinghua University; University of Chinese Academy of Sciences
- **投稿日**: 2025年07月17日
- **カテゴリ**: cs.CL, cs.AI

## 簡単に説明すると
この論文は、大規模言語モデル（LLM）に与える「文脈（コンテキスト）」を体系的に設計・最適化する「コンテキストエンジニアリング」という新しい学問分野を提案し、包括的なサーベイを行ったものです。1400本以上の研究論文を分析し、従来の「プロンプトエンジニアリング」を超えた、より体系的で高度な情報設計手法を分類・整理しています。

LLMの性能は与えられる文脈情報によって根本的に決定されるという認識のもと、単純なプロンプト設計から、外部知識の統合、メモリシステム、ツール連携、マルチエージェントシステムまで、複雑な情報ペイロードの最適化手法を体系化しています。特に、LLMが複雑な文脈を理解する能力は優れているが、同等に洗練された長文の出力を生成する能力には大きな制限があるという「理解と生成の非対称性」を重要な研究課題として指摘しています。

## 1. 研究概要
### 1.1 背景と動機
LLMは自然言語理解、生成、推論において前例のない能力を示していますが、その性能と有効性は根本的に受け取る「文脈」によって支配されています。この文脈は、単純な指示プロンプトから洗練された外部知識ベースまで多岐にわたり、モデルの行動を制御し、知識を拡張し、能力を引き出すための主要なメカニズムとして機能します。

LLMが基本的な指示追従システムから複雑なアプリケーションの中核的な推論エンジンへと進化するにつれて、情報ペイロードを設計・管理する方法も「コンテキストエンジニアリング」という正式な学問分野へと発展しました。しかし、コンテキストエンジニアリングの各領域は主に孤立して研究されており、技術間の基本的な関連性が不明瞭になり、研究者や実践者にとって大きな障壁となっています。

現在のLLMは、自己注意メカニズムの二次計算複雑性、頻繁なハルシネーション、入力のバリエーションに対する問題のある感度、意味的な深さや一貫性を欠く応答など、重要な技術的障壁に直面しています。これらの課題に対処するため、分野全体を統一的に理解できるフレームワークが急務となっています。

### 1.2 主要な貢献
本論文は、コンテキストエンジニアリングに関する初の包括的かつ体系的なレビューを提供し、以下の貢献を行っています。

- **新しい構造化分類法の提案**: 多面的な技術を「基礎的コンポーネント」と「システム実装」に分類する体系的な分類法を開発しました。
- **基礎的コンポーネントの体系化**: コンテキスト取得・生成、コンテキスト処理、コンテキスト管理の3つの重要な段階を通じて、コンテキストエンジニアリングの体系的なパイプラインを定義しました。
- **システム実装の分析**: 高度なRAG、メモリシステム、ツール統合推論、マルチエージェントシステムなど、LLMを外部現実に橋渡しする複雑なアプリケーション指向の実装を詳細に分析しました。
- **重要な研究ギャップの特定**: 現在のモデルが複雑な文脈を理解する能力と、同等に洗練された長文出力を生成する能力との間に存在する根本的な非対称性を明らかにしました。
- **評価手法と将来の方向性**: 評価方法論を議論し、有望な研究方向を示すことで、複雑なランドスケープをナビゲートするための技術的ロードマップを提供しました。

## 2. 提案手法
### 2.1 手法の概要
本論文は、コンテキストエンジニアリングを形式的に定義し、従来のプロンプトエンジニアリングとの違いを明確にしています。コンテキストエンジニアリングでは、文脈Cを動的に構造化された情報コンポーネントのセット（c1, c2, ..., cn）として再概念化し、これらのコンポーネントは関数のセットによってソース化、フィルタリング、フォーマットされ、最終的に高レベルのアセンブリ関数Aによって調整されます。

C = A(c1, c2, ..., cn)

コンポーネントciは以下のような技術領域にマッピングされます：
- c_instr: システム指示とルール（コンテキスト取得・生成）
- c_know: 外部知識（RAG、知識グラフ統合）
- c_tools: 利用可能な外部ツールの定義と署名（関数呼び出し、ツール統合推論）
- c_mem: 以前のインタラクションからの永続的情報（メモリシステム、コンテキスト管理）
- c_state: ユーザー、世界、マルチエージェントシステムの動的状態
- c_query: ユーザーの即時リクエスト

### 2.2 技術的詳細
コンテキストエンジニアリングの最適化問題は、タスクの分布Tに対して、LLMの出力の期待品質を最大化する理想的なコンテキスト生成関数のセット（F = {A, Retrieve, Select, ...}）を見つけることとして形式化されます：

F* = argmax_F E_τ~T [Reward(P_θ(Y | C_F(τ)), Y*_τ)]

ここで、τは特定のタスクインスタンス、C_F(τ)はそのタスクに対してFの関数によって生成されたコンテキスト、Y*_τは理想的な出力です。この最適化は、モデルのコンテキスト長制限|C| ≤ L_maxなどのハード制約に従います。

論文は、動的コンテキストオーケストレーション、情報理論的最適性、ベイズコンテキスト推論などの深い数学的原理を明らかにしています。例えば、知識の取得は、クエリc_queryが与えられたときの目標回答Y*との相互情報量を最大化する問題として定式化できます：

Retrieve* = argmax_Retrieve I(Y*; c_know | c_query)

### 2.3 新規性
従来のプロンプトエンジニアリングと比較して、コンテキストエンジニアリングは以下の点で革新的です：

- **モデル**: 静的な文字列から動的で構造化されたアセンブリへの移行
- **複雑性**: 文字列空間の手動または自動検索から、システムレベルの最適化へ
- **情報**: 固定された情報内容から、制約下でのタスク関連情報の最大化へ
- **状態**: 主にステートレスから、明示的なメモリと状態コンポーネントを持つ本質的にステートフルへ
- **スケーラビリティ**: 長さと複雑さによる脆弱性から、モジュラー構成による複雑性管理へ
- **エラー分析**: 手動検査から、個々のコンテキスト関数の体系的評価とデバッグへ

## 3. 実験結果
### 3.1 実験設定
本論文は包括的なサーベイ論文であるため、独自の実験は行っていませんが、1400本以上の研究論文から収集した実験結果を体系的に分析しています。評価は以下の観点から行われています：

- コンポーネントレベルの評価（プロンプト効果性、長文脈処理、自己文脈化、構造化データ統合）
- システムレベルの統合評価（RAG、メモリシステム、ツール統合推論、マルチエージェントシステム）
- ベンチマークデータセット（GAIA、GTA、WebArena、LongMemEval、BFCL など）

### 3.2 主要な結果
論文で報告されている主要な知見には以下が含まれます：

- **長文脈処理**: 現在のモデルは数百万トークンまでコンテキストウィンドウを拡張できるが、拡張された文脈全体で一貫した理解を維持することに苦労している
- **メモリシステム**: 商用AIアシスタントは長期間のインタラクションを通じて30%の精度低下を示し、メモリの永続性と取得効率に大きな欠陥がある
- **ツール統合**: GPT-4はGTAベンチマークでタスクの50%未満しか完了できず、人間のパフォーマンス92%と比較して大きなギャップがある
- **自己改善**: GPT-4は反復的な自己改善プロセスを通じて約20%の改善を達成できる

### 3.3 既存手法との比較
論文は、各技術カテゴリーにおける最先端の手法を詳細に比較しています：

- **RAG アーキテクチャ**: モジュラーRAG、エージェンティックRAG、グラフ強化RAGの進化と性能向上
- **メモリアーキテクチャ**: 短期記憶（コンテキストウィンドウ）と長期記憶（外部ストレージ）の統合アプローチ
- **マルチエージェントシステム**: KQML、FIPA ACL、MCP プロトコルなどの通信プロトコルの比較

## 4. 実用性評価
### 4.1 実装の容易性
コンテキストエンジニアリングは、モジュラーで構成可能なアプローチを採用することで、実装の柔軟性を大幅に向上させています。FlashRAGのようなフレームワークは、5つのコアモジュールと16のサブコンポーネントを提供し、独立した調整とパイプラインの組み合わせを可能にしています。しかし、複数のコンポーネントを統合する際の相互作用の複雑さは依然として課題となっています。

### 4.2 計算効率
コンテキストエンジニアリングは、リソース集約的な従来のアプローチに対する効率的な代替手段を提供します。具体的には：

- インテリジェントなコンテンツフィルタリングによるトークン消費の削減
- 動的コンテキスト最適化による精密なトークンレベルのコンテンツ選択
- 長文脈推論のための注意操作メカニズム

ただし、自己注意メカニズムのO(n²)スケーリング制限は、超長シーケンスに対する根本的な計算上の課題として残っています。

### 4.3 応用可能性
コンテキストエンジニアリング技術は、以下のような幅広い応用分野で実用化されています：

- **会話型AI**: 長期記憶を活用したパーソナライズされた対話システム
- **科学研究**: ChemCrowのような化学合成設計の自動化
- **医療**: 医療インタラクションのためのメモリ調整を採用したヘルスケアアシスタント
- **自動運転**: 推論、反省、記憶を通じて人間のような知識を注入するDiLu
- **コード生成**: 実行認識デバッグフレームワークによる最大9.8%の性能向上

## 5. まとめと所感
### 5.1 論文の意義
この論文は、コンテキストエンジニアリングを独自の原則、方法論、課題を持つ独立した学問分野として確立する重要な貢献をしています。1400本以上の論文の体系的な分析を通じて、分野の現状を包括的に把握し、将来の研究のためのロードマップを提供しています。

特に重要なのは、LLMの理解能力と生成能力の間に存在する根本的な非対称性の発見です。現在のモデルは、高度なコンテキストエンジニアリングによって強化されると、複雑な文脈を理解する際に顕著な熟練度を示しますが、同等に洗練された長文の出力を生成する際には顕著な制限を示します。この「理解と生成のギャップ」は、今後の研究における決定的な優先事項となっています。

### 5.2 今後の展望
論文は、コンテキストエンジニアリングの将来について以下の方向性を示しています：

- 理論的基礎: 統一された理論的フレームワークの開発、スケーリング法則の理解、構成的理解の向上
- 技術革新: 効率的な長文脈処理のための次世代アーキテクチャの開発。インテリジェントなコンテキストアセンブリシステム、高度なマルチエージェント調整メカニズムも含まれます。
- 応用主導の研究: ドメイン特化、プロトコル標準化、人間とAIの協調、セキュリティと倫理的な考慮事項

コンテキストエンジニアリングは、AIが複雑で多コンポーネントのシステムに向かって進化する中で、ますます中心的な役割を果たすことが期待されます。この学際的な性質は、コンピュータサイエンス、認知科学、言語学、ドメイン固有の専門知識にわたる協調的な研究アプローチを必要とし、文脈認識AIシステムの責任ある開発を支援することになるでしょう。
