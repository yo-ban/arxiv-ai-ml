# Same Content, Different Answers: Cross-Modal Inconsistency in MLLMs

## 基本情報
- arXiv ID: 2512.08923v1 (https://arxiv.org/abs/2512.08923)
- 著者: Angela van Sprang, Laurens Samson, Ana Lucic, Erman Acar, Sennay Ghebreab, Yuki M. Asano
- 所属: University of Amsterdam, City of Amsterdam, University of Technology Nuremberg  
- 投稿日: 2024年12月11日
- カテゴリ: cs.AI, cs.LG, cs.CV

## 簡単に説明すると

この研究は、マルチモーダル大規模言語モデル（MLLMs）の重大な問題である「クロスモーダル不整合」を体系的に評価する革新的なベンチマークを提案している。同じ意味の情報をテキスト、画像、混合の3つの形式で提示したとき、現在のMLLMsはすべて異なる回答を出力することを15のモデルを用いて実証した。

RESTとREST+という2つの包括的ベンチマークを開発し、OCRエラーを制御した上でもこの不整合が存在することを明確に示した。特にSoEBenchという新しい連立方程式タスクを導入し、事前学習データによる汚染を排除した純粋な評価を可能とした。最も興味深い発見は、視覚的特性（解像度や色）がOCRが正確でも性能に影響を与えることと、モデルの内部表現の類似度と一貫性スコアが相関することである。

## 1. 研究概要

### 1.1 背景と動機

近年のマルチモーダル大規模言語モデル（MLLMs）は、視覚と言語を共有空間で表現するよう訓練されていますが、この共同表現が実際にモダリティ間で一貫した推論を可能とするかは疑問視されています。既存研究では、異なるMLLMsにおいて「モダリティギャップ」の存在が指摘されており、テキストと画像の埋め込みが共同埋め込み空間内の異なる領域を占めることが知られています。

この問題は実用上深刻です。DeepSeek-OCRなどの研究では、テキストを画像としてレンダリングしてトークンコストを削減するアプローチを提案していますが、モデルが画像からテキストを正確に読み取れても、ネイティブテキストと同等の推論が可能かは明確ではありません。既存のベンチマークは、単一モデルの評価に留まるか、OCR性能の制御を行わないため、テキスト認識の失敗と推論不整合を混同する可能性がありました。

この「クロスモーダル不整合」とは、意味的に同一の情報を異なるモダリティで提示した場合に、入力形式にのみ基づいて異なる結果を生成する現象です。この問題の体系的評価と理解は、MLLMsの信頼性と実用性の向上において極めて重要です。

### 1.2 主要な貢献

本研究の主要な貢献は以下の3点である。

RESTとREST+ベンチマークの提案として、クロスモーダル不整合を測定する包括的なベンチマークシステムを開発した。従来ベンチマークとは異なり、OCR複雑性を制御し、事前学習時に見られなかったことが保証されるSoEBenchタスクを含んでいる。

15のフロンティアMLLMsの体系的評価では、現在の15のMLLMsを評価し、OCRを制御した上でも実質的な不整合（最低10%の不整合）が存在することを実証した。これにより、現在のモデルが捉えきれていない解決可能な問題の顕著なギャップを明らかにした。

内部表現の機構的分析では、同じ情報を異なるモダリティで表現したサンプルの内部表現を分析し、それらがマッチしないペアより高いコサイン類似度を示すこと、およびこの類似度の大きさが一貫性スコアと相関することを発見した。

## 2. 提案手法

### 2.1 手法の概要

RESTとREST+は、MLLMsのクロスモーダル推論一貫性を体系的に評価するベンチマークです。RESTは同じ意味内容を3つの形式（テキストのみ、画像のみ、混合）で提示し、OCR性能の潜在的な交絡効果を制御しながら、モデルが同一情報に対して一貫した出力を生成するかを測定します。

ベンチマークは4つの評価タスクで構成されている。OCRタスクは画像からレンダリングされたテキストを抽出し、テキストタスクはテキスト質問に回答し、画像タスクは画像としてレンダリングされた質問に回答し、混合タスクは画像としてのコンテクストとテキストとしての質問を組み合わせる。

SoEBench、MMLU、ARC、GSM-Symbolicの4つのデータセットを使用し、OCR複雑性を最小化するため800文字以下の質問に制限し、LaTeXコードを含む質問を除外した。テキストを読みやすくするため、白背景に高解像度（DPI 200）の黒いDejaVu Sansテキストで画像をレンダリングした。

### 2.2 技術的詳細

REST+は視覚的特性（解像度、フォント、色）がクロスモーダル不整合に与える影響を研究するため、各画像の10の視覚的変換を作成します。3つのフォントファミリー（DejaVu Sans、Courier New、Cursive）、3つのDPI値（50、100、200）の9つの組み合わせと、DejaVu Sansを使用した200 DPIでの1つの色付きバリアント（赤、緑、青、シアン、マゼンタ、黄色）を含みます。

SoEBenchは連立一次方程式の解を求めるタスクスイートで、シンボリック変数を含み基本的な代数推論を要求し、すべてのインスタンスは単一の整数解を持つよう生成されています。制限されたシンボルセット（数字0-9と文字A-E）によりOCR複雑性を削減し、性能差が認識エラーではなく推論を反映することを保証しています。

評価指標として、Render-Equivalence Rate（RER）を導入し、全モダリティで同じ回答を与える質問の割合を測定します。Cross-Modality Failure Rate（CFR）は少なくとも1つのモダリティで解答可能だが全モダリティでは解答不可能な質問における不整合を評価します。Max Modal Coverage（MMC）は少なくとも1つのモダリティを通じて解決される質問の割合を表します。

### 2.3 新規性

本研究の技術的新規性は以下の点にあります。

従来の評価手法とは異なり、RESTはOCR性能を明示的に制御し、テキスト認識の失敗と推論不整合を分離しています。これまでのベンチマークは単一モデルの評価に限定されるか、実際の読みやすさを制御しないため、認識失敗と推論不整合を混同していました。

SoEBenchの導入により、事前学習データ汚染を排除した純粋な評価を可能としました。既存のベンチマークではデータ汚染の影響を除外することは困難でしたが、新規生成されたタスクにより真の推論能力を測定できます。

REST+における視覚的特性の体系的変化は、OCRが正確でも視覚的特性が性能に影響することを示した初の研究です。従来研究ではOCRエラーと推論不整合の混在により、この効果は明確に分離されていませんでした。

内部表現の機構的分析により、表現類似度と行動レベルの一貫性の関連を初めて実証しました。これはモダリティギャップが性能に与える影響の直接的証拠を提供し、今後の改善方向を示唆しています。

## 3. 実験結果

### 3.1 実験設定

15の最先端MLLMsを対象として包括的な評価を実施しました。対象モデルはGPT-5-mini、Claude Haiku 4.5、Gemini 2.5 Flash Lite、GPT-4o-mini等のクローズドソースモデルと、Qwen-2.5 32B、InternVL3-14B、Phi-4等のオープンソースモデルを含みます。

RESTベンチマークの各質問に対してMLLMは4つの入力プロンプトを受け取ります。まずOCR性能を確認するため画像の転写を行い、続いてテキスト、混合、画像タスクでChain-of-Thought（CoT）プロンプティングを使用します。出力は1024トークンに制限し（SoEBenchは2048）、再現性のため温度を0に設定しています。

評価は4つのデータセット（SoEBench、MMLU、ARC、GSM-Symbolic）で実施し、OCR複雑性最小化のため800文字以下の質問に制限し、LaTeXコードを含む質問を除外しました。Character Error Rate（CER）でOCR性能を評価し、文字挿入、削除、置換を測定して参照長で正規化しています。

### 3.2 主要な結果

RER一貫性スコアはMLLMs間で大幅に変化し、6.6%から90.7%の範囲を示しました。OCR正解の質問のみを評価した場合、全モデルでRERスコアが等しいかわずかに高くなり、OCRエラーが一貫性に影響することとOCR複雑性を制御する取り組みが正当であることが確認されました。

クローズドソースモデルが最高の一貫性スコアを達成し、GPT-5-miniとClaude Haiku 4.5がそれぞれ90.7%と90.3%（OCR正解時）を記録しました。オープンソースモデルの中では、Qwen-2.5 32BがRER 84.7%で首位を占めています。

CFRの結果は憂慮すべきパターンを明らかにしました。GPT-5-miniでさえ、少なくとも1つのモダリティで解決可能な質問の8.7%で全モダリティ間の一貫した解決に失敗しました。この不整合はPhi-4では82.3%に達し、正解の取得が入力形式（テキスト、混合、画像）に依存することを意味します。

ほぼ全モデルがテキストモダリティで最良の性能を示し、統計的t検定により、モデルがテキストを画像より好み（t=17.7、p<0.05）、画像が混合より困難（t=-7.2、p<0.05）であることが確認されました。複数のモデルファミリー（Phi、Gemma、ChatGPT、Claude）が一貫してテキストで最良性能を達成しています。

### 3.3 既存手法との比較

SoEBenchでの評価により、データ汚染とOCRの影響を除外した純粋な比較を実施しました。全モデルがOCRをほぼ完璧に実行でき（DeepSeek-Tinyを除く）、GemmaとGPTモデルは依然としてテキストモダリティで優位性を示しました。興味深いことに、他のベンチマークで大幅なテキスト優位性を示していたPhi-4が画像モダリティでより良い性能を発揮しました。

「OCR先行、後解決」アプローチの評価では、一部モデル（GPT-5-mini、Phi-4、Gemma-3-4B）で多くのRESTベンチマークでの改善が見られました。しかし、一部のケース（例：InternVL3 2BのSoEBenchでの性能）では性能が大幅に悪化し、OCRがクロスモーダル不整合の交絡因子ではないことが補強されました。

REST+での評価では、より困難な条件下でのOCR性能低下とRER・CFRスコアの悪化が確認されました。高いCFR値（最良：30.2%）は入力形式の重要性を示し、異なるフォント、色、解像度が回答の正誤を決定する可能性を明らかにしました。興味深いことに、多くのモデルが黒文字より色付きテキストで良好な性能を示し、フォント解像度がOCR性能を制御した場合でも不整合に影響することが確認されました。

## 4. 実用性評価

### 4.1 実装の容易性

RESTとREST+ベンチマークの実装は比較的容易です。主要なコンポーネントは既存のデータセット（MMLU、ARC、GSM-Symbolic）の再構成と、新規のSoEBenchの生成です。画像レンダリングは標準的なライブラリを使用して実装でき、OCR評価も確立された手法により実現可能です。

ベンチマーク評価の自動化は、正規表現による答えの解析と標準的な評価指標の計算を通じて実現されています。内部表現分析はオープンソースモデルの隠れ状態にアクセス可能なため比較的実装しやすく、コサイン類似度計算は標準的な数学ライブラリで処理できます。

ただし、15の異なるMLLMsとの統合には、各モデルのAPIインターフェースや推論形式の差異に対応する必要があります。また、REST+での10の視覚的変換の生成は、フォント管理とレンダリングパラメーターの慎重な制御を要求します。

### 4.2 計算効率

ベンチマーク評価の計算コストは合理的です。RESTは各質問に対して4つのタスク（OCR、テキスト、画像、混合）を実行するため、標準的なベンチマークより4倍の推論が必要ですが、質問数の制限により管理可能です。SoEBenchは新規生成されるため既存データセットより小規模で、計算コストを効果的に制御できます。

REST+はより計算集約的で、各質問に対して10の視覚的変換を評価するため推論回数が大幅に増加します。しかし、MLLMsの推論コストを考慮すると、画像のレンダリングと前処理コストは相対的に無視できます。

内部表現分析では、各モデルの隠れ状態を抽出する必要があるため追加の計算オーバーヘッドが発生しますが、コサイン類似度計算自体は軽量です。全体として、学術研究での使用には実用的な計算効率を維持しています。

### 4.3 応用可能性

RESTとREST+ベンチマークの応用可能性は非常に広範囲です。まず、MLLM開発者にとって、モデルの信頼性と一貫性を評価する重要なツールとして活用できます。特に、本研究で明らかになったテキストモダリティの優位性は、モデルアーキテクチャの改善方向を示唆します。

実用的なMLLMsシステムの展開において、このベンチマークは入力形式による性能変動を予測し、最適なモダリティ選択を支援できます。例えば、DeepSeek-OCRのようなテキスト圧縮手法の評価において、トークン効率だけでなく推論品質への影響も測定できます。

教育と研究分野では、このベンチマークはモダリティギャップの理解と、マルチモーダル表現学習の改善に貢献します。内部表現の分析手法は、他のマルチモーダルタスクにも適用可能で、モデル解釈可能性の向上に寄与します。

産業応用では、文書処理、視覚質問応答、教育技術などの分野でMLLMsの信頼性評価に活用できます。特に、視覚的特性（解像度、色、フォント）が性能に与える影響の知見は、実世界での展開時のロバスト性向上に重要です。

ただし、現在のベンチマークは主に英語に焦点を当てているため、多言語環境への拡張が今後の課題となります。また、より複雑な視覚的コンテンツや専門ドメインへの適用には、追加的な検証が必要です。

## 5. まとめと所感

### 5.1 論文の意義

この研究は、MLLMs分野における重要かつ実用的な問題に光を当てた画期的な貢献です。従来、マルチモーダル能力の評価は主に精度に焦点を当てていましたが、本研究は「一貫性」という新しい評価軸を導入し、現在の最先端モデルにおける根本的な限界を明らかにしました。

技術的貢献として、RESTとREST+ベンチマークの設計は極めて巧妙です。OCR性能の制御、データ汚染の回避、視覚的特性の体系的変化など、従来研究で見過ごされていた交絡因子を丁寧に分離した実験設計は学術的に非常に価値があります。特に、SoEBenchの導入により純粋な推論能力を測定できるようにした点は、今後のベンチマーク設計の模範となるでしょう。

実用的意義において、15のMLLMsすべてで10-90%の不整合率が観測された事実は、現在のMLLMsの実用展開における重大なリスクを示しています。入力形式によって回答が変わる現象は、医療診断、教育、意思決定支援などの重要なアプリケーションでの信頼性に直接的な影響を与えます。

理論的貢献として、内部表現の類似度と行動レベルの一貫性の相関の発見は、モダリティギャップ問題の機構的理解を大幅に前進させました。これは今後のマルチモーダル表現学習の研究方向に重要な指針を提供します。

### 5.2 今後の展望

技術的発展の方向性として、最も重要な課題はMLLMsアーキテクチャの根本的改善です。本研究で明らかになったテキストモダリティの優位性を踏まえ、モダリティ間のバランスを改善する新しい訓練手法や損失関数の開発が急務です。特に、表現類似度と一貫性の相関を活用した新しい目的関数の設計が有望な研究方向となるでしょう。

ベンチマークの拡張においては、より多様な言語とドメインへの展開が重要です。現在の英語中心の評価から多言語環境へ拡張することで、言語固有のモダリティギャップの理解が深まるでしょう。また、数学的推論以外の複雑な認知タスクへのベンチマーク適用も興味深い研究方向です。

実用的応用では、本研究の知見を活用したアダプティブなモダリティ選択システムの開発が期待されます。入力内容や文脈に基づいて最適なモダリティを動的に選択することで、現在のMLLMsの制約を緩和できる可能性があります。

長期的には、真にモダリティに依存しない推論が可能なMLLMsの実現が最終目標となります。これは、現在のファウンデーション型からの根本的なパラダイムシフトを要求し、新しいアーキテクチャや訓練手法の開発を必要とするでしょう。

社会的影響の観点から、MLLMsの一貫性向上は、AI システムへの信頼性向上と、より広範囲での安全な実用化を可能とします。この研究が示した課題の解決は、AGI実現に向けた重要なマイルストーンの一つとなることでしょう。
