# OSMO: Open-Source Tactile Glove for Human-to-Robot Skill Transfer

## 基本情報
- **arXiv ID**: 2512.08920v1 (https://arxiv.org/abs/2512.08920)
- **著者**: Jessica Yin, Haozhi Qi, Youngsun Wi, Sayantan Kundu, Mike Lambeta, William Yang, Changhao Wang, Tingfan Wu, Jitendra Malik, Tess Hellebrekers
- **所属**: Meta FAIR, University of Michigan, University of Pennsylvania
- **投稿日**: 2024年12月12日
- **カテゴリ**: cs.AI, cs.LG

## 簡単に説明すると
この論文は、人間からロボットへの技能転移を可能にする触覚手袋「OSMO」を提案している。従来の動画による学習では捉えられない接触力の情報を、12個の3軸触覚センサーを搭載した手袋で取得し、人間のデモンストレーションからロボットが直接学習できるシステムを開発した。特に接触力が重要な拭き作業において、触覚情報を含む手法が視覚のみの手法を上回る性能を示した（71.69%対55.75%の成功率）。全てのハードウェア設計、ファームウェア、組み立て説明書がオープンソースで公開されており、プロジェクトウェブサイトは https://jessicayin.github.io/osmo_tactile_glove/ で確認できる。

## 1. 研究概要
### 1.1 背景と動機
人間の巧妙な操作技能をロボットに転移することは、ロボット工学の長年の課題である。
従来、人間のデモンストレーションからの学習は主に視覚データに依存してきたが、接触力という重要な情報が欠如している。
例えば、ニンジンを切る作業を動画だけで理解することは不可能で、成功に必要な繊細な力制御は視覚では捉えられない。
多くの異なる力が視覚的にほぼ同じ外観を生み出すため、力制御の重要な情報は視覚には見えない。

人間データセットは、データ収集の容易さとアクセシビリティによりロボット研究で価値あるリソースとなっている。
人間データセットの大部分は動画で構成されており、AR/VR用ウェアラブルデバイスや視覚ベース手追跡の進歩により、人間動画のロボットデータソースとしての使用がさらに拡大している。
しかし、動画だけでは接触リッチな操作タスクに不可欠な触覚情報が決定的に不足しているため、しばしば不十分である。

既存の触覚センサー技術には異なるトレードオフが存在する。
光学触覚センサーは高空間分解能を実現するが、嵩張り、様々な表面形状への適応が困難である。
抵抗式触覚センサーは薄く柔軟な形状を提供するが、通常は法線力のみを測定し、接触理解に重要なせん断力を見逃している。
磁気触覚センサーは皮膚のような代替手段を提供し、磁気粒子変位の磁力計測定を通じてせん断力と法線力を捉えることができる。

### 1.2 主要な貢献
本研究は、人間からロボットへの技能転移のための触覚手袋ハードウェア研究に重要な貢献を行った。

- 野外での人間デモンストレーション収集のためのOSMO触覚手袋を紹介し、オープンソース化した。ハードウェア設計、センサークロストーク軽減戦略、製造プロセスを提示し、コミュニティでの幅広い使用と人間触覚データの探索を支援するために全設計ファイルをプロジェクトウェブサイトで公開した
- OSMOグローブで収集した人間デモンストレーションのみを使用して接触リッチなロボットポリシーを訓練・展開するアルゴリズムパイプラインを開発した。結果として得られた触覚対応ポリシーは、持続的接触が必要な拭き取りタスクで視覚のみのベースラインを大幅に上回った

## 2. 提案手法
### 2.1 手法の概要
OSMOは、人間からロボットへの技能転移のためのオープンソース触覚手袋である。
設計目標として以下の5つの要件を設定した：(1)デモンストレーション収集時の制約のない人間の器用性、(2)豊富な法線力とせん断力の感知、(3)手全体の触覚カバレッジ、(4)野外手追跡方法との幅広い互換性、(5)人間とロボット手の両方への展開可能性。

手袋は指先と手のひらに12個の3軸触覚センサーを配置し、法線力とせん断力の両方を測定する。
0.3Nから80Nの感知範囲を持つ磁気触覚センサーを使用し、薄い形状でハプティックフィードバックを可能にする。
手のひらセンサーは手のひら運動の主要な平面領域に対応する3つのセクションに配置されている。

OSMOは既存の手追跡システムとの互換性を重視して設計された。
Aria 2スマートグラスやQuest 3などのウェアラブルデバイス、視覚的オクルージョンに堅牢なManusクアンタム手追跡グローブ、汎用RGB動画処理用のHaMeRやDyn-HaMRなどの既製の視覚モデルとの互換性を持つ。

### 2.2 技術的詳細
磁気触覚センサーの感知原理は、磁力計と近傍の軟磁性エラストマー間の相対位置変化に基づく。
軟磁性エラストマーが変形すると、磁力計は磁束の変化を測定し、これを適用されたXYZ力と相関させることができる。
本研究では、生の磁束信号（μT）を直接触覚データとして使用している。

軟磁石パッチは3Dプリント型でシリコーン（EcoFlex 00-30）と磁性微粒子（MQFP-15-7）を1:1:1の比率で混合して鋳造される。
室温で硬化後、パッチは脱型され、パルス磁化器で8秒間2kVで軸方向に磁化される。
各個別センサーPCBは2つの3軸磁力計（BMM350）と1つの6軸IMU（BHI360）で構成される。

12個の密接配置された磁気センサーへのスケーリングは、重大なクロストークを導入する。
近接性により、各磁力計は指と手のひらの動きと変形中に隣接する軟磁石からの磁場摂動を検出し、触覚信号にノイズを加える。
本研究では、クロストーク軽減のための2つの新技術を導入した：(1)外部磁場を減衰させるためのセンサーアーキテクチャに統合されたMuMetal遮蔽、(2)コモンモードノイズを削減するためのタクセルあたりデュアル磁力計差動感知レイアウト。

実験結果により、遮蔽とデュアル磁力計を組み合わせたアプローチが、単一磁力計と比較して平均ノイズを57%削減し、デュアル磁力計・非遮蔽構成と比較して18%削減することが示された。

### 2.3 新規性
本研究の新規性は複数の技術的・方法論的側面に及ぶ。
第一に、既存の柔軟なグローブベースデバイスは運動学のみまたは法線力のみに限定されていたが、OSMOは完全な人間の器用性を保持しながらせん断力と法線力の両方を捉える最初の柔軟プラットフォームである。

第二に、ウェアラブル形状での12個の密接配置磁気センサーのマルチセンサークロストーク軽減に対処した初の研究である。
MuMetal遮蔽と差動感知の組み合わせは、この規模での新しいアプローチを表している。

第三に、人間とロボット手の両方に展開可能な共有プラットフォーム設計により、データ収集と展開時の実施形態ギャップを最小化している。
この設計選択により、通常必要な画像編集、インペインティング、手マスキングステップなしに、既製の視覚エンコーダーの使用が可能になる。

## 3. 実験結果
### 3.1 実験設定
接触リッチな拭き取りタスクでOSMO触覚手袋を使用した人間からロボットへの技能転移を実証した。
拭き取りは一貫した持続的接触圧力の維持が必要で、触覚感知は直接捉えることができるが視覚のみでは推論に苦労するタスクである。

人間デモンストレーションの収集では、ユーザーが触覚手袋を着用し、1台のシーンカメラ（Realsense D435）でIRおよびRGB画像を撮影した。
全データストリームは25HzでROS2バッグファイルとして記録された。
総計140のデモンストレーション、約2時間のデータを記録した。

データ処理パイプラインでは、RGB画像から手姿勢を推定し、SAM2を使用して手マスクを抽出し、HaMeRを適用して3Dキーポイント、手首姿勢、完全な手メッシュを取得した。
FoundationStereoを使用してRealSense IRペアからステレオ深度を計算し、較正された外部パラメータを使用して点群をロボットフレームに投影した。

運動学的リターゲティングでは、MuJoCoの既製IKソルバーを使用して人間の指先と手首軌跡をロボット関節コマンドに変換した。
Ability Handが人間の手と同様のサイズであるため、人間の指先位置を直接IKターゲットとして使用可能である。

### 3.2 主要な結果
OSMO触覚手袋で収集されたデータにより、拭き取りタスクを成功裏に達成する自律ポリシーの訓練が可能であることを示した。
拡散ポリシーとして実装されたポリシーは、RGB画像、ロボット状態、触覚信号を入力として受け取り、アームと手の両方のターゲット関節位置からなるアクションチャンクを出力する。

ネットワークアーキテクチャは2つのコンポーネントで構成される：各モダリティを個別にエンコードする部分（ロボット状態と触覚信号用の2つのMLP、画像特徴抽出用のDINOv2エンコーダー）と、このベクトルに条件付けられた逐次アクションシーケンス予測用のデノイジングネットワーク。

12回のロールアウトでの評価において、触覚手袋+視覚+固有受容の組み合わせが71.69±27.43%の成功率を達成し、視覚+固有受容の55.75±30.01%、固有受容のみの27.12±32.38%を上回った。
成功指標はマーカーピクセルの消去率で測定された。

### 3.3 既存手法との比較
視覚のみの手法と比較して、触覚情報を含む手法は明確な優位性を示した。
視覚のみのポリシーは接触関連の失敗モードを示し、適切な接触圧力を維持できずに拭き取りタスクで失敗することが多かった。

失敗モード分析により、触覚フィードバックなしのポリシーは：(1)表面との接触を失い空中で動作する、(2)不十分な圧力で軽く触れる、(3)過剰な圧力により表面を損傷する、といった問題を示すことが確認された。
触覚対応ポリシーはこれらの接触関連失敗モードを排除し、一貫した適切な接触圧力を維持できた。

クロストーク軽減の有効性も定量的に評価された。
ロボット手で手袋を着用した状態で、指の動きと隣接接触変形の2つのシナリオでクロストークノイズを測定した。
遮蔽とデュアル磁力計の組み合わせアプローチは、単一磁力計ベースラインと比較して平均57%、デュアル磁力計・非遮蔽構成と比較して18%のノイズ削減を達成した。

## 4. 実用性評価
### 4.1 実装の容易性
OSMOの設計は実装の容易性とコミュニティ採用を重視している。
全てのハードウェア設計、ファームウェア、組み立て説明書が完全にオープンソースで公開されており、コミュニティでの幅広い使用と探索を支援している。

ハードウェアコンポーネントは商業的に入手可能な部品で構成されており、特殊な製造設備は不要である。
軟磁石パッチは標準的な3Dプリント型とシリコーン鋳造で製造可能で、PCBは標準的な電子製造プロセスで作製できる。
MuMetal遮蔽は水ジェット切断で加工可能で、組み立ては基本的な電子工作技能で実行できる。

ソフトウェア面では、STM32マイクロコントローラー用のカスタムファームウェアがSTM32CubeIDEでフラッシュ可能で、ネイティブのPythonおよびROS2インターフェースが時間同期センサーパケットをサポートしている。
データ処理パイプラインは確立されたライブラリ（HaMeR、SAM2、FoundationStereo）を使用している。

### 4.2 計算効率
OSMOシステムは計算効率に優れた設計となっている。
触覚データ処理は軽量で、12個のセンサーからの生の磁束信号（μT）を直接使用するため、複雑な信号処理や校正手順が不要である。

実時間性能において、システムは25Hzでデータをストリーミングし、ポリシー推論時にはDINOv2エンコーダーを凍結して計算負荷を削減している。
手姿勢推定段階では、HaMeRは事前訓練された効率的なモデルであり、ステレオ深度計算はFoundationStereoで実行される。

メモリ使用量も効率的で、触覚データは3×2×5次元（XYZ軸×2磁力計×5センサー）の比較的小さな配列として表現される。
差動感知処理は各タイムステップでペア磁力計読み値の単純な減算として実装され、計算オーバーヘッドは最小限である。

### 4.3 応用可能性
OSMOの応用可能性は幅広い分野に及ぶ。
第一に、接触リッチな操作タスクの研究分野において、OSMOは様々なタスク（組み立て、料理、清掃作業）での人間デモンストレーション収集を可能にする。
オープンソース性により、研究者は特定のアプリケーションに合わせて設計を修正・拡張できる。

第二に、OSMOの人間とロボット手の両方への展開可能性により、様々なロボットプラットフォームでの使用が期待される。
本研究ではPsyonic Ability Handで実証したが、Inspire HandやSharpa Handなど他の擬人化ロボット手への自然な拡張が可能である。

第三に、医療リハビリテーションや義肢制御分野での応用可能性がある。
触覚フィードバックを提供する能力により、義肢ユーザーの器用性向上や医療訓練での触覚フィードバック提供に貢献できる可能性がある。

第四に、VR/AR環境での触覚フィードバック提供により、より没入感のあるインタラクション体験の実現が期待される。
既存のAR/VRデバイスとの互換性により、この方向での発展が促進される。

## 5. まとめと所感
### 5.1 論文の意義
本論文は、人間からロボットへの技能転移という重要な研究分野において、触覚情報の活用という新たな視点を提供している。
従来の視覚ベース手法では捉えられない接触力情報を効果的に取得・活用する完整なシステムを提案し、実際のロボットタスクでその有効性を実証した点で高く評価される。

ハードウェア設計から信号処理、機械学習パイプラインまでの包括的なアプローチにより、研究コミュニティが直ちに活用できる実用的なソリューションを提供している。
特に、全設計のオープンソース化により、この分野の研究加速に大きく貢献することが期待される。

技術的貢献も多岐にわたり、マルチセンサークロストーク軽減、人間・ロボット共用プラットフォーム設計、触覚データを活用した拡散ポリシーなど、それぞれが独立して価値のある研究成果となっている。
実験結果の定量的評価と詳細な失敗モード分析により、提案手法の優位性が明確に示されている。

### 5.2 今後の展望
今後の発展方向として、複数の有望な方向性が考えられる。
第一に、より多様なタスクでの評価拡張である。
本研究では拭き取りタスクに焦点を当てたが、組み立て、料理、清掃など他の接触リッチタスクでの性能検証により、手法の汎用性を確認できる。

第二に、センサー技術のさらなる改良である。
現在の12センサー構成をより高密度配置に拡張したり、センサー感度や動作範囲の向上により、より精密な触覚フィードバックが可能になる。
また、温度や振動などの他の触覚モダリティの統合も興味深い方向性である。

第三に、機械学習手法の発展である。
現在の拡散ポリシーから、より効率的な学習アルゴリズムやオンライン適応機能を持つ手法への発展により、より少ないデモンストレーションでの学習や動的環境への適応が可能になる可能性がある。

第四に、他のロボットプラットフォームや身体化への展開である。
二本指グリッパーから多指ハンド、さらには全身ロボットシステムまで、様々な実施形態での触覚フィードバック活用により、ロボット操作能力の大幅な向上が期待される。

最後に、実世界展開での長期信頼性や耐久性の向上も重要な課題である。
日常使用での磨耗や環境条件への対応により、実用的な触覚ロボットシステムの実現に向けた重要な前進が期待される。
