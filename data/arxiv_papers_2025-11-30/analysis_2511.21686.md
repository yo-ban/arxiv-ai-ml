# Matrix: Peer-to-Peer Multi-Agent Synthetic Data Generation Framework

## 基本情報
- arXiv ID: 2511.21686v1 (https://arxiv.org/abs/2511.21686)
- 著者: Dong Wang, Yang Li, Ansong Ni, Ching-Feng Yeh他11名
- 所属: FAIR at Meta
- 投稿日: 2024年11月30日
- カテゴリ: cs.AI, cs.LG

## 簡単に説明すると
この論文は、大規模言語モデル（LLM）の学習に必要な合成データを効率的に生成するために、分散型のピア・ツー・ピア（P2P）マルチエージェントフレームワーク「Matrix」を提案している。従来の集中管理型オーケストレーションの代わりに、エージェント間で制御情報とデータをメッセージとして直接やり取りする仕組みを採用している。これにより、数万規模の同時エージェントワークフローを効率的に実行できるようになった。Meta社のFAIRチームが開発し、オープンソースとして公開予定です。GitHub: https://github.com/facebookresearch/matrix です。

## 1. 研究概要
### 1.1 背景と動機
大規模言語モデルや多モーダル基盤モデルの訓練において、コストが高く、ノイズが多く、プライバシーに敏感な人間作成データセットへの依存を減らすため、合成データの重要性が高まっています。特に最近では、単一のモデルや固定パイプラインではなく、複数の知能エージェント間の相互作用を通じてデータを生成するエージェンティック合成データ生成への注目が集まっています。

この新しいパラダイムにより、コード合成、指示・対話作成、知識に基づく質問応答、多モーダルコンテンツ生成など、多様な生成タスクにおけるマルチエージェント協調が可能となります。これらのワークフローは、従来の線形データ生成パイプラインを超えて、ループを含む複雑な制御フローを持つことが特徴です。

しかし、既存のマルチエージェント合成フレームワークは、集中オーケストレーターに依存することでスケーラビリティのボトルネックを生み出すという問題を抱えている。また、特定ドメインにハードコードされており柔軟性に欠けるという課題もある。大規模展開においては、これらの設計は深刻なスケーラビリティ課題に直面する。

### 1.2 主要な貢献
本研究では、分散型マルチエージェント合成データ生成のための革新的なソリューションを提供しています。

- スケーラブルなランタイムの導入: 数万の同時ワークフローを効率的に実行可能な大規模マルチエージェント合成データ生成ランタイム「Matrix」を開発した。ピア・ツー・ピアエージェントアーキテクチャにより、メッセージ組み込み制御と状態表現を採用している。これにより集中オーケストレーションのボトルネックとバッチレベル同期による遊休時間を排除する。
- 柔軟で拡張可能な設計: 多様なマルチエージェントユースケースに対応する柔軟性と拡張性を提供する。モジュラーアーキテクチャにより、生成ループ、LLM推論用分散サービス、コンテナ化実行などの主要コンポーネントを分離している。システム全体をHydraを通じて設定可能とする。
- 包括的な性能評価: Collaborative Reasoner、NaturalReasoning、Tau2-benchという3つの代表的なケーススタディにおいて評価を実施した。Matrixは、同等のハードウェアリソース下で、専用ベースラインシステムに対して2-15倍高いトークンスループットを達成する。同時に比較可能な出力品質を維持することを実証する。
- オープンソーススタックの活用: SLURM、Ray、vLLM、SGLang、Apptainerなど、オープンソーススタックで構築されている。オープンウェイトモデルとLLM APIプロキシの両方をサポートする。オープン開発と協働研究を促進するためコミュニティに公開される予定である。

## 2. 提案手法
### 2.1 手法の概要
Matrixは、データ生成をデータ間変換として捉える分散ランタイムです。各入力行は独立したタスクを表し、ランタイムは多数のタスクを同時に実行し、それぞれが独自のエージェンティックワークフローを動作させます。

Matrix の核心アイデアは、集中型オーケストレーションを分散化されたメッセージ駆動スケジューリングに置き換えるピア・ツー・ピア（P2P）エージェントアーキテクチャにある。各タスクの状態（オーケストレーションロジック、中間結果、会話履歴を含む）は、エージェント間で渡されるメッセージにシリアライズされる。アクティブエージェントがこの状態を消費・更新し、オーケストレーターによって決定された次のエージェントに発行する。

エージェント自体はステートレスであるため、クラスター全体で弾力的かつ独立的にスケールできます。従来のSparkやRay Dataのような分散実行エンジンでのバッチレベルスケジューリングとは異なり、Matrixはピア・ツー・ピアメッセージオーケストレーションを通じて行レベルスケジューリングを実行し、各タスクがエージェント間を非同期で進行できるようにします。

### 2.2 技術的詳細
システムアーキテクチャは4つの主要コンポーネントで構成されています。クラスター管理は、SLURM上にRayクラスターを実行基板として配置し、Ray ServeがvLLM、SGLang、FastGenを通じて高スループットLLM推論サービスを提供します。コンテナ化実行はApptainerを通じてサポートされ、オンデマンドでステートフル環境を起動可能とします。

設定管理はHydraを通じて行われ、エージェントロール、入出力スキーマ、生成メトリクス、リソース要件などを指定します。設定には制御・データフロー管理を担当するオーケストレーターも定義されます。主要な共有データ構造は会話履歴であり、制御フローはデータ依存条件に基づいてエージェント実行順序とタスク終了を動的に決定します。

コアアルゴリズムでは、各入力データムがオーケストレーターインスタンスにカプセル化され、初期エージェントに渡されます。エージェントはインスタンスを処理し、オーケストレーター状態を更新し、制御を次に指定されたエージェントに転送します。このプロセスは完了まで繰り返し継続されます。

分散サービスでは、計算集約的なタスクをエージェントから分離し、独立してスケールできるようにします。LLM推論にはHTTPオーバーヘッドを回避するgRPCベース通信を採用します。Apptainerコンテナのようなステートフルサービスでは、リソースプールとレジストリを通じてコンテナIDによる効率的なルーティングを実現します。

### 2.3 新規性
本研究の新規性は、マルチエージェント合成データ生成において初めて真のピア・ツー・ピアアーキテクチャを実現した点にあります。従来のフレームワークが集中オーケストレーションに依存していたのに対し、Matrixはエージェント間の直接メッセージ交換により制御とデータフローを管理します。

また、従来のバッチレベルスケジューリングの代わりに行レベルスケジューリングを採用することで、バッチ内の遅いタスクが他のタスクをブロックすることなく、各タスクが完了次第すぐに次のタスクをトリガーできるようにしました。これにより、アイドル時間を排除し、リソース使用効率を最大化します。

さらに、オーケストレーター内の大容量会話コンテンツをRayの分散オブジェクトストアに効率的にオフロードする仕組みにより、ネットワーク帯域幅を最適化し、システム全体のスケーラビリティを向上させています。

## 3. 実験結果
### 3.1 実験設定
実験は3つの代表的なケーススタディで実施されました。Collaborative Reasoner（Coral）では、LLMのマルチエージェント協調推論を対話駆動タスクで評価し、2つのエージェントが議論、反対、合意に達する多ターン相互作用を扱います。

NaturalReasoningでは、STEM、経済学、社会科学など多様なドメインでのLLMの推論能力向上を目指す大規模データセット作成を対象とし、Filter、Score、Questionの3つのエージェントによるワークフローを実装します。

Tau2-benchでは、AIエージェントとユーザーシミュレーターが共有環境でツールとAPIを通じて相互作用する二重制御環境での対話エージェント評価を実施し、User-simulator、Assistant、Tool-executor、Reward-calculatorの4つの機能エージェントを配置します。

### 3.2 主要な結果
Collaborative Reasonerの実験では、31台のA100ノード（248 GPU）環境において、P2P-agentが5,000の最適並行性に設定されたCoralベースラインに対して12,400の並行性を設定し、4時間で20億トークンを生成しました。P2P-agentは公式Coral実装に対して6.8倍高いスループットを達成し、両システムが0.4732対0.4778の合意正確性でほぼ同等のデータ品質を維持しました。

NaturalReasoningでは、25百万のDCLMウェブドキュメント処理において、P2P-agentがRay Dataベースラインに対して2.1倍高いトークンスループットを実現しました。この効率性向上は、バッチレベルスケジューリングでは遅いタスクが新しいバッチ開始をブロックするのに対し、行レベルスケジューリングでは各完了行が即座に次のタスクをトリガーできることによります。

Tau2-benchでは、13台のH100ノード環境で1,500コンテナと56のgpt-oss-120bレプリカを配置し、P2P-agentがTau2-agentベースラインに対して15.4倍多いトークン/秒を生成しながら、比較可能なタスク報酬を維持しました。

### 3.3 既存手法との比較
既存の集中オーケストレーション手法との比較では、Matrixのピア・ツー・ピアアーキテクチャが一貫して優れた性能を示しています。Collaborative Reasonerでは、ベースラインシステムの集中オーケストレーションアプローチが単一制御点からの大量非同期タスクスケジューリングのオーバーヘッドによりボトルネックとなってプラトーに達するのに対し、Matrix実装はGPUノード追加とともにほぼ線形にスケールします。

従来のバッチ処理システム（Ray Data）との比較では、同質ワークロードでは固定サイズバッチによる効率性があるものの、可変計算要求や分岐制御フローを持つタスクにおいて非効率性を示します。バッチ内の長時間実行タスクが他のタスクをブロックし、アイドルリソースとGPU未使用を引き起こします。

メッセージオフロード機能の評価では、512バイト閾値（約12%の会話に対応）での大容量会話コンテンツオフロード時に、クラスター全体のピークネットワーク使用率が約1GB/sから760MB/sに減少し、約20%の削減を実現しています。

## 4. 実用性評価
### 4.1 実装の容易性
MatrixはSLURM、Ray、vLLM、SGLang、Apptainerなど完全にオープンソーススタックで構築されており、実装とデプロイメントが容易です。Hydraを通じたシステム設定可能性により、ユーザーはコアロジックを変更することなく、多様なデータ生成タスクやエージェントロールに容易に適応できます。

モジュラーアーキテクチャにより、生成ループと分散サービス（LLM推論とコンテナ化実行）などの主要コンポーネントが分離されており、個別の開発とテストが可能です。Ray Actorとしてのエージェント実装により、スケーラブルな並列化とワーカーノード間での細粒度リソース配置が実現されています。

### 4.2 計算効率
Matrixの行レベルスケジューリングアプローチにより、従来のバッチレベル処理で発生するバブル効果を排除し、より高いGPU使用率と異種マルチエージェントワークロードでの低エンドツーエンドレイテンシを実現しています。

3つの並列性タイプ（データ、タスク、エージェント並列性）のサポートにより、クラスター使用率とスケーラビリティを最大化します。LLMベースエージェントでは計算コストが入力パイプラインオーバーヘッドを上回るため、Matrixのピア・ツー・ピアアーキテクチャと分散サービスが中程度のデータ・エージェントレベル並列性でも効率的なクラスターリソース使用を保証します。

### 4.3 応用可能性
Matrixは、コード合成、指示・対話作成、知識に基づく質問応答、多モーダルコンテンツ生成など、幅広いエージェンティック合成データ生成タスクに適用可能です。オープンウェイトモデルとLLM APIプロキシの両方をサポートし、多様な展開シナリオに対応します。

将来的には、多モーダルデータ生成とオンポリシー連続データ合成への拡張が計画されており、さらなる応用範囲の拡大が期待されます。実際の顧客サポートやトラブルシューティング環境でのタスク解決軌道生成など、実世界アプリケーションでの活用も実証されています。

## 5. まとめと所感
### 5.1 論文の意義
本論文は、マルチエージェント合成データ生成における根本的な課題である集中オーケストレーションのボトルネックを、革新的なピア・ツー・ピアアーキテクチャにより解決した重要な貢献です。数万規模の同時エージェントワークフロー実行を可能にし、従来手法に対して2-15倍のスループット改善を実現したことは、大規模LLM訓練における合成データ生成の実用性を大幅に向上させました。

Meta社のFAIRチームによる開発で、完全オープンソースでの公開予定という点も、AI研究コミュニティにとって非常に価値の高い貢献となります。実際の大規模プロダクション環境での検証と、多様なユースケースでの適用実績により、研究段階を超えた実用システムとしての信頼性が実証されています。

### 5.2 今後の展望
今後の発展方向として、多モーダルデータ生成とオンポリシー連続データ合成への拡張が計画されています。これらの拡張により、テキストに限定されない多様なデータモダリティでの合成データ生成が可能となり、より包括的なAIシステム訓練への適用が期待されます。

また、コミュニティ主導の開発と再現性をサポートするためのオープンソース公開により、さらなるイノベーションと改良が促進されることが期待されます。分散システム設計のベストプラクティスとして、他の大規模AI研究プロジェクトへの影響も大きいと考えられます。

エッジコンピューティング環境やプライバシー保護データ生成への適用可能性も高く、分散AIシステムの新たな標準となる可能性を秘めています。
