# Inverting Trojans in LLMs

## 基本情報
- arXiv ID: 2509.16203v1 (https://arxiv.org/abs/2509.16203)
- 著者: Zhengxing Li, Guangmingmei Yang, Jayaram Raghuram, David J. Miller, George Kesidis
- 所属: School of EECS, Penn State University Park, PA, USA; Anomalee Inc., State College, PA, USA
- 投稿日: 2025年09月23日
- カテゴリ: cs.AI, cs.LG, cs.CR

## 簡単に説明すると

この論文は、大規模言語モデル（LLM）に仕込まれた「トロイの木馬」のような隠れた攻撃（バックドア攻撃）を検出・特定する新しい手法「BABI」を提案しています。バックドア攻撃とは、特定のトリガーフレーズが入力に含まれると、モデルが攻撃者の意図した誤った応答を出力してしまう攻撃です。従来の画像分野で使われていた検出手法をLLMに単純に適用することは困難でした。入力空間が離散的であることや候補トリガーの組み合わせが膨大であることが理由です。

BABI手法は3つの主要コンポーネントから構成されます。

1. 単語の組み合わせを貪欲に増やしていく離散探索
2. ターゲットクラスのクリーンサンプルとの類似度を活用した暗黙的なブラックリスト機能
3. 異常に高い確信度での誤分類を検出する仕組み

実験では、既存手法とは異なり、実際に埋め込まれたバックドアトリガーを正確に復元できることを実証しています。

## 1. 研究概要
### 1.1 背景と動機

大規模言語モデル（LLM）は、バックドア・データポイズニング攻撃に対して非常に脆弱です。この攻撃では、攻撃者の指定したバックドアトリガーフレーズがモデルの入力プロンプトに含まれると、攻撃者の意図した応答をモデルが生成してしまいます。このような毒は、基盤モデルの訓練に使用される膨大なデータリソースや指示ファインチューニングセット内に仕込まれる可能性があります。

成功する攻撃は、極めて少量のデータ毒でも実現可能です。クリーンなプロンプトに対するモデルの精度を劣化させることがありません。トリガーは「無害な」フレーズである必要があります。人間の検査や単純な自動化手段では容易に検出されないものである必要があります。

画像分類に使用されるAIには効果的なバックドア検出・反転スキームが開発されています。しかし、これらの手法をLLMに単純に「移植」することには困難があります。

第一に、LLMの入力空間は離散的です。多くのバックドア反転手法の中核となる勾配ベースの探索を妨げます。第二に、考慮すべきトークンの組み合わせが約30,000のトークン長乗個存在します。組み合わせ爆発の問題があります。第三に、LLMにおいては、攻撃の推定ターゲット応答（クラス）と強い周辺的関連を持つトークンをブラックリストに登録する必要があります。

### 1.2 主要な貢献

この研究の主要な貢献は、LLM向けの新しいバックドアトリガー反転・検出アプローチの開発です。提案手法は既存研究と異なり、実際に埋め込まれたバックドアトリガーフレーズを確実に検出し、成功裏に反転できることを実証しています。

- 離散探索アルゴリズム: 選択された単語リストから開始し、候補トリガーを貪欲に積み上げる探索手法
- 暗黙的ブラックリスト機能: 推定ターゲットクラスの小さなクリーンサンプルセットとの活性化空間における平均コサイン類似度を評価することで実現
- 高い信頼度での誤分類検出: 候補トリガーが高い誤分類を誘発し、異常に高い決定信頼度を示す場合の検出機能
- 実証的な有効性: 多くの最近の研究とは異なり、実際のバックドアトリガーフレーズの復元に成功

## 2. 提案手法
### 2.1 手法の概要

BABI（Backdoor Attack Backdoor Inversion）防御手法は、LLMにおけるバックドア攻撃を検出・反転させるための統合的なアプローチです。従来の画像分野で開発された手法とは異なり、テキストの離散的な性質と組み合わせ爆発の問題に対処するために特別に設計されています。

手法の核となるのは、候補トリガーを評価するためのスコア関数L_t(z)です。これは負マージン損失M_t(z)と暗黙的ブラックリスト機能を提供するコサイン類似度ペナルティK_t(z)の組み合わせです。この2つの要素により、真のバックドアトリガーを効果的に特定できます。同時に自然に高い関連性を持つ単語（例：「magnificent」と「positive」）を除外可能です。

### 2.2 技術的詳細

提案手法の中核となる数学的定式化は以下の通りです。負マージン損失は次式で定義されます：

M_t(z) = (1/|D_{-t}|) Σ_{s≠t} Σ_{x∈D_s} (p(s|x:z:i) - p(t|x:z:i))

ここで、p(s|a)は入力プロンプトaに対する応答sのモデル事後確率、xはデータ入力、iは指示プロンプト、zは候補トリガーです。

暗黙的ブラックリスト機能は、内部層の活性化ベクトルにおける平均コサイン類似度として実装されます：

K_t(z) = (1/|D_t|) Σ_{x∈D_t} κ(φ(x:i), φ(z:i))

κ(x,y) = ⟨x,y⟩/(‖x‖‖y‖)はコサイン類似度、φは内部層の活性化ベクトルです。

最終的なスコア関数は：L_t(z) = M_t(z) + λK_t(z) （λ > 0）

トリガー反転手順は、単語レベルから開始して段階的に長いシーケンスを構築する貪欲アルゴリズムを採用しています。各段階で上位N個の候補を保持し、順列を生成して評価します。

### 2.3 新規性

本研究の新規性は複数の側面にあります。第一に、明示的なブラックリストが利用できない場合でも機能する暗黙的ブラックリスト機能の導入です。これは、活性化空間におけるコサイン類似度を利用して、自然に高い関連性を持つ単語を自動的に除外します。

第二に、離散探索アプローチの採用により、従来の連続空間最適化の制約を回避しています。単語の順列生成と段階的な長さ拡張により、計算効率を保ちながら幅広い候補を評価できます。

第三に、既存研究と異なり、実際に埋め込まれたバックドアトリガーフレーズの復元を実証している点です。多くの先行研究では理論的な検出にとどまっていましたが、本研究は ground-truth トリガーの正確な特定に成功しています。

第四に、教師なし検出戦略の採用により、既知のクリーンモデルや毒されたモデルに依存しない実用的なアプローチを実現しています。

## 3. 実験結果
### 3.1 実験設定

実験は FLAN-T5 small モデルを使用して実施されました。10個のモデルインスタンスが SST-2 データセットの異なるサブセットで微調整され、バイナリ出力（positive/negative）と指示プロンプト「Is this review positive or negative?」が使用されました。

5つのモデルはクリーンに保たれ、5つのモデルは毒されました。毒されたモデルは「d_x」（dirty-label poisoning、毒率x%）と「c_y」（clean-label poisoning、毒率y%）として表記されています。dirty-label攻撃では、0.5%、0.8%、1%のネガティブレビューに中性的なトリガーフレーズ「Tell me seriously.」が注入され、positiveとして誤ラベル付けされました。clean-label攻撃では、5%、7%のポジティブレビューがトリガーフレーズで修正されましたが、ラベルは変更されませんでした。

反転・検出に使用されるクリーンセット（クラスあたり50サンプル）は IMDB テストセットから抽出されました。明示的ブラックリストでは、positive に対する事後確率が0.8を超える、またはnegativeに対する事後確率が0.65を超えるトークンが除外されました。内部層φとして第3エンコーダブロックの出力が選択され、λ=40が主実験で使用されました。

### 3.2 主要な結果

実験結果は提案手法の有効性を明確に示しています。クリーンな精度は全ての毒されたモデルで90%以上を維持し（90.46%〜91.74%）、攻撃成功率（ASR）は98.13%〜100%と非常に高い値を示しました。これは攻撃が効果的に実装されていることを確認しています。

トリガー反転結果では、単語レベル（j=1）で ground-truth トークン「seriously」が全ての毒されたモデルでトップ5以内に出現しました。二単語シーケンス（j=2）では、「Tell seriously」がd_0.5、d_0.8、c_7でトップ8以内に一貫して復元されました。三単語シーケンス（j=3）では、完全なフラグメント「Tell me seriously」がd_0.5とc_5でトップランクの候補として特定されました。

ロバストネス分析では、λパラメータの広い範囲（λ値の変化）に対して ground-truth トリガーフラグメントのランクが安定していることが示されました。「seriously」と「Tell seriously」のランクはトップ20以内に維持されました。

### 3.3 既存手法との比較

バックドア検出では、Δμ(t)とΔρ(t)の二次元プロットにおいて、5つの真の事例（毒されたモデル、positive ターゲット応答）が15の非事例（クリーンモデルの両応答、毒されたモデルのnegativeターゲット応答）から明確に分離可能であることが示されました。

既存手法との主要な違いは、ground-truth バックドアトリガーの実際の復元能力です。ONION、TABDet、DBS22、Piccolo、CLIBE、BEEARなどの先行研究は、理論的な検出や候補生成にとどまっており、実際に埋め込まれたトリガーの正確な特定は実証していませんでした。

さらに、多くの既存手法がハイパーパラメータの設定や教師ありの検出器学習のために既知のクリーンモデルと毒されたモデルを必要とするのに対し、本手法は教師なしアプローチを採用しており、実用性において優位性があります。

計算効率の面では、離散探索と段階的な候補絞り込みにより、組み合わせ爆発の問題を効果的に管理しています。N=20という比較的小さな候補数でも高い成功率を達成しており、実装の実用性を示しています。

## 4. 実用性評価
### 4.1 実装の容易性

提案手法は実装が比較的容易な設計となっています。核となるアルゴリズムは標準的な機械学習ライブラリで実装可能な数学的操作（コサイン類似度計算、事後確率評価、貪欲探索）のみを使用しており、特殊なハードウェアや複雑な前処理を必要としません。

ハイパーパラメータの設定も簡潔で、主要なパラメータは最大トリガー長J、候補数N、ペナルティ重みλの3つです。実験では広いλ範囲でロバストな性能を示しており、細かなチューニングを必要としません。明示的ブラックリストは利用可能であれば使用できますが、必須ではなく、暗黙的ブラックリスト機能により代替可能です。

既存のLLMアーキテクチャへの統合も容易で、内部層の活性化ベクトルにアクセスできれば実装可能です。FLAN-T5での実証実験は、他のトランスフォーマーベースモデルへの適用可能性を示唆しています。

### 4.2 計算効率

計算効率は実用的なレベルで管理されています。組み合わせ爆発の問題は、段階的な候補絞り込み（各段階でトップN個を保持）により効果的に解決されています。N=20という設定でも高い検出成功率を達成しており、計算コストと性能のバランスが適切に取れています。

内部層の活性化ベクトル計算は推論時に一度実行すれば十分で、訓練段階での追加コストは発生しません。コサイン類似度の計算は線形時間で実行可能で、スケーラビリティの懸念はありません。

実験環境（NVIDIA A100 GPU）での実行時間は報告されていませんが、離散探索の性質上、勾配ベースの最適化よりも予測可能な計算時間を提供します。バッチ処理により候補評価の並列化も可能で、実用的な展開における計算効率をさらに改善できます。

### 4.3 応用可能性

応用可能性は非常に高く、複数の方向での拡張が期待されます。現在の実装は分類タスクに焦点を当てていますが、著者らは生成タスクへの拡張を将来の課題として言及しています。多クラス分類への拡張も理論的に可能で、順序統計学的p値を用いた検出統計の拡張が提案されています。

セキュリティ監査ツールとしての活用では、モデル展開前のバックドア検査、継続的なモニタリング、インシデント対応における原因調査などに適用可能です。教師なしアプローチの採用により、既知の攻撃パターンに依存しない汎用的な防御ツールとして機能します。

研究面では、LLMセキュリティの基礎的な理解向上、新しい攻撃手法の開発における防御ベンチマーク、ロバストネス評価フレームワークの構築などに貢献できます。産業応用では、金融、医療、自動運転など高い信頼性が要求される分野でのLLM展開における品質保証プロセスの一部として統合可能です。

コード移植性と言語非依存性により、様々なLLMアーキテクチャやドメインでの適用が期待されます。活性化空間での操作という一般的なアプローチにより、特定のモデルアーキテクチャに制約されない汎用性を持っています。

## 5. まとめと所感
### 5.1 論文の意義

本論文は、LLMセキュリティ分野において重要な理論的・実用的貢献を提供しています。最も重要な意義は、従来研究が達成できていなかった ground-truth バックドアトリガーの正確な復元を実証したことです。これまでの多くの研究が理論的な検出や候補生成にとどまっていた中で、実際に埋め込まれた攻撃パターンの特定に成功したことは、この分野における大きな進歩を表しています。

技術的な革新性では、暗黙的ブラックリスト機能の導入が特に価値があります。従来の明示的ブラックリストの限界を克服し、活性化空間におけるコサイン類似度を利用した自動除外メカニズムは、実用的な防御システムの構築において重要な要素技術となり得ます。

方法論的な貢献として、教師なしアプローチの採用により実用性を大幅に向上させています。既知のクリーンモデルや毒されたモデルを必要としない設計は、実際の展開シナリオにおける適用可能性を高めています。また、離散探索と段階的構築による計算効率の実現は、スケーラビリティの課題に対する現実的な解決策を提供しています。

セキュリティの観点では、LLMの信頼性向上に直接貢献する実用的なツールを提供しています。AI安全性が社会的な関心事となっている現在、このような防御技術の開発は極めて重要な意味を持ちます。

### 5.2 今後の展望

短期的な研究発展として、より大規模なLLMモデル（GPT系、Llama系など）での評価と検証が必要です。現在の実験はFLAN-T5 smallに限定されており、パラメータ数が桁違いに大きなモデルでの有効性確認が求められます。また、多クラス分類（2クラス以上）での性能評価と、より複雑なドメインでの実証実験も重要な課題です。

技術的な拡張では、著者らが言及している生成タスクへの適用が最も重要な発展方向です。分類タスクから自由な応答生成への拡張は、実用性を大幅に向上させる可能性があります。また、多言語環境での適用性評価、異なるトークナイザーとの互換性検証、リアルタイム検出システムの構築なども重要な研究課題です。

実用化に向けては、計算効率のさらなる改善、検出精度の向上、偽陽性率の低減が必要です。特に、本格的な産業展開には、現在よりも高速な処理と高い信頼性が求められるでしょう。統合型セキュリティフレームワークの一部としての位置づけも重要で、他の防御技術との協調動作の研究が有望です。

長期的には、この研究がLLMセキュリティ分野の基盤技術として発展し、より高度な攻撃に対する防御手法の開発、プライバシー保護技術との統合、説明可能なAIセキュリティシステムの構築などに貢献することが期待されます。また、規制や標準化の観点から、LLMの安全性評価における標準的な手法として採用される可能性もあります。
