# MANZANO: A Simple and Scalable Unified Multimodal Model with a Hybrid Vision Tokenizer

## 基本情報
- arXiv ID: 2509.16197v1 (https://arxiv.org/abs/2509.16197)
- 著者: Yanghao Li他26名（Apple）
- 所属: Apple
- 投稿日: 2025年09月22日（推定）
- カテゴリ: cs.CV, cs.AI, cs.LG

## 簡単に説明すると
MANZANOは、画像理解と画像生成の両方を統一的に扱うマルチモーダル大規模言語モデル（MLLM）です。従来の統一モデルでは、理解と生成タスクの間にパフォーマンスのトレードオフが存在していました。MANZANOは「ハイブリッド画像トークナイザー」という新しいアプローチを提案し、この問題を効果的に軽減しています。

1つの共有視覚エンコーダーから、理解用の連続表現と生成用の離散表現を同時に生成します。これによりタスク間の競合を最小限に抑えながら、両方の能力を高いレベルで実現しています。特にテキストリッチな評価において、専門特化モデルと競合する性能を示しています。Apple社の大規模研究チームによる成果として注目されています。

## 1. 研究概要
### 1.1 背景と動機
統一マルチモーダルモデルは、理解と生成の両方の能力を統合することで、複雑な世界推論やマルチモーダル指示追従などの創発的能力を解き放つ可能性があります。しかし、実際には生成能力を追加することで理解性能が劣化するという問題が存在していました。

主な課題として、視覚トークン化の競合する性質が挙げられます。自己回帰生成では通常、離散画像トークンが好まれます。一方で理解タスクでは連続埋め込みが有効とされています。

多くの既存モデルは、理解用に意味エンコーダー、生成用に量子化トークナイザー（VQ-VAEなど）を使用するデュアルトークナイザー戦略を採用しています。これにより言語モデルが異なる2つの画像トークンタイプを処理する必要があります。高レベル意味領域と低レベル空間領域という異なる特性により、大きなタスク競合を引き起こしていました。

### 1.2 主要な貢献
本研究の主要な貢献は次の通りです。

- ハイブリッド画像トークナイザーの提案: 1つの共有視覚エンコーダーから、理解用の連続表現と生成用の離散表現を同時に生成する統一的なアプローチ。
- タスク競合の効果的軽減: 同一エンコーダー由来の表現により、LLM内でのタスク間競合を最小限に抑制。
- 優れた性能: 統一モデルでありながら、特に文字リッチな評価において専門特化モデルと競合する理解性能を達成。
- スケーラビリティの実証: LLMデコーダー（300M〜30B）および画像デコーダー（0.9B〜3.5B）の両方向でのスケーリング効果を実証。
- シンプルで効果的な設計: 標準的なAR目的関数と明確に分離されたコンポーネントにより、簡潔性とスケーラビリティを実現。

## 2. 提案手法
### 2.1 手法の概要
MANZANOは3つの主要コンポーネントから構成されています。

1. ハイブリッド視覚トークナイザー: 連続表現と離散表現の両方を生成。
2. 統一LLMデコーダー: テキストトークンと連続画像埋め込みを受け入れ、次の離散画像またはテキストトークンを自己回帰的に予測。
3. 画像デコーダー: 予測された画像トークンから画像ピクセルをレンダリング。

推論パイプラインでは、理解タスクではハイブリッド画像トークナイザーが連続特徴を抽出します。これらの特徴がテキスト特徴と共に統一LLMデコーダーに供給されて最終回答を予測します。生成タスクでは、テキスト入力から画像トークンのシーケンスを予測します。画像デコーダーがこれらのトークンを画像ピクセルにレンダリングします。

### 2.2 技術的詳細
ハイブリッド画像トークナイザーは以下の3つのコンポーネントで構成されます。

1. 視覚バックボーン: 標準的なVision Transformer (ViT)。
2. 連続アダプター: 3×3 STC層により空間トークン数を9分の1に削減します。例えば、42×42×1024から14×14×9216に変換します。その後MLPによりLLM特徴次元（例: 2048）に投影します。
3. 離散アダプター: STC圧縮後、Finite Scalar Quantization (FSQ)により特徴を量子化（64Kコードブック）してからMLP投影。

**統一LLM**では、事前訓練されたLLMデコーダーにハイブリッド画像トークナイザーを接続し、テキスト、理解、生成データの混合データセットで統一訓練を行います。

**画像デコーダー**では、事前訓練されたハイブリッド画像トークナイザー上で訓練され、離散画像トークンからピクセル空間で画像を再構成します。DiT-Airアーキテクチャを採用し、層ごとのパラメータ共有戦略により標準MMDiTモデルのサイズを約66%削減しながら同等の性能を維持しています。

### 2.3 新規性
従来の統一モデルが抱えていた主要な問題点について、次のような解決策を提示しています。

1. 統一意味空間: 両方の分岐が同一エンコーダーバックボーンから派生する。連続トークンおよび離散トークンが共通の意味空間に存在し、潜在的なタスク競合を削減する。
2. シンプリシティおよびスケーラビリティ: 標準的な損失関数と明確に分離されたコンポーネントにより、統一化とスケーリングを簡素化する。
3. 実用的なスケーリング: LLM/MLLMと拡散デコーダーの成熟したスケーラブル訓練パイプラインを活用する。

## 3. 実験結果
### 3.1 実験設定
理解評価では次の3つのカテゴリで評価を実施しました。
- 一般VQA: SeedBench, RealWorldQA, MMBench
- 知識・推論: AI2D, ScienceQA, MMMU, MathVista
- テキストリッチ文書・チャート理解: ChartQA, TextVQA, DocVQA, InfoVQA, OCRBench

生成評価では次の2つの手法で評価しました。
- 自動評価: GenEval, DPGBench, WISE
- 人間評価: 800の挑戦的プロンプトでの構造的整合性、指示追従、美的品質の3次元評価

### 3.2 主要な結果
**理解性能**: 3Bスケールで、統一モデルでありながら多くの理解ベンチマークで最先端性能を達成。特にテキストリッチタスクで優れた性能を示し、ChartQA、TextVQA、DocVQA、OCRBenchの5つのベンチマークのうち4つで最高性能を記録。

**生成性能**: GenEvalおよびWISEにおいて統一MLLM中で最先端結果を達成。
3Bモデルはより大きな統一モデルと競合または優越する性能を示した。
30Bへのスケーリングにより特にWISEで大幅な向上を実現。

**スケーリング効果**: LLMデコーダー（300M→30B）のスケーリングで理解・生成両方のベンチマークで実質的改善。画像デコーダー（0.9B→3.5B）のスケーリングで構造的整合性が大幅向上（+9.9）。

### 3.3 既存手法との比較
トークナイザー戦略比較では次のような結果を得ました。
- 純粋離散ベースライン: 量子化による情報損失で理解性能が大幅低下
- デュアルエンコーダーベースライン: 一部劣化軽減も、すべての理解タスクでハイブリッドトークナイザーより劣る
- ハイブリッドトークナイザー: 最小のタスク競合で両方のアプローチを上回る

統一 vs 単一タスク比較では、300Mと3Bの両スケールで、ハイブリッドトークナイザーによる統一LLMが専用単一タスクモデルとほぼ同等の性能を実現し、タスク間競合なしの統一化を実証。

## 4. 実用性評価
### 4.1 実装の容易性
MANZANOの設計は実装の簡潔性を重視しており、次の特徴により実装が容易です。
- 標準的なAR目的関数のみを使用し、追加の補助損失やタスク別ヘッドが不要
- コンポーネントが明確に分離されており、意味予測（LLMデコーダー）と詳細生成（画像デコーダー）の独立スケーリングが可能
- 成熟したLLM/MLLMと拡散デコーダーの訓練パイプラインを活用可能

### 4.2 計算効率
計算効率に関しては、次の最適化が施されている。
- STC層による空間トークン数の9分の1削減
- DiT-Airアーキテクチャによる画像デコーダーのパラメータ66%削減
- FSQによるシンプルかつスケーラブルな量子化（64Kコードブック）
- 解像度を256から2048ピクセルまで段階的に向上させる方式による画像デコーダー訓練の計算コスト最適化

### 4.3 応用可能性
幅広い応用可能性を持ちます。以下のような分野での活用が期待されます。
- 基本的な画像理解・生成タスクから高度な画像編集まで対応
- 指示ガイド編集、スタイル転送、インペインティング、アウトペインティング、深度推定などの多様な編集機能
- 多言語OCR、知識・推論、ドキュメント理解など専門的なタスクでの優れた性能
- スケーラブルな設計により、さらなる能力とモダリティの統合可能性

## 5. まとめと所感
### 5.1 論文の意義
この論文は、マルチモーダルAIの分野において統一モデルの性能向上に関する重要な進歩を示しています。従来の統一モデルが直面していた理解と生成間のトレードオフという根本的な問題に対して、ハイブリッド画像トークナイザーという elegant な解決策を提案しています。

特に注目すべきは、Apple社という大手テクノロジー企業による大規模研究チームでの取り組みであり、理論的貢献だけでなく実用的な観点からも高い価値を持つことです。27名の著者による充実した研究体制は、この分野での包括的で信頼性の高い成果を保証しています。

また、テキストリッチなタスクでの優れた性能は、実世界のアプリケーション（文書理解、チャート分析など）への直接的な応用可能性を示しており、商用利用の観点からも重要な意味を持ちます。

### 5.2 今後の展望
今後の発展方向として、次の領域での進展が期待されます。

1. **対話的編集の拡張**: 現在の画像編集機能をさらに発展させ、より複雑な対話的編集シナリオへの対応
2. **推論能力の強化**: 世界知識推論や複雑な視覚推論タスクでのさらなる改善
3. **マルチモーダリティの拡張**: 音声や動画など他のモダリティとの統合可能性
4. **効率性の向上**: 種々のトークナイザー設計手法や計算コストをさらに最適化した訓練手法の開発
5. **専門ドメインへの適用**: 医療、科学、教育など特定分野での特化モデルの開発

この研究は、「統一化が創造性を犠牲にする必要はない」という重要なメッセージを示している。明確な目的関数および優れた視覚表現により、シンプルでスケーラブルなモデルが両方の領域で高い性能を達成できることを実証した。これは今後のマルチモーダルAI研究の方向性に大きな影響を与える可能性がある。