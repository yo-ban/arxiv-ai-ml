# Plot'n Polish: Zero-shot Story Visualization and Disentangled Editing with Text-to-Image Diffusion Models

## 基本情報
- arXiv ID: 2509.04446v1 (https://arxiv.org/abs/2509.04446)
- 著者: Kiymet Akdemir、Jing Shi、Kushal Kafle、Brian Price、Pinar Yanardag
- 所属: Virginia Tech, Adobe Research
- 投稿日: 2025年9月6日
- カテゴリ: cs.CV, cs.AI, cs.CL

## 簡単に説明すると
この論文では物語の可視化において一貫性のある画像シーケンスを生成し、
生成後に複数フレーム間で一貫した編集を可能にする「Plot'n Polish」というゼロショットフレームワークを提案しています。
従来の物語の可視化手法では、キャラクターや設定の一貫性を保つことが困難であり、
生成後の編集機能も限定的でした。

Plot'n Polishは、グリッド事前分布（grid prior）を活用した新しいマルチフレーム編集メカニズムにより、
これらの問題を解決しています。
ユーザーは物語の生成から細かな編集（衣装の色変更など）、
大規模な変更（キャラクター交換、スタイル変更など）まで、
全フレーム間で一貫性を保ちながら行うことができます。
プロジェクトページ（plotnpolish.github.io）で実際の結果を確認できます。

## 1. 研究概要
### 1.1 背景と動機
テキストから画像を生成する拡散モデルの発展により、物語可視化への応用が注目されていますが、
既存手法には重大な制約があります。
多くの手法は各フレームを独立して生成するため、
キャラクターや設定に視覚的不整合が生じやすく、物語全体の一貫性が損なわれています。

また、創作プロセスでは生成後の修正や調整が重要ですが、
既存手法は生成後の編集機能が限定的で、
変更を加える場合には全体を再生成する必要がありました。
これは創作者にとって大きな制約となっており、
柔軟な創作プロセスを阻害していました。

特に実用的な創作支援を考えると、単一フレームの編集ではなく、
複数フレーム間で一貫した編集をする能力が不可欠です。
例えば、キャラクターの衣装を変更する際、
その変更が物語全体のフレームに一貫して反映される必要があります。

### 1.2 主要な貢献
この論文では、物語の可視化分野における複数の重要な技術的革新を達成しています。

フレームワーク設計の貢献として、初期の物語可視化と生成後の修正を統合した統一的なフレームワークを提案しています。
これにより、ユーザーは単一のシステム内で物語の生成から詳細な編集まで、
一貫したワークフローで行うことができます。

技術的革新として、グリッド事前分布を活用したマルチフレーム編集メカニズムを開発しました。
この手法により、複数フレーム間での空間的情報の相互作用が可能になり、
編集の一貫性を保ちながら柔軟な修正が実現されています。

編集機能の拡張として、局所的な細かい調整（アクセサリーの追加、色の変更など）から、
大規模な変更（キャラクター交換、全体的なスタイル変更など）まで、
幅広い編集タスクに対応しています。
特に重要なのは、これらの編集が全フレーム間で一貫して適用される点です。

実用性の向上として、他の手法で生成された既存の物語画像や、
出版された絵本の画像も編集対象とでき、
既存のワークフローに容易に統合可能な汎用性を実現しました。

## 2. 提案手法
### 2.1 手法の概要
Plot'n Polishの核心は、グリッド表現を用いたマルチフレーム編集フレームワークです。
システムは2つの主要段階で構成されています。

第一段階では、LLMによる物語生成または ユーザー提供のプロンプトに基づいて、
既製のテキスト-画像モデル（SDXL等）を使用して初期の物語テンプレートを作成します。
この段階では、各フレームを独立して生成するため、
キャラクターの外見や設定に不整合を生じる可能性があります。

第二段階では、独自のマルチフレーム編集フレームワークにより、
これらの不整合を修正し、全フレーム間での一貫性を確保します。
編集対象の概念（例：キャラクター）と編集プロンプトを指定することで、
対象領域のマスクを自動抽出し、一貫した修正を適用します。

### 2.2 技術的詳細
グリッド事前分布の活用が本手法の技術的核心です。
複数フレームを矩形グリッド状に配置することで、
フレーム間の空間的な相互作用を促進し、一貫した編集を実現します。

n個のフレームをγ = φ × β サイズのグループに分割し、
φ × βの矩形グリッドに配置します。
各拡散ステップにおいて、潜在表現z_grid,tがノイズ除去プロセスで更新されます。
一貫性を確保するため、各ステップでフレームをランダムに再グループ化し、
孤立した不整合の発生を防いでいます。

潜在ブレンディングによる制御メカニズムにより、
マスクされた領域のみを編集し、背景や非対象領域への意図しない変更を防止します。
編集後の潜在表現と元画像から導出された潜在表現を、
マスクに基づいて要素ごとに組み合わせることで、精密な編集制御を実現しています。

ControlNetを統合することで、深度情報による構造的制約を適用し、
元画像の構造的整合性を保ちながら編集を行います。
局所編集には0.4、全体編集には1.0の深度条件を適用し、
編集の性質に応じた適応的制御を行っています。

### 2.3 新規性
本研究の最も重要な新規性は、物語可視化における複数フレーム間での一貫した編集を実現した初の手法である点です。
従来手法では単一フレームの編集または全体の再生成しか選択肢がありませんでしたが、
本手法は両者の中間となる柔軟な編集機能を提供しています。

グリッド事前分布を物語可視化に応用した点も技術的新規性として挙げられます。
複数画像間の空間的相互作用を活用することで、
個別編集では達成困難な高い一貫性を実現しています。

ゼロショット編集能力により、事前の訓練や微調整なしに、
多様な編集タスクに対応できる汎用性を実現しました。
これは実用的な創作支援システムとして重要な特徴です。

既存画像の編集対応により、他の手法で生成された画像や、
実在する出版物からの画像も編集対象とできる高い互換性を持っています。
この特徴により、既存の創作ワークフローへの統合が容易になっています。

## 3. 実験結果
### 3.1 実験設定
実験は包括的な定量的・定性的評価で構成されています。
200の物語（各9フレーム、計1,800フレーム）をGPT-4で生成し、
多様なキャラクターと設定を含む評価データセットを構築しました。

評価指標として、画像類似度（CLIP-I、DINO、LPIPS）と
テキスト整合性（CLIP-T）を用いて客観的評価を行いました。
さらに、Prolific.comから50名の参加者による主観評価も実施し、
一貫性、テキスト整合性、編集の分離性を5段階で評価しました。

比較対象として、最新の物語可視化手法（StoryDiffusion、ConsiStory、AutoStudio、Intelligent Grimm）
および画像編集手法（InstructPix2Pix、LEDITS++、Plug-and-Play）を用いました。
実験は単一のNVIDIA A40 GPUで実行され、実用的な計算環境での性能を検証しています。

### 3.2 主要な結果
物語生成タスクにおいて、本手法はCLIP-T（0.36）で最高スコアを達成し、
生成画像とテキストプロンプトの整合性において優位性を示しました。
また、LPIPS（0.47）でも最低値を達成し、フレーム間の一貫性が高いことが確認されました。

主観評価では、一貫性（2.90）とテキスト整合性（2.82）の両方で最高評価を獲得し、
人間の評価者からも高く評価されました。
これは技術的性能が実際のユーザー体験にも反映されていることを示しています。

編集タスクにおいては、全ての指標で大幅な性能向上を達成しました。
CLIP-I（0.93）、DINO（0.88）、CLIP-T（0.33）で最高スコア、
LPIPS（0.10）で最低スコアを記録し、編集の精度と一貫性の高さが実証されました。

主観評価でも編集の全側面（一貫性4.17、テキスト整合性4.08、分離性4.17）で
他手法を大きく上回る評価を得ており、実用的な編集システムとしての有効性が確認されました。

### 3.3 既存手法との比較
物語生成における比較では、他手法との明確な性能差が観察されました。
StoryDiffusionは生成速度（9秒）では優位ですが、キャラクターの一貫性維持に課題があります。
ConsiStoryは高いCLIP-Iスコア（0.83）を示しますが、
実際には意図されたキャラクターを正確に描画できない場合が多く見られました。

AutoStudioとIntelligent Grimmは、それぞれ異なる制約を持っています。
AutoStudioは衣装の変更や視覚的融合の問題があり、
Intelligent Grimmは特定データセットへの依存により柔軟性が制限されています。

編集タスクの比較では、本手法の優位性がより顕著に現れました。
既存の画像編集手法は、InstructPix2Pixが意図しない領域への変更、
LEDITS++が融合の問題、Plug-and-Playが生成失敗などの課題を抱えています。

実行時間の面では、初期フレーム生成2秒、編集9秒/フレーム（計11秒）と、
品質と速度のバランスの取れた性能を実現しています。
これは実用的な創作支援システムとして十分な応答性能です。

## 4. 実用性評価
### 4.1 実装の容易性
Plot'n Polishは比較的実装が容易な設計となっています。
既存の拡散モデル（SD 1.5、SDXL）やControlNet、
一般的なセグメンテーションモデル（YOLO-World、EfficientSAM）を組み合わせることで構築可能です。

3×3グリッドという単純な構造を採用しており、複雑なアーキテクチャ設計は不要です。
また、IP-Adapterとの互換性により、パーソナライゼーション機能も容易に統合できます。

ただし、セグメンテーションモデルの性能に依存するため、
マスク生成の精度が編集品質に直接影響します。
重複するオブジェクトがある場合など、一部制約はありますが、
10画像のバッチ処理を2秒で完了する効率性を持っています。

### 4.2 計算効率
計算効率の面では実用的なレベルを達成しています。
単一A40 GPUでの動作が可能であり、特別な計算資源は不要です。

初期テンプレート生成（2秒）＋編集処理（9秒）で計11秒の処理時間は、
創作プロセスにおいて許容できる応答時間です。
この性能は他の最新手法と比較しても競争力があります。

グリッドサイズの調整により、品質と計算コストのトレードオフを制御可能です。
3×3グリッドは品質と効率のバランスが取れた選択として実験的に検証されています。

### 4.3 応用可能性
応用可能性は非常に広範囲にわたります。
デジタルコンテンツ制作、教育用教材作成、マーケティング資料制作など、
視覚的ストーリーテリングが必要な様々な分野での活用が期待されます。

既存画像の編集対応により、出版社や制作会社が持つ既存資産の活用も可能です。
Gutenbergプロジェクトからの画像編集実験で示されたように、
著作権フリーの教育資源への適用も有望です。

個人制作者から商業制作まで、スケールに応じた利用が可能な柔軟性を持っています。
LoRAモデルやIP-Adapterとの統合により、ブランドキャラクターや特定スタイルの維持も実現できます。

今後の発展として、インタラクティブな分岐ストーリーへの対応も計画されており、
より複雑な物語構造への適用も期待されます。

## 5. まとめと所感
### 5.1 論文の意義
この論文は、物語可視化分野における重要な技術的突破を達成しています。
複数フレーム間での一貫した編集という、これまで未解決だった課題に対する
実用的で効果的な解決策を提示した点が最も重要な貢献です。

技術的革新として、グリッド事前分布を物語可視化に応用し、
フレーム間の空間的相互作用を通じて一貫性を確保するアプローチは独創的です。
既存の画像編集手法とは異なる、物語特有の要求に特化した設計思想が評価できます。

実用性の観点でも、ゼロショット編集能力と既存画像対応により、
現実の創作ワークフローに即座に統合可能なシステムを実現しています。
これは研究レベルの技術を実用レベルまで押し上げた重要な成果です。

評価の包括性も特筆すべき点です。
定量的指標、主観評価、アブレーション・スタディを組み合わせた
多角的な評価により、手法の有効性を説得力を持って示しています。

### 5.2 今後の展望
技術的発展の方向として、セグメンテーション精度への依存度軽減が重要な課題です。
アテンション・マップを用いた実験で示されたように、
より柔軟なマスク生成手法の開発により、さらなる汎用性向上が期待されます。

より高解像度モデル（SDXL、Flux）への対応は既に検証されていますが、
今後登場するさらに高性能な基盤モデルとの統合により、
生成品質のさらなる向上が見込まれます。

インタラクティブ要素の強化により、リアルタイムでの編集や、
ユーザーとの対話的な物語創作支援システムへの発展も可能です。
これにより、創作プロセスがより直感的で効率的なものとなるでしょう。

産業応用の拡大として、エンターテインメント、教育、マーケティング分野での
具体的な導入事例の蓄積により、技術の成熟度と実用性がさらに向上することが期待されます。
特に教育分野では、個別化された学習教材作成への応用が有望です。

長期的には、より複雑な物語構造（分岐、時系列変化、複数視点など）への対応や、
3D空間での物語可視化への拡張など、さらなる技術発展の可能性を秘めています。