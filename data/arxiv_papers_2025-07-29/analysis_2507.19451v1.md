# GS-Occ3D: Scaling Vision-only Occupancy Reconstruction for Autonomous Driving with Gaussian Splatting

## 基本情報
- **arXiv ID**: 2507.19451v1 (https://arxiv.org/abs/2507.19451)
- **著者**: Tsinghua University (IIIS, AIR), Shanghai Qi Zhi Institute, BAAI, Mercedes-Benz Group China Ltd.の研究者チーム
- **所属**: 清華大学情報科学技術学院、清華大学AI研究院、上海斉智研究院、北京智源人工智能研究院、メルセデスベンツグループ中国
- **投稿日**: 2025年07月28日
- **カテゴリ**: cs.CV

## 簡単に説明すると
この論文は、自動運転のための占有率（Occupancy）再構成を、高価なLiDARセンサーを使わずにカメラ画像のみで実現する新しい手法「GS-Occ3D」を提案しています。

占有率再構成とは、自動運転車が周囲の3D空間のどの部分が物体で占められているかを理解するための重要な技術です。従来の手法では高価なLiDARセンサーが必要でしたが、GS-Occ3Dはカメラ画像のみで同等以上の性能を達成します。

技術的には、Octree（八分木）構造とGaussian Surfel（ガウシアンサーフェル）表現を組み合わせ、シーンを静的背景、地面、動的物体の3つに分解して効率的に再構成します。特に注目すべきは、Waymoデータセット全体をビジョンのみで再構成した初の研究であり、下流タスクでLiDARベースの手法と同等以上の性能を示しました。

プロジェクトページ：https://gs-occ3d.github.io/

## 1. 研究概要
### 1.1 背景と動機
自動運転における占有率再構成は、知覚と計画の両方に必要な幾何学的事前情報を提供する重要な技術です。しかし、既存の手法は主にLiDARベースの占有率アノテーションに依存しており、以下の問題を抱えています：

1. **スケーラビリティの制限**：高価な専用調査車両が必要で、大規模なデータ収集が困難
2. **コストの問題**：LiDARセンサーは高価で、メンテナンスコストも高い
3. **データの制約**：クラウドソーシングによる大規模データ活用が不可能

一方、ビジョンベースのアプローチは、消費者グレードの車両から収集可能な豊富なカメラデータを活用できる可能性があります。しかし、ビジョンのみでの占有率再構成には以下の課題があります：

- **スパースな視点**：限られたカメラ数（Waymoでは5台）による観測の不完全性
- **深刻な遮蔽**：動的物体による視界の遮断
- **長距離移動**：高速道路などでの長時間の移動による一貫性の維持困難
- **動的要素**：移動する車両や歩行者の正確なモデリング

既存のビジョンベース手法の多くはメッシュ表現を使用していますが、不完全な幾何形状と追加の後処理が必要となり、スケーラビリティが制限されます。

### 1.2 主要な貢献
この研究の主要な貢献は以下の通りです：

- LiDARに依存しないスケーラブルなビジョンのみの占有率ラベル生成パイプラインの導入
- パノラマストリートビューから地面、背景、動的物体を効果的に再構成する手法の開発
- Waymoデータセット全体をビジョンのみで再構成した初の研究成果
- Occ3D-Waymoでの下流占有率モデルの有効性とOcc3D-nuScenesでの優れたゼロショット汎化性能の実証

## 2. 提案手法
### 2.1 手法の概要
GS-Occ3Dは、スケーラブルなビジョンのみの占有率再構成フレームワークです。主要な革新は、運転環境を幾何学的に異なる3つのコンポーネントに戦略的に分解することです：

1. **静的背景**：Octreeベースの階層的サーフェル表現でマルチスケールの忠実度を実現
2. **地面**：大面積の一貫性を高めるために支配的な構造要素として明示的に再構成
3. **動的物体**：動きに関連する占有率パターンをより良く捉え、遮蔽アーティファクトを削減するために個別に処理

### 2.2 技術的詳細
#### Octreeベースのガウシアンサーフェル
スパースビュー条件での幾何学的事前情報の欠如に対処するため、初期のスパースポイントクラウドをシーンの骨格として使用するOctreeベースのガウシアンサーフェルを採用します。

Octreeレベル数Kは以下のように決定されます：
```
K = ⌊log₂(d_max/d_min)⌉ + 1
```
ここで、d_minとd_maxはカメラ中心とSfMポイント間の最小・最大距離です。

各Octreeレベルlのボクセル中心は以下のように計算されます：
```
V_L = {⌊P/(ε/2^L)⌉ · (ε/2^L)}
```
ここで、Pは3Dスパースポイントクラウドの座標、εは最も粗いレベルの基本ボクセルサイズです。

#### 地面再構成
道路表面がカメラポーズにほぼ平行であると仮定し、カメラポーズをxy平面に投影することで地面ガウシアンサーフェルを初期化します。高度を扱うため、各サーフェルのz座標は固定高さオフセットを持つ最近傍カメラポーズを使用して調整されます。

#### 動的物体再構成
各動的車両は、RGBイメージから予測された3Dバウンディングボックスに関連付けられ、追跡されたポーズR_tとt_tを持つポイントクラウドで表現されます。初期ポーズのノイズを軽減するため、学習可能な補正を追加します：
```
R'_t = R_t · ΔR_t,  t'_t = t_t + Δt_t
```

#### 損失関数
総損失は5つのコンポーネントの重み付け和です：
```
L = L_rgb + λ_geo·L_geo + λ_obj·L_obj + λ_road·L_road + λ_sky·L_sky
```

幾何損失L_geoは、サーフェル正則化、深度歪み、深度-法線一貫性の3項から構成されます。

### 2.3 新規性
GS-Occ3Dの主要な新規性は以下の点にあります：

1. **Octreeベースのガウシアンサーフェル表現**：効率的で階層的な空間分割により、大規模シーンでのスケーラブルな幾何再構成を実現
2. **シーンの分解戦略**：静的背景、地面、動的物体を個別にモデリングすることで、各要素の特性に最適化された処理を実現
3. **明示的な地面再構成**：道路面の大面積一貫性を大幅に改善
4. **統合的な占有率ラベル生成パイプライン**：フレーム単位の分割、マルチフレーム集約、レイキャスティングによる高品質なラベル生成

## 3. 実験結果
### 3.1 実験設定
**データセット**：
- Waymo Open Dataset：約1,000枚/シーンの画像を含む大規模データセット
- Waymo Static-32分割：幾何再構成評価用
- Occ3D-Waymo：798訓練シーン、202検証シーン（ego-staticシーンを除外後：637訓練、165検証）
- Occ3D-nuScenes：ゼロショット汎化評価用の150検証シーン

**ベースライン**：
- 幾何再構成：NeuS、F²-NeRF、StreetSurf（暗黙的手法）、2DGS、PGSR、GVKF（明示的手法）
- 占有率予測：CVT-Occ（SOTA占有率モデル）をOcc3D（LiDARベース）ラベルと比較

**評価指標**：
- 幾何精度：Chamfer Distance（CD）
- レンダリング品質：PSNR
- 効率性：ストレージ、GPUメモリ、訓練時間
- 占有率予測：IoU、F1スコア、精度、再現率

### 3.2 主要な結果
**幾何再構成の結果**：
- Waymo Static-32でCD=0.56を達成し、LiDAR入力/教師ありのStreetSurf（CD=0.90）やNeuS（CD=0.76）を上回るSOTA性能
- PSNR=26.89の高品質レンダリングを維持
- 訓練時間0.8時間、GPUメモリ10GB、ストレージ80MBの高効率

**占有率予測の結果**：
- Occ3D-Waymo検証セット：IoU 44.7%（Occ3Dラベルの57.4%と比較して妥当な範囲）
- Occ3D-nuScenes（ゼロショット）：IoU 33.4%でOcc3Dラベルの31.4%を上回る
- 特に遠方やテクスチャのある領域でより完全な幾何を生成

**LiDARに対する優位性**：
1. より広いカバレッジ：高層ビルなど、LiDARの限定的な空間カバレッジを補完
2. 優れたゼロショット汎化：より広範な幾何に汎化
3. 豊富なセマンティクス：66カテゴリ（Occ3Dの16カテゴリと比較）を識別可能
4. 悪天候での潜在的優位性：雨天シーンでより良い汎化を示す

### 3.3 既存手法との比較
GS-Occ3Dは以下の点で既存手法を凌駕します：

1. **幾何再構成精度**：ビジョンのみでありながら、LiDAR教師ありの手法を上回る
2. **効率性**：Octree構造により、高速な訓練と低メモリ使用を実現
3. **スケーラビリティ**：Waymoデータセット全体の再構成に成功した初の手法
4. **汎化性能**：異なるセンサー設定のnuScenesでも良好な性能を維持

## 4. 実用性評価
### 4.1 実装の容易性
GS-Occ3Dの実装は比較的シンプルで、以下の要素から構成されます：

1. 検出器フリーのSfMによる初期ポイントクラウド生成
2. セグメンテーションモデル（Mask2Former）による物体分離
3. Octreeベースのガウシアンサーフェル最適化
4. 占有率ラベル生成パイプライン

特別なハードウェアは不要で、一般的なGPUで実行可能です。

### 4.2 計算効率
GS-Occ3Dは高い計算効率を示します：

- 訓練時間：シーンあたり0.8時間（最速クラス）
- GPUメモリ：10GB（2DGSの15GB、GVKFの24GBより少ない）
- ストレージ：80MB（PGSRの78MBとほぼ同等）
- Octree構造により、大規模シーンでも効率的な処理が可能

### 4.3 応用可能性
GS-Occ3Dの応用可能性は非常に広範です：

1. **大規模自動ラベリング**：クラウドソーシングデータからの占有率ラベル自動生成
2. **コスト削減**：高価なLiDARセンサーなしで同等の性能を実現
3. **データの閉ループ**：実運用で収集したカメラデータを継続的に活用
4. **マルチモーダル学習**：豊富なセマンティック情報を活用した高度な認識タスク
5. **悪天候対応**：視覚的手がかりとテクスチャ情報を活用した頑健な再構成

## 5. まとめと所感
### 5.1 論文の意義
この研究は、自動運転における占有率再構成の分野に重要なパラダイムシフトをもたらしています。主要な意義は以下の通りです：

第一に、高価なLiDARセンサーへの依存を排除し、カメラのみで同等以上の性能を達成したことです。これにより、自動運転技術の民主化と大規模展開への道が開かれました。

第二に、Waymoデータセット全体をビジョンのみで再構成することに成功し、手法のスケーラビリティを実証しました。これは、クラウドソーシングによる大規模データ活用の可能性を示しています。

第三に、シーンを静的背景、地面、動的物体に分解する戦略により、各要素の特性に最適化された処理を実現しました。この設計思想は、複雑なシーンを扱う他のタスクにも応用可能です。

第四に、ゼロショット汎化でLiDARベースの手法を上回ったことは、ビジョンベース手法の潜在的優位性を示唆しています。豊富なテクスチャ情報と学習された事前知識の活用が鍵となっています。

### 5.2 今後の展望
この研究は多くの興味深い将来の方向性を示唆しています：

1. **リアルタイム処理**：現在の0.8時間の訓練時間をさらに短縮し、オンライン学習への展開
2. **セマンティックの活用**：66カテゴリの豊富なセマンティック情報を下流タスクでより効果的に活用
3. **悪天候への対応**：雨、雪、霧などの条件下でのロバスト性のさらなる向上
4. **他センサーとの融合**：必要に応じてレーダーなど他の低コストセンサーとの統合
5. **エンドツーエンド学習**：占有率予測と計画・制御の統合的な最適化

技術的には、より効率的なOctree構造の設計、動的物体のより精密なモデリング、長距離移動での一貫性のさらなる向上などが重要な研究課題となるでしょう。

実用面では、この技術により、より多くの車両からデータを収集し、継続的に性能を向上させるデータ駆動型の自動運転システムの実現が期待されます。LiDARに依存しない手法の確立は、自動運転技術の普及において重要なマイルストーンとなるでしょう。