# MMBench-GUI: Hierarchical Multi-Platform Evaluation Framework for GUI Agents

## 基本情報
- **arXiv ID**: 2507.19478v1 (https://arxiv.org/abs/2507.19478)
- **著者**: Zichen Ding, Bowen Yang, Zehao Li, Zhaoyang Liu, Qingyun Li, Xuan Dong, Zhe Chen, Weiyun Wang, Xiangyu Zhao, Jixuan Chen, Haodong Duan, Tianbao Xie, Chenyu Yang, Shiqian Su, Yue Yu, Yuan Huang, Yiqian Liu, Xiao Zhang, Yanting Zhang, Xiangyu Yue, Weijie Su, Xizhou Zhu, Wei Shen, Jifeng Dai, Wenhai Wang
- **所属**: Shanghai AI Laboratory, Shanghai Jiao Tong University, Xiamen University, University of Science and Technology of China, The Hong Kong University of Science and Technology, Harbin Institute of Technology, Tsinghua University, Nanjing University, Fudan University, University of Hong Kong, Donghua University, The Chinese University of Hong Kong
- **投稿日**: 2025年07月28日
- **カテゴリ**: cs.CV, cs.CL

## 簡単に説明すると
この論文は、GUIを操作するAIエージェントを評価するための包括的なベンチマーク「MMBench-GUI」を提案しています。

MMBench-GUIは、Windows、macOS、Linux、iOS、Android、Webの6つのプラットフォームにわたって、8,000以上のタスクを含む階層的な評価フレームワークです。4つの段階的な難易度レベル（GUI理解、要素グラウンディング、タスク自動化、タスク協調）を設定し、GUIエージェントの能力を体系的に評価します。

特に注目すべきは、タスクの成功率だけでなく、どれだけ効率的にタスクを完了したかを測定する新しい評価指標「Efficiency-Quality Area (EQA)」を導入したことです。これにより、実用的なGUIエージェントに必要な「正確さ」と「効率性」の両面を評価できます。

ベンチマークのコードとデータは公開予定とのことで、https://github.com/open-compass/MMBench-GUI で利用可能になる予定です。

## 1. 研究概要
### 1.1 背景と動機
近年、Vision-Language Model（VLM）の急速な発展により、GUIを操作するAIエージェントの能力が大幅に向上しています。AnthropicのComputer-Use AgentやOpenAIのOperatorなど、実用的なGUIエージェントが登場し始めています。しかし、既存の評価ベンチマークには以下のような重大な制限がありました。

第一に、既存のベンチマークは個別の能力を評価することに重点を置いており、エージェントの総合的な能力や複数の能力間の関係を包括的に分析できていませんでした。例えば、ScreenSpotは空間的な位置特定能力を評価し、OSWorldは最終的なタスクの成功に焦点を当てていますが、根底にある能力の全範囲を直接評価していません。

第二に、現在の評価指標はタスクの精度と成功率を主に重視し、操作効率を見落としています。実際の使用場面では、タスクを完了するだけでなく、どれだけ効率的に完了するかも重要です。

第三に、評価シナリオのカバー範囲が不十分で、実世界で広く使用されているGUIシステムを完全に代表していません。特に、macOSプラットフォームのオンラインタスク評価が欠如していました。

これらの課題を解決するため、研究チームは包括的で階層的、かつマルチプラットフォームなベンチマークフレームワークの開発が必要だと判断しました。

### 1.2 主要な貢献
この研究の主要な貢献は以下の通りです。

- 人間中心の視点から着想を得た、進歩的な構造を持つクロスプラットフォーム・階層的ベンチマークの提案。4つの必須能力をカバーし、静的タスク（L1とL2）では細粒度の難易度層別化を導入し、動的タスク（L3とL4）では実世界の変動性をより良く反映する新しいタスク構築を提供しています。
- Windows、Linux、macOS、Android、iOS、Webを含む広く使用されているすべてのオペレーティングシステムにまたがる初の評価ベンチマークの開発。統一されたプロトコルの下で、GUIエージェントの一貫したマルチプラットフォーム評価を可能にしました。特に、macOSのオンラインタスクシナリオを含む初のベンチマークとなっています。
- オンラインタスクでのエージェント行動の成功と効率の両方を評価する新しい指標「Efficiency-Quality-Aware (EQA)」の導入。従来の成功率（SR）のみに焦点を当てていたベンチマークとは異なり、EQAはタスクがステップ予算内でいつ完了したかも考慮し、アクションの冗長性を測定します。

## 2. 提案手法
### 2.1 手法の概要
MMBench-GUIは、GUIエージェントの能力を体系的に評価するための階層的フレームワークです。人間がGUIタスクを実行する際に必要な認知能力の分析に基づいて、評価プロセスを多段階の階層に整理しています。

具体的には、以下の4つの上昇レベルで構成されています：
1. L1-GUI Content Understanding（GUI内容理解）：GUIスクリーンショットから情報を抽出、理解、推論する能力を評価
2. L2-GUI Element Grounding（GUI要素グラウンディング）：インタラクティブなUI要素の正確な空間的位置特定能力を測定
3. L3-GUI Task Automation（GUIタスク自動化）：単一アプリケーション内でのエンドツーエンドの自動化能力を評価
4. L4-GUI Task Collaboration（GUIタスク協調）：複数のアプリケーション間での協調的なタスク実行能力を評価

各レベルは複雑さが増加するタスクセットと関連付けられており、徐々に要求の厳しいシナリオでのエージェントの熟練度をテストするように設計されています。

### 2.2 技術的詳細
#### L1-GUI Content Understanding
L1レベルでは、GUIスクリーンショットに基づく多肢選択式の質問応答（MCQA）タスクとして形式化されています。エージェントは視覚的観察（GUIスクリーンショット）Vと質問q、選択肢のセットOを入力として受け取り、正しい答えo*を選択する必要があります。

質問は3つの難易度（easy、medium、hard）に分類され、UI要素の機能、インターフェース内の構造的関係、コンテンツの状態、階層的レイアウト、実行可能なタスクなど、GUIのさまざまな側面に焦点を当てています。

評価指標としては、選択肢数に応じた動的調整係数αを導入した精度を使用しています。

#### L2-GUI Element Grounding
L2レベルでは、タスク目的と現在の観察（スクリーンショット）に基づいて、対象要素の空間的位置を正確に特定する能力を評価します。

指示は2つのタイプに分類されます：
- Basic：視覚的特徴と大まかな位置を記述し、知覚ベースのグラウンディングをテスト
- Advanced：暗黙的な手がかりを通じて機能的理解をターゲットとする

評価では、エージェントが予測したインタラクションポイント（座標）が注釈付きバウンディングボックス内に入るかどうかで成功を判定します。

#### L3-GUI Task Automation
L3レベルでは、単一アプリケーション内での複数ステップのタスクを完了する能力を評価します。エージェントは各時間ステップtで、現在のUI状態の視覚的観察Vtを受け取り、タスク指示、履歴、関連アプリケーションに基づいてアクションAtとパラメータPtを生成します。

重要な革新として、Efficiency-Quality Area (EQA)指標を導入しました。EQAは、タスクの成功と完了速度を共同で考慮し、より少ないステップでより多くのタスクを解決するエージェントに報酬を与えます。

#### L4-GUI Task Collaboration
L4レベルでは、複数のアプリケーション間でアクションを調整し、複雑なワークフローを編成する能力を評価します。エージェントは異なるインターフェース間で情報を転送し、アプリケーション間の依存関係を管理し、操作を一貫して順序付ける必要があります。

### 2.3 新規性
MMBench-GUIの主要な新規性は以下の点にあります：

1. 階層的評価フレームワーク：基本的なインターフェース理解から複雑なクロスアプリケーションタスク実行まで、段階的に評価する体系的なアプローチ
2. マルチプラットフォーム対応：6つの主要プラットフォーム（Windows、macOS、Linux、iOS、Android、Web）を統一的に評価できる初のベンチマーク
3. 効率性指標EQA：タスクの成功率だけでなく、完了までのステップ数を考慮した新しい評価指標
4. 実世界のタスクを反映した評価設計：スクリーンショットのみを使用し、A11yツリーやSoMデータなどの補助的なアーティファクトを意図的に除外

## 3. 実験結果
### 3.1 実験設定
評価には、プロプライエタリモデル（GPT-4o、Claude-3.7、Qwen-Max-VL）とオープンソースモデル（Qwen2.5シリーズ、UI-TARSシリーズ、InternVLシリーズ、Aguvis、ShowUI、UGround、OS-Atlas）を含む、代表的なVLMとLLMモデルのスペクトラムを使用しました。

ベンチマークは8,123のタスクで構成され、各プラットフォームの内訳は以下の通りです：
- Windows: 1,536タスク
- macOS: 1,013タスク
- Linux: 1,344タスク
- iOS: 989タスク（L3&L4は除く）
- Android: 1,758タスク
- Web: 1,483タスク

### 3.2 主要な結果
L1（GUI理解）の結果では、InternVL3-72Bが全難易度レベルで最高のパフォーマンスを示し、easyレベルで79.15%、mediumレベルで77.89%、hardレベルで75.70%の精度を達成しました。

L2（要素グラウンディング）では、専門的な視覚グラウンディングモデルが汎用言語モデルを大幅に上回りました。例えば、UGround-V1-7Bは平均65.68%のスコアを達成したのに対し、GPT-4oは2.87%、Claude-3.7は4.66%にとどまりました。

L3（タスク自動化）では、モジュラーアプローチ（GPT-4o + UGround-V1-7BまたはGPT-4o + UI-TARS-1.5-7B）が最高の成功率を示しました。50ステップの予算で、これらの組み合わせは17.50%と26.58%の成功率を達成しました。

L4（タスク協調）では、すべてのモデルのパフォーマンスが大幅に低下し、最高のモデル（GPT-4o + UI-TARS-1.5-7B）でも成功率は8.87%にとどまりました。

### 3.3 既存手法との比較
既存のベンチマークと比較して、MMBench-GUIは以下の優位性を示しました：

1. 包括性：単一の能力評価に焦点を当てた既存のベンチマーク（ScreenSpot、OSWorldなど）と異なり、MMBench-GUIは4つの相互に関連する能力を体系的に評価
2. プラットフォームカバレッジ：特定のプラットフォームに限定された既存のベンチマークと異なり、6つの主要プラットフォームすべてをカバー
3. 効率性評価：成功率のみを評価する既存のベンチマークと異なり、EQA指標により操作効率も評価可能

## 4. 実用性評価
### 4.1 実装の容易性
MMBench-GUIは、研究者と開発者が容易に使用できるように設計されています。評価環境は仮想化技術を使用して構築されており、再現可能で堅牢なGUI環境を提供します。ベンチマークコードとデータは公開予定で、標準的な評価プロトコルに従って実装されています。

### 4.2 計算効率
EQA指標の分析により、現在のGUIエージェントの計算効率に関する重要な洞察が得られました。多くのモデルは、タスクを最終的に完了した場合でも、過度の冗長ステップを含んでいます。例えば、UI-TARS-72B-DPOは最も強い効率プロファイルを達成し、EQ1を0.773に増加させながら、EQ2を8.96から5.75に圧縮しました。

### 4.3 応用可能性
MMBench-GUIの応用可能性は非常に広範です：

1. GUIエージェント開発：開発者は自身のモデルの弱点を特定し、改善に焦点を当てることができます
2. クロスプラットフォーム自動化：異なるプラットフォーム間でのエージェントの汎化能力を評価できます
3. 実世界のタスク自動化：オフィス作業、ウェブナビゲーション、モバイルアプリ操作など、様々な実用的なシナリオでの評価が可能

## 5. まとめと所感
### 5.1 論文の意義
この研究は、GUIエージェント評価の分野に重要な貢献をしています。特に、以下の5つの重要な発見が得られました：

1. 汎用言語モデルは、タスク分解、計画、自己反省に優れているが、細粒度の視覚的インタラクションに苦戦する
2. 正確な視覚グラウンディングがGUIタスク実行の成功率を大きく決定する
3. 効率性（ステップの最小化と早期停止を含む）は、GUIエージェントのパフォーマンスの重要だが未探索の次元である
4. アクション空間の制限により、特にGUIタスク協調シナリオでエージェントの計画されたアクションの実行能力が制限される
5. 多くのGUIエージェントは単純なケースでは優れているが、タスクの複雑さが増すにつれてその有効性は大幅に低下し、限定的な汎化能力を明らかにする

これらの発見は、現在のGUIエージェントの根本的なボトルネックを明らかにし、将来の研究開発に貴重な指針を提供しています。

### 5.2 今後の展望
研究チームは、今後の展開として以下の3つの側面を強化する予定です：

1. より広範なモデルカバレッジ：オープンソース、プロプライエタリ、最新のRLベースのシステムを含む、より広いスペクトラムのモデルを評価
2. より深い分析：より豊富な実験プールで、細粒度の分析を実行し、より堅牢で一般化可能な発見を生成
3. タスクの拡張とエラー帰属：より広範なアプリケーションをカバーするためにオンラインタスクを追加し、その正確性を段階的に検証し、失敗の正確な原因を特定するための十分なランタイム詳細をログに記録

この研究は、実用的なGUIエージェントの開発に向けた重要な一歩であり、今後のAIエージェント研究の基盤となることが期待されます。