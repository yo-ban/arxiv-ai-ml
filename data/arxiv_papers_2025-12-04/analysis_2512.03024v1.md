# TokenPowerBench: Benchmarking the Power Consumption of LLM Inference

## 基本情報
- arXiv ID: 2512.03024v1 (https://arxiv.org/abs/2512.03024v1)
- 著者: Chenxu Niu・Wei Zhang・Jie Li・Yongjian Zhao・Tongyang Wang・Xi Wang・Yong Chen
- 所属: Texas Tech University, Texas Advanced Computing Center, Southeast University
- 投稿日: 2024年12月4日
- カテゴリ: cs.AI

## 簡単に説明すると
本論文では大規模言語モデル（LLM）の推論における電力消費を測定・分析するための初の包括的ベンチマークフレームワーク「TokenPowerBench」を提案しています。LLMサービスが日々数十億のクエリに応答する現在、推論処理が総電力消費の90%以上を占めています。しかし既存のベンチマークは主に訓練やパフォーマンスに焦点を当てており、推論の電力消費測定は十分にサポートされていません。

TokenPowerBenchは3層アーキテクチャを特徴としています。それはモデル選択・プロンプトデータセット・推論エンジンの宣言的設定インターフェースです。またGPU・ノード・システムレベルの電力キャプチャ測定層、prefillとdecodeステージへのエネルギー帰属するフェーズ整列メトリクスパイプラインです。

本フレームワークは1億パラメータから先端Llama3-405Bモデルまで15以上の人気オープンソースLLMをカバーしています。バッチサイズ・コンテキスト長・並列化戦略・量子化などのパラメータがトークンあたりのジュール数に与える影響を詳細に分析しています。

## 1. 研究概要
### 1.1 背景と動機
LLMがモダンAIアプリケーションの基盤インフラとなり、翻訳・推薦・対話などで数十億のユーザインタラクションを処理している。大学・国立研究所・クラウドプロバイダがGPU支援推論サービスとAIテストベッドを設置する中、根本的なシステム課題が未解決のまま残っている。それは「LLMプロンプトを提供するための電力消費は何か。」という問いです。先行研究はLLM訓練のエネルギー需要に主に焦点を当てていました。しかし最近の証拠は推論プロセスが大規模デプロイメントでエネルギーフットプリントを支配することを示しています。AWSレポートによると、推論がエネルギー消費の90%以上を占めています。グローバルLLM市場は2024年の約56億ドルから2030年には350億ドル超に拡大予測されています。AI推論市場も2025年の1060億ドルから2030年には2500億ドル超に成長予測されています。Gartnerは2028年までにデータセンターワークロードアクセラレータの80%以上が推論専用になると予測しています。

### 1.2 主要な貢献
本研究の主要な貢献は次の通りです。

まず、初の包括的ベンチマークとして、TokenPowerBenchはフェーズ認識電力テレメトリとトークンレベル正規化を結合した初のオープンソースフレームワークです。これはMLPerfや既存プロファイリングツールが残した重要なギャップを埋めます。

次に、幅広いモデルカバレッジとして、初回リリースで15以上の人気オープンソースLLMをプロファイルします。1B-405Bパラメータの範囲でLLaMAシリーズ・Mistralシリーズ・Falconシリーズ・Qwenシリーズを含み、コミュニティにとって最も包括的なエネルギーデータセットを提供します。

さらに、初のパラメータ感度分析として、推論パラメータがdecodeフェーズ全体でエネルギー消費に与える影響の詳細な比較を提供します。バッチサイズ・コンテキスト長・量子化などのパラメータが対象です。

最後に、先端SOTAモデル対応として、先端LLMの代表例であるLlama 3.1 405Bのケーススタディに基づく詳細分析を特徴とします。

## 2. 提案手法
### 2.1 手法の概要
[詳細な説明]。

### 2.2 技術的詳細
[アルゴリズムや数式の説明]。

### 2.3 新規性
[既存手法との違い]。

## 3. 実験結果
### 3.1 実験設定
[データセット、評価指標など]。

### 3.2 主要な結果
[定量的・定性的結果]。

### 3.3 既存手法との比較
[比較結果と分析]。

## 4. 実用性評価
### 4.1 実装の容易性
[評価]。

### 4.2 計算効率
[評価]。

### 4.3 応用可能性
[評価]。

## 5. まとめと所感
### 5.1 論文の意義
[考察・総合評価]。

### 5.2 今後の展望
[将来性や改善点]。
