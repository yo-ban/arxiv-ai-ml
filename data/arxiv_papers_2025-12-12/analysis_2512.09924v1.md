# ReViSE: Towards Reason-Informed Video Editing in Unified Models with Self-Reflective Learning

## 基本情報
- arXiv ID は 2512.09924v1 である（https://arxiv.org/abs/2512.09924 ）
- 著者は Xinyu Liu、Hangjie Yuan、Yujie Wei、Jiazheng Xing、Yujin Han、Jiahao Pan らである
- 所属機関は香港科技大学、浙江大学、復旦大学、香港大学、中国人民大学、通義実験室である
- 投稿日は2024年12月13日である
- カテゴリは cs.CV、cs.AI である

## 簡単に説明すると
この論文は、動画編集における推論能力の不足を解決する新しいフレームワーク「ReViSE」を提案しています。
現在の統合動画生成モデルは、理解と生成においては優秀ですが、物理的妥当性や因果関係を考慮した推論に基づく動画編集では苦戦しています。
例えば「ボートを削除する」のような単純な操作はできます。しかし「ボートが出発した1時間後の景色を想像する」といった時間的推論を要する編集には対応できません。

ReViSEは、モデル内部のVision-Language Model（VLM）を活用した自己反映学習フレームワークにより、この問題を解決します。
内部のVLMが編集結果を評価し、指示と論理的に一致するかどうかのフィードバックを提供することで、生成器の推論行動を改善します。
また、RVE-Benchという包括的なベンチマークを構築し、推論に基づく動画編集の系統的評価を可能にしています。
実験では、従来手法に対して32%の性能向上を達成しています。
コードとモデルは https://github.com/Liuxinyv/ReViSE で公開されています。

## 1. 研究概要
### 1.1 背景と動機
近年の統合生成モデルは印象的な編集能力を示していますが、その多くは視覚的要素の追加、削除、置換といった文字通りの変換に限定されています。
これらのモデルは、シーン内の基本的なプロセスや物理的力学の理解を必要とする推論に基づく編集において課題を抱えています。
このような編集では、単純なパターン認識を超えて、物理的妥当性と因果的力学に関する暗黙的推論を統合します。

従来の指示による動画編集手法は、主に表面レベルのピクセル操作に焦点を当てています。実世界の理解に必要な暗黙の因果関係や常識的推論が欠けています。
この制限により、指示に対して意味的に忠実でありながら、シーンの文脈と論理的かつ物理的に一貫した編集を実現することが困難になっています。

この研究は重要な観察に基づいています。強力な理解能力と生成能力を持つことが、推論による編集の熟練度を必ずしも保証しないことです。
Supervised Fine-Tuning（SFT）は指示追従を改善しますが、推論能力の向上には不十分であることが判明しています。

### 1.2 主要な貢献
この研究では、推論に基づく動画編集における根本的な課題に対処するため、以下の主要な貢献を提供しています。

- RVE-Benchの提案：Reason-Informed Video Editing（RVE）タスクのための初の包括的ベンチマークで、複雑な実世界動的システムの暗黙的理解をモデルに求める評価基盤
- ReViSE（Self-Reflective Reasoning）フレームワークの開発：統合モデルが内部VLMを本質的批評者として活用するエンドツーエンド自己教師ありパラダイム
- 包括的実験による性能実証：RVE-Benchにおいて最先端性能を達成するだけでなく、論理的一貫性と視覚品質の両方における自己反映機構の有効性を詳細分析で検証

## 2. 提案手法
### 2.1 手法の概要
ReViSEフレームワークは、生成モジュールと内部理解モジュールの2つの中核コンポーネントから構成されています。
生成モジュールは動画編集を担当し、内部理解モジュールは編集精度を評価して自己反映フィードバックを提供します。
この相乗効果により、モデルは訓練中に推論能力を反復的に洗練できます。

アーキテクチャは、事前訓練済みVision-Language Model（例：ViLA）と生成拡散モデル（例：Wan）を活用したコネクタベース統合モデルを基盤としています。
マルチモーダル入力は別々のエンコーダーで処理されます。ソース動画は動画エンコーダーで視覚の潜在表現に変換されます。テキスト指示はT5エンコーダーでテキストトークンシーケンスに変換されます。
理解モジュールは視覚的・テキスト的入力の両方を処理してマルチモーダル意味表現を生成します。

### 2.2 技術的詳細
自己反映機構の中核は、モデルの内部理解モジュールを安定で信頼性のある検証器として機能させることです。
QAベース検証機構を導入し、モデルがVLMを活用して編集の精度と一貫性を検証できるようにします。

信頼性のある検証を確保するため、理解モジュールに最終的な「Yes/No」確率スコアを予測する前に動画編集プロセスを推論するよう指示するシステムプロンプトを設計しています。
各編集指示に対して、VLMは4つの重要な次元で編集結果を評価します：編集精度、保存一貫性、生成自然性、生成リアリズム。
VLMは全4次元が満たされた場合のみ「Yes」と応答し、そうでなければ「No」と応答します。

訓練目的として、Unified Semantic Optimization（USO）とReward Weighted Optimization（RWO）の2つの最適化戦略を提案しています。
USOは生成損失と統合意味損失を組み合わせ、RWOは批評者のフィードバックに基づいて生成損失を重み付けする、より直接的なアプローチを提供します。

### 2.3 新規性
ReViSEの新規性は、統合動画モデルにおいて推論と編集を橋渡しする自己反映学習パラダイムにあります。
従来の強化学習手法が高価な外部報酬モデルに依存するのに対し、ReViSEは主として内的監督で動作します。

内部VLMを批評者として活用することで、生成された編集が指示を論理的に満たすかどうかを評価し、生成器に勾配レベルのフィードバックを提供します。
この自己教師ありアプローチは、外部データセットや人間のアノテーションを必要とせずに、モデルが自身の推論能力を向上させることを可能にします。

さらに、RVE-Benchベンチマークの構築により、推論に基づく動画編集の系統的評価が初めて可能になりました。
このベンチマークは、明示的推論と文脈内生成の2つの相補的サブセットを含み、多様な推論次元と実世界編集シナリオをカバーしています。

## 3. 実験結果
### 3.1 実験設定
RVE-Benchでの実験は、Omni-Video、InsV2V、InsViE、VACEなど複数の最先端ベースライン手法と比較して実施されました。
評価は6つの主要メトリクスで行われました。ViCLIP_T、Edit Accuracy、Preservation Consistencyが含まれます。
また、Generation Naturalness、Generation Realism、Overall scoreも評価対象としています。

ベンチマークは1,000のユニークなトリプレット（ソース動画、テキスト指示、対応する編集動画）で構成され、GPT-4oを活用した堅牢な推論対応評価フレームワークを使用しています。
評価は意味的一貫性と知覚品質の2つの主要側面から生成動画を評価します。

実験は4つの推論カテゴリ（因果推論、時間推論、空間推論、常識推論）にわたって実施され、各カテゴリでReViSEの性能を詳細に分析しています。

### 3.2 主要な結果
ReViSEは全推論カテゴリにわたって一貫して他のモデルを上回り、特にEdit Accuracy（EA）側面で最も大幅な改善を達成しました。
時間推論では38%のOverallスコア改善（3.6756→5.0786）、因果推論では30%の改善を実現しています。

従来手法と比較して、ReViSEは推論に基づく指示の解釈と実行における優れた能力を実証しました。
例えば、「深い森に逃げ込んだ」という指示から背景を「深い森」に変換する際、視覚的一貫性を維持しながらアーティファクトを回避することに成功しています。

文脈内の動画生成サブセットでは、ReViSEが複雑な変換を正確に解釈することが示されました。「丸太が機械的変換を受けて木材チップの山に積み重なる」といった変換において現実的な動画を生成する唯一の手法です。

### 3.3 既存手法との比較
従来の動画編集データセット（Ditto-1M）での評価では、ReViSEは4つの代表的ベースラインを一貫して上回り、Overallスコアで36.7%の向上を達成しました。
保存一貫性（PC）スコアが低めに報告されています。これは編集品質の低さを意味するのではなく、むしろ意味のある変更をしていることを示しています。

訓練目的のアブレーション研究では、SFTとRWOが編集性能を改善する一方、USOが全メトリクスで優れた結果を達成することが示されました。
USOは編集精度を27%改善し、RWOの11%改善を大きく上回りました。

定性的結果は、ReViSEが物理的プロセスを論理的に理解することを確認しています。指示に応じて高品質な視覚的変換を生成する能力を有しています。

## 4. 実用性評価
### 4.1 実装の容易性
ReViSEフレームワークは既存のコネクタベース統合モデルに容易に統合可能です。
内部VLMを批評者として活用するアプローチは、外部報酬モデルや追加データセットの必要性を排除し、実装の簡素化を実現しています。

フレームワークの自己教師あり性質により、人間のアノテーションやドメイン専門知識への依存を最小限に抑えています。
標準的な深層学習フレームワークでの実装が可能で、既存のコードベースとの統合も比較的容易です。

QAベース検証機構の設計は直感的で理解しやすく、システムプロンプトの調整により異なるタスクや要求に適応可能です。

### 4.2 計算効率
自己反映学習アプローチは、外部モデルへの依存を回避することで計算効率を向上させています。
内部VLMの活用により、追加の推論オーバーヘッドを最小限に抑えながら品質向上を実現しています。

フレームワークの統合的性質により、別々の理解モジュールと生成モジュールを維持する必要がなく、メモリ効率も改善されています。
訓練中の勾配計算も効率的に実行され、大規模データセットでのスケーラビリティを確保しています。

### 4.3 応用可能性
ReViSEの応用範囲は広く、教育コンテンツ作成、映画制作、ゲーム開発など多様な分野での活用が期待されます。
推論に基づく編集能力により、より高度で自然な動画変換が可能になります。

医療や科学分野での可視化、建築や工業デザインでのプロトタイピング、マーケティングでの創造的コンテンツ生成など、専門分野での応用も有望です。
フレームワークの汎用性により、異なるドメインや言語への適応も比較的容易と考えられます。

リアルタイム編集アプリケーションへの展開も技術的に実現可能で、ユーザーインターフェースの改善により一般ユーザーへの普及も期待できます。

## 5. まとめと所感
### 5.1 論文の意義
この論文は、動画編集における推論能力の重要性を明確に示し、実用的な解決策を提供している点で高く評価できます。
統合動画モデルの理解能力と生成能力のギャップを埋めるという明確な問題設定があります。自己反映学習による革新的アプローチは学術的および実用的に意義深いものです。

RVE-Benchの構築により、推論に基づく動画編集の評価基盤が確立され、今後の研究発展に重要な貢献をしています。
ベンチマークの多様性と包括性は、この分野の標準的評価ツールとしての価値を持つと考えられます。

技術的革新として、外部報酬モデルに依存しない自己教師あり学習アプローチは、実装の簡素化と性能向上を同時に実現している点で特に価値があります。
これは、より広範囲なアプリケーションでの採用を促進する可能性があります。

### 5.2 今後の展望
今後の研究方向として、より複雑な推論タスクへの拡張や、マルチモーダル編集（音声やテキストとの同期編集）への応用が考えられます。
長期的な時間的推論や階層的推論への対応も重要な課題となるでしょう。

実世界データでの検証や、ユーザースタディによる人間の知覚との整合性確認も今後必要な評価項目です。
また、計算効率のさらなる改善や、より軽量なモデルでの実現可能性の探求も実用化に向けて重要です。

多言語対応や文化的コンテキストの考慮、倫理的編集ガイドラインの統合なども、グローバルな展開を考える上で重要な課題となるでしょう。
このフレームワークが推論に基づくAI生成コンテンツの発展における基盤技術となる可能性は高く、今後の発展が期待されます。