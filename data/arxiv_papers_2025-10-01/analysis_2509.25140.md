# ReasoningBank: Scaling Agent Self-Evolving with Reasoning Memory

## 基本情報
- arXiv ID: 2509.25140v1 (https://arxiv.org/abs/2509.25140)
- 著者: Siru Ouyang, Jun Yan, I-Hung Hsu, Yanfei Chen, Ke Jiang, Zifeng Wang, Rujun Han, Long T. Le, Samira Daruki, Xiangru Tang, Vishy Tirumalashetty, George Lee, Mahsan Rofouei, Hangfei Lin, Jiawei Han, Chen-Yu Lee, Tomas Pfister
- 所属: University of Illinois Urbana-Champaign, Google Cloud AI Research, Yale University, Google Cloud AI
- 投稿日: 2025年09月30日
- カテゴリ: cs.AI, cs.LG

## 簡単に説明すると
この論文は、大規模言語モデル（LLM）エージェントが過去の経験から学習し、持続的に改善していくための革新的なメモリフレームワーク「ReasoningBank」を提案しています。従来のエージェントは各タスクを独立して処理し、過去の成功や失敗から学習できないという重大な問題がありました。ReasoningBankは、成功体験だけでなく失敗体験からも一般化可能な推論戦略を抽出し、構造化されたメモリアイテムとして保存します。

さらに、メモリとテスト時スケーリングの強力な相乗効果を生み出す「MaTTS（Memory-aware Test-Time Scaling）」も導入している。これによりエージェントの探索経験を深化させ、より高品質なメモリを構築できる。WebArena、Mind2Web、SWE-Bench-Verifiedでの実験結果は、既存手法に対して最大34.2%の相対的改善と16.0%の効率向上を示している。

## 1. 研究概要

### 1.1 背景と動機
大規模言語モデルエージェントの急速な発展により、ウェブブラウジングやソフトウェア開発など、複雑な実世界タスクに対応する多段階対話型エージェントの需要が高まっています。これらのエージェントが永続的で長期実行される役割に展開されるにつれ、継続的なタスクストリームに自然に遭遇するようになります。

しかし、現在のエージェントには深刻な問題があります。各タスクを独立して処理するため、タスク間で蓄積された経験から学習できない。その結果、過去のエラーを繰り返し、関連問題から得られた貴重な洞察を破棄し、時間とともにエージェントシステムをより有能にする自己進化能力を欠いています。この問題は、過去の経験から学習できるメモリ対応エージェントシステムの構築の必要性を強調しています。

既存のエージェントメモリに関する研究は、主に過去の対話を再利用のために保存することに焦点を当てています。しかし、これらのアプローチは多くの場合、生の軌跡や一般的で成功したルーチン（ワークフロー、手順）の活用に限定されています。このようなアプローチには2つの根本的な欠点がある。第一に、より高レベルで転用可能な推論パターンを抽出する能力を欠いている。第二に、成功体験を過度に重視するため、エージェント自身の失敗から得られる貴重な教訓がほとんど探索されていない。

### 1.2 主要な貢献
この研究は3つの重要な貢献を提供している。

ReasoningBankフレームワークの提案では、成功体験と失敗体験の両方から一般化可能な推論戦略を抽出する新しいメモリフレームワークを開発した。これは、生の軌跡や成功のみのルーチンに限定された従来研究を超越する。

MaTTSによるメモリとスケーリングの相乗効果では、メモリとテスト時スケーリングの間に強力な相乗効果を生み出すMaTTSを導入した。メモリ駆動型経験をエージェントの新しいスケーリング次元として確立している。

実験評価では、WebArena、Mind2Web、SWE-Bench-Verifiedでの広範な実験を通じて、提案手法が既存方法に対して効果性と効率性の両方で改善をもたらすことを実証した。さらに、エージェントが失敗から学習し、時間とともにますます複雑で創発的な推論戦略を開発できることを示した。

## 2. 提案手法

### 2.1 手法の概要
ReasoningBankは、エージェントが過去の経験から学習し持続的に改善するための革新的なメモリフレームワークです。このシステムの核心は、生の軌跡ではなく構造化された知識単位として推論戦略とヒントを抽出し、将来の再利用のために保存することです。

システムは3つの主要なステップで動作する。まず、メモリ検索段階では、エージェントが現在のクエリコンテキストでReasoningBankを照会する。埋め込みベース類似性検索を使用してトップN個の関連経験とそれに対応するメモリアイテムを特定する。検索されたアイテムはエージェントのシステム指示に注入され、過去の有用な経験に基づいた意思決定を確保します。

現在のクエリタスクが完了すると、メモリ構築を行い新しいメモリアイテムを抽出する。LLM-as-a-judgeを採用して、クエリと軌跡が与えられた場合の結果を成功または失敗としてラベル付けし、グランドトゥルースにアクセスすることなく完了軌跡の正確性の代理信号を取得します。これらの信号に基づいて、成功体験は検証済み戦略を提供し、失敗体験は反実仮想信号と落とし穴を提供して防護策を鋭くします。

最後に、メモリ統合はこれらのアイテムを単純な追加操作でReasoningBankに組み込む。進化するメモリアイテムのリポジトリを維持する。これらのステップが組み合わさって閉ループプロセスを形成する。エージェントが過去の経験を活用し、現在のタスクから新しいメモリを構築する。継続的なメモリ更新により、テスト時学習シナリオでの持続的な進化を可能にする。

### 2.2 技術的詳細
**メモリスキーマ**: ReasoningBankのメモリアイテムは、低レベルの実行詳細を抽象化しながら転用可能な推論パターンと戦略を保持する構造化された知識単位として設計されている。各メモリアイテムは3つのコンポーネントを指定する。タイトルは核となる戦略や推論パターンを要約する簡潔な識別子である。説明はメモリアイテムの簡潔な一文要約である。コンテンツは過去の経験から抽出された蒸留推論ステップ、意思決定理論、運用洞察を記録する。

**MaTTS（Memory-aware Test-Time Scaling）**: ReasoningBankを強力な経験学習者として活用し、経験スケーリングを研究してメモリとテスト時スケーリングの間の強力な相乗効果を確立する。幅（より多くのタスクを追加）ではなく、深さ（各単一タスクをより多くの探索で取り組む）を通じて経験をスケールすることに焦点を当てている。

MaTTSは2つの補完的な実装を設計している。並列スケーリングでは、検索されたメモリアイテムの指導の下で同じクエリに対して複数の軌跡を生成する。異なる軌跡間での比較・対比（自己対比）により、一貫した推論パターンを特定しながら偽解を除外する。逐次スケーリングでは、初期完了後に単一軌跡内で推論を反復的に洗練し、自己洗練の原理に従う。この過程で生成される中間ノートも、最終解には現れない可能性のある推論試行、修正、洞察を捉えるため、メモリの貴重な信号として使用される。

### 2.3 新規性
この研究の主要な技術的新規性は複数の側面にわたる。まず、失敗からの体系的学習において、従来の手法が成功軌跡のみに焦点を当てるのに対し、ReasoningBankは失敗体験からも建設的な信号を抽出する最初のシステムである。これにより、予防的教訓と落とし穴の識別が可能になる。

メモリとテスト時スケーリングの統合は新しいパラダイムである。従来のテスト時スケーリングは推論タスクに焦点を当てており、多段階対話的シナリオでの応用は十分に探索されていなかった。この研究は、メモリがスケーリングを有望なロールアウトに導くことを示している。多様なロールアウトがより価値のある対比信号でメモリを豊かにする相乗効果を初めて実証している。

**構造化メモリ抽象化**では、タイトル/説明/コンテンツの三層スキーマにより、人間が解釈可能で機械が使用可能な両方の特性を持つメモリアイテムを作成します。これは生の軌跡保存や成功のみの手順とは根本的に異なるアプローチです。

**閉ループ学習プロセス**では、検索→構築→統合の継続的サイクルにより、エージェントが経験から継続的に学習し進化できる自己改善システムを実現しています。

## 3. 実験結果

### 3.1 実験設定
実験は3つの挑戦的なベンチマークで実施された。WebArenaは、多様なドメインにわたる一般的なウェブナビゲーションを特徴とし、Shopping、Admin、Gitlab、Reddit、Multiの5つのサブセットを含む。Mind2Webは、クロスタスク、クロスウェブサイト、クロスドメインの一般化でエージェントの汎用性をテストする。SWE-Bench-Verifiedは、リポジトリレベルの問題解決を評価する。

比較対象として、メモリフリーエージェント（No Memory）から軌跡ベースメモリ（Synapse）、ワークフローベースメモリ（AWM）まで幅広いベースラインを考慮した。エージェントは、ウェブブラウジング用のBrowserGym環境とSWE用のbash専用環境でGemini-2.5とClaude-3.7モデル上に構築された。ReActスタイルでデフォルトのデコーディング構成を使用した。

評価は効果性（成功率）と効率性（平均対話ステップ）に焦点を当て、各データセットで特定のメトリクスが異なります。WebArenaでは成功率（SR）とステップ数、Mind2Webでは要素精度（EA）、アクションF1（AF1）、ステップ成功率（SSR）、タスクレベル成功率（SR）、SWE-Bench-Verifiedでは解決率とステップ数を測定しました。

### 3.2 主要な結果
**ReasoningBankの一貫した優位性**: すべてのデータセットとLLMバックボーンでベースラインを一貫して上回りました。WebArenaでは、3つの異なるバックボーンLLMでメモリフリーエージェントと比較して全体的な成功率を+8.3、+7.2、+4.6改善しました。Mind2Webでも同様のパターンが見られ、クロスタスク、クロスウェブサイト、クロスドメイン設定で明確な利益を提供し、データセットとモデルサイズ全体での利益の一貫性とスケーラビリティを強調しています。

**転用可能なメモリによる汎化性向上**: 挑戦的な汎化設定でも評価しました。WebArenaのMultiサブセットは複数のウェブサイト間でのメモリ転送を要求し、ReasoningBankは最強ベースラインに対して+4.6の平均SR利益を達成しました。対照的に、AWMのような強力なベースラインは利益を提供できず、この設定では劣化さえしました。Mind2Webでは、より高い一般化要求を課すクロスドメイン設定で利益が特に顕著でした。

**効率性の大幅改善**: より高い成功率に加えて、タスク完了に必要な対話ステップ数も削減しました。WebArenaでは、ほぼすべてのサブセットとバックボーンで「No Memory」と比較して平均ステップ数を最大1.4削減し、他のメモリベースラインと比較して1.6削減しました。SWE-Bench-Verifiedでも平均ステップがそれぞれ2.8と1.3ステップ削減されました。

**MaTTSのスケーリング効果**: 並列スケーリングと逐次スケーリングの両方がパフォーマンスを向上させました。MaTTSでは、並列スケーリングが49.7（k=1）から55.1（k=5）に成長し、逐次スケーリングは49.7から54.5に上昇しました。メモリなしのMaTTSベースラインでは利益がより小さく一貫性がなく、MaTTSがより強力で安定した改善を可能にすることを強調しています。

### 3.3 既存手法との比較
**メモリとスケーリングの相乗効果**: より良いメモリがより強力なテスト時スケーリングパフォーマンスを可能にします。BoN結果に焦点を当てると、スケーリングの利益は基盤となるメモリに大きく依存します。メモリなしでは、スケーリングはわずかな改善しかもたらさず、BoNは39.0から40.6にしか上昇しません。SynapseやAWMのような弱いメモリメカニズムは適度な利益を提供し、それぞれ42.8と45.5に達します。対照的に、ReasoningBankを持つMaTTSは最強の利益を提供し、BoNが49.7から52.4に上昇します。

**スケーリングによる記憶キュレーションの改善**: スケーリングがメモリにどのようにフィードバックするかを公平に評価するため、Pass@1を報告しました。これはメモリキュレーション後の軌跡の平均品質を測定し、非スケーリングケースとの直接比較を可能にします。結果は印象的です：スケーリングは実際に弱いメモリのパフォーマンスを低下させ、Synapseは40.6から40.1に低下し、AWMは44.4から41.2に低下しました。対照的に、ReasoningBankは恩恵を受ける唯一の方法で、Pass@1が49.7から50.8に上昇しました。

**失敗軌跡の組み込み**: 成功軌跡のみを使用する場合と成功と失敗の両方を活用する場合を比較した結果、SynapseやAWMのようなベースライン手法は成功軌跡のみから記憶を構築するため、失敗から恩恵を受けることができません。失敗が追加された場合、それらのパフォーマンスは制限されるか劣化さえします。対照的に、ReasoningBankの設計は成功と失敗の両方から推論パターンの蒸留を可能にし、成功のみのトレースで46.5を達成し、失敗が含まれる場合はさらに49.7に改善しました。

## 4. 実用性評価

### 4.1 実装の容易性
ReasoningBankは実装の容易性を重視して設計されています。システムは意図的に最小限の設計を採用しており、複雑な統合アルゴリズムから生じる交絡因子を導入することなく、ReasoningBank自体の貢献を強調しています。メモリ検索には標準的な埋め込みベース類似性検索を使用し、統合は単純な追加操作を採用しています。

ストレージはJSON形式で維持され、各エントリはタスククエリ、元の軌跡、対応するメモリアイテムで構成されます。すべてのメモリアイテムは{title、description、content}スキーマで保存されます。埋め込みは各与えられたクエリに対して事前計算され、効率的な類似性検索のために別のJSONファイルに保存されます。

既存のLLMエージェントフレームワークとの統合は直截的で、メモリモジュールが関連メモリを追加のシステム指示としてエージェントに提供します。この設計により、既存のエージェントシステムへの組み込みが容易になり、最小限の変更で導入できます。

### 4.2 計算効率
計算コストの観点から、ReasoningBankは追加のLLM呼び出しを必要とします。具体的には、メモリ抽出のための呼び出し、LLM-as-a-judgeによる軌跡評価、検索のための埋め込み計算が含まれます。各軌跡に対して最大3つのメモリアイテムを抽出し、バックボーンLLMと同じ抽出器を温度1.0で使用します。

テスト時スケーリング（MaTTS）では、スケーリング因子kに比例して計算が増加します。並列スケーリングの場合は軌跡数、逐次スケーリングの場合は洗練ステップ数を示します。しかし、実験結果は、この追加計算投資が効果性（成功率向上）と効率性（ステップ削減）の両方で大きな見返りをもたらすことを示しています。

メモリプールは各独立実行で永続化され、テスト時学習全体を通じて経験の継続的蓄積を可能にします。現在の実装では線形成長となりますが、より高度な統合メカニズム（マージ、忘却）を将来的に組み込むことで、長期的なスケーラビリティを改善できます。

### 4.3 応用可能性
ReasoningBankフレームワークはドメインに依存しない設計となっており、幅広い応用可能性を持ちます。WebArena、Mind2Web、SWE-Bench-Verifiedでの評価により、ウェブブラウジングとソフトウェアエンジニアリングの両分野での有効性が実証されています。このフレームワークは、逐次意思決定を含む他のタスクにも適用可能です。

特に、構造化メモリスキーマ（タイトル/説明/コンテンツ）は一般化可能で、様々なドメインの推論パターンと戦略を捉えることができます。成功と失敗の両方から学習する能力は、多くの実世界アプリケーションで重要な特徴です。エージェントが展開される期間が長くなるほど、このような継続学習能力の価値は高まります。

メモリ駆動型経験スケーリングというパラダイムは、エージェントの新しいスケーリング次元として確立されており、従来の計算スケーリングを超えた革新的なアプローチを提供します。この概念は、より高度なエージェントシステムの開発において重要な方向性を示しています。

## 5. まとめと所感

### 5.1 論文の意義
この論文は、LLMエージェントの持続的改善という重要な問題に対して、実用的で効果的な解決策を提供しています。ReasoningBankフレームワークの最も重要な貢献は、失敗経験からの学習を体系化したことです。従来の研究が成功経験のみに焦点を当てる中、失敗から建設的な信号を抽出する能力は、より堅牢で適応性の高いエージェントシステムの構築において画期的な進歩です。

メモリとテスト時スケーリングの相乗効果の発見は、理論的にも実用的にも重要な意味を持ちます。単純な計算スケーリングを超えて、「メモリ駆動型経験スケーリング」という新しいパラダイムを確立することで、エージェント研究に新しい次元を追加しています。この相乗効果により、高品質なメモリがスケーリングをより有望な方向に導き、豊富な探索経験がより強力なメモリを構築するという好循環が生まれます。

実験結果の包括性と一貫性も注目に値します。WebArena、Mind2Web、SWE-Bench-Verifiedという異なる性質のベンチマークで、複数のLLMバックボーン（Gemini-2.5、Claude-3.7）で一貫した改善を示すことで、提案手法の汎用性と堅牢性を強く支持しています。特に、効果性だけでなく効率性の改善（最大26.9%のステップ削減）を同時に達成していることは、実用的な価値を高めています。

創発的行動の観察も興味深い発見です。メモリアイテムが実行指向の戦略から適応的自己反省、さらには構成的戦略へと進化する過程は、強化学習の学習ダイナミクスに似た現象を示しており、エージェントの高次推論能力の発展可能性を示唆しています。

### 5.2 今後の展望
この研究は将来的な発展方向について多くの可能性を開いています。まず、**構成的メモリ**の探索により、個別のメモリアイテムを高レベル戦略に組み合わせる能力を開発することで、より豊富な戦略とより強い汎化を長期間タスクで実現できる可能性があります。

**高度なメモリアーキテクチャ**の統合により、階層化された製品レベルのメモリスタックを構築することも重要な方向性です。エピソード的トレース、短期「作業」メモリ、長期統合知識を decay/refresh ポリシーとともに統合することで、より洗練されたメモリ管理システムを実現できます。

現在のシステムの制限事項への対処も必要です。LLM-as-a-judgeへの依存性を軽減するため、より強力な検証器、human-in-the-loopフィードバック、アンサンブル判定の導入により、メモリ誘導の信頼性を向上させることができます。また、より高度な統合メカニズム（マージ、忘却、階層化統合）の開発により、長期的なスケーラビリティの問題を解決できます。

さらに、このフレームワークを他のドメインや複雑なマルチエージェントシステムに拡張することで、集合的学習と経験共有の可能性を探索できます。メモリアイテムの構成性を活用したマクロレベル戦略の自動発見や、異なるタスクドメイン間でのメモリ転送学習も興味深い研究方向です。

この研究は、自己進化型エージェントシステムの実現に向けた重要な一歩を提供しており、今後のエージェント研究とAIシステムの実用展開において大きな影響を与える可能性があります。特に、継続的改善能力を持つ実世界エージェントの開発において、この研究が示したメモリ駆動型学習パラダイムは中核的な技術要素となることが期待されます。