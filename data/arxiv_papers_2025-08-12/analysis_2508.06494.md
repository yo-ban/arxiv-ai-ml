# LightSwitch: Multi-view Relighting with Material-guided Diffusion

## 基本情報
- arXiv ID: 2508.06494v1 (https://arxiv.org/abs/2508.06494)
- 著者: Yehonathan Litman, Fernando De la Torre, Shubham Tulsiani (Carnegie Mellon University)
- 所属: Carnegie Mellon University
- 投稿日: 2025年08月13日
- カテゴリ: cs.CV

## 簡単に説明すると
LightSwitchは、物体の複数視点画像から照明条件を変更した画像を生成する新しい手法です。この技術により、ある照明条件で撮影された物体の画像を、別の照明条件下での見た目に変換できます。例えば、室内で撮影された物体を屋外の太陽光下で撮影したような画像に変換可能です。

本手法の特徴は、物体の材質情報（アルベド、粗さ、金属性など）を推定して活用する点です。これにより、現実的で一貫性のある照明変更を実現しています。また、複数視点の画像を同時処理することで、視点間で一貫した結果を生成します。プロジェクトページは https://yehonathanlitman.github.io/light_switch で公開されています。

## 1. 研究概要
### 1.1 背景と動機
近年、NeRFやGaussian Splattingなどの技術により、複数視点の画像から高品質な3D表現を復元することが可能になりました。しかし、これらの手法で得られた3D表現は、撮影時の照明条件が焼き込まれており、新しい環境での照明下でレンダリングできません。これは、バーチャルリアリティや視覚効果の合成などの応用において大きな制限となっています。

既存のrelighting手法は、大きく2つのカテゴリに分類されます。逆レンダリング手法は、幾何形状、外観、材質特性を分離した3D表現を推定し、物理ベースレンダリングによってrelightingを実現します。しかし、これらの最適化ベースの手法は計算コストが高く、単純な微分可能レンダラーの使用により複雑な照明効果のモデリングが制限されます。

一方、学習ベースの「直接relighting」手法は、入力画像と目標照明から直接relightingされた画像を生成します。画像拡散モデルの活用により高品質な出力を効率的に生成できます。しかし単一視点での処理のため、視点間の一貫性が保たれません。

### 1.2 主要な貢献
本研究では、単一視点のrelightingタスクではなく、複数の入力視点を一貫してrelightingするタスクとして定式化することで、これらの問題を解決しています。さらに、逆レンダリング手法から着想を得て、予測された材質特性を追加入力として活用しています。主要な貢献は以下の通りです。

- 推定された内在的特性（材質情報）を活用したマルチビュー一貫性のあるrelighting拡散フレームワーク「LightSwitch」の提案
- 任意の数の入力画像に対応可能な分散推論スキームの開発。処理時間を従来手法の1/10以下に短縮
- 合成データと実世界データの両方において、既存の学習ベースrelighting手法を上回る性能の実証
- 高精度な逆レンダリング手法と同等以上のrelighting品質を、約2分という短時間で実現

## 2. 提案手法
### 2.1 手法の概要
LightSwitchは、固定された未知の照明下で撮影された複数視点のポーズ付き入力画像を受け取り、指定された目標照明条件でrelightingを行う拡散フレームワークです。本手法は、Stable Diffusion 2.1をベースとし、マルチビュー材質ガイドrelightingのためにファインチューニングされています。

システムは大きく2つの段階で構成されています。まず、単一視点でのrelightingを学習し、その後マルチビュー一貫性を持つrelightingへと拡張します。この段階的なアプローチにより、照明と物体の相互作用の理解を効果的に形成できます。

### 2.2 技術的詳細
**材質認識の単一視点Relighting**: relighting拡散UNetは、Stable Diffusion 2.1のUNetから初期化されます。未知の照明下の入力画像を目標照明下の画像へとrelightingするようにファインチューニングされます。UNetの入力層は、入力画像、材質内在情報、Plücker座標レイマップとしてエンコードされたカメラポーズ情報を条件付けするように修正されています。

材質情報として、アルベド、オクルージョン、粗さ、金属性（ORM）に対応するピクセルごとの画像材質マップを使用します。これらの材質表現は、簡略化されたDisney principled BRDFモデルに従っています。材質情報は照明間で一定であり、これを条件付けとして使用することで、鏡面反射や吸収などの多様な外観効果を持つビューのrelightingが可能になります。

**照明情報の組み込み**: 照明情報をdenoising UNetに組み込むため、照明クロスアテンションモジュールを追加し、UNetの残りの部分と共にファインチューニングします。目標照明は、高ダイナミックレンジ画像として与えられ、正規化環境マップとトーンマップされた環境マップの2つに変換されます。これらの組み合わせにより、強い照明（太陽、ライトなど）と柔らかい照明（反射、環境光など）の両方の情報をネットワークに提供できます。

**マルチビューRelightingのDenoising**: 単一視点relightingの学習後、マルチビュー予測のためにdenoising UNetを修正します。マルチビュー自己アテンションモジュールを追加し、継続的にトレーニングします。マルチビューアテンションにより、バッチ内のすべての潜在ピクセルが同じ空間で統合されます。これにより与えられた照明において、すべての入力外観情報を考慮した一貫性のあるrelightingを予測できます。

### 2.3 新規性
本手法の新規性は以下の点にあります。

1. **マルチビュー一貫性**: 従来の単一視点relighting手法とは異なり、複数視点を同時に処理することで、視点間で一貫したrelightingを実現している。ある視点で観察された手がかり（例：鏡面反射の鋭さ）が他の視点のrelightingに活用される。

2. **材質情報の活用**: 予測された材質特性（アルベド、粗さ、金属性）を追加入力として使用することで、複雑な外観効果を持つ物体のrelighting精度を向上させている。

3. **スケーラブルな推論スキーム**: 任意の数の入力視点に対応可能な分散denoising機構を導入している。各denoisingイテレーションでデータをシャッフルし、新しいバッチをサンプリングする。これにより、最終的にすべての潜在変数が相互にアテンションし、データセット全体で一貫した予測を実現する。

## 3. 実験結果
### 3.1 実験設定
実験では、BlenderVaultとObjaverseから約10万個のオブジェクトを含むデータセットを構築しました。各オブジェクトについて、半球上の8つのカメラポーズから8つの異なる環境マップ下でビューをレンダリングしています。環境マップは、PolyheavenやLavalなどのオンラインソースから取得した約4,000個のデータセットからランダムに選択されます。

評価には、合成データセットとしてNeRF synthetic dataset（5オブジェクト）、実世界データセットとしてObjects with Lighting（8オブジェクト）を使用しています。材質推定には、StableMaterialMVを使用し、512×512解像度での高品質な材質マップ推定のために追加でファインチューニングを行っています。

### 3.2 主要な結果
**2D画像Relighting**: 合成テストオブジェクトでの評価において、LightSwitchは既存の拡散ベースrelighting手法を上回る性能を示しました。比較対象はNeural GafferとDiLightNetです。画像レベルリスケーリング（ILR）での評価では、PSNRが26.01、SSIMが0.888、LPIPSが0.216を達成し、ベースライン手法を上回っています。

特に注目すべきは、シーンレベルリスケーリング（SLR）での評価結果です。これはシーン内のすべてのビューで単一のスケールを計算する厳しい指標です。LightSwitchは他の手法と比較して最小の品質低下（PSNR低下0.15）を示し、視点間の一貫性が高いことを実証しています。

**3D Novel View Relighting**: NeRF syntheticデータセットでの評価では、LightSwitchは5つのオブジェクトすべてにおいて高い性能を示しました。高度な逆レンダリング手法（MaterialFusion、NVDiffrecMC、TensoIR、R3DGS）と同等以上の結果を達成しています。処理時間において優位性があり、約2分で高品質なrelightingを実現しています（比較手法は15分から480分）。

Objects with Lightingデータセットでの実世界オブジェクトの評価でも、LightSwitchは多くの逆レンダリング手法を上回る性能を示しました。具体的にはPSNR: 25.43、SSIM: 0.84、LPIPS: 0.297を達成しました。

### 3.3 既存手法との比較
定性的な比較において、LightSwitchは以下の点で優れています。

1. **外観の正確性**: ベースライン手法はソースビューの詳細を目標relightingに焼き込んでしまう。一方、LightSwitchは材質情報を活用して鏡面反射などの複雑な外観効果を正確にrelightingする。

2. **視点間の一貫性**: 単一視点手法では視点間で不一貫なrelightingが生じるが、LightSwitchはマルチビューアテンションにより一貫した結果を生成する。

3. **処理効率**: 逆レンダリング手法と比較して、短い処理時間で同等以上の品質を実現している。8つのRTX A6000 GPUを使用した場合、約2分で処理が完了する。

## 4. 実用性評価
### 4.1 実装の容易性
LightSwitchは、Stable Diffusion 2.1をベースとしているため、既存の拡散モデルのインフラストラクチャを活用できます。材質推定にはStableMaterialMVを使用し、3Dガウシアンスプラッティングによる新規視点合成も標準的な手法を採用しているため、実装は比較的容易です。

分散推論スキームも、バッチ処理とシャッフリングという単純な仕組みで実現されており、特殊なハードウェアや複雑な実装を必要としません。

### 4.2 計算効率
本手法の大きな利点は、その計算効率の高さです。8つのGPUを使用した場合、約2分で高解像度（1728×1120）のrelightingが可能です。1つのGPUのみを使用した場合でも約14分で処理が完了し、これは最速の逆レンダリング手法（R3DGS）と同程度ですが、はるかに高品質な結果を生成します。

分散推論により、入力視点数に応じてスケーラブルに処理できるため、密な多視点データにも効率的に対応可能です。

### 4.3 応用可能性
LightSwitchは以下のような幅広い応用が期待されます。

1. **バーチャルリアリティ/拡張現実**: 実世界で撮影されたオブジェクトを仮想環境に統合する際、環境の照明に合わせてオブジェクトの外観を調整できる。

2. **映画・ゲーム制作**: 既存の3Dアセットを異なる照明シーンで再利用する際に、物理的に正確なrelightingを高速に実現できる。

3. **Eコマース**: 商品画像を様々な照明条件下で表示することで、より現実的な商品プレビューを提供できる。

4. **建築ビジュアライゼーション**: 建物や内装を異なる時間帯や天候条件下でビジュアライズできる。

## 5. まとめと所感
### 5.1 論文の意義
LightSwitchは、マルチビューrelightingという重要な問題に対して、材質情報と拡散モデルを効果的に組み合わせた革新的なアプローチを提示しています。従来の逆レンダリング手法の精度と、学習ベース手法の効率性を両立させることに成功しており、実用的な3Dコンテンツ制作パイプラインへの統合が期待できます。

特に、視点間の一貫性を保ちながら高品質なrelightingを実現し、かつ処理時間を短縮した点は、実用化に向けて極めて重要な貢献です。査読前の論文ではありますが、定量的・定性的評価の両面で説得力のある結果を示しており、技術的な完成度は高いと評価できます。

### 5.2 今後の展望
論文で指摘されている制限事項として、事前学習済み拡散モデルの固定された潜在空間への依存があります。これにより反射などの鋭い細部のエンコード/デコード能力が制限されます。またアーキテクチャはマルチビュー一貫性と材質認識推論を促進しますが、予測が物理的に妥当であることは保証されていません。

今後の研究方向として、学習ベースのrelightingと物理ベースレンダリングをより密接に結びつける代替アーキテクチャやメカニズムの探求が期待されます。また、より大規模で多様なデータセットでの学習や、動的なシーンへの拡張、リアルタイム処理の実現なども重要な課題として挙げられます。

本研究は、高品質な3Dコンテンツ制作の民主化に向けた重要な一歩であり、今後のrelighting技術の発展に大きな影響を与える可能性があります。