# Interactive Training: Feedback-Driven Neural Network Optimization

## 基本情報
- **arXiv ID**: 2510.02297v1 (https://arxiv.org/abs/2510.02297)
- **著者**: Wentao Zhang, Yang Young Lu, Yuntian Deng
- **所属**: University of Waterloo, University of Wisconsin-Madison
- **投稿日**: 2025年10月03日
- **カテゴリ**: cs.LG

## 簡単に説明すると
この論文は、ニューラルネットワークの訓練を従来の「設定して待つ」方式から「リアルタイムで調整できる」方式に変革する「Interactive Training」フレームワークを提案している。
料理でいえば、オーブン料理（一度設定したら終わるまで変更不可）から、ガスコンロ料理（火加減を随時調整可能）への転換にあたる。
人間の専門家やAIエージェントが、訓練中にリアルタイムで学習率調整、データセット更新、モデルパラメータ変更、チェックポイント復帰などの介入を行えるシステムを構築している。
GitHub（https://github.com/yuntian-group/interactive-training）とオンラインデモ（https://interactivetraining.ai）が公開されており、Hugging Face Transformersに基づいて実装されている。

## 1. 研究概要
### 1.1 背景と動機
従来のニューラルネットワーク訓練は、事前に設定したハイパーパラメータや訓練戦略に基づく静的なプロセスであり、訓練開始後は結果が出るまで受動的に待つしかない状況にあった。
この固定的な訓練パラダイムは、訓練中に予期しない問題が発生した際の柔軟性に欠けており、損失の不安定化、特定タスクでの性能不足、勾配消失問題などが生じても、訓練を途中で停止し、設定を手動調整してから再開するという非効率的な対応しか取れなかった。

特に大規模計算クラスターでの訓練では、ジョブの再投入によるキュー待機時間が発生し、計算資源の浪費と開発サイクルの遅延を招いていた。
Meta社のOPT言語モデル開発では、ハードウェア障害と損失発散により少なくとも35回の手動再開が必要だったという事例も示すように、現実の大規模訓練では既に相当量の人間介入が発生している。

著者らは、この課題を解決するため、訓練プロセスを「ガスコンロで料理するように」リアルタイムで調整可能な対話的システムに変革することを目指した。
この発想は、料理中に味を確認しながら調味料を調整する直感的な行為から着想を得ており、機械学習の訓練においても同様の適応的制御が有効であると考えた。

### 1.2 主要な貢献
本研究は、ニューラルネットワーク訓練における従来の静的パラダイムを根本的に変革する包括的なフレームワークを提案している。
主要な技術的貢献として、制御サーバー、対話的トレーナー、フロントエンドダッシュボードから構成される3層アーキテクチャを設計し、これにより人間専門家やAIエージェントが訓練プロセスにリアルタイムで介入できる環境を実現した。

- **リアルタイム最適化制御**: 学習率、勾配クリッピング閾値、重み減衰など、オプティマイザーのハイパーパラメータを訓練中に動的調整可能
- **動的データセット管理**: 訓練中にデータセットの追加、更新、重み付け変更を実行し、実世界のデプロイメントから収集されたデータを即座に学習に反映
- **モデルレベル介入**: 特定レイヤーの重みリセット、パラメータ初期化、チェックポイントの保存・復帰による分岐実験の実現
- **勾配レベル制御**: カスタム勾配の注入、勾配ノルムに基づく動的クリッピング閾値設定など、細粒度の訓練制御
- **分岐実験機能**: 同一チェックポイントから複数の訓練軌道を並行して探索し、結果を比較検証する機能

## 2. 提案手法
### 2.1 手法の概要
Interactive Trainingフレームワークは、FastAPIベースの制御サーバーを中核とする3層アーキテクチャで構成されている。
制御サーバーは、フロントエンドダッシュボードと対話的トレーナー間の通信を仲介し、ユーザーからの介入コマンドを受信・配信するとともに、訓練メトリクスをリアルタイムでブロードキャストする役割を担う。

対話的トレーナーは、Hugging Face TransformersのTrainerクラスを拡張して実装されており、既存の訓練スクリプトへの変更を最小限に抑えている。
具体的には、`make_interactive(Trainer)`というヘルパー関数を通じて、従来のTrainerを対話的機能で拡張し、InteractiveCallback、CheckpointCallback、LoggingCallback、RunPauseCallbackなどのカスタムコールバック関数により、各勾配ステップ後に介入コマンドを処理する仕組みを構築している。

フロントエンドダッシュボードは、ReactとTypeScriptで構築された現代的なWebインターフェースであり、Weights & Biasesのような従来の監視ツールとは異なり、双方向通信をサポートしている。
ユーザーは、損失曲線や勾配ノルムなどの訓練メトリクスをリアルタイムで確認しながら、Optimizer、Model、Checkpoint、Datasetの各制御パネルを通じて具体的な介入コマンドを発行できる。

### 2.2 技術的詳細
システムの通信プロトコルは、JSON形式のメッセージ構造に基づいており、各コマンドは`command`（コマンド種別）、`args`（JSON形式の引数）、`time`（UNIX タイムスタンプ）、`uuid`（一意識別子）、`status`（実行状態）のフィールドで構成される。
実行状態は「requested」「pending」「running」「completed」「success」「failed」の6段階で管理され、コマンドの追跡と状態確認を可能にしている。

制御サーバーは、受信したコマンドを種別ごとにコマンドキューに分類し、非同期処理により順次実行する。
対話的トレーナーからは、損失値、勾配ノルム、訓練状態更新などのメトリクスがイベントキューを通じて制御サーバーに報告され、WebSocket接続を介してすべての接続クライアントにブロードキャストされる。

具体的な介入コマンドとして、`update_optimizer`（学習率等の調整）、`save_checkpoint`/`load_checkpoint`（チェックポイント管理）、`pause_training`/`resume_training`/`stop_training`（訓練制御）、`model_layer_operation`（レイヤー操作）、`update_dataset`（データセット更新）、`do_evaluate`（評価実行）などが実装されている。

データセット更新機能では、`make_interactive_dataset`関数によりPyTorchの`Dataset`および`IterableDataset`クラスを拡張し、各エポック終了時に`initialize`メソッドまたはユーザー定義の`reload_dataset`関数を呼び出すことで、新しいデータと設定を動的に組み込む仕組みを実現している。

### 2.3 新規性
従来の機械学習における人間参加型学習（Human-in-the-Loop ML）やAutoMLアプローチとは根本的に異なる新規性を持つ。
既存の能動学習では、学習アルゴリズムが人間にラベル付けを要求する受動的な関係にとどまり、対話的機械学習でも予め定義されたスケジュールや特定形式の入力に限定されていた。

本手法は、訓練プロセスの任意の時点で、任意の種類の介入を可能にする真のリアルタイム制御を実現している点で画期的である。
Population-Based Training（PBT）のようなAutoML手法が複数の試行にわたる自動ハイパーパラメータ調整を行うのに対し、Interactive Trainingは単一の訓練実行内でのリアルタイム調整を可能にする。

また、従来の監視ツールが受動的な可視化に留まるのに対し、本フレームワークは積極的な制御インターフェースを提供し、訓練を「黒箱プロセス」から「対話的プロセス」に変革している。
ネットワークベースの分離設計により、訓練プロセスと制御ロジックを疎結合に保ち、異なるマシン間での分散実行も可能にしている。

## 3. 実験結果
### 3.1 実験設定
評価実験は3つのケーススタディで構成されている。
第1のケーススタディでは、Wikitext-2データセットでのGPT-2ファインチューニングにおいて、人間専門家による対話的介入と従来の固定学習率スケジュールを比較した。
ベースライン手法では、初期学習率1×10^-5から線形減衰する固定スケジュールを使用し、対話的手法では人間専門家がダッシュボードの訓練動態可視化を観察しながら学習率を動的調整した。

第2のケーススタディでは、自動化された介入の可能性を検証するため、OpenAIのo4-miniモデルを用いたLLMエージェントによる自動介入を評価した。
意図的に過大な学習率（5×10^-3）で訓練を開始し、学習率スケジューラーを無効化することで不安定性を誘発し、LLMエージェントが100勾配ステップごとに訓練ログのテキスト要約を受け取り、学習率の「倍増」「半減」「維持」のいずれかを決定する設定で実験を行った。

第3のケーススタディでは、NeuralOS（拡散モデルによるOS画面予測システム）の実世界デプロイメントにおいて、リアルタイムデータ更新機能を検証した。
初期モデルを2ヶ月間合成データで訓練後、https://neural-os.com でのオンライン公開により14日間で746の実ユーザー操作シーケンス（88K フレーム遷移）を収集し、継続的ファインチューニングプロセスに動的に組み込んだ。

### 3.2 主要な結果
人間専門家による対話的介入実験では、静的ベースラインと比較して明確な性能向上が確認された。
検証損失の比較において、対話的手法は固定学習率スケジュールを上回る収束性能を示し、人間専門家が訓練損失の振動を観察して適切なタイミングで学習率を減少させることで、安定した収束を実現した。
学習率軌跡の分析から、専門家が損失の停滞や不安定性に応じて適応的調整を行い、従来の静的訓練では不可能な細かな制御を実現していることが確認された。

LLMエージェントによる自動介入実験では、初期の過大学習率による訓練不安定化からの自動回復が実証された。
LLMエージェントは観察された損失不安定性に応答して適切なタイミングで学習率削減を推奨し、固定的な過大学習率での継続と比較して大幅な性能改善を達成した。
この結果は、汎用LLMであっても適切なプロンプト設計により、効果的な訓練介入判断が可能であることを示している。

NeuralOSでの実世界データ更新実験では、実ユーザーデータの組み込みにより、特にFirefoxブラウザとの対話や新フォルダ作成など、実ユーザーが頻繁に試行するタスクにおいて劇的な性能向上が観察された。
ファインチューニング前後の定性的比較では、合成データのみでは困難だった複雑なユーザー操作パターンの学習が、実データの動的組み込みにより可能になったことが確認された。

### 3.3 既存手法との比較
従来のハイパーパラメータチューニング手法との比較において、Interactive Trainingは計算効率と最終性能の両面で優位性を示した。
グリッドサーチや Bayesian Optimizationのような既存手法が複数の独立した試行を必要とするのに対し、対話的手法は単一実行内でリアルタイム調整により最適化を達成し、計算リソースの大幅な節約を実現した。

人間専門家による介入では、固定スケジュールでは予測困難な最適タイミングでの学習率調整が可能となり、事前に最適スケジュールを特定することの難しさを解決した。
例えば、ある静的実行では高い定数学習率により3エポック目で発散が生じたが、専門家は2エポック目で損失振動の兆候を察知して学習率を削減し、発散を防止した。

AutoMLアプローチとの比較では、Population-Based Training（PBT）が複数の並行実行間でのハイパーパラメータ共有に依存するのに対し、Interactive Trainingは単一実行内での柔軟な制御を可能にし、より直接的で理解しやすい最適化プロセスを提供している。

## 4. 実用性評価
### 4.1 実装の容易性
Interactive Trainingの最大の実用的利点は、既存の訓練スクリプトへの変更を最小限に抑える設計思想にある。
Hugging Face Transformersを使用する標準的な訓練コードでは、`make_interactive(Trainer)`という単一のヘルパー関数呼び出しのみで対話的機能を有効化できる。
この設計により、既存のプロジェクトへの導入障壁が大幅に低減されている。

フレームワークの拡張性も高く評価される。
新しい介入コマンドの追加は、コマンドタイプの定義、ハンドラー関数の登録、制御サーバーとトレーナーコールバックの拡張という明確な手順で実現できる。
コミュニティによる新機能開発を促進するオープンソース設計が採用されている。

ただし、分散訓練環境での同期メカニズムや大規模システムでのオーバーヘッド管理には、追加的なエンジニアリング作業が必要となる可能性がある。
現在の実装は単一ノード環境に最適化されており、極大規模分散訓練での実用性には改善の余地がある。

### 4.2 計算効率
制御サーバーとの通信オーバーヘッドは、数ミリ秒程度の軽微なものに設計されており、実質的な訓練性能への影響は最小限に抑えられている。
WebSocketベースのリアルタイム通信とRESTful APIによるコマンド送信の組み合わせにより、効率的な双方向通信を実現している。

介入の実行タイミングは、勾配ステップ間の安全なタイミングに調整されるため、訓練の数値的安定性を損なうことなく変更を適用できる。
例えば、「レイヤーXをリセット」のような操作は、中途半端な更新を避けるため次の反復境界まで実行が延期される。

ネットワークベースの分離設計により、制御機能と訓練処理の疎結合が実現されており、制御サーバーがモデル重みを任意に読み取ることはできず、セキュリティ上の懸念も軽減されている。
メモリ上での効率的な状態管理により、シリアライゼーションオーバーヘッドも回避されている。

### 4.3 応用可能性
Interactive Trainingは、機械学習の訓練ワークフローに「継続的統合」の概念を導入する潜在力を持つ。
ソフトウェア開発における継続的統合が頻繁な増分更新、迅速なテスト、即座のデプロイメントサイクルを通じて開発プロセスを革新したように、本手法は「継続的モデル訓練」ワークフローを可能にする。

実世界の応用例として、言語モデリング、強化学習、推薦システム、適応的コンテンツ生成など、急速に進化する環境での利用が期待される。
特に、デプロイされたモデルからのフィードバック収集、リアルタイムデータ注入、即座のモデル改善というサイクルは、ユーザー体験の継続的向上を実現する。

研究開発フェーズでは、仮説の迅速な検証、デバッグ効率の向上、実験サイクルの高速化により、研究生産性の大幅な向上が期待される。
教育分野では、機械学習の訓練動態を対話的に学習できる教育ツールとしての応用も考えられる。

長期的には、専門化されたAIエージェントによる完全自動化された訓練監視・介入システムの構築により、人間の監督を最小限に抑えた自律的な学習システムの実現が展望される。

## 5. まとめと所感
### 5.1 論文の意義
この研究は、機械学習における訓練パラダイムの根本的変革を提案する極めて革新的な取り組みである。
従来の「設定→実行→待機」という受動的プロセスから、「観察→調整→改善」という能動的プロセスへの転換は、単なる技術的改善を超えて、機械学習エンジニアリングの哲学的転換を意味する。

特に注目すべきは、理論研究に留まらず、完全に実装されたオープンソースフレームワークとして公開されている点である。
GitHub上での公開とオンラインデモの提供により、研究コミュニティによる即座の検証と拡張が可能となっており、実用的インパクトが期待される。

技術的な観点では、Hugging Face Transformersという広く採用されているフレームワークとの統合により、実用性と普及可能性を同時に確保している。
この戦略的な実装選択は、学術的成果の産業界への橋渡しとして高く評価される。

3つのケーススタディの設計も秀逸であり、人間専門家による介入、AIエージェントによる自動介入、実世界データの動的更新という異なる応用シナリオを通じて、フレームワークの多面的な価値を実証している。
特にNeuralOSでの実証実験は、研究室環境を超えた実世界での有効性を示している。

### 5.2 今後の展望
この研究が切り開く将来的な研究方向は多岐にわたり、機械学習分野に長期的な影響を与える可能性が高い。
短期的には、より洗練されたAI介入エージェントの開発、分散訓練環境での最適化、より豊富な介入コマンドライブラリの構築が期待される。

中期的には、訓練動態の「健康指標」に基づく自動異常検知、制約誘導型訓練による公平性・安全性の確保、解釈可能性プローブとの統合による説明可能なAIの実現などが展望される。
特に、ニューロンの活性化統計や隠れ状態の標準偏差などの指標による「死んだニューロン」の検出と自動回復は、訓練の堅牢性向上に大きく貢献するだろう。

長期的には、完全自律的な学習システムの実現が究極的目標となる。
専門化されたAIエージェントが訓練を監視し、異常を検知し、プロアクティブに介入することで、人間の監督を最小限に抑えた継続的学習が可能になる。
これは、AIシステムの自己改善能力の実現という、人工知能研究の根本的目標に向けた重要な一歩となる。

ただし、再現性の確保と専門知識要件という課題も指摘されており、これらの解決が普及の鍵となる。
介入ログの記録・再生機能による再現性向上、AIアシスタントによる初心者支援、ベストプラクティスの体系化などの改善が必要である。

総合的に見て、この研究は機械学習分野における新たな研究領域の創出と、実用的フレームワークの提供を同時に達成した優れた貢献であり、今後の発展が大いに期待される。
