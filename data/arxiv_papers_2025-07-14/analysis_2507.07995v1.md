# Single-pass Adaptive Image Tokenization for Minimum Program Search

## 基本情報
- arXiv ID: 2507.07995v1 (https://arxiv.org/abs/2507.07995)
- 著者: Shivam Duggal, Sanghyun Byun, William T. Freeman, Antonio Torralba, Phillip Isola
- 所属: Massachusetts Institute of Technology, LG Electronics
- 投稿日: 2025年07月14日
- カテゴリ: cs.CV, cs.LG

## 簡単に説明すると
この論文は、アルゴリズム情報理論（AIT）のコルモゴロフ複雑性の原理に基づいて、画像を適応的にトークン化する新しい手法「KARL（Kolmogorov-Approximating Representation Learning）」を提案しています。従来の手法が複数回の推論を必要とするのに対し、KARLは単一パスで画像の複雑さに応じて最適なトークン数を予測します。
各画像に対して固定長の表現を使用する従来手法とは異なり、画像の本質的な複雑さに基づいて可変長のトークン表現を生成します。
研究コードは https://github.com/ShivamDuggal4/karl で公開されています。

## 1. 研究概要
### 1.1 背景と動機
コルモゴロフ複雑性（KC）の原理によれば、知的な表現とはデータを可能な限り短いプログラムに圧縮することです。しかし、現在の視覚表現学習システム（SimCLR、DINO、MAE、VAEなど）は、すべての入力に対して固定長の表現を使用しており、複雑さや馴染み度の違いを無視しています。

最近の適応的トークン化手法は可変長表現を割り当てることでこの問題に対処していますが、テスト時に最も予測的な表現を見つけるために複数のエンコーディングを検索します。これは、ビデオモデルや視覚言語モデル（VLM）などの大規模アプリケーションでは計算コストが高くなります。

本研究は、コルモゴロフ複雑性の原理に着想を得て、画像の近似KC（最小プログラムサイズ）に達するまでトークンを予測し、単一の前方パスで必要なトークン数を決定する手法を提案します。

### 1.2 主要な貢献
本研究の主要な貢献は以下の通りです。
- 単一パスで適応的なトークン数を予測するKARL（Kolmogorov-Approximating Representation Learning）の提案
- Upside-Down強化学習パラダイムに類似した、損失条件付き訓練戦略の導入
- 既存の適応的トークナイザーと同等の性能を単一パスで達成
- KARLのスケーリング則の分析（エンコーダー/デコーダーサイズ、連続vs離散トークン化の影響）
- 適応的画像トークン化とアルゴリズム情報理論の概念的な関連性の考察
- 人間の複雑性判断との強い相関の実証

## 2. 提案手法
### 2.1 手法の概要
KARLは、画像、最大トークン予算、および満たすべき再構成の損失閾値を入力として受け取り、必要なトークンのみを出力します（近似最小プログラムサイズ）。不要なトークンはマスクアウトされます。

アーキテクチャは、Perceiverモデルに着想を得た1Dトークン化を採用しています。画像は最初にVQGANを使用して2Dトークンのグリッドにマッピングされ、これらが初期化された1Dトークンと連結されてトランスフォーマーベースのエンコーダーに渡されます。

### 2.2 技術的詳細
KARLの訓練は、各イテレーションで2つのフェーズから構成されます。

**フェーズ1：画像複雑性の推定**：
- 与えられたトークン予算Tで近無損失圧縮を試みる
- 再構成エラーε₀を計算（通常は完全な再構成は不可能）。

**フェーズ2：複雑性に基づくトークン化の学習**：
- トークン予算をT+ΔTに増やす
- フェーズ1で得られたε₀を条件として、同じ品質を達成
- 追加のΔTトークンは不要であるため、これらをマスクするよう学習。

この訓練戦略により、画像の本質的な複雑さに応じたトークン割り当てが可能になります。高複雑性の画像では、少ないトークン数で低い誤差を達成することは困難であるため、そのような（低損失、低トークン数）の条件ペアは訓練中に現れません。

### 2.3 新規性
本研究の新規性は以下の点にあります。

第一に、反復的な探索を必要とせず、単一の前方パスで適応的なトークン化を実現する点です。これは計算効率の観点から重要な改善です。

第二に、Upside-Down強化学習のパラダイムに類似した訓練手法を採用している点です。再構成品質をタスク条件として扱い、報酬に基づいて条件付きで予測します。

第三に、コルモゴロフ複雑性の不変性原理（KC_ε(x,T) = KC_ε(x,T+ΔT)）に基づいた訓練戦略です。一度十分なトークン数が見つかれば、追加のトークンは不要であるという原理を活用しています。

## 3. 実験結果
### 3.1 実験設定
実験は以下の設定で実施されました。

**ベースライン手法**には、以下を使用しました。
- ALIT：反復的トークナイザー
- One-D-Piece：Matryoshkaスタイルの手法

**評価指標**には、以下を使用しました。
- 単一画像メトリクス：L1損失、LPIPS、SSIM、DreamSim
- 最小トークン数（近似KC）

**データセット**には、以下を使用しました。
- ImageNet100およびImageNet1K
- Savoiasデータセット（人間の複雑性判断との比較用）

### 3.2 主要な結果
固定トークン数での比較では、KARLは既存手法と同等の性能を示しました。L1、LPIPS、SSIMで最高性能を達成し、DreamSimでもALITに次ぐ性能を示しました。

可変トークン数での実験では、KARLの大きな利点が明らかになりました。
- ALITは再構成品質の目標を達成するために平均7-8回のエンコーダー・デコーダー実行が必要。
- One-D-Pieceは単一のエンコーディングパスで済むが、最適な表現を見つけるために2-4回のデコーダー実行が必要。
- KARLは単一パスで目標品質を満たすトークン数を予測（1回のエンコーダー実行+1回のデコーダー実行）。

人間の複雑性判断との相関実験では、Savoiasデータセットを用いて強い相関を確認しました。人間が低複雑と判断した画像の47%が32-64トークンに割り当てられ、高複雑と判断された画像は主に256トークンを使用しました。

### 3.3 既存手法との比較
KARLの主な優位性は推論効率にあります。

**計算効率の比較**では、以下の結果が得られました。
- ALIT：低い再構成閾値では最大8倍のエンコーダー・デコーダー実行が必要。
- One-D-Piece：平均2-4倍のデコーダー実行が必要。
- KARL：常に1回のエンコーダー実行と1回のデコーダー実行のみ。

**スケーリング則の分析**では、小さなエンコーダーと大きなデコーダーの組み合わせが最良の結果を示しました。これは、エンコーダーは既存のVQGANトークンを1Dトークンに蒸留する単純なタスクであるため、大きな容量を必要としないことを示唆しています。

## 4. 実用性評価
### 4.1 実装の容易性
KARLの実装は比較的シンプルです。標準的なトランスフォーマーアーキテクチャをベースとし、既存のVQGANやVAEトークナイザーの上に構築できます。損失条件付き訓練戦略は明確で再現性が高いです。

研究コードがGitHubで公開されており、HuggingFaceのモデルとして利用可能になる予定です。既存の視覚言語モデルやビデオ生成モデルへの統合も容易です。

### 4.2 計算効率
KARLの最大の利点は推論時の計算効率です。以下の特徴があります。
- 単一パスで適応的なトークン数を決定（反復的探索が不要）。
- テスト時の計算コストが予測可能で一定。
- 大規模なバッチ処理に適している。
- VLMsやビデオモデルなど、高速推論が必要なアプリケーションに最適。

訓練時は2フェーズの処理が必要ですが、これは訓練時のみのオーバーヘッドであり、推論時には影響しません。

### 4.3 応用可能性
KARLの応用可能性は広範囲に及びます。

**視覚言語モデル（VLMs）**：入力画像の複雑さに応じてトークン数を適応的に調整し、計算効率を改善。

**ビデオ生成・理解**：フレームごとの複雑さに応じたトークン割り当てにより、長時間のビデオ処理を効率化。

**画像圧縮**：コルモゴロフ複雑性に基づく新しい圧縮アルゴリズムの開発。

**異常検出**：予測されるトークン数が異常に多い画像をOOD（分布外）データとして検出。

**データセット設計**：画像の複雑さ分析に基づいた、計算効率の高い事前学習データセットの構築。

## 5. まとめと所感
### 5.1 論文の意義
本研究は、適応的画像トークン化において重要なブレークスルーを達成しています。単一パスで画像の複雑さに応じた最適なトークン数を予測できることは、計算効率の観点から実用的な価値が高いです。

特に重要なのは、アルゴリズム情報理論の原理を実用的な深層学習システムに適用した点です。コルモゴロフ複雑性という理論的概念を、実際の画像処理タスクに応用可能な形で実装しています。

また、人間の複雑性判断との強い相関を示したことで、モデルが学習した表現と人間の直感が整合していることが確認されました。これは、より解釈可能で信頼性の高いAIシステムの開発につながる可能性があります。

### 5.2 今後の展望
今後の研究方向として以下が考えられます。

**理論的発展**：コルモゴロフ複雑性以外のAIT概念（Sophistication、Logical Depth）の実装と評価。

**アーキテクチャの改良**：計算効率を向上させるエンコーダー・デコーダー設計の探求。

**マルチモーダル拡張**：テキスト、音声、ビデオなど他のモダリティへの適用。

**下流タスクの最適化**：特定のタスクに対する損失条件の自動調整メカニズムの開発。

**大規模モデルへの統合**：GPT-4VやGeminiなどの大規模マルチモーダルモデルへの組み込み。

この研究は、より効率的で知的な視覚表現学習への道を開くものであり、今後のコンピュータビジョンと機械学習の発展に大きく貢献することが期待されます。