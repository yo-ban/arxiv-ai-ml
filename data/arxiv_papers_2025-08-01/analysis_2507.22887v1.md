# Where to show Demos in Your Prompt: A Positional Bias of In-Context Learning

## 基本情報
- **arXiv ID**: 2507.22887v1 (https://arxiv.org/abs/2507.22887v1)
- **著者**: Kwesi Cobbina, Tianyi Zhou
- **所属**: University of Maryland, College Park
- **投稿日**: 2025年07月31日
- **カテゴリ**: cs.CL, cs.AI

## 簡単に説明すると
この論文は、大規模言語モデル（LLM）がプロンプト内のどこにデモンストレーション（例示）を配置するかによって、予測精度が大きく変動するという新しいバイアスを発見した研究です。具体的には、同じデモを使っていても、プロンプトの最初に置くか最後に置くかで、精度が最大20ポイントも変化し、予測の半分近くが変わってしまうことがあります。

研究では、10個のオープンソースLLM（Qwen、Llama3、Mistral、Cohereの各ファミリー）を使って、8つのタスク（分類、質問応答、要約、推論）で実験を行いました。その結果、デモをプロンプトの最初（特にシステムプロンプトの開始位置）に配置すると最も安定した高い精度が得られ、最後（ユーザーメッセージの末尾）に配置すると予測が不安定になることが分かりました。

本論文では、HuggingFaceのチャットテンプレートドキュメント（https://huggingface.co/docs/transformers/main/chat_templating）やLLaMA Factory（https://github.com/hiyouga/LLaMA-Factory）などの既存のインストラクションチューニングフレームワークへの言及がありますが、本研究独自のコードリポジトリへのリンクは提供されていません。

## 1. 研究概要
### 1.1 背景と動機
大規模言語モデル（LLM）の急速な進化により、分類、質問応答、要約などのタスクで前例のないfew-shotおよびzero-shot汎化が可能になりました。この新しいパラダイムの中心にあるのがインコンテキスト学習（ICL）で、モデルが入力プロンプトに直接埋め込まれたデモンストレーションを処理することで新しいタスクに動的に適応します。

しかし、最近の研究により重要な脆弱性が明らかになっています。デモの順序やデモの数への小さな摂動が予測不可能にパフォーマンスを低下させる可能性があります。この脆さは再現性を損なうだけでなく、LLMが体系的な推論を行う能力についての仮定に疑問を投げかけ、現在のモデルが本当にコンテキストから学習しているのか、それとも単に表面的なパターンを利用しているだけなのかという緊急の疑問を提起しています。

先行研究では主にデモの選択、テンプレートの言い回しに焦点を当てていましたが、デモの配置位置（命令、クエリ、その他のコンテキスト要素に対する相対的な位置）の役割は十分に探求されていませんでした。この研究は、空間的配置がICLの有効性をどのように調整するかを理解するギャップに対処するため、分類、推論、生成にまたがる8つのタスクで位置効果の体系的な調査を行いました。

### 1.2 主要な貢献
本研究は5つの補完的な貢献を行っています：
- インコンテキスト学習における以前報告されていない位置バイアス（DPP bias: Demos' Position in Prompt bias）を初めて発見し定量化しました。同一のデモブロックをプロンプト内で単に移動させるだけで、精度が最大50パーセントポイント変化し、モデルの予測のほぼ半分が反転することを示しました。
- この洞察に基づいて、4つの標準的なデモ配置（システムプロンプトの開始/終了、ユーザーメッセージの開始/終了）を分離する制御された評価パイプラインを設計し、パフォーマンスの変化が純粋に位置に起因することを保証しました。
- 正味のパフォーマンスシフトと出力の変動性の両方を捉えるため、accuracy-changeとprediction-changeという2つのタスク非依存のメトリクスを導入しました。
- このフレームワークを使用して、8つのタスクと10の最先端LLMにわたる位置効果の最初の大規模実証研究を実施し、モデルサイズが大きくなるにつれて重要度が低下する一貫した初頭効果を明らかにしました。
- これらの発見を実用的なガイドラインに変換しました。

## 2. 提案手法
### 2.1 手法の概要
本研究では、プロンプト内のインコンテキストデモンストレーションの位置がモデルのパフォーマンスにどのように影響するかを調査する体系的なフレームワークを提案しています。このアプローチは、DPPバイアスの問題を形式化し、考慮されるデモンストレーション配置の範囲を定義し、パフォーマンスの変動を測定するための評価パイプラインを概説します。

研究の焦点は、LLMに小さなデモンストレーションセットとクエリが与えられ、すべてが単一のプロンプトに連結される古典的なインコンテキスト学習シナリオです。重要なことに、本研究ではプロンプトPの内容（命令、デモンストレーション、クエリ）を固定し、プロンプト内のデモンストレーションブロックの構造的位置のみを操作します。

### 2.2 技術的詳細
最近の命令調整されたLLMでは、プロンプトにシステムプロンプトを含めることができ、その後にユーザーメッセージが続きます（チャットスタイル形式）。この構造を活用して、k個のデモのブロックをプロンプトに挿入できる4つの異なる標準的なデモンストレーション位置を定義しました：

1. **Start of System Prompt (ssp)**: デモブロックはシステムメッセージの最初、命令内容の前に配置
2. **End of System Prompt (esp)**: デモブロックはシステムメッセージの最後、一般的な命令の後でユーザーのクエリの前に配置
3. **Start of User Message (sum)**: デモブロックはユーザーメッセージの最初、実際のクエリテキストの前に挿入（デフォルト位置）
4. **End of User Message (eum)**: デモンストレーションブロックはユーザーメッセージの最後、クエリの後に追加

評価メトリクスとして、タスク固有のメトリクス（MCQ問題の精度、抽出的QAのF1とExact Match、要約のROUGE-LとBERTScore）に加えて、以下の2つの新しいメトリクスを導入しました：

**Accuracy Change (Δmetric)**: ゼロショットに対する特定の位置でのデモンストレーション追加の影響を定量化
Δmetric = Metricposition - Metriczero-shot

**Prediction Change (Δpred)**: デモンストレーション配置によって誘発される個々のモデル出力の変動性を測定
Δpred = #answer flips / #Q

### 2.3 新規性
本研究の新規性は以下の点にあります：

1. **空間的位置の独立した研究**: 先行研究がデモの内部順序に焦点を当てていたのに対し、本研究はデモブロック全体の位置を変更することで、純粋に空間的な効果を分離しています。

2. **システム・ユーザーロールを考慮した分析**: 命令調整されたモデルのチャットテンプレート構造を活用し、システムプロンプトとユーザーメッセージという異なるロール間でのデモ配置の影響を初めて体系的に調査しています。

3. **包括的な評価フレームワーク**: 8つの異なるタスクタイプ（分類、QA、要約、推論）と10の最先端モデルにわたる大規模な実験を実施し、位置効果の一般性を実証しています。

4. **新しい診断メトリクス**: accuracy-changeとprediction-changeという2つのタスク非依存のメトリクスを導入し、標準的な精度メトリクスでは見逃される隠れた変動性を明らかにしています。

## 3. 実験結果
### 3.1 実験設定
実験は以下の設定で実施されました：

**モデル**: 4つのオープンソースモデルファミリーから合計10のモデルを使用
- Qwen (1.5B, 7B, 72B)
- Llama3 (1B, 3B, 8B, 70B)
- Mistral (7B, 8x7B)
- Cohere (8B, 32B)

**データセット**: 8つのNLPタスクにわたる評価
- 分類: MNLI, AG News, ARC
- 多肢選択: MMLU
- 質問応答: SQuAD, GSM8K
- 要約: XSum, CNN/DailyMail

**評価指標**:
- 分類・多肢選択: Accuracy
- 質問応答: F1スコア、Exact Match
- 要約: ROUGE-L、BERTScore
- 追加メトリクス: Accuracy Change、Prediction Change

全ての実験でデモンストレーション数は5に固定し、デモブロック内のデモは条件間で同一に保ち、パフォーマンスの違いが純粋に位置効果に起因することを保証しました。

### 3.2 主要な結果
実験結果から、以下の重要なパターンが明らかになりました：

**位置バイアスの一貫性**: ベンチマークデータセット全体で一貫した顕著なパターンが現れました。プロンプトの最初に配置されたデモンストレーション（sspまたはesp）は、プロンプトの後半の配置（eum）よりも確実に優れたパフォーマンスを示し、デフォルトのICL位置（sum）をしばしば上回りました。

**タスク別の結果**:
- **分類・QAタスク**: MNLI、AG News、ARC、MMLUで、sspへのデモ配置が最も一貫した精度向上をもたらしました。特にMMLUでは、sspでゼロショットベースラインに対して+18%の精度向上を示しました。
- **算術タスク**: スケールに敏感な傾向を示しました。小規模モデル（1.5B-8B）はssp、esp位置を一貫して好みますが、LLAMA3 70Bはeumで改善を示し、モデル容量が位置の効果を調整することを示唆しています。
- **生成的要約**: パフォーマンスの変動性が最も深刻でした。LLAMA3 3BでXSumでは、sspからeumへの移動で改善された予測の割合が82.5%から27.5%に低下しました。

**スケーリング法則**: モデルサイズが大きくなるにつれて、予測の変動性（% changed）が減少し、パフォーマンスの安定性が向上することが観察されました。ただし、堅牢性の程度はタスクに依存し、サイズに対して一様に単調ではありませんでした。

### 3.3 既存手法との比較
本研究は既存手法と直接比較するものではなく、ICLにおける新しい次元（空間的位置効果）を明らかにするものです。しかし、関連する先行研究との比較において以下の点が明らかになりました：

**内部順序バイアスとの違い**: Lu et al. (2022)が報告した内部デモ順序による±15%の精度変動に対し、本研究では空間的位置の変更により最大50パーセントポイントの精度変化を観察しました。

**メカニズム的仮説の検証**: Olsson et al. (2022)やChan et al. (2022)が提案した初頭効果（primacy bias）の仮説を支持する結果が得られ、トランスフォーマーベースのモデルが初期トークンを不均衡に重視する傾向が確認されました。

**予測変化の詳細分析**: Sankey図を使用した遷移分析により、標準的な精度メトリクスでは見逃される局所的な不安定性が明らかになりました。例えば、LLAMA3 3BのMMLUでは、sspからeumへの移動により多数の正解から不正解への遷移が発生しました。

## 4. 実用性評価
### 4.1 実装の容易性
本研究で提案されたアプローチは、実装が非常に容易です。既存のLLMシステムに対して、以下の簡単な変更を加えるだけで適用可能です：

- **コード変更の最小化**: デモンストレーションの配置位置を変更するだけで、モデルアーキテクチャやトレーニングプロセスの変更は不要です。
- **既存フレームワークとの互換性**: HuggingFaceのTransformersライブラリなど、主要なLLMフレームワークで使用されているチャットテンプレート形式と完全に互換性があります。
- **即座の適用**: プロンプトエンジニアリングの一部として、すぐに実践できる知見です。

実装の推奨事項として、論文では以下のような具体的なガイドラインが提供されています：
1. デモンストレーションはプロンプトの最初（特にssp位置）に配置する
2. eum位置（ユーザーメッセージの最後）は避ける
3. モデルサイズとタスクタイプに応じて最適な位置を調整する

### 4.2 計算効率
計算効率の観点から、本アプローチは追加の計算コストを発生させません：

- **推論時間の変化なし**: デモの位置を変更してもモデルの推論時間は変わりません。
- **メモリ使用量の変化なし**: プロンプトの総長は同じなので、メモリ要件も変わりません。
- **バッチ処理との互換性**: 標準的なバッチ推論パイプラインでそのまま使用可能です。

実際、適切な位置にデモを配置することで、より少ないデモンストレーションで同等またはそれ以上のパフォーマンスを達成できる可能性があり、結果的に計算効率が向上する可能性もあります。

### 4.3 応用可能性
本研究の発見は、幅広い実世界のアプリケーションに適用可能です：

**即座に適用可能な領域**:
- チャットボットやアシスタントシステム
- コード生成ツール
- 文書要約システム
- 質問応答システム
- 感情分析や分類タスク

**産業界への影響**:
- **プロンプトエンジニアリングのベストプラクティス**: 企業がLLMを導入する際の標準的なガイドラインとして活用可能
- **プロダクション環境での安定性向上**: 予測の変動性を減らすことで、より信頼性の高いシステムを構築可能
- **コスト削減**: 最適な配置により少ないデモで高い性能を達成し、APIコストを削減

**将来の拡張可能性**:
- マルチモーダルモデルへの適用
- Chain-of-Thoughtプロンプティングとの組み合わせ
- 自動プロンプト最適化システムへの統合
- モデル固有の位置バイアスを考慮した新しい評価ベンチマークの開発

## 5. まとめと所感
### 5.1 論文の意義
この論文は、インコンテキスト学習における以前見過ごされていた重要な次元を明らかにした点で非常に意義深い研究です。主な貢献と意義は以下の通りです：

**科学的貢献**: LLMの振る舞いに関する新しい理解を提供し、モデルがコンテキストをどのように処理するかについての基礎的な洞察を与えています。特に、同じ内容でも配置位置によって大きく結果が変わるという発見は、LLMが真に「理解」しているのか、それとも表面的なパターンに依存しているのかという根本的な問いに新たな視点を提供しています。

**実践的価値**: すぐに適用可能な具体的なガイドラインを提供しており、産業界でLLMを使用する際の信頼性と一貫性を大幅に向上させる可能性があります。特に、プロンプトエンジニアリングにおいて、これまで経験的に行われていた試行錯誤に科学的な根拠を与えています。

**方法論的革新**: accuracy-changeとprediction-changeという新しいメトリクスの導入により、モデルの振る舞いをより細かく分析できるようになりました。これらのメトリクスは、今後のLLM評価において標準的なツールになる可能性があります。

**再現性への貢献**: LLMの出力の変動性に関する理解を深めることで、より再現性の高い実験設計が可能になります。これは、LLM研究の科学的厳密性を高める上で重要な貢献です。

### 5.2 今後の展望
論文では以下のような将来の研究方向が提案されています：

**メカニズムの深い理解**: なぜ特定の位置が優遇されるのか、注意機構の初期化、デコーダーの初頭効果、命令チューニングテンプレート、またはトレーニングコーパスの慣習によるものなのかを調査する解釈可能性研究が必要です。

**適用範囲の拡大**: 
- few-shot chain-of-thoughtプロンプトへの拡張
- 実世界の命令データセット（HELM、BIG-Benchなど）での検証
- マルチモーダルモデルへの適用

**自動最適化**: デモの配置を内容と共同で適応させる自動デモ配置最適化ルーチンの開発が、より堅牢なICLシステムへの原則的な道筋を提供する可能性があります。

**潜在的な課題と改善点**:
- 本研究は英語のタスクに限定されており、多言語での検証が必要
- クローズドソースの商用モデル（GPT-4など）での検証も重要
- より複雑な実世界のタスク（コード生成、数学的証明など）での評価
- デモの数や質と位置効果の相互作用の詳細な分析

**長期的な影響**: この研究は、LLMの設計と評価の方法を根本的に変える可能性があります。位置的堅牢性が、プロンプト最適化と命令ファインチューニングパイプラインの両方でコアな軸として考慮されるべきであることを示唆しています。
