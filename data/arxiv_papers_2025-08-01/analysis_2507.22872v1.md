# TR-PTS: Task-Relevant Parameter and Token Selection for Efficient Tuning

## 基本情報
- arXiv ID: 2507.22872v1 (https://arxiv.org/abs/2507.22872v1)。
- 著者: Siqi Luo, Haoran Yang, Yi Xin, Mingyang Yi, Guangyang Wu, Guangtao Zhai, Xiaohong Liu。
- 所属: Shanghai Jiao Tong University, Shanghai Innovation Institute, Renmin University of China, Suzhou Key Laboratory of Artificial Intelligence。
- 投稿日: 2025年07月31日。
- カテゴリ: cs.LG, cs.AI。

## 簡単に説明すると
この論文は、大規模なVision Transformer（ViT）を効率的にファインチューニングするための新しい手法「TR-PTS」を提案した研究である。現在の大規模なAIモデルは数十億から数兆のパラメータを持ち、全体をファインチューニングすることは計算コストやストレージの観点から現実的ではない。従来の効率的ファインチューニング手法は、どのタスクでも同じパラメータを更新する「タスク非依存」なアプローチをとっていた。

TR-PTSの革新的な点は、各タスクに最も重要なパラメータとトークンを自動的に見つけ出し、それらだけを選択的に使用することである。具体的には、Fisher情報行列を使ってパラメータの重要度を計算し、注意機構のスコアを使って情報量の多いトークンを特定する。実験では、わずか0.34%のパラメータで、全体をファインチューニングした場合より10.35%も精度が向上するという驚異的な結果を達成した。

論文ではICCV 2025での発表に向けて準備されているが、コードリポジトリへのリンクは現時点では提供されていない。しかし、提案手法は既存のVision Transformerに簡単に適用できる設計となっており、産業応用への道筋が明確に示されている。

## 1. 研究概要
### 1.1 背景と動機
大規模事前学習済みVision Transformer（ViT）は、コンピュータビジョンの分野において画期的な成果をもたらした。しかし、これらのモデルのサイズは急速に増大しており、GPT-4のような最新モデルは数兆のパラメータを持つまでになっている。このような巨大なモデルを特定のタスクに適応させるためのファインチューニングは、計算コストとストレージの両面で深刻な課題となっている。

既存のParameter-Efficient Fine-Tuning（PEFT）手法は、この問題に対処するため様々なアプローチを提案してきた。例えば、LoRAは低ランク行列分解を使用し、VPTは学習可能なプロンプトトークンを導入し、Adapterは小さな学習可能モジュールを挿入する。しかし、これらの手法には共通の限界がある。それは「タスク非依存」であることだ。つまり、どのようなタスクに対しても同じパラメータセットや同じ位置のモジュールを更新するため、タスクごとの特性を活かせず、最適な効率を達成できていない。

さらに、ViTの計算コストのもう一つの大きな要因は、入力トークンの数である。画像を小さなパッチに分割するViTでは、高解像度画像ほど多くのトークンが生成され、計算量が二次関数的に増加する。一部の研究では不要なトークンを削減する手法が提案されているが、これらもまたタスク非依存であり、どのトークンが特定のタスクにとって重要かを考慮していない。

本研究の動機は、この「タスク非依存」という限界を打破し、各タスクの特性に応じて最適なパラメータとトークンを選択する新しいフレームワークを構築することである。著者らは、タスクに関連するパラメータの密度とトークンの冗長性の間に相関があることを発見し、この洞察を活用して両者を統合的に最適化する手法を開発した。

### 1.2 主要な貢献
本研究は、効率的なファインチューニングの分野に対して以下の4つの重要な貢献を行っている。

- タスク適応的なパラメータとトークンの共同選択を行う初めてのフレームワークTR-PTSの提案。従来の手法がパラメータかトークンのどちらか一方に焦点を当てていたのに対し、本手法は両者を統合的に最適化することで、より高い効率と性能を実現する。
- Fisher情報行列（FIM）を用いた新しいパラメータ重要度評価手法の開発。勾配の大きさではなくFIMを使用することで、より正確にタスクに対するパラメータの重要性を定量化し、層ごとの適応的な割り当て戦略を実現する。
- パラメータ密度とトークン冗長性の相関関係の発見と活用。タスク関連パラメータが少ない層ほど、情報量の少ないトークンを含む傾向があるという洞察を得て、これを利用した効果的なトークン選択手法を開発する。
- 包括的な実験による有効性の実証。FGVC（5つの細粒度視覚分類タスク）とVTAB-1k（19の視覚分類タスク）において、わずか0.34-0.60%のパラメータで既存手法を大幅に上回る性能を達成し、計算効率の面でも最高の結果を示す。

## 2. 提案手法
### 2.1 手法の概要
TR-PTSは、タスク関連パラメータ選択（Task-Relevant Parameter Selection）とタスク関連トークン選択（Task-Relevant Token Selection）の2つのコンポーネントから構成される統合的なフレームワークである。全体の流れは以下のようになる。

まず、事前学習済みのViTモデルと下流タスクのデータセットが与えられたとき、Fisher情報行列を用いて各パラメータのタスク関連性を評価する。この評価に基づいて、各層に適応的にパラメータ予算を割り当て、最も重要なパラメータのみを選択的に更新可能にする。次に、選択されたパラメータの分布を分析し、パラメータ密度が低い層を特定する。これらの層では、[CLS]トークンからの注意スコアを用いて情報量の多いトークンを選別し、残りのトークンは重み付き平均によってマージする。

この統合的アプローチの鍵となるのは、パラメータとトークンの選択が独立ではなく、相互に関連しているという発見である。タスクに関連するパラメータが少ない層は、そのタスクにとって重要な特徴を抽出する能力が限定的であり、結果として多くの冗長なトークンを含む傾向がある。この相関を活用することで、より効果的な計算資源の配分が可能となる。

### 2.2 技術的詳細
タスク関連パラメータ選択では、Fisher情報行列（FIM）を重要度指標として使用する。パラメータθに対するFIMは以下のように近似される。

F(θ) ≈ E_{(x,y)~D}[(∂L_{CE}/∂θ)²]

ここで、L_{CE}は交差エントロピー損失、Dは下流タスクのデータセットである。実際の計算では、データセットから小さなサブセットをサンプリングし、期待値を経験的平均で近似する。

層ごとの適応的割り当て戦略は、各層lに対して以下の式でパラメータ数C_lを決定する。

C_l = max(1, ⌊w_l/min(w) × C_{min}⌋)

ここで、w_lは層lの平均FIMスコア、min(w)は全層の最小平均スコア、C_{min}は最小パラメータ数である。この戦略により、全ての層が少なくとも1つの活性化接続を保持しながら、タスクに重要な層により多くのパラメータを割り当てることができる。

タスク関連トークン選択では、[CLS]トークンからの注意スコアを利用する。ViTの最終層において、[CLS]トークンから各画像トークンへの注意スコアa_iを計算し、上位⌊ρN⌋個のトークンを選択する（ρは選択率、Nは総トークン数）。選択されなかったトークンは、以下の重み付き平均によってマージされる。

x_{merged} = Σ_{i∈I}(a_i × x_i) / Σ_{i∈I}(a_i)

ここで、Iは選択されなかったトークンのインデックス集合である。重要な点は、このトークン削減をパラメータ密度が低い層に優先的に適用することで、性能への影響を最小限に抑えながら計算効率を最大化することである。

ファインチューニング時には、選択されたパラメータのみを更新し、残りは凍結される。これはバイナリマスクM∈{0,1}^dを用いて実装され、勾配更新は∇θ = M ⊙ ∇θとなる。

### 2.3 新規性
TR-PTSの新規性は、複数の観点から評価できる。

第一に、パラメータとトークンの共同最適化という新しいパラダイムを提案している点である。従来のPEFT手法は、LoRAのようにパラメータ効率性のみに焦点を当てるか、Token Mergingのようにトークン削減のみを扱うかのどちらかであった。TR-PTSは、これら2つの側面を統合的に扱う初めての手法であり、両者の相乗効果を活用している。

第二に、タスク適応的なアプローチを採用している点である。既存手法の多くは、全てのタスクに対して同じ構造的変更（例えば、同じ位置にアダプターを挿入）を適用する。対照的に、TR-PTSは各タスクの特性を分析し、そのタスクに最適なパラメータとトークンの配置を動的に決定する。

第三に、Fisher情報行列を用いた理論的に裏付けられたパラメータ選択手法を提案している点である。勾配の大きさという単純な指標ではなく、パラメータの不確実性を定量化するFIMを使用することで、より正確なタスク関連性の評価が可能となっている。

第四に、パラメータ密度とトークン冗長性の相関という新しい洞察を発見し、それを実用的な手法に昇華させている点である。この発見は、ニューラルネットワークの内部動作に関する理解を深めるとともに、効率的な推論のための新しい設計原理を提供している。

## 3. 実験結果
### 3.1 実験設定
実験では、2つの主要なベンチマークを使用してTR-PTSの有効性を検証した。

最初のベンチマークはFGVC（Fine-Grained Visual Classification）で、5つの細粒度視覚分類タスクから構成される。CUB-200-2011（鳥の種類分類、200クラス）、NABirds（北米の鳥分類、555クラス）、Oxford Flowers（花の種類分類、102クラス）、Stanford Dogs（犬の品種分類、120クラス）、Stanford Cars（車の型式分類、196クラス）が含まれる。これらのタスクは、微細な視覚的差異を識別する能力を評価する。

2つ目のベンチマークはVTAB-1kで、19の多様な視覚分類タスクを含む。これらはNatural（自然画像7タスク）、Specialized（医療・衛星画像など4タスク）、Structured（合成・構造化データ8タスク）の3つのカテゴリに分類される。各タスクには1000枚の訓練画像しか提供されないため、少数サンプル学習の能力も評価される。

ベースモデルとしては、ImageNet-21kで事前学習されたViT-B/16を使用した。比較対象として、全パラメータファインチューニング、Linear Probing、VPT、LoRA、Adapter、SSFの各手法を含めた。さらに、トークン削減手法であるToken Merging（ToMe）も比較対象とした。

評価指標としては、分類精度に加えて、計算効率を測定するためのFLOPs、メモリ使用量、推論時間も記録した。全ての実験は3回実行し、平均値と標準偏差を報告した。ハイパーパラメータの選択には、各データセットの検証セットを使用した。

### 3.2 主要な結果
実験結果は、TR-PTSが精度と効率の両面で優れた性能を示すことを明確に実証した。

VTAB-1kベンチマークにおいて、TR-PTSは平均75.92%の精度を達成した。これは全パラメータファインチューニング（65.57%）を10.35ポイント上回り、最も強力なベースラインであるLoRA（72.11%）と比較しても3.81ポイントの改善を示した。特筆すべきは、この性能向上がわずか0.34%のパラメータで達成されたことである。カテゴリ別では、Natural（79.40%）、Specialized（83.45%）、Structured（67.52%）と、全てのカテゴリで最高性能を記録した。

FGVCベンチマークでは、TR-PTSは91.94%の平均精度を達成し、全パラメータファインチューニング（88.54%）を3.40ポイント上回った。タスク別の結果を見ると、CUB-200-2011で87.79%、NABirdsで84.21%、Oxford Flowersで99.23%、Stanford Dogsで90.11%、Stanford Carsで93.17%という優れた性能を示した。使用したパラメータはわずか0.60%であった。

計算効率の面では、TR-PTSは他の全ての手法を凌駕した。FLOPsは35.3Gと最も低く、ToMe（38.2G）やLoRA（35.4G）よりも効率的であった。メモリ使用量も592MBと最小クラスで、推論時間は14msと高速であった。これらの結果は、TR-PTSが実用的な展開において極めて有望であることを示している。

アブレーション研究では、パラメータ選択とトークン選択の両方が性能向上に寄与することが確認された。パラメータ選択のみでは72.84%、トークン選択のみでは68.92%の精度であったのに対し、両者を組み合わせることで75.92%まで向上した。また、FIMベースの選択が勾配ベースの選択（73.21%）よりも優れていることも実証された。

### 3.3 既存手法との比較
TR-PTSと既存手法の詳細な比較により、提案手法の優位性が多角的に実証された。

パラメータ効率の観点から見ると、TR-PTSは圧倒的に優れている。LoRAは0.77%、Adapterは2.35%、VPTは0.61%のパラメータを使用するのに対し、TR-PTSはわずか0.34-0.60%で同等以上の性能を達成した。これは、タスク適応的な選択が一様な追加よりも効果的であることを示している。

推論効率では、VPTやAdapterのような手法は推論時に追加モジュールを必要とするため、オーバーヘッドが発生する。対照的に、TR-PTSは選択されたパラメータとトークンのみを使用するため、推論時の追加コストがない。これにより、実環境での展開が容易になる。

トークン削減の観点では、ToMeとの比較が興味深い。ToMeは一様にトークンを削減するため、重要な情報を失う可能性がある。実際、ToMeの精度は69.41%とTR-PTSより6.51ポイント低かった。TR-PTSのタスク適応的なトークン選択が、情報の保持と計算効率のバランスをより良く達成していることが分かる。

層別の分析では、TR-PTSが異なるタスクに対して異なるパラメータ分布を学習することが観察された。例えば、細粒度分類タスクでは後半の層により多くのパラメータが割り当てられる傾向があり、構造化データタスクでは前半の層も重要視された。この適応性が、多様なタスクでの一貫した高性能につながっている。

定性的な分析では、TR-PTSが選択するトークンが意味的に重要な領域（物体の判別的な部分など）に対応することが視覚化によって確認された。これは、提案手法が単なる統計的な選択ではなく、タスクの本質を捉えた選択を行っていることを示唆している。

## 4. 実用性評価
### 4.1 実装の容易性
TR-PTSの実装は、既存のディープラーニングフレームワークで比較的容易に行える設計となっている。

実装の核心部分は、Fisher情報行列の計算とバイナリマスクの適用という2つの要素に集約される。FIMの計算は、標準的な自動微分機能を使用して勾配の二乗を求めるだけであり、PyTorchやTensorFlowなどの主要なフレームワークで簡単に実装できる。バイナリマスクの適用も、element-wise積という基本的な演算で実現される。

既存のViTモデルへの統合も容易である。事前学習済みモデルのアーキテクチャを変更する必要はなく、ファインチューニングのフェーズでマスクを適用するだけで良い。これは、LoRAやAdapterのように新しいモジュールを挿入する手法と比べて、実装の複雑さが大幅に低い。

ハイパーパラメータの数も最小限に抑えられている。主要なハイパーパラメータは、パラメータ選択率とトークン選択率の2つのみである。論文では、これらの値の選択に関するガイドラインも提供されており、多くの場合、デフォルト値（パラメータ0.5%、トークン70%）で良好な結果が得られることが示されている。

コードの保守性という観点でも優れている。TR-PTSのコアロジックは数百行程度で実装可能であり、複雑な依存関係もない。これにより、研究者や実務者が独自の拡張や改良を加えることも容易である。

### 4.2 計算効率
TR-PTSの計算効率は、複数の段階で最適化されている。

初期化フェーズでは、FIMの計算に一定のオーバーヘッドが発生する。しかし、これは一度だけ実行すれば良く、小さなデータサブセット（通常は数百サンプル）で十分な精度が得られる。実験では、この初期化に要する時間は、単一のGPUで数分程度であった。

ファインチューニング中の効率は特に優れている。更新するパラメータ数が0.5%未満に削減されるため、勾配計算とパラメータ更新の両方が大幅に高速化される。実測値では、全パラメータファインチューニングと比較して、エポックあたりの訓練時間が約85%削減された。

推論時の効率向上も顕著である。トークン数の削減により、self-attentionの計算量がO(N²)からO((ρN)²)に削減される（ρ<1）。ρ=0.7の場合、理論的には計算量が51%削減される。実際の推論時間も、14msという高速性を達成しており、リアルタイムアプリケーションにも適用可能である。

メモリ効率の面でも大きな利点がある。パラメータの大部分が凍結されるため、勾配を保存する必要がなく、メモリ使用量が大幅に削減される。これにより、より大きなバッチサイズの使用や、リソース制約のある環境での展開が可能となる。

さらに、TR-PTSは並列化にも適している。パラメータとトークンの選択は層ごとに独立して実行できるため、複数のGPUを使用した効率的な並列処理が可能である。

### 4.3 応用可能性
TR-PTSの応用範囲は、視覚タスクを超えて広がる可能性を持っている。

直接的な応用として、産業界で一般的な視覚タスクへの適用が挙げられる。品質検査、医療画像診断、自動運転、セキュリティ監視など、高精度と高効率が同時に要求される分野で特に有用である。例えば、エッジデバイスでの展開が必要な場合、TR-PTSの低計算コストは決定的な優位性となる。

マルチタスク学習への拡張も有望である。各タスクに対して異なるパラメータセットを選択できるため、単一のモデルで複数のタスクを効率的に扱うことが可能である。これは、リソース制約のある環境で複数の機能を提供する必要があるアプリケーションに最適である。

他のモダリティへの適用も考えられる。論文では視覚タスクに焦点を当てているが、TR-PTSの基本原理は言語モデルや音声認識モデルにも適用可能である。特に、Transformerアーキテクチャを使用するモデルであれば、最小限の修正で適用できる。

継続学習のシナリオでも有用である。新しいタスクを学習する際、既存のタスクに関連するパラメータを保護しながら、新しいパラメータセットを選択的に更新できる。これにより、破滅的忘却を緩和しつつ、効率的な知識の蓄積が可能となる。

実時間適応の可能性も興味深い。FIMの計算は比較的軽量であるため、オンラインでタスクの特性が変化する環境でも、動的にパラメータとトークンの選択を更新することが可能である。これは、環境が変化する実世界のアプリケーションにとって重要な特性である。

## 5. まとめと所感
### 5.1 論文の意義
TR-PTSは、大規模モデルの効率的ファインチューニングという現代的な課題に対して、理論的に裏付けられた実用的な解決策を提供した点で高く評価できる。

最も重要な貢献は、「タスク適応性」という新しいパラダイムの確立である。従来のPEFT手法が画一的なアプローチを取っていたのに対し、TR-PTSは各タスクの特性を分析し、それに最適化された構成を動的に決定する。これは、「one-size-fits-all」から「tailored-to-task」への重要なパラダイムシフトを示している。

パラメータとトークンの相関という発見も、理論的に興味深い。この洞察は、ニューラルネットワークの内部表現がどのように構造化されているかについての理解を深める。タスクに関連する情報が、パラメータとトークンの両方の次元で局在化されているという発見は、より効率的なアーキテクチャ設計への道を開く。

実用面での意義も大きい。わずか0.34%のパラメータで10%以上の性能向上を達成したという結果は、産業応用において革命的である。特に、推論時の追加コストがないという特性は、大規模展開を考える企業にとって極めて魅力的である。

方法論的にも、Fisher情報行列を実用的なツールとして活用した点は評価に値する。理論的な概念を実践的な手法に落とし込み、その有効性を実証したことで、他の研究者にも新しい方向性を示している。

### 5.2 今後の展望
TR-PTSの研究は、多くの将来的な発展可能性を示唆している。

技術的な拡張として、動的なパラメータ・トークン選択の探求が挙げられる。現在の手法では選択が固定されているが、入力やタスクの進行に応じて動的に調整することで、さらなる効率化が期待できる。また、選択の粒度をより細かくすることで、例えばアテンションヘッドレベルでの選択も可能かもしれない。

理論的な深化も重要である。なぜ特定のパラメータがタスクに重要なのか、どのような特徴がトークンの重要性を決定するのか、これらの問いに対するより深い理解が必要である。説明可能AIの観点からも、選択の根拠を人間が理解できる形で提示することは価値がある。

他のアーキテクチャへの適用も興味深い研究方向である。最近のMamba、RWKV、Hyenaなどの新しいアーキテクチャにも、同様の原理を適用できる可能性がある。特に、これらのアーキテクチャの効率性とTR-PTSの効率化を組み合わせることで、さらなるブレークスルーが期待できる。

より大規模なモデルへの適用も重要な課題である。現在の実験はViT-Bに限定されているが、数十億パラメータ規模のモデルでの検証が必要である。スケーリング則がどのように変化するか、選択戦略をどう調整すべきかは、実用化に向けて解決すべき問題である。

最後に、社会的インパクトの観点から、TR-PTSのような効率化技術は、AIの民主化に貢献する可能性がある。計算リソースが限られた組織や個人でも、最先端のモデルを活用できるようになることで、AI技術の恩恵がより広く共有されることが期待される。同時に、エネルギー消費の削減という環境面での貢献も無視できない。

TR-PTSは、効率性と性能の両立という難しい課題に対して、エレガントで実用的な解決策を提示した。この研究が示した方向性は、今後のAI研究において重要な指針となるだろう。