# InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency

## 基本情報
- arXiv ID: 2508.18265v1 (https://arxiv.org/abs/2508.18265)
- 著者: Weiyun Wang他45+名の共著
- 所属: Shanghai AI Laboratory (上海AI実験室)
- 投稿日: 2025年08月27日
- カテゴリ: cs.CV, cs.AI, cs.LG

## 簡単に説明すると
InternVL3.5は、マルチモーダル大規模言語モデル（MLLM）の新しいファミリーです。
推論能力・汎用性・推論効率において改善を実現しています。
主な技術革新として、2段階の強化学習手法「Cascade Reinforcement Learning」を導入しています。
また、動的な解像度選択をする「Visual Resolution Router (ViR)」も特徴です。
GPU間で視覚エンコーダーと言語モデルを分離配置する「Decoupled Vision-Language Deployment (DvD)」も採用しています。
これらにより、前バージョンのInternVL3と比較して推論性能が16.0%向上しています。
推論速度は4.05倍高速化を実現しています。
商用モデルGPT-5との性能差を3.9%まで縮めています。

関連リンクとしては以下があります。
- GitHub: https://github.com/OpenGVLab/InternVL
- HuggingFace: https://huggingface.co/OpenGVLab/InternVL3_5-241B-A28B

## 1. 研究概要
### 1.1 背景と動機
マルチモーダル大規模言語モデル（MLLM）は近年、単純なマルチモーダル理解を超えています。
テキスト関連タスク、推論タスク、エージェンティックタスクなど、より汎用的で複雑かつ現実的なタスクに焦点を当てています。
しかし、商用モデルと現在のオープンソースモデルの間には性能差が存在しています。
また、長い視覚コンテキストや高解像度理解などのマルチモーダル機能の成長は、計算コストの増大を伴います。
これは実世界のアプリケーションにおける重要なボトルネックとなっています。

既存のオープンソースの取り組みでは、強化学習（RL）手法を用いてこのギャップを埋めようとしています。
しかし、MLLMに対する安定した効果的でスケーラブルな強化学習フレームワークは依然として課題です。
さらに、マルチモーダル能力の向上は計算コストの増加を伴うため、推論効率の改善も重要な課題となっています。

### 1.2 主要な貢献
この研究では、InternVLシリーズの最新版であるInternVL3.5を導入しています。
汎用性、推論能力、効率性において改善を達成しています。

主要な貢献は以下の通りです。

第一に、Cascade Reinforcement Learning (Cascade RL)を提案しています。
これは効率的で拡張可能かつ安定した方法で推論能力を強化する新しい強化学習フレームワークです。
オフラインRL段階で安定した収束を実現し、オンラインRL段階で精密なアライメントを行う2段階プロセスです。

第二に、Visual Resolution Router (ViR)を導入しています。
これは視覚トークンの解像度を動的に調整し、性能を犠牲にすることなく推論効率を最適化する技術です。
パッチレベルでの意味的豊富さを評価し、最適な圧縮率を選択します。

第三に、Decoupled Vision-Language Deployment (DvD)を開発しています。
これは視覚エンコーダーと言語モデルを異なるGPU間で分離配置し、計算負荷を効果的にバランシングする配置戦略です。

第四に、包括的な評価とオープンソース化を実施しています。
1Bから241Bまでの様々なモデルサイズを含む密な結合モデルとMixture-of-Experts（MoE）モデルを公開しています。
全てのモデルとコードを一般公開しています。

## 2. 提案手法
### 2.1 手法の概要
InternVL3.5は前バージョンのInternVL3と比較して、3つの主要な技術革新により優れた性能と高速な推論を実現しています。

モデルアーキテクチャは従来の「ViT-MLP-LLM」パラダイムを踏襲しています。
Qwen3シリーズやGPT-OSSを言語モデルとして、InternViT-300MやInternViT-6Bを視覚エンコーダーとして初期化しています。
さらに、リソース制約のあるシナリオに適したバリアントであるInternVL3.5-Flashも提供しています。

### 2.2 技術的詳細

Cascade Reinforcement Learning (Cascade RL)について説明します。
Cascade RLは、オフラインRLとオンラインRLの利点を組み合わせた2段階のフレームワークです。

オフライン強化学習段階では、Mixed Preference Optimization（MPO）を使用しています。
これにより効率的に満足のいく性能を達成します。
MPOの損失関数は以下の通りです。
```
L_MPO = w_p * L_p + w_q * L_q + w_g * L_g
```
ここで、L_p（選好損失）、L_q（品質損失）、L_g（生成損失）はそれぞれDPO、BCO、LM損失を使用します。

オンライン強化学習段階では、GSPO（参照モデル制約なし）を採用しています。
これにより出力分布を精密に調整し、モデルの性能上限をさらに押し上げます。
GSPOは複数の生成された応答にわたって重要度サンプリングとアドバンテージ正規化を使用します。

Visual Resolution Router (ViR)について説明します。
ViRは、各画像パッチの意味的豊富さを評価して最適な圧縮率（1/4または1/16）を動的に選択するバイナリ分類器です。
各パッチは最初に1024個の視覚トークンとして表現されます。
ピクセルシャッフルモジュールを通じて256トークンに圧縮されます。
InternVL3.5-Flashでは、より高い圧縮率の追加ピクセルシャッフルモジュールにより64トークンまで圧縮可能となっています。

Visual Consistency Learning（ViCO）により訓練されます。
異なる圧縮率での出力間のKLダイバージェンスを最小化する一貫性訓練と、損失比閾値に基づく動的パーセンタイル閾値τを用いたルーター訓練をします。

Decoupled Vision-Language Deployment (DvD)について説明します。
DvDは、システムを視覚サーバーと言語サーバーに分離します。
視覚サーバーはViT、MLP、ViRコンポーネントを処理します。
言語サーバーはLLM推論のみを処理します。
視覚サーバーから言語サーバーへは、TCP/RDMA経由でBF16視覚特徴量の一方向通信をします。
3段階の非同期パイプライン設計により、視覚処理、特徴伝送、言語処理の並列実行が可能となっています。

### 2.3 新規性
InternVL3.5の新規性について説明します。

段階的な強化学習アプローチが特徴です。
従来の単一段階の強化学習と異なり、オフラインRLによる安定した基盤構築とオンラインRLによる精密調整を組み合わせています。
これにより、安定性とスケーラビリティを両立しています。
1Bから241Bまでの全モデルサイズで一貫した向上を実現しています。

パッチ単位の動的圧縮も革新的です。
既存のDynamic High Resolutionが画像の幅と高さの観点からのみパッチを分割するのに対し、ViRは意味的内容の観点からも適応性を導入しています。
これにより、性能をほぼ維持しながら視覚トークン数を50%削減できます。

分離配置による効率化も新しい取り組みです。
従来の単一GPU配置と異なり、視覚処理と言語処理を異なるGPU間で分離します。
これにより、計算並列性とハードウェア利用率を最大化しています。
この手法により、単独で最大2.01倍、ViRとの組み合わせで最大4.05倍の速度向上を実現しています。

## 3. 実験結果
### 3.1 実験設定
InternVL3.5の評価は36のベンチマークにわたって実施されています。
4つの主要なマルチモーダルタスクタイプに分類されています。

一般タスクには以下があります。
MMStar、MMVet、MMBench V1.1、MTVQA、AI2D、OCRBenchなど13のベンチマークです。

推論タスクには以下があります。
MMMU、MathVista、MathVision、MathVerse、DynaMath、WeMath、OlympiadBench、LogicVistaなど8のベンチマークです。

テキスト中心タスクには以下があります。
MATH500、AIME24、AIME25、GPQA、MMLU-Pro、GAOKAO、IFEvalなど7のベンチマークです。

エージェンティックタスクには以下があります。
SGP-Bench、ScreenSpot、ScreenSpot-v2、OSWorld-G、VSI-Bench、ERQA、SpaCE-10など8のベンチマークです。

比較対象として、オープンソースMLLMおよびGPT-5を使用しています。

### 3.2 主要な結果

全体的な性能比較について説明します。
InternVL3.5-241B-A28Bは、オープンソースMLLMの中で総合スコア74.1を達成しています。
商用モデルGPT-5の74.0と匹敵する結果を示しています。
特に一般的なマルチモーダルタスクにおいて、オープンソースモデルの中で主導的な地位を維持しています。

推論能力の改善について説明します。
MMMUでInternVL3.5-241B-A28Bが77.7スコアを達成しています。
MathVistaでは82.7スコアを達成しています。
全体的な推論改善として、全モデルサイズで平均10+ポイントの向上を達成しています。
InternVL3.5-8BはMMMUで73.4スコア（InternVL3-8Bの62.7から+10.7ポイント向上）を達成しています。

効率性の改善について説明します。
推論速度は前バージョンと比較して4.05倍の高速化を実現しています。
ViR単体では視覚トークン50%削減で性能維持率約100%を達成しています。
DvD単体では最大2.01倍の速度向上を実現しています。
リクエスト処理能力は896px解像度で2.54 req/sから8.81 req/s（3.47倍向上）となっています。

訓練効率性について説明します。
Cascade RLは2エピソードのGSPOと比較して47%少ないGPU時間（約5.8K GPU時間 vs 約11K時間）でより優れた結果を達成しています。

### 3.3 既存手法との比較

オープンソースモデルとの比較について説明します。
InternVL3.5は、最新のオープンソースMLLMであるStep-3と比較して良好な性能を示しています。
テキストタスクでInternVL3.5-30B-A3Bが+2.0ポイント、InternVL3.5-241B-A28Bが+8.4ポイントの向上を示しています。
推論タスクにおいても、全ての比較対象を上回る性能を実現しています。

商用モデルとの比較について説明します。
GPT-5との性能ギャップを以下の通り縮小しています。
一般タスクでは74.1 vs 74.0（ほぼ同等）です。
推論タスクでは67.1 vs 74.3（7.2ポイント差）です。
テキストタスクでは85.3 vs 91.3（6.0ポイント差）です。
総合では74.1 vs 74.0（3.9%の性能差まで縮小）しています。

汎用性の実証について説明します。
InternVL3.5は、GUI理解、具現化タスク、SVG理解など多様な応用分野において、強力な性能を示しています。
特に、SGP-BenchでInternVL3.5-241B-A28Bが70.7スコアを達成し、全オープンソースモデルを上回っています。

## 4. 実用性評価
### 4.1 実装の容易性
InternVL3.5は実装面において高い実用性を提供しています。

モデルの多様性と選択肢について説明します。
1Bから241Bまでの幅広いパラメータサイズのモデルを提供しています。
リソース制約に応じて最適なモデルを選択可能です。
密結合モデル（1B、2B、4B、8B、14B、38B）とMoEモデル（20B-A4B、30B-A3B、241B-A28B）の両方を提供しています。
異なる計算環境とアプリケーション要件に対応しています。

オープンソース化について説明します。
全モデルとコードがGitHubとHuggingFaceで公開されています。
研究者や開発者が容易にアクセス・活用できます。
特に、実装詳細やトレーニングレシピが詳細に文書化されているため、再現性が高いです。

既存フレームワークとの互換性について説明します。
「ViT-MLP-LLM」パラダイムを踏襲しているため、既存のマルチモーダルAIパイプラインとの統合が比較的容易です。
また、Qwen3シリーズやGPT-OSSなどの既存の言語モデルを活用しているため、実装コストが抑制されています。

### 4.2 計算効率
InternVL3.5は計算効率において顕著な改善を実現しています。

推論効率の向上について説明します。
ViRとDvDの組み合わせにより、前バージョンと比較して最大4.05倍の推論速度向上を実現しています。
特に高解像度入力において効果が顕著で、448pxでの1.19倍から1344pxでの1.97倍まで、解像度が高いほど高速化効果が増大します。

メモリ効率の最適化について説明します。
Visual Resolution Routerにより視覚トークン数を50%削減できるため、GPUメモリ使用量の削減が可能です。
これにより、より大きなバッチサイズでの処理や、リソース制約のある環境での実行が可能となります。

訓練効率の改善について説明します。
Cascade RLフレームワークにより、従来手法と比較して47%少ないGPU時間で優れた性能を達成しています。
これは、大規模モデルの訓練コスト削減に直接貢献します。

スケーラビリティについて説明します。
DvDによる分離配置により、視覚処理と言語処理を異なるGPU間で並列実行できます。
そのため、大規模な推論ワークロードに対する拡張性が向上しています。

### 4.3 応用可能性
InternVL3.5は広範囲な応用分野において高い適用可能性を示しています。

学術・研究分野での応用について説明します。
36のベンチマークにわたる包括的な評価により、数学的推論、視覚的理解、テキスト処理、マルチモーダル統合など多様な研究課題に対応可能です。
特に、MMMU（77.7）やMathVista（82.7）での高スコアは、複雑な学術的タスクへの適用可能性を示しています。

産業応用での活用について説明します。
GUI操作、文書理解（OCRBench: 90.7）、具現化AIなどの実用的タスクでの高性能により、産業分野への応用が期待されます。

多言語・多文化対応について説明します。
multilingual benchmarks（MTVQA等）での良好な性能により、グローバルなアプリケーション展開が可能です。

スケーラブルな配置について説明します。
1Bから241Bまでの多様なモデルサイズにより、エッジデバイスから大規模サーバーまで、異なる計算環境への配置が可能です。
特に、ViRやDvDによる効率化技術により、リソース制約のある環境でも高性能な推論が実現できます。

リアルタイム処理での活用について説明します。
4.05倍の推論高速化により、リアルタイムのマルチモーダル対話システム、ライブ画像解析、インタラクティブなAIアプリケーションなどの時間的制約の厳しい用途への適用が可能です。

## 5. まとめと所感
### 5.1 論文の意義
InternVL3.5は、オープンソースマルチモーダルAI分野において画期的な進歩を示しています。
本研究の重要な意義は、商用モデルGPT-5との性能差を3.9%まで縮めた点にあります。
これまでオープンソースと商用モデル間には性能ギャップが存在していましたが、InternVL3.5はこのギャップを縮小し、オープンソースAIの可能性を実証しています。

技術的革新性について説明します。
Cascade Reinforcement Learningは、従来の一段階での強化学習の限界を克服します。
安定性と効率性を両立させる新しいパラダイムを提示しています。
オフライン・オンライン段階の組み合わせにより、1Bから241Bまでの全スケールで一貫した改善を実現している点は、スケーラブルなAI訓練手法として高く評価できます。

実用性の高い効率化技術について説明します。
Visual Resolution RouterとDecoupled Vision-Language Deploymentは、性能を犠牲にすることなく効率化を実現しています。
特に、視覚トークン50%削減での性能維持は、実用的なマルチモーダルシステムの構築において極めて重要な技術的貢献です。

包括的な評価の価値について説明します。
36のベンチマークにわたる広範囲な評価は、マルチモーダルAIの能力を多角的に検証しています。
学術界および産業界にとって貴重な参考資料となっています。
特に、推論タスク、テキストタスク、エージェンティックタスクでの高い性能は、AGI（汎用人工知能）に向けた重要なマイルストーンを示しています。

オープンサイエンスへの貢献について説明します。
全モデルとコードの公開により、研究コミュニティ全体の発展に貢献しています。
これにより、他の研究者がこの成果を基盤として更なる改善や応用研究を進めることが可能となります。

### 5.2 今後の展望

短期的な改善可能性について説明します。
現在のGPT-5との性能差は、Cascade RLの更なる最適化により改善される可能性が高いです。
特に、HallusionBenchでの課題は、幻覚抑制技術の導入により解決できると考えられます。

効率化技術の発展について説明します。
ViRとDvDの成功は、更なる効率化技術の開発への道筋を示しています。
動的な解像度選択をより精密化したり、モデルの異なるコンポーネントをより細かく分離配置することで、さらなる効率向上が期待されます。
特に、エッジデバイスでの実行を想定した軽量化技術の発展が重要となります。

応用分野の拡大について説明します。
現在の高い汎用性を基盤として、より専門的な分野への特化版の開発が期待されます。
具体的には医療画像解析、法的文書処理、科学研究の支援等があります。
特に、具現化AIやGUIタスクでの高性能は、ロボティクスや自動化システムでの実用化を加速させるでしょう。

マルチモーダル理解の深化について説明します。
現在の成果を基盤として、より複雑なマルチモーダル推論（複数の画像・動画・音声を統合した理解）や、時系列データの長期記憶と理解への拡張が考えられます。
これにより、より人間に近い総合的な知能システムの実現に近づくことができます。

商用化と社会実装について説明します。
技術的成熟度の高さから、近い将来に商用サービスや製品への統合が活発化すると予想されます。
教育、医療、エンターテインメント、産業自動化など、様々な分野でのマルチモーダルAIアプリケーションの普及が期待されます。

潜在的な課題について説明します。
一方で、これほど高性能なモデルの普及は、誤情報生成、プライバシー侵害、労働市場への影響など、社会的課題も生じさせる可能性があります。
今後は技術発展と並行して、責任あるAI開発と規制フレームワークの構築が重要となります。